<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>在 Kubernetes 上搭建 EFK 日志收集系统</title>
    <url>/2019/11/06/%E5%9C%A8Kubernetes%E4%B8%8A%E6%90%AD%E5%BB%BAEFK%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<p>Kubernetes 中比较流行的日志收集解决方案是 <code>Elasticsearch</code>、<code>Fluentd</code> 和 <code>Kibana</code>（EFK）技术栈，也是官方现在比较推荐的一种方案。</p><p><code>Elasticsearch</code> 是一个实时的、分布式的可扩展的搜索引擎，允许进行全文、结构化搜索，它通常用于索引和搜索大量日志数据，也可用于搜索许多不同类型的文档。</p><a id="more"></a>

<p>Elasticsearch 通常与 <code>Kibana</code> 一起部署，Kibana 是 Elasticsearch 的一个功能强大的数据可视化 Dashboard，Kibana 允许你通过 web 界面来浏览 Elasticsearch 日志数据。</p>
<p><code>Fluentd</code>是一个流行的开源数据收集器，我们将在 Kubernetes 集群节点上安装 Fluentd，通过获取容器日志文件、过滤和转换日志数据，然后将数据传递到 Elasticsearch 集群，在该集群中对其进行索引和存储。</p>
<p>我们先来配置启动一个可扩展的 Elasticsearch 集群，然后在 Kubernetes 集群中创建一个 Kibana 应用，最后通过 DaemonSet 来运行 Fluentd，以便它在每个 Kubernetes 工作节点上都可以运行一个 Pod。</p>
<p><img src="/2019/11/06/%E5%9C%A8Kubernetes%E4%B8%8A%E6%90%AD%E5%BB%BAEFK%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%E7%B3%BB%E7%BB%9F/20180511161547422" alt="img"></p>
<h2 id="部署nfs-client"><a href="#部署nfs-client" class="headerlink" title="部署nfs-client"></a>部署nfs-client</h2><h3 id="创建-Provisioner"><a href="#创建-Provisioner" class="headerlink" title="创建 Provisioner"></a>创建 Provisioner</h3><p>要使用 StorageClass，我们就得安装对应的自动配置程序，比如我们这里存储后端使用的是 nfs，那么我们就需要使用到一个 nfs-client 的自动配置程序，我们也叫它 Provisioner，这个程序使用我们已经配置好的 nfs 服务器，来自动创建持久卷，也就是自动帮我们创建 PV。</p>
<ul>
<li>自动创建的 PV 以<code>${namespace}-${pvcName}-${pvName}</code>这样的命名格式创建在 NFS 服务器上的共享数据目录中</li>
<li>而当这个 PV 被回收后会以<code>archieved-${namespace}-${pvcName}-${pvName}</code>这样的命名格式存在 NFS 服务器上。</li>
</ul>
<p>当然在部署<code>nfs-client</code>之前，我们需要先成功安装上 nfs 服务器，前面的课程中我们已经过了，服务地址是<strong>10.151.30.57</strong>，共享数据目录是<strong>/data/k8s/</strong>，然后接下来我们部署 nfs-client 即可，我们也可以直接参考<a href="https://github.com/kubernetes-incubator/external-storage/tree/master/nfs-client" target="_blank" rel="noopener">nfs-client 的文档</a>，进行安装即可。</p>
<p><strong>第一步</strong>：配置 Deployment，将里面的对应的参数替换成我们自己的 nfs 配置（nfs-client.yaml）</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  strategy:</span></span><br><span class="line"><span class="attr">    type:</span> <span class="string">Recreate</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      serviceAccountName:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line"><span class="attr">          image:</span> <span class="string">quay.io/external_storage/nfs-client-provisioner:latest</span></span><br><span class="line"><span class="attr">          volumeMounts:</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">nfs-client-root</span></span><br><span class="line"><span class="attr">              mountPath:</span> <span class="string">/persistentvolumes</span></span><br><span class="line"><span class="attr">          env:</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">PROVISIONER_NAME</span></span><br><span class="line"><span class="attr">              value:</span> <span class="string">fuseim.pri/ifs</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">NFS_SERVER</span></span><br><span class="line"><span class="attr">              value:</span> <span class="number">10.151</span><span class="number">.30</span><span class="number">.57</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">NFS_PATH</span></span><br><span class="line"><span class="attr">              value:</span> <span class="string">/data/k8s</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">nfs-client-root</span></span><br><span class="line"><span class="attr">          nfs:</span></span><br><span class="line"><span class="attr">            server:</span> <span class="number">10.151</span><span class="number">.30</span><span class="number">.57</span></span><br><span class="line"><span class="attr">            path:</span> <span class="string">/data/k8s</span></span><br></pre></td></tr></table></figure>

<p><strong>第二步</strong>：将环境变量 NFS_SERVER 和 NFS_PATH 替换，当然也包括下面的 nfs 配置，我们可以看到我们这里使用了一个名为 nfs-client-provisioner 的<code>serviceAccount</code>，所以我们也需要创建一个 sa，然后绑定上对应的权限：（nfs-client-sa.yaml）</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nfs-client-provisioner-runner</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="attr">  - apiGroups:</span> <span class="string">[""]</span></span><br><span class="line"><span class="attr">    resources:</span> <span class="string">["persistentvolumes"]</span></span><br><span class="line"><span class="attr">    verbs:</span> <span class="string">["get",</span> <span class="string">"list"</span><span class="string">,</span> <span class="string">"watch"</span><span class="string">,</span> <span class="string">"create"</span><span class="string">,</span> <span class="string">"delete"</span><span class="string">]</span></span><br><span class="line"><span class="attr">  - apiGroups:</span> <span class="string">[""]</span></span><br><span class="line"><span class="attr">    resources:</span> <span class="string">["persistentvolumeclaims"]</span></span><br><span class="line"><span class="attr">    verbs:</span> <span class="string">["get",</span> <span class="string">"list"</span><span class="string">,</span> <span class="string">"watch"</span><span class="string">,</span> <span class="string">"update"</span><span class="string">]</span></span><br><span class="line"><span class="attr">  - apiGroups:</span> <span class="string">["storage.k8s.io"]</span></span><br><span class="line"><span class="attr">    resources:</span> <span class="string">["storageclasses"]</span></span><br><span class="line"><span class="attr">    verbs:</span> <span class="string">["get",</span> <span class="string">"list"</span><span class="string">,</span> <span class="string">"watch"</span><span class="string">]</span></span><br><span class="line"><span class="attr">  - apiGroups:</span> <span class="string">[""]</span></span><br><span class="line"><span class="attr">    resources:</span> <span class="string">["events"]</span></span><br><span class="line"><span class="attr">    verbs:</span> <span class="string">["list",</span> <span class="string">"watch"</span><span class="string">,</span> <span class="string">"create"</span><span class="string">,</span> <span class="string">"update"</span><span class="string">,</span> <span class="string">"patch"</span><span class="string">]</span></span><br><span class="line"><span class="attr">  - apiGroups:</span> <span class="string">[""]</span></span><br><span class="line"><span class="attr">    resources:</span> <span class="string">["endpoints"]</span></span><br><span class="line"><span class="attr">    verbs:</span> <span class="string">["create",</span> <span class="string">"delete"</span><span class="string">,</span> <span class="string">"get"</span><span class="string">,</span> <span class="string">"list"</span><span class="string">,</span> <span class="string">"watch"</span><span class="string">,</span> <span class="string">"patch"</span><span class="string">,</span> <span class="string">"update"</span><span class="string">]</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">run-nfs-client-provisioner</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="attr">  - kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line"><span class="attr">    namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line"><span class="attr">  kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nfs-client-provisioner-runner</span></span><br><span class="line"><span class="attr">  apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure>

<p>我们这里新建的一个名为 nfs-client-provisioner 的<code>ServiceAccount</code>，然后绑定了一个名为 nfs-client-provisioner-runner 的<code>ClusterRole</code>，而该<code>ClusterRole</code>声明了一些权限，其中就包括对<code>persistentvolumes</code>的增、删、改、查等权限，所以我们可以利用该<code>ServiceAccount</code>来自动创建 PV。</p>
<p><strong>第三步</strong>：nfs-client 的 Deployment 声明完成后，我们就可以来创建一个<code>StorageClass</code>对象了：（nfs-client-class.yaml）</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">course-nfs-storage</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">fuseim.pri/ifs</span> <span class="comment"># or choose another name, must match deployment's env PROVISIONER_NAME'</span></span><br></pre></td></tr></table></figure>

<p>我们声明了一个名为 course-nfs-storage 的<code>StorageClass</code>对象，注意下面的<code>provisioner</code>对应的值一定要和上面的<code>Deployment</code>下面的 PROVISIONER_NAME 这个环境变量的值一样。</p>
<p>现在我们来创建这些资源对象吧：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl create -f nfs-client.yaml</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl create -f nfs-client-sa.yaml</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl create -f nfs-client-class.yaml</span></span><br></pre></td></tr></table></figure>

<p>创建完成后查看下资源状态：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl get pods</span><br><span class="line">NAME                                             READY     STATUS             RESTARTS   AGE</span><br><span class="line">...</span><br><span class="line">nfs-client-provisioner-7648b664bc-7f9pk          1/1       Running            0          7h</span><br><span class="line">...</span><br><span class="line">$ kubectl get storageclass</span><br><span class="line">NAME                 PROVISIONER      AGE</span><br><span class="line">course-nfs-storage   fuseim.pri/ifs   11s</span><br></pre></td></tr></table></figure>

<h3 id="新建-PVC"><a href="#新建-PVC" class="headerlink" title="新建 PVC"></a>新建 PVC</h3><p>上面把<code>StorageClass</code>资源对象创建成功了，接下来我们来通过一个示例测试下动态 PV，首先创建一个 PVC 对象：(test-pvc.yaml)</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">test-pvc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  accessModes:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">ReadWriteMany</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="attr">    requests:</span></span><br><span class="line"><span class="attr">      storage:</span> <span class="number">1</span><span class="string">Mi</span></span><br></pre></td></tr></table></figure>

<p>我们这里声明了一个<code>PVC</code>对象，采用 <code>ReadWriteMany</code> 的访问模式，请求 1Mi 的空间，但是我们可以看到上面的 PVC 文件我们没有标识出任何和 StorageClass 相关联的信息，那么如果我们现在直接创建这个 PVC 对象能够自动绑定上合适的 PV 对象吗？显然是不能的(前提是没有合适的 PV)，我们这里有两种方法可以来利用上面我们创建的 StorageClass 对象来自动帮我们创建一个合适的 PV:</p>
<ul>
<li>第一种方法：在这个<code>PVC</code>对象中添加一个声明<code>StorageClass</code>对象的标识，这里我们可以利用一个<code>annotations</code>属性来标识，如下</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">test-pvc</span></span><br><span class="line"><span class="attr">  annotations:</span></span><br><span class="line">    <span class="string">volume.beta.kubernetes.io/storage-class:</span> <span class="string">"course-nfs-storage"</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  accessModes:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">ReadWriteMany</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="attr">    requests:</span></span><br><span class="line"><span class="attr">      storage:</span> <span class="number">1</span><span class="string">Mi</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>第二种方法：我们可以设置这个 course-nfs-storage 的 StorageClass 为 Kubernetes 的默认存储后端，我们可以用<code>kubectl patch</code>命令来更新：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">$</span> <span class="string">kubectl</span> <span class="string">patch</span> <span class="string">storageclass</span> <span class="string">course-nfs-storage</span> <span class="bullet">-p</span> <span class="string">'&#123;"metadata": &#123;"annotations":&#123;"storageclass.kubernetes.io/is-default-class":"true"&#125;&#125;&#125;'</span></span><br></pre></td></tr></table></figure>

<p>上面这两种方法都是可以的，当然为了不影响系统的默认行为，我们这里还是采用第一种方法，直接创建即可：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">$</span> <span class="string">kubectl</span> <span class="string">create</span> <span class="bullet">-f</span> <span class="string">test-pvc.yaml</span></span><br><span class="line"><span class="string">persistentvolumeclaim</span> <span class="string">"test-pvc"</span> <span class="string">created</span></span><br><span class="line"><span class="string">$</span> <span class="string">kubectl</span> <span class="string">get</span> <span class="string">pvc</span></span><br><span class="line"><span class="string">NAME</span>         <span class="string">STATUS</span>    <span class="string">VOLUME</span>                                     <span class="string">CAPACITY</span>   <span class="string">ACCESS</span> <span class="string">MODES</span>   <span class="string">STORAGECLASS</span>          <span class="string">AGE</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">test-pvc</span>     <span class="string">Bound</span>     <span class="string">pvc-73b5ffd2-8b4b-11e8-b585-525400db4df7</span>   <span class="number">1</span><span class="string">Mi</span>        <span class="string">RWX</span>            <span class="string">course-nfs-storage</span>    <span class="number">2</span><span class="string">m</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>我们可以看到一个名为 test-pvc 的 PVC 对象创建成功了，状态已经是<code>Bound</code>了，是不是也产生了一个对应的<code>VOLUME</code> 对象，最重要的一栏是<code>STORAGECLASS</code>，现在是不是也有值了，就是我们刚刚创建的<code>StorageClass</code>对象 course-nfs-storage。</p>
<p>然后查看下 PV 对象呢：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pv</span></span><br><span class="line">NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                STORAGECLASS          REASON    AGE</span><br><span class="line">...</span><br><span class="line">pvc-73b5ffd2-8b4b-11e8-b585-525400db4df7   1Mi        RWX            Delete           Bound       default/test-pvc     course-nfs-storage              8m</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>可以看到是不是自动生成了一个关联的 PV 对象，访问模式是<code>RWX</code>，回收策略是 <code>Delete</code>，这个 PV 对象并不是我们手动创建的吧，这是通过我们上面的 <code>StorageClass</code> 对象自动创建的。这就是 StorageClass 的创建方法。</p>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>接下来我们还是用一个简单的示例来测试下我们上面用 StorageClass 方式声明的 PVC 对象吧：(test-pod.yaml)</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">test-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">test-pod</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line"><span class="attr">    command:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">"/bin/sh"</span></span><br><span class="line"><span class="attr">    args:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">"-c"</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">"touch /mnt/SUCCESS &amp;&amp; exit 0 || exit 1"</span></span><br><span class="line"><span class="attr">    volumeMounts:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">nfs-pvc</span></span><br><span class="line"><span class="attr">      mountPath:</span> <span class="string">"/mnt"</span></span><br><span class="line"><span class="attr">  restartPolicy:</span> <span class="string">"Never"</span></span><br><span class="line"><span class="attr">  volumes:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">nfs-pvc</span></span><br><span class="line"><span class="attr">    persistentVolumeClaim:</span></span><br><span class="line"><span class="attr">      claimName:</span> <span class="string">test-pvc</span></span><br></pre></td></tr></table></figure>

<p>上面这个 Pod 非常简单，就是用一个 <strong>busybox</strong> 容器，在 /mnt 目录下面新建一个 SUCCESS 的文件，然后把 /mnt 目录挂载到上面我们新建的 test-pvc 这个资源对象上面了，要验证很简单，只需要去查看下我们 nfs 服务器上面的共享数据目录下面是否有 SUCCESS 这个文件即可：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl create -f <span class="built_in">test</span>-pod.yaml</span></span><br><span class="line">pod "test-pod" created</span><br></pre></td></tr></table></figure>

<p>然后我们可以在 nfs 服务器的共享数据目录下面查看下数据：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> ls /data/k8s/</span></span><br><span class="line">default-test-pvc-pvc-73b5ffd2-8b4b-11e8-b585-525400db4df7</span><br></pre></td></tr></table></figure>

<p>我们可以看到下面有名字很长的文件夹，这个文件夹的命名方式是不是和我们上面的规则：<strong>${namespace}-${pvcName}-${pvName}</strong>是一样的，再看下这个文件夹下面是否有其他文件：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> ls /data/k8s/default-test-pvc-pvc-73b5ffd2-8b4b-11e8-b585-525400db4df7</span></span><br><span class="line">SUCCESS</span><br></pre></td></tr></table></figure>

<p>我们看到下面有一个 SUCCESS 的文件，是不是就证明我们上面的验证是成功的啊。</p>
<p>另外我们可以看到我们这里是手动创建的一个 PVC 对象，在实际工作中，使用 StorageClass 更多的是 StatefulSet 类型的服务，<code>StatefulSet</code>类型的服务我们也可以通过一个<code>volumeClaimTemplates</code>属性来直接使用 StorageClass，如下：(test-statefulset-nfs.yaml)</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nfs-web</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  serviceName:</span> <span class="string">"nginx"</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">nfs-web</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      terminationGracePeriodSeconds:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">        image:</span> <span class="attr">nginx:1.7.9</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">        volumeMounts:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">www</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/usr/share/nginx/html</span></span><br><span class="line"><span class="attr">  volumeClaimTemplates:</span></span><br><span class="line"><span class="attr">  - metadata:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">www</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line">        <span class="string">volume.beta.kubernetes.io/storage-class:</span> <span class="string">course-nfs-storage</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      accessModes:</span> <span class="string">[</span> <span class="string">"ReadWriteOnce"</span> <span class="string">]</span></span><br><span class="line"><span class="attr">      resources:</span></span><br><span class="line"><span class="attr">        requests:</span></span><br><span class="line"><span class="attr">          storage:</span> <span class="number">1</span><span class="string">Gi</span></span><br></pre></td></tr></table></figure>

<p>实际上 volumeClaimTemplates 下面就是一个 PVC 对象的模板，就类似于我们这里 StatefulSet 下面的 template，实际上就是一个 Pod 的模板，我们不单独创建成 PVC 对象，而用这种模板就可以动态的去创建了对象了，这种方式在 StatefulSet 类型的服务下面使用得非常多。</p>
<p>直接创建上面的对象：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl create -f <span class="built_in">test</span>-statefulset-nfs.yaml</span></span><br><span class="line">statefulset.apps "nfs-web" created</span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pods</span></span><br><span class="line">NAME                                             READY     STATUS              RESTARTS   AGE</span><br><span class="line">...</span><br><span class="line">nfs-web-0                                        1/1       Running             0          1m</span><br><span class="line">nfs-web-1                                        1/1       Running             0          1m</span><br><span class="line">nfs-web-2                                        1/1       Running             0          33s</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>创建完成后可以看到上面的3个 Pod 已经运行成功，然后查看下 PVC 对象：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pvc</span></span><br><span class="line">NAME            STATUS    VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS          AGE</span><br><span class="line">...</span><br><span class="line">www-nfs-web-0   Bound     pvc-cc36b3ce-8b50-11e8-b585-525400db4df7   1Gi        RWO            course-nfs-storage    2m</span><br><span class="line">www-nfs-web-1   Bound     pvc-d38285f9-8b50-11e8-b585-525400db4df7   1Gi        RWO            course-nfs-storage    2m</span><br><span class="line">www-nfs-web-2   Bound     pvc-e348250b-8b50-11e8-b585-525400db4df7   1Gi        RWO            course-nfs-storage    1m</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>我们可以看到是不是也生成了3个 PVC 对象，名称由模板名称 name 加上 Pod 的名称组合而成，这3个 PVC 对象也都是 绑定状态了，很显然我们查看 PV 也可以看到对应的3个 PV 对象：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pv</span></span><br><span class="line">NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                   STORAGECLASS          REASON    AGE</span><br><span class="line">...                                                        1d</span><br><span class="line">pvc-cc36b3ce-8b50-11e8-b585-525400db4df7   1Gi        RWO            Delete           Bound       default/www-nfs-web-0   course-nfs-storage              4m</span><br><span class="line">pvc-d38285f9-8b50-11e8-b585-525400db4df7   1Gi        RWO            Delete           Bound       default/www-nfs-web-1   course-nfs-storage              4m</span><br><span class="line">pvc-e348250b-8b50-11e8-b585-525400db4df7   1Gi        RWO            Delete           Bound       default/www-nfs-web-2   course-nfs-storage              4m</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>查看 nfs 服务器上面的共享数据目录：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> ls /data/k8s/</span></span><br><span class="line">...</span><br><span class="line">default-www-nfs-web-0-pvc-cc36b3ce-8b50-11e8-b585-525400db4df7</span><br><span class="line">default-www-nfs-web-1-pvc-d38285f9-8b50-11e8-b585-525400db4df7</span><br><span class="line">default-www-nfs-web-2-pvc-e348250b-8b50-11e8-b585-525400db4df7</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>是不是也有对应的3个数据目录，这就是我们的 StorageClass 的使用方法，对于 StorageClass 多用于 StatefulSet 类型的服务，在后面的课程中我们还学不断的接触到。</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="https://www.qikqiak.com/post/kubernetes-persistent-volume2/" target="_blank" rel="noopener">https://www.qikqiak.com/post/kubernetes-persistent-volume2/</a></p>
<h2 id="创建-Elasticsearch-集群"><a href="#创建-Elasticsearch-集群" class="headerlink" title="创建 Elasticsearch 集群"></a>创建 Elasticsearch 集群</h2><p>在创建 Elasticsearch 集群之前，我们先创建一个命名空间，我们将在其中安装所有日志相关的资源对象。</p>
<p>新建一个 kube-logging.yaml 文件：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">logging</span></span><br></pre></td></tr></table></figure>

<p>然后通过 kubectl 创建该资源清单，创建一个名为 logging 的 namespace：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl create -f kube-logging.yaml</span></span><br><span class="line">namespace/logging created</span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get ns</span></span><br><span class="line">NAME           STATUS    AGE</span><br><span class="line">default        Active    244d</span><br><span class="line">istio-system   Active    100d</span><br><span class="line">kube-ops       Active    179d</span><br><span class="line">kube-public    Active    244d</span><br><span class="line">kube-system    Active    244d</span><br><span class="line">logging        Active    4h</span><br><span class="line">monitoring     Active    35d</span><br></pre></td></tr></table></figure>

<p>现在创建了一个命名空间来存放我们的日志相关资源，接下来可以部署 EFK 相关组件，首先开始部署一个3节点的 Elasticsearch 集群。</p>
<p>这里我们使用3个 Elasticsearch Pod 来避免高可用下多节点集群中出现的“脑裂”问题，当一个或多个节点无法与其他节点通信时会产生“脑裂”，可能会出现几个主节点。</p>
<blockquote>
<p>了解更多 Elasticsearch 集群脑裂问题，可以查看文档<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html#split-brain" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html#split-brain</a></p>
</blockquote>
<p>一个关键点是您应该设置参数<code>discover.zen.minimum_master_nodes=N/2+1</code>，其中<code>N</code>是 Elasticsearch 集群中符合主节点的节点数，比如我们这里3个节点，意味着<code>N</code>应该设置为2。这样，如果一个节点暂时与集群断开连接，则另外两个节点可以选择一个新的主节点，并且集群可以在最后一个节点尝试重新加入时继续运行，在扩展 Elasticsearch 集群时，一定要记住这个参数。</p>
<p>首先创建一个名为 elasticsearch 的无头服务，新建文件 elasticsearch-svc.yaml，文件内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">elasticsearch</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">logging</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">elasticsearch</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">elasticsearch</span></span><br><span class="line"><span class="attr">  clusterIP:</span> <span class="string">None</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">    - port:</span> <span class="number">9200</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">rest</span></span><br><span class="line"><span class="attr">    - port:</span> <span class="number">9300</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">inter-node</span></span><br></pre></td></tr></table></figure>

<p>定义了一个名为 elasticsearch 的 Service，指定标签<code>app=elasticsearch</code>，当我们将 Elasticsearch StatefulSet 与此服务关联时，服务将返回带有标签<code>app=elasticsearch</code>的 Elasticsearch Pods 的 DNS A 记录，然后设置<code>clusterIP=None</code>，将该服务设置成无头服务。最后，我们分别定义端口9200、9300，分别用于与 REST API 交互，以及用于节点间通信。</p>
<p>使用 kubectl 直接创建上面的服务资源对象：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl create -f elasticsearch-svc.yaml</span></span><br><span class="line">service/elasticsearch created</span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get services --namespace=logging</span></span><br><span class="line">Output</span><br><span class="line">NAME            TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)             AGE</span><br><span class="line">elasticsearch   ClusterIP   None         &lt;none&gt;        9200/TCP,9300/TCP   26s</span><br></pre></td></tr></table></figure>

<p>现在我们已经为 Pod 设置了无头服务和一个稳定的域名<code>.elasticsearch.logging.svc.cluster.local</code>，接下来我们通过 StatefulSet 来创建具体的 Elasticsearch 的 Pod 应用。</p>
<p>Kubernetes StatefulSet 允许我们为 Pod 分配一个稳定的标识和持久化存储，Elasticsearch 需要稳定的存储来保证 Pod 在重新调度或者重启后的数据依然不变，所以需要使用 StatefulSet 来管理 Pod。</p>
<blockquote>
<p>要了解更多关于 StaefulSet 的信息，可以查看官网关于 StatefulSet 的相关文档：<a href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/</a>。</p>
</blockquote>
<p>新建名为 elasticsearch-statefulset.yaml 的资源清单文件，首先粘贴下面内容：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">es-cluster</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">logging</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  serviceName:</span> <span class="string">elasticsearch</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">elasticsearch</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">elasticsearch</span></span><br></pre></td></tr></table></figure>

<p>该内容中，我们定义了一个名为 es-cluster 的 StatefulSet 对象，然后定义<code>serviceName=elasticsearch</code>和前面创建的 Service 相关联，这可以确保使用以下 DNS 地址访问 StatefulSet 中的每一个 Pod：<code>es-cluster-[0,1,2].elasticsearch.logging.svc.cluster.local</code>，其中[0,1,2]对应于已分配的 Pod 序号。</p>
<p>然后指定3个副本，将 matchLabels 设置为<code>app=elasticsearch</code>，所以 Pod 的模板部分<code>.spec.template.metadata.lables</code>也必须包含<code>app=elasticsearch</code>标签。</p>
<p>然后定义 Pod 模板部分内容：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">  spec:</span></span><br><span class="line"><span class="attr">    containers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">elasticsearch</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">docker.elastic.co/elasticsearch/elasticsearch-oss:6.4.3</span></span><br><span class="line"><span class="attr">      resources:</span></span><br><span class="line"><span class="attr">        limits:</span></span><br><span class="line"><span class="attr">          cpu:</span> <span class="number">1000</span><span class="string">m</span></span><br><span class="line"><span class="attr">        requests:</span></span><br><span class="line"><span class="attr">          cpu:</span> <span class="number">100</span><span class="string">m</span></span><br><span class="line"><span class="attr">      ports:</span></span><br><span class="line"><span class="attr">      - containerPort:</span> <span class="number">9200</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">rest</span></span><br><span class="line"><span class="attr">        protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="attr">      - containerPort:</span> <span class="number">9300</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">inter-node</span></span><br><span class="line"><span class="attr">        protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="attr">      volumeMounts:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">data</span></span><br><span class="line"><span class="attr">        mountPath:</span> <span class="string">/usr/share/elasticsearch/data</span></span><br><span class="line"><span class="attr">      env:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">cluster.name</span></span><br><span class="line"><span class="attr">        value:</span> <span class="string">k8s-logs</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">node.name</span></span><br><span class="line"><span class="attr">        valueFrom:</span></span><br><span class="line"><span class="attr">          fieldRef:</span></span><br><span class="line"><span class="attr">            fieldPath:</span> <span class="string">metadata.name</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">discovery.zen.ping.unicast.hosts</span></span><br><span class="line"><span class="attr">        value:</span> <span class="string">"es-cluster-0.elasticsearch,es-cluster-1.elasticsearch,es-cluster-2.elasticsearch"</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">discovery.zen.minimum_master_nodes</span></span><br><span class="line"><span class="attr">        value:</span> <span class="string">"2"</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">ES_JAVA_OPTS</span></span><br><span class="line"><span class="attr">        value:</span> <span class="string">"-Xms512m -Xmx512m"</span></span><br></pre></td></tr></table></figure>

<p>该部分是定义 StatefulSet 中的 Pod，我们这里使用一个<code>-oss</code>后缀的镜像，该镜像是 Elasticsearch 的开源版本，如果你想使用包含<code>X-Pack</code>之类的版本，可以去掉该后缀。然后暴露了9200和9300两个端口，注意名称要和上面定义的 Service 保持一致。然后通过 volumeMount 声明了数据持久化目录，下面我们再来定义 VolumeClaims。最后就是我们在容器中设置的一些环境变量了：</p>
<ul>
<li>cluster.name：Elasticsearch 集群的名称，我们这里命名成 k8s-logs。</li>
<li>node.name：节点的名称，通过<code>metadata.name</code>来获取。这将解析为 es-cluster-[0,1,2]，取决于节点的指定顺序。</li>
<li>discovery.zen.ping.unicast.hosts：此字段用于设置在 Elasticsearch 集群中节点相互连接的发现方法。我们使用 unicastdiscovery 方式，它为我们的集群指定了一个静态主机列表。由于我们之前配置的无头服务，我们的 Pod 具有唯一的 DNS 域<code>es-cluster-[0,1,2].elasticsearch.logging.svc.cluster.local</code>，因此我们相应地设置此变量。由于都在同一个 namespace 下面，所以我们可以将其缩短为<code>es-cluster-[0,1,2].elasticsearch</code>。要了解有关 Elasticsearch 发现的更多信息，请参阅 Elasticsearch 官方文档：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery.html</a>。</li>
<li>discovery.zen.minimum_master_nodes：我们将其设置为<code>(N/2) + 1</code>，<code>N</code>是我们的群集中符合主节点的节点的数量。我们有3个 Elasticsearch 节点，因此我们将此值设置为2（向下舍入到最接近的整数）。要了解有关此参数的更多信息，请参阅官方 Elasticsearch 文档：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html#split-brain" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html#split-brain</a>。</li>
<li>ES_JAVA_OPTS：这里我们设置为<code>-Xms512m -Xmx512m</code>，告诉<code>JVM</code>使用<code>512 MB</code>的最小和最大堆。您应该根据群集的资源可用性和需求调整这些参数。要了解更多信息，请参阅设置堆大小的相关文档：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/heap-size.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/heap-size.html</a>。</li>
</ul>
<p>接下来添加关于 initContainer 的内容：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">    initContainers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">fix-permissions</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">      command:</span> <span class="string">["sh",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"chown -R 1000:1000 /usr/share/elasticsearch/data"</span><span class="string">]</span></span><br><span class="line"><span class="attr">      securityContext:</span></span><br><span class="line"><span class="attr">        privileged:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">      volumeMounts:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">data</span></span><br><span class="line"><span class="attr">        mountPath:</span> <span class="string">/usr/share/elasticsearch/data</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">increase-vm-max-map</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">      command:</span> <span class="string">["sysctl",</span> <span class="string">"-w"</span><span class="string">,</span> <span class="string">"vm.max_map_count=262144"</span><span class="string">]</span></span><br><span class="line"><span class="attr">      securityContext:</span></span><br><span class="line"><span class="attr">        privileged:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">increase-fd-ulimit</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">      command:</span> <span class="string">["sh",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"ulimit -n 65536"</span><span class="string">]</span></span><br><span class="line"><span class="attr">      securityContext:</span></span><br><span class="line"><span class="attr">        privileged:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p>这里我们定义了几个在主应用程序之前运行的 Init 容器，这些初始容器按照定义的顺序依次执行，执行完成后才会启动主应用容器。</p>
<p>第一个名为 fix-permissions 的容器用来运行 chown 命令，将 Elasticsearch 数据目录的用户和组更改为<code>1000:1000</code>（Elasticsearch 用户的 UID）。因为默认情况下，Kubernetes 用 root 用户挂载数据目录，这会使得 Elasticsearch 无法方法该数据目录，可以参考 Elasticsearch 生产中的一些默认注意事项相关文档说明：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html#_notes_for_production_use_and_defaults" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html#_notes_for_production_use_and_defaults</a>。</p>
<p>第二个名为 increase-vm-max-map 的容器用来增加操作系统对<code>mmap</code>计数的限制，默认情况下该值可能太低，导致内存不足的错误，要了解更多关于该设置的信息，可以查看 Elasticsearch 官方文档说明：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html</a>。</p>
<p>最后一个初始化容器是用来执行<code>ulimit</code>命令增加打开文件描述符的最大数量的。</p>
<blockquote>
<p>此外 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html#_notes_for_production_use_and_defaults" target="_blank" rel="noopener">Elastisearch Notes for Production Use</a> 文档还提到了由于性能原因最好禁用 swap，当然对于 Kubernetes 集群而言，最好也是禁用 swap 分区的。</p>
</blockquote>
<p>现在我们已经定义了主应用容器和它之前运行的 Init Containers 来调整一些必要的系统参数，接下来我们可以添加数据目录的持久化相关的配置，在 StatefulSet 中，使用 volumeClaimTemplates 来定义 volume 模板即可：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">  volumeClaimTemplates:</span></span><br><span class="line"><span class="attr">  - metadata:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">data</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">elasticsearch</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      accessModes:</span> <span class="string">[</span> <span class="string">"ReadWriteOnce"</span> <span class="string">]</span></span><br><span class="line"><span class="attr">      storageClassName:</span> <span class="string">es-data-db</span></span><br><span class="line"><span class="attr">      resources:</span></span><br><span class="line"><span class="attr">        requests:</span></span><br><span class="line"><span class="attr">          storage:</span> <span class="number">50</span><span class="string">Gi</span></span><br></pre></td></tr></table></figure>

<p>我们这里使用 volumeClaimTemplates 来定义持久化模板，Kubernetes 会使用它为 Pod 创建 PersistentVolume，设置访问模式为<code>ReadWriteOnce</code>，这意味着它只能被 mount 到单个节点上进行读写，然后最重要的是使用了一个名为 es-data-db 的 StorageClass 对象，所以我们需要提前创建该对象，我们这里使用的 NFS 作为存储后端，所以需要安装一个对应的 provisioner 驱动，前面关于 StorageClass 的课程中已经和大家介绍过方法，新建一个 elasticsearch-storageclass.yaml 的文件，文件内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">es-data-db</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">fuseim.pri/ifs</span>  <span class="comment"># 该值需要和 provisioner 配置的保持一致</span></span><br></pre></td></tr></table></figure>

<p>最后，我们指定了每个 PersistentVolume 的大小为 50GB，我们可以根据自己的实际需要进行调整该值。最后，完整的 Elasticsearch StatefulSet 资源清单文件内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">es-cluster</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">logging</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  serviceName:</span> <span class="string">elasticsearch</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">elasticsearch</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">elasticsearch</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">elasticsearch</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">docker.elastic.co/elasticsearch/elasticsearch-oss:6.4.3</span></span><br><span class="line"><span class="attr">        resources:</span></span><br><span class="line"><span class="attr">            limits:</span></span><br><span class="line"><span class="attr">              cpu:</span> <span class="number">1000</span><span class="string">m</span></span><br><span class="line"><span class="attr">            requests:</span></span><br><span class="line"><span class="attr">              cpu:</span> <span class="number">100</span><span class="string">m</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">9200</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">rest</span></span><br><span class="line"><span class="attr">          protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">9300</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">inter-node</span></span><br><span class="line"><span class="attr">          protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="attr">        volumeMounts:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">data</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/usr/share/elasticsearch/data</span></span><br><span class="line"><span class="attr">        env:</span></span><br><span class="line"><span class="attr">          - name:</span> <span class="string">cluster.name</span></span><br><span class="line"><span class="attr">            value:</span> <span class="string">k8s-logs</span></span><br><span class="line"><span class="attr">          - name:</span> <span class="string">node.name</span></span><br><span class="line"><span class="attr">            valueFrom:</span></span><br><span class="line"><span class="attr">              fieldRef:</span></span><br><span class="line"><span class="attr">                fieldPath:</span> <span class="string">metadata.name</span></span><br><span class="line"><span class="attr">          - name:</span> <span class="string">discovery.zen.ping.unicast.hosts</span></span><br><span class="line"><span class="attr">            value:</span> <span class="string">"es-cluster-0.elasticsearch,es-cluster-1.elasticsearch,es-cluster-2.elasticsearch"</span></span><br><span class="line"><span class="attr">          - name:</span> <span class="string">discovery.zen.minimum_master_nodes</span></span><br><span class="line"><span class="attr">            value:</span> <span class="string">"2"</span></span><br><span class="line"><span class="attr">          - name:</span> <span class="string">ES_JAVA_OPTS</span></span><br><span class="line"><span class="attr">            value:</span> <span class="string">"-Xms512m -Xmx512m"</span></span><br><span class="line"><span class="attr">      initContainers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">fix-permissions</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">        command:</span> <span class="string">["sh",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"chown -R 1000:1000 /usr/share/elasticsearch/data"</span><span class="string">]</span></span><br><span class="line"><span class="attr">        securityContext:</span></span><br><span class="line"><span class="attr">          privileged:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">        volumeMounts:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">data</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/usr/share/elasticsearch/data</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">increase-vm-max-map</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">        command:</span> <span class="string">["sysctl",</span> <span class="string">"-w"</span><span class="string">,</span> <span class="string">"vm.max_map_count=262144"</span><span class="string">]</span></span><br><span class="line"><span class="attr">        securityContext:</span></span><br><span class="line"><span class="attr">          privileged:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">increase-fd-ulimit</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">        command:</span> <span class="string">["sh",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"ulimit -n 65536"</span><span class="string">]</span></span><br><span class="line"><span class="attr">        securityContext:</span></span><br><span class="line"><span class="attr">          privileged:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  volumeClaimTemplates:</span></span><br><span class="line"><span class="attr">  - metadata:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">data</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">elasticsearch</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      accessModes:</span> <span class="string">[</span> <span class="string">"ReadWriteOnce"</span> <span class="string">]</span></span><br><span class="line"><span class="attr">      storageClassName:</span> <span class="string">es-data-db</span></span><br><span class="line"><span class="attr">      resources:</span></span><br><span class="line"><span class="attr">        requests:</span></span><br><span class="line"><span class="attr">          storage:</span> <span class="number">100</span><span class="string">Gi</span></span><br></pre></td></tr></table></figure>

<p>现在直接使用 kubectl 工具部署即可：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl create -f elasticsearch-storageclass.yaml</span></span><br><span class="line">storageclass.storage.k8s.io "es-data-db" created</span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl create -f elasticsearch-statefulset.yaml</span></span><br><span class="line">statefulset.apps/es-cluster created</span><br></pre></td></tr></table></figure>

<p>添加成功后，可以看到 logging 命名空间下面的所有的资源对象：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get sts -n logging</span></span><br><span class="line">NAME         DESIRED   CURRENT   AGE</span><br><span class="line">es-cluster   3         3         20h</span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pods -n logging</span></span><br><span class="line">NAME                      READY     STATUS    RESTARTS   AGE</span><br><span class="line">es-cluster-0              1/1       Running   0          20h</span><br><span class="line">es-cluster-1              1/1       Running   0          20h</span><br><span class="line">es-cluster-2              1/1       Running   0          20h</span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get svc -n logging</span></span><br><span class="line">NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE</span><br><span class="line">elasticsearch   ClusterIP   None             &lt;none&gt;        9200/TCP,9300/TCP   20h</span><br></pre></td></tr></table></figure>

<p>Pods 部署完成后，我们可以通过请求一个 REST API 来检查 Elasticsearch 集群是否正常运行。使用下面的命令将本地端口9200转发到 Elasticsearch 节点（如es-cluster-0）对应的端口：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl port-forward es-cluster-0 9200:9200 --namespace=logging</span></span><br><span class="line">Forwarding from 127.0.0.1:9200 -&gt; 9200</span><br><span class="line">Forwarding from [::1]:9200 -&gt; 9200</span><br></pre></td></tr></table></figure>

<p>然后，在另外的终端窗口中，执行如下请求：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> curl http://localhost:9200/_cluster/state?pretty</span></span><br></pre></td></tr></table></figure>

<p>正常来说，应该会看到类似于如下的信息：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  "cluster_name" : "k8s-logs",</span><br><span class="line">  "compressed_size_in_bytes" : 348,</span><br><span class="line">  "cluster_uuid" : "QD06dK7CQgids-GQZooNVw",</span><br><span class="line">  "version" : 3,</span><br><span class="line">  "state_uuid" : "mjNIWXAzQVuxNNOQ7xR-qg",</span><br><span class="line">  "master_node" : "IdM5B7cUQWqFgIHXBp0JDg",</span><br><span class="line">  "blocks" : &#123; &#125;,</span><br><span class="line">  "nodes" : &#123;</span><br><span class="line">    "u7DoTpMmSCixOoictzHItA" : &#123;</span><br><span class="line">      "name" : "es-cluster-1",</span><br><span class="line">      "ephemeral_id" : "ZlBflnXKRMC4RvEACHIVdg",</span><br><span class="line">      "transport_address" : "10.244.4.191:9300",</span><br><span class="line">      "attributes" : &#123; &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    "IdM5B7cUQWqFgIHXBp0JDg" : &#123;</span><br><span class="line">      "name" : "es-cluster-0",</span><br><span class="line">      "ephemeral_id" : "JTk1FDdFQuWbSFAtBxdxAQ",</span><br><span class="line">      "transport_address" : "10.244.2.215:9300",</span><br><span class="line">      "attributes" : &#123; &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    "R8E7xcSUSbGbgrhAdyAKmQ" : &#123;</span><br><span class="line">      "name" : "es-cluster-2",</span><br><span class="line">      "ephemeral_id" : "9wv6ke71Qqy9vk2LgJTqaA",</span><br><span class="line">      "transport_address" : "10.244.40.4:9300",</span><br><span class="line">      "attributes" : &#123; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>看到上面的信息就表明我们名为 k8s-logs 的 Elasticsearch 集群成功创建了3个节点：es-cluster-0，es-cluster-1，和es-cluster-2，当前主节点是 es-cluster-0。</p>
<h2 id="创建-Kibana-服务"><a href="#创建-Kibana-服务" class="headerlink" title="创建 Kibana 服务"></a>创建 Kibana 服务</h2><p>Elasticsearch 集群启动成功了，接下来我们可以来部署 Kibana 服务，新建一个名为 kibana.yaml 的文件，对应的文件内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">kibana</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">logging</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">kibana</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">  - port:</span> <span class="number">5601</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">NodePort</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">kibana</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">kibana</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">logging</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">kibana</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">kibana</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">kibana</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">kibana</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">docker.elastic.co/kibana/kibana-oss:6.4.3</span></span><br><span class="line"><span class="attr">        resources:</span></span><br><span class="line"><span class="attr">          limits:</span></span><br><span class="line"><span class="attr">            cpu:</span> <span class="number">1000</span><span class="string">m</span></span><br><span class="line"><span class="attr">          requests:</span></span><br><span class="line"><span class="attr">            cpu:</span> <span class="number">100</span><span class="string">m</span></span><br><span class="line"><span class="attr">        env:</span></span><br><span class="line"><span class="attr">          - name:</span> <span class="string">ELASTICSEARCH_URL</span></span><br><span class="line"><span class="attr">            value:</span> <span class="attr">http://elasticsearch:9200</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">5601</span></span><br></pre></td></tr></table></figure>

<p>上面我们定义了两个资源对象，一个 Service 和 Deployment，为了测试方便，我们将 Service 设置为了 NodePort 类型，Kibana Pod 中配置都比较简单，唯一需要注意的是我们使用 ELASTICSEARCH_URL 这个环境变量来设置Elasticsearch 集群的端点和端口，直接使用 Kubernetes DNS 即可，此端点对应服务名称为 elasticsearch，由于是一个 headless service，所以该域将解析为3个 Elasticsearch Pod 的 IP 地址列表。</p>
<p>配置完成后，直接使用 kubectl 工具创建：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl create -f kibana.yaml</span></span><br><span class="line">service/kibana created</span><br><span class="line">deployment.apps/kibana created</span><br></pre></td></tr></table></figure>

<p>创建完成后，可以查看 Kibana Pod 的运行状态：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pods --namespace=logging</span></span><br><span class="line">NAME                      READY     STATUS    RESTARTS   AGE</span><br><span class="line">es-cluster-0              1/1       Running   0          20h</span><br><span class="line">es-cluster-1              1/1       Running   0          20h</span><br><span class="line">es-cluster-2              1/1       Running   0          20h</span><br><span class="line">kibana-7558d4dc4d-5mqdz   1/1       Running   0          20h</span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get svc --namespace=logging</span></span><br><span class="line">NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE</span><br><span class="line">elasticsearch   ClusterIP   None             &lt;none&gt;        9200/TCP,9300/TCP   20h</span><br><span class="line">kibana          NodePort    10.105.208.253   &lt;none&gt;        5601:31816/TCP      20h</span><br></pre></td></tr></table></figure>

<p>如果 Pod 已经是 Running 状态了，证明应用已经部署成功了，然后可以通过 NodePort 来访问 Kibana 这个服务，在浏览器中打开<code>http://&lt;任意节点IP&gt;:31816</code>即可，如果看到如下欢迎界面证明 Kibana 已经成功部署到了 Kubernetes集群之中。</p>
<p><img src="/2019/11/06/%E5%9C%A8Kubernetes%E4%B8%8A%E6%90%AD%E5%BB%BAEFK%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%E7%B3%BB%E7%BB%9F/yBp0Hl.jpg" alt="kibana welcome">kibana welcome</p>
<h2 id="部署-Fluentd"><a href="#部署-Fluentd" class="headerlink" title="部署 Fluentd"></a>部署 Fluentd</h2><p><code>Fluentd</code> 是一个高效的日志聚合器，是用 Ruby 编写的，并且可以很好地扩展。对于大部分企业来说，Fluentd 足够高效并且消耗的资源相对较少，另外一个工具<code>Fluent-bit</code>更轻量级，占用资源更少，但是插件相对 Fluentd 来说不够丰富，所以整体来说，Fluentd 更加成熟，使用更加广泛，所以我们这里也同样使用 Fluentd 来作为日志收集工具。</p>
<h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><p>Fluentd 通过一组给定的数据源抓取日志数据，处理后（转换成结构化的数据格式）将它们转发给其他服务，比如 Elasticsearch、对象存储等等。Fluentd 支持超过300个日志存储和分析服务，所以在这方面是非常灵活的。主要运行步骤如下：</p>
<ul>
<li>首先 Fluentd 从多个日志源获取数据</li>
<li>结构化并且标记这些数据</li>
<li>然后根据匹配的标签将数据发送到多个目标服务去</li>
</ul>
<p><img src="/2019/11/06/%E5%9C%A8Kubernetes%E4%B8%8A%E6%90%AD%E5%BB%BAEFK%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%E7%B3%BB%E7%BB%9F/lfDrcH.jpg" alt="fluentd 架构">fluentd 架构</p>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>一般来说我们是通过一个配置文件来告诉 Fluentd 如何采集、处理数据的，下面简单和大家介绍下 Fluentd 的配置方法。</p>
<h4 id="日志源配置"><a href="#日志源配置" class="headerlink" title="日志源配置"></a>日志源配置</h4><p>比如我们这里为了收集 Kubernetes 节点上的所有容器日志，就需要做如下的日志源配置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;source&gt;</span><br><span class="line"></span><br><span class="line">@id fluentd-containers.log</span><br><span class="line"></span><br><span class="line">@type tail</span><br><span class="line"></span><br><span class="line">path /var/log/containers/*.log</span><br><span class="line"></span><br><span class="line">pos_file /var/log/fluentd-containers.log.pos</span><br><span class="line"></span><br><span class="line">time_format %Y-%m-%dT%H:%M:%S.%NZ</span><br><span class="line"></span><br><span class="line">tag raw.kubernetes.*</span><br><span class="line"></span><br><span class="line">format json</span><br><span class="line"></span><br><span class="line">read_from_head true</span><br><span class="line"></span><br><span class="line">&lt;/source&gt;</span><br></pre></td></tr></table></figure>

<p>上面配置部分参数说明如下：</p>
<ul>
<li>id：表示引用该日志源的唯一标识符，该标识可用于进一步过滤和路由结构化日志数据</li>
<li>type：Fluentd 内置的指令，<code>tail</code>表示 Fluentd 从上次读取的位置通过 tail 不断获取数据，另外一个是<code>http</code>表示通过一个 GET 请求来收集数据。</li>
<li>path：<code>tail</code>类型下的特定参数，告诉 Fluentd 采集<code>/var/log/containers</code>目录下的所有日志，这是 docker 在 Kubernetes 节点上用来存储运行容器 stdout 输出日志数据的目录。</li>
<li>pos_file：检查点，如果 Fluentd 程序重新启动了，它将使用此文件中的位置来恢复日志数据收集。</li>
<li>tag：用来将日志源与目标或者过滤器匹配的自定义字符串，Fluentd 匹配源/目标标签来路由日志数据。</li>
</ul>
<h4 id="路由配置"><a href="#路由配置" class="headerlink" title="路由配置"></a>路由配置</h4><p>上面是日志源的配置，接下来看看如何将日志数据发送到 Elasticsearch：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;match **&gt;</span><br><span class="line"></span><br><span class="line">@id elasticsearch</span><br><span class="line"></span><br><span class="line">@type elasticsearch</span><br><span class="line"></span><br><span class="line">@log_level info</span><br><span class="line"></span><br><span class="line">include_tag_key true</span><br><span class="line"></span><br><span class="line">type_name fluentd</span><br><span class="line"></span><br><span class="line">host &quot;#&#123;ENV[&apos;OUTPUT_HOST&apos;]&#125;&quot;</span><br><span class="line"></span><br><span class="line">port &quot;#&#123;ENV[&apos;OUTPUT_PORT&apos;]&#125;&quot;</span><br><span class="line"></span><br><span class="line">logstash_format true</span><br><span class="line"></span><br><span class="line">&lt;buffer&gt;</span><br><span class="line"></span><br><span class="line">@type file</span><br><span class="line"></span><br><span class="line">path /var/log/fluentd-buffers/kubernetes.system.buffer</span><br><span class="line"></span><br><span class="line">flush_mode interval</span><br><span class="line"></span><br><span class="line">retry_type exponential_backoff</span><br><span class="line"></span><br><span class="line">flush_thread_count 2</span><br><span class="line"></span><br><span class="line">flush_interval 5s</span><br><span class="line"></span><br><span class="line">retry_forever</span><br><span class="line"></span><br><span class="line">retry_max_interval 30</span><br><span class="line"></span><br><span class="line">chunk_limit_size &quot;#&#123;ENV[&apos;OUTPUT_BUFFER_CHUNK_LIMIT&apos;]&#125;&quot;</span><br><span class="line"></span><br><span class="line">queue_limit_length &quot;#&#123;ENV[&apos;OUTPUT_BUFFER_QUEUE_LIMIT&apos;]&#125;&quot;</span><br><span class="line"></span><br><span class="line">overflow_action block</span><br><span class="line"></span><br><span class="line">&lt;/buffer&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>match：标识一个目标标签，后面是一个匹配日志源的正则表达式，我们这里想要捕获所有的日志并将它们发送给 Elasticsearch，所以需要配置成<code>**</code>。</li>
<li>id：目标的一个唯一标识符。</li>
<li>type：支持的输出插件标识符，我们这里要输出到 Elasticsearch，所以配置成 elasticsearch，这是 Fluentd 的一个内置插件。</li>
<li>log_level：指定要捕获的日志级别，我们这里配置成<code>info</code>，表示任何该级别或者该级别以上（INFO、WARNING、ERROR）的日志都将被路由到 Elsasticsearch。</li>
<li>host/port：定义 Elasticsearch 的地址，也可以配置认证信息，我们的 Elasticsearch 不需要认证，所以这里直接指定 host 和 port 即可。</li>
<li>logstash_format：Elasticsearch 服务对日志数据构建反向索引进行搜索，将 logstash_format 设置为<code>true</code>，Fluentd 将会以 logstash 格式来转发结构化的日志数据。</li>
<li>Buffer： Fluentd 允许在目标不可用时进行缓存，比如，如果网络出现故障或者 Elasticsearch 不可用的时候。缓冲区配置也有助于降低磁盘的 IO。</li>
</ul>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>要收集 Kubernetes 集群的日志，直接用 DasemonSet 控制器来部署 Fluentd 应用，这样，它就可以从 Kubernetes 节点上采集日志，确保在集群中的每个节点上始终运行一个 Fluentd 容器。当然可以直接使用 Helm 来进行一键安装，为了能够了解更多实现细节，我们这里还是采用手动方法来进行安装。</p>
<p>首先，我们通过 ConfigMap 对象来指定 Fluentd 配置文件，新建 fluentd-configmap.yaml 文件，文件内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">fluentd-config</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">logging</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line">    <span class="string">addonmanager.kubernetes.io/mode:</span> <span class="string">Reconcile</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="string">system.conf:</span> <span class="string">|-</span></span><br><span class="line">    <span class="string">&lt;system&gt;</span></span><br><span class="line">      <span class="string">root_dir</span> <span class="string">/tmp/fluentd-buffers/</span></span><br><span class="line">    <span class="string">&lt;/system&gt;</span></span><br><span class="line">  <span class="string">containers.input.conf:</span> <span class="string">|-</span></span><br><span class="line">    <span class="string">&lt;source&gt;</span></span><br><span class="line">      <span class="string">@id</span> <span class="string">fluentd-containers.log</span></span><br><span class="line">      <span class="string">@type</span> <span class="string">tail</span></span><br><span class="line">      <span class="string">path</span> <span class="string">/var/log/containers/*.log</span></span><br><span class="line">      <span class="string">pos_file</span> <span class="string">/var/log/es-containers.log.pos</span></span><br><span class="line">      <span class="string">time_format</span> <span class="string">%Y-%m-%dT%H:%M:%S.%NZ</span></span><br><span class="line">      <span class="string">localtime</span></span><br><span class="line">      <span class="string">tag</span> <span class="string">raw.kubernetes.*</span></span><br><span class="line">      <span class="string">format</span> <span class="string">json</span></span><br><span class="line">      <span class="string">read_from_head</span> <span class="literal">true</span></span><br><span class="line">    <span class="string">&lt;/source&gt;</span></span><br><span class="line">    <span class="comment"># Detect exceptions in the log output and forward them as one log entry.</span></span><br><span class="line">    <span class="string">&lt;match</span> <span class="string">raw.kubernetes.**&gt;</span></span><br><span class="line">      <span class="string">@id</span> <span class="string">raw.kubernetes</span></span><br><span class="line">      <span class="string">@type</span> <span class="string">detect_exceptions</span></span><br><span class="line">      <span class="string">remove_tag_prefix</span> <span class="string">raw</span></span><br><span class="line">      <span class="string">message</span> <span class="string">log</span></span><br><span class="line">      <span class="string">stream</span> <span class="string">stream</span></span><br><span class="line">      <span class="string">multiline_flush_interval</span> <span class="number">5</span></span><br><span class="line">      <span class="string">max_bytes</span> <span class="number">500000</span></span><br><span class="line">      <span class="string">max_lines</span> <span class="number">1000</span></span><br><span class="line">    <span class="string">&lt;/match&gt;</span></span><br><span class="line">  <span class="string">system.input.conf:</span> <span class="string">|-</span></span><br><span class="line">    <span class="comment"># Logs from systemd-journal for interesting services.</span></span><br><span class="line">    <span class="string">&lt;source&gt;</span></span><br><span class="line">      <span class="string">@id</span> <span class="string">journald-docker</span></span><br><span class="line">      <span class="string">@type</span> <span class="string">systemd</span></span><br><span class="line">      <span class="string">filters</span> <span class="string">[&#123;</span> <span class="string">"_SYSTEMD_UNIT"</span><span class="string">:</span> <span class="string">"docker.service"</span> <span class="string">&#125;]</span></span><br><span class="line">      <span class="string">&lt;storage&gt;</span></span><br><span class="line">        <span class="string">@type</span> <span class="string">local</span></span><br><span class="line">        <span class="string">persistent</span> <span class="literal">true</span></span><br><span class="line">      <span class="string">&lt;/storage&gt;</span></span><br><span class="line">      <span class="string">read_from_head</span> <span class="literal">true</span></span><br><span class="line">      <span class="string">tag</span> <span class="string">docker</span></span><br><span class="line">    <span class="string">&lt;/source&gt;</span></span><br><span class="line">    <span class="string">&lt;source&gt;</span></span><br><span class="line">      <span class="string">@id</span> <span class="string">journald-kubelet</span></span><br><span class="line">      <span class="string">@type</span> <span class="string">systemd</span></span><br><span class="line">      <span class="string">filters</span> <span class="string">[&#123;</span> <span class="string">"_SYSTEMD_UNIT"</span><span class="string">:</span> <span class="string">"kubelet.service"</span> <span class="string">&#125;]</span></span><br><span class="line">      <span class="string">&lt;storage&gt;</span></span><br><span class="line">        <span class="string">@type</span> <span class="string">local</span></span><br><span class="line">        <span class="string">persistent</span> <span class="literal">true</span></span><br><span class="line">      <span class="string">&lt;/storage&gt;</span></span><br><span class="line">      <span class="string">read_from_head</span> <span class="literal">true</span></span><br><span class="line">      <span class="string">tag</span> <span class="string">kubelet</span></span><br><span class="line">    <span class="string">&lt;/source&gt;</span></span><br><span class="line">  <span class="string">forward.input.conf:</span> <span class="string">|-</span></span><br><span class="line">    <span class="comment"># Takes the messages sent over TCP</span></span><br><span class="line">    <span class="string">&lt;source&gt;</span></span><br><span class="line">      <span class="string">@type</span> <span class="string">forward</span></span><br><span class="line">    <span class="string">&lt;/source&gt;</span></span><br><span class="line">  <span class="string">output.conf:</span> <span class="string">|-</span></span><br><span class="line">    <span class="comment"># Enriches records with Kubernetes metadata</span></span><br><span class="line">    <span class="string">&lt;filter</span> <span class="string">kubernetes.**&gt;</span></span><br><span class="line">      <span class="string">@type</span> <span class="string">kubernetes_metadata</span></span><br><span class="line">    <span class="string">&lt;/filter&gt;</span></span><br><span class="line">    <span class="string">&lt;match</span> <span class="string">**&gt;</span></span><br><span class="line">      <span class="string">@id</span> <span class="string">elasticsearch</span></span><br><span class="line">      <span class="string">@type</span> <span class="string">elasticsearch</span></span><br><span class="line">      <span class="string">@log_level</span> <span class="string">info</span></span><br><span class="line">      <span class="string">include_tag_key</span> <span class="literal">true</span></span><br><span class="line">      <span class="string">host</span> <span class="string">elasticsearch</span></span><br><span class="line">      <span class="string">port</span> <span class="number">9200</span></span><br><span class="line">      <span class="string">logstash_format</span> <span class="literal">true</span></span><br><span class="line">      <span class="string">request_timeout</span>    <span class="number">30</span><span class="string">s</span></span><br><span class="line">      <span class="string">&lt;buffer&gt;</span></span><br><span class="line">        <span class="string">@type</span> <span class="string">file</span></span><br><span class="line">        <span class="string">path</span> <span class="string">/var/log/fluentd-buffers/kubernetes.system.buffer</span></span><br><span class="line">        <span class="string">flush_mode</span> <span class="string">interval</span></span><br><span class="line">        <span class="string">retry_type</span> <span class="string">exponential_backoff</span></span><br><span class="line">        <span class="string">flush_thread_count</span> <span class="number">2</span></span><br><span class="line">        <span class="string">flush_interval</span> <span class="number">5</span><span class="string">s</span></span><br><span class="line">        <span class="string">retry_forever</span></span><br><span class="line">        <span class="string">retry_max_interval</span> <span class="number">30</span></span><br><span class="line">        <span class="string">chunk_limit_size</span> <span class="number">2</span><span class="string">M</span></span><br><span class="line">        <span class="string">queue_limit_length</span> <span class="number">8</span></span><br><span class="line">        <span class="string">overflow_action</span> <span class="string">block</span></span><br><span class="line">      <span class="string">&lt;/buffer&gt;</span></span><br><span class="line">    <span class="string">&lt;/match&gt;</span></span><br></pre></td></tr></table></figure>

<p>上面配置文件中我们配置了 docker 容器日志目录以及 docker、kubelet 应用的日志的收集，收集到数据经过处理后发送到 elasticsearch:9200 服务。</p>
<p>然后新建一个 fluentd-daemonset.yaml 的文件，文件内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">fluentd-es</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">logging</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">fluentd-es</span></span><br><span class="line">    <span class="string">kubernetes.io/cluster-service:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="string">addonmanager.kubernetes.io/mode:</span> <span class="string">Reconcile</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">fluentd-es</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">fluentd-es</span></span><br><span class="line">    <span class="string">kubernetes.io/cluster-service:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="string">addonmanager.kubernetes.io/mode:</span> <span class="string">Reconcile</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="attr">- apiGroups:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">""</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">"namespaces"</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">"pods"</span></span><br><span class="line"><span class="attr">  verbs:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">"get"</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">"watch"</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">"list"</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">fluentd-es</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">fluentd-es</span></span><br><span class="line">    <span class="string">kubernetes.io/cluster-service:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="string">addonmanager.kubernetes.io/mode:</span> <span class="string">Reconcile</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="attr">- kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">fluentd-es</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">logging</span></span><br><span class="line"><span class="attr">  apiGroup:</span> <span class="string">""</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line"><span class="attr">  kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">fluentd-es</span></span><br><span class="line"><span class="attr">  apiGroup:</span> <span class="string">""</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">fluentd-es</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">logging</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">fluentd-es</span></span><br><span class="line"><span class="attr">    version:</span> <span class="string">v2.0.4</span></span><br><span class="line">    <span class="string">kubernetes.io/cluster-service:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="string">addonmanager.kubernetes.io/mode:</span> <span class="string">Reconcile</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      k8s-app:</span> <span class="string">fluentd-es</span></span><br><span class="line"><span class="attr">      version:</span> <span class="string">v2.0.4</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        k8s-app:</span> <span class="string">fluentd-es</span></span><br><span class="line">        <span class="string">kubernetes.io/cluster-service:</span> <span class="string">"true"</span></span><br><span class="line"><span class="attr">        version:</span> <span class="string">v2.0.4</span></span><br><span class="line">      <span class="comment"># This annotation ensures that fluentd does not get evicted if the node</span></span><br><span class="line">      <span class="comment"># supports critical pod annotation based priority scheme.</span></span><br><span class="line">      <span class="comment"># Note that this does not guarantee admission on the nodes (#40573).</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line">        <span class="string">scheduler.alpha.kubernetes.io/critical-pod:</span> <span class="string">''</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      serviceAccountName:</span> <span class="string">fluentd-es</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">fluentd-es</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">cnych/fluentd-elasticsearch:v2.0.4</span></span><br><span class="line"><span class="attr">        env:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">FLUENTD_ARGS</span></span><br><span class="line"><span class="attr">          value:</span> <span class="bullet">--no-supervisor</span> <span class="bullet">-q</span></span><br><span class="line"><span class="attr">        resources:</span></span><br><span class="line"><span class="attr">          limits:</span></span><br><span class="line"><span class="attr">            memory:</span> <span class="number">500</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">          requests:</span></span><br><span class="line"><span class="attr">            cpu:</span> <span class="number">100</span><span class="string">m</span></span><br><span class="line"><span class="attr">            memory:</span> <span class="number">200</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">        volumeMounts:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">varlog</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/var/log</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">varlibdockercontainers</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/data/docker/containers</span></span><br><span class="line"><span class="attr">          readOnly:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">config-volume</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/etc/fluent/config.d</span></span><br><span class="line"><span class="attr">      nodeSelector:</span></span><br><span class="line">        <span class="string">beta.kubernetes.io/fluentd-ds-ready:</span> <span class="string">"true"</span></span><br><span class="line"><span class="attr">      tolerations:</span></span><br><span class="line"><span class="attr">      - key:</span> <span class="string">node-role.kubernetes.io/master</span></span><br><span class="line"><span class="attr">        operator:</span> <span class="string">Exists</span></span><br><span class="line"><span class="attr">        effect:</span> <span class="string">NoSchedule</span></span><br><span class="line"><span class="attr">      terminationGracePeriodSeconds:</span> <span class="number">30</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">varlog</span></span><br><span class="line"><span class="attr">        hostPath:</span></span><br><span class="line"><span class="attr">          path:</span> <span class="string">/var/log</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">varlibdockercontainers</span></span><br><span class="line"><span class="attr">        hostPath:</span></span><br><span class="line"><span class="attr">          path:</span> <span class="string">/data/docker/containers</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">config-volume</span></span><br><span class="line"><span class="attr">        configMap:</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">fluentd-config</span></span><br></pre></td></tr></table></figure>

<p>我们将上面创建的 fluentd-config 这个 ConfigMap 对象通过 volumes 挂载到了 Fluentd 容器中，另外为了能够灵活控制哪些节点的日志可以被收集，所以我们这里还添加了一个 nodSelector 属性：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">nodeSelector:</span></span><br><span class="line">  <span class="string">beta.kubernetes.io/fluentd-ds-ready:</span> <span class="string">"true"</span></span><br></pre></td></tr></table></figure>

<p>意思就是要想采集节点的日志，那么我们就需要给节点打上上面的标签，比如我们这里3个节点都打上了该标签：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get nodes --show-labels</span></span><br><span class="line">NAME      STATUS    ROLES     AGE       VERSION   LABELS</span><br><span class="line">master    Ready     master    245d      v1.10.0   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/fluentd-ds-ready=true,beta.kubernetes.io/os=linux,kubernetes.io/hostname=master,node-role.kubernetes.io/master=</span><br><span class="line">node02    Ready     &lt;none&gt;    165d      v1.10.0   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/fluentd-ds-ready=true,beta.kubernetes.io/os=linux,com=youdianzhishi,course=k8s,kubernetes.io/hostname=node02</span><br><span class="line">node03    Ready     &lt;none&gt;    225d      v1.10.0   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/fluentd-ds-ready=true,beta.kubernetes.io/os=linux,jnlp=haimaxy,kubernetes.io/hostname=node03</span><br></pre></td></tr></table></figure>

<p>另外由于我们的集群使用的是 kubeadm 搭建的，默认情况下 master 节点有污点，所以要想也收集 master 节点的日志，则需要添加上容忍：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">tolerations:</span></span><br><span class="line"><span class="attr">- key:</span> <span class="string">node-role.kubernetes.io/master</span></span><br><span class="line"><span class="attr">  operator:</span> <span class="string">Exists</span></span><br><span class="line"><span class="attr">  effect:</span> <span class="string">NoSchedule</span></span><br></pre></td></tr></table></figure>

<p>另外需要注意的地方是，我这里的测试环境更改了 docker 的根目录：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> docker info</span></span><br><span class="line">...</span><br><span class="line">Docker Root Dir: /data/docker</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>所以上面要获取 docker 的容器目录需要更改成<code>/data/docker/containers</code>，这个地方非常重要，当然如果你没有更改 docker 根目录则使用默认的<code>/var/lib/docker/containers</code>目录即可。</p>
<p>分别创建上面的 ConfigMap 对象和 DaemonSet：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl create -f fluentd-configmap.yaml</span></span><br><span class="line">configmap "fluentd-config" created</span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl create -f fluentd-daemonset.yaml</span></span><br><span class="line">serviceaccount "fluentd-es" created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io "fluentd-es" created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io "fluentd-es" created</span><br><span class="line">daemonset.apps "fluentd-es" created</span><br></pre></td></tr></table></figure>

<p>创建完成后，查看对应的 Pods 列表，检查是否部署成功：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pods -n logging</span></span><br><span class="line">NAME                      READY     STATUS    RESTARTS   AGE</span><br><span class="line">es-cluster-0              1/1       Running   0          1d</span><br><span class="line">es-cluster-1              1/1       Running   0          1d</span><br><span class="line">es-cluster-2              1/1       Running   0          1d</span><br><span class="line">fluentd-es-2z9jg          1/1       Running   1          35s</span><br><span class="line">fluentd-es-6dfdd          1/1       Running   0          35s</span><br><span class="line">fluentd-es-bfkg7          1/1       Running   0          35s</span><br><span class="line">kibana-7558d4dc4d-5mqdz   1/1       Running   0          1d</span><br></pre></td></tr></table></figure>

<p><strong>注意</strong>：如果当前node没有打上<code>fluentd-ds-ready=true</code> lable的话，对应的pod <code>fluentd</code>不会被启动。</p>
<p>Fluentd 启动成功后，我们可以前往 Kibana 的 Dashboard 页面中，点击左侧的<code>Discover</code>，可以看到如下配置页面：</p>
<p><img src="/2019/11/06/%E5%9C%A8Kubernetes%E4%B8%8A%E6%90%AD%E5%BB%BAEFK%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%E7%B3%BB%E7%BB%9F/kSLsgE.jpg" alt="create index">create index</p>
<p>在这里可以配置我们需要的 Elasticsearch 索引，前面 Fluentd 配置文件中我们采集的日志使用的是 logstash 格式，这里只需要在文本框中输入<code>logstash-*</code>即可匹配到 Elasticsearch 集群中的所有日志数据，然后点击下一步，进入以下页面：</p>
<p><img src="/2019/11/06/%E5%9C%A8Kubernetes%E4%B8%8A%E6%90%AD%E5%BB%BAEFK%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%E7%B3%BB%E7%BB%9F/bc7n1S.jpg" alt="index config">index config</p>
<p>在该页面中配置使用哪个字段按时间过滤日志数据，在下拉列表中，选择<code>@timestamp</code>字段，然后点击<code>Create index pattern</code>，创建完成后，点击左侧导航菜单中的<code>Discover</code>，然后就可以看到一些直方图和最近采集到的日志数据了：</p>
<p><img src="/2019/11/06/%E5%9C%A8Kubernetes%E4%B8%8A%E6%90%AD%E5%BB%BAEFK%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%E7%B3%BB%E7%BB%9F/wHFvnu.jpg" alt="log data">log data</p>
<h3 id="测试-1"><a href="#测试-1" class="headerlink" title="测试"></a>测试</h3><p>现在我们来将上一节课的计数器应用部署到集群中，并在 Kibana 中来查找该日志数据。</p>
<p>新建 counter.yaml 文件，文件内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">counter</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">count</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    args:</span> <span class="string">[/bin/sh,</span> <span class="bullet">-c,</span></span><br><span class="line">            <span class="string">'i=0; while true; do echo "$i: $(date)"; i=$((i+1)); sleep 1; done'</span><span class="string">]</span></span><br></pre></td></tr></table></figure>

<p>该 Pod 只是简单将日志信息打印到 stdout，所以正常来说 Fluentd 会收集到这个日志数据，在 Kibana 中也就可以找到对应的日志数据了，使用 kubectl 工具创建该 Pod：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl create -f counter.yaml</span></span><br></pre></td></tr></table></figure>

<p>Pod 创建并运行后，回到 Kibana Dashboard 页面，在上面的<code>Discover</code>页面搜索栏中输入<code>kubernetes.pod_name:counter</code>，就可以过滤 Pod 名为 counter 的日志数据：</p>
<p><img src="/2019/11/06/%E5%9C%A8Kubernetes%E4%B8%8A%E6%90%AD%E5%BB%BAEFK%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%E7%B3%BB%E7%BB%9F/HsYSF3.jpg" alt="counter log data">counter log data</p>
<p>我们也可以通过其他元数据来过滤日志数据，比如 您可以单击任何日志条目以查看其他元数据，如容器名称，Kubernetes 节点，命名空间等。</p>
<p>到这里，我们就在 Kubernetes 集群上成功部署了 EFK ，要了解如何使用 Kibana 进行日志数据分析，可以参考 Kibana 用户指南文档：<a href="https://www.elastic.co/guide/en/kibana/current/index.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/kibana/current/index.html</a></p>
<p>当然对于在生产环境上使用 Elaticsearch 或者 Fluentd，还需要结合实际的环境做一系列的优化工作，本文中涉及到的资源清单文件都可以在<a href="https://github.com/cnych/kubernetes-learning/tree/master/efkdemo" target="_blank" rel="noopener">https://github.com/cnych/kubernetes-learning/tree/master/efkdemo</a>找到。</p>
<blockquote>
<p>参考文档: <a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-an-elasticsearch-fluentd-and-kibana-efk-logging-stack-on-kubernetes" target="_blank" rel="noopener">How To Set Up an Elasticsearch, Fluentd and Kibana (EFK) Logging Stack on Kubernetes</a></p>
<p>参考链接：<a href="https://www.jianshu.com/p/1000ae80a493" target="_blank" rel="noopener">https://www.jianshu.com/p/1000ae80a493</a></p>
</blockquote>
<h2 id="部署logtrail"><a href="#部署logtrail" class="headerlink" title="部署logtrail"></a>部署logtrail</h2><p>下载kibana对应版本的logtrail <a href="https://github.com/sivasamyk/logtrail" target="_blank" rel="noopener">https://github.com/sivasamyk/logtrail</a></p>
<p>由于kibana镜像不带logtrail，安装插件后需要重启kibana，在容器下无法重启。因此需要基于kibana镜像重新生成一个带插件的新镜像。</p>
<p>以6.7.0版本为例，Dockerfile如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># elk https://hub.docker.com/r/sebp/elk</span><br><span class="line">#FROM sebp/elk:670</span><br><span class="line">FROM docker.elastic.co/kibana/kibana-oss:6.7.0</span><br><span class="line">#ADD 02-beats-input.conf /etc/logstash/conf.d/02-beats-input.conf</span><br><span class="line">#ADD 30-output.conf /etc/logstash/conf.d/30-output.conf</span><br><span class="line"># kibanasivasamyk/logtrail </span><br><span class="line">ADD ./logtrail-6.7.0-0.1.31.zip /opt/kibana/plugin/logtrail-6.7.0-0.1.31.zip</span><br><span class="line">#  kibana</span><br><span class="line"># WORKDIR $&#123;KIBANA_HOME&#125;</span><br><span class="line"># kibana</span><br><span class="line">RUN bin/kibana-plugin install file:///opt/kibana/plugin/logtrail-6.7.0-0.1.31.zip</span><br></pre></td></tr></table></figure>

<p>执行build命令</p>
<blockquote>
<p>docker build  –network=host -t docker.elastic.co/kibana/kibana-oss:kibana-logtrail .</p>
</blockquote>
]]></content>
      <categories>
        <category>持续集成</category>
      </categories>
      <tags>
        <tag>k8s</tag>
        <tag>EFK</tag>
      </tags>
  </entry>
  <entry>
    <title>【转】docker容器和镜像区别</title>
    <url>/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<blockquote>
<p>来源 | <a href="http://sina.lt/gfmf" target="_blank" rel="noopener">http://sina.lt/gfmf</a></p>
</blockquote><p>这篇文章希望能够帮助读者深入理解Docker的命令，还有容器（container）和镜像（image）之间的区别，并深入探讨容器和运行中的容器之间的区别。 </p><p><a href="http://dockerone.com/uploads/article/20151103/d6ad9c257d160164480b25b278f4a2ad.png" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115301_427.png" alt=" 10张图带你深入理解Docker容器和镜像"></a></p><p>当我对Docker技术还是一知半解的时候，我发现理解Docker的命令非常困难。于是，我花了几周的时间来学习Docker的工作原理，更确 切地说，是关于Docker统一文件系统（the union file system）的知识，然后回过头来再看Docker的命令，一切变得顺理成章，简单极了。 </p><a id="more"></a>



<p>题外话：就我个人而言，掌握一门技术并合理使用它的最好办法就是深入理解这项技术背后的工作原理。通常情况 下，一项新技术的诞生常常会伴随着媒体的大肆宣传和炒作，这使得用户很难看清技术的本质。更确切地说，新技术总是会发明一些新的术语或者隐喻词来帮助宣 传，这在初期是非常有帮助的，但是这给技术的原理蒙上了一层砂纸，不利于用户在后期掌握技术的真谛。 </p>
<p>Git就是一个很好的例子。我之前不能够很好的使用Git，于是我花了一段时间去学习Git的原理，直到这时，我才真正明白了Git的用法。我坚信只有真正理解Git内部原理的人才能够掌握这个工具。 </p>
<h3 id="Image-Definition"><a href="#Image-Definition" class="headerlink" title="Image Definition"></a>Image Definition</h3><p>镜像（Image）就是一堆只读层（read-only layer）的统一视角，也许这个定义有些难以理解，下面的这张图能够帮助读者理解镜像的定义。 </p>
<p><a href="http://dockerone.com/uploads/article/20151103/522c40256149bad2b471d1a97c2b6bb5.png" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115301_703.png" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>从左边我们看到了多个只读层，它们重叠在一起。除了最下面一层，其它层都会有一个指针指向下一层。这些层是Docker内部的实现细节，并且能够 在主机（译者注：运行Docker的机器）的文件系统上访问到。统一文件系统（union file system）技术能够将不同的层整合成一个文件系统，为这些层提供了一个统一的视角，这样就隐藏了多层的存在，在用户的角度看来，只存在一个文件系统。 我们可以在图片的右边看到这个视角的形式。 </p>
<p>你可以在你的主机文件系统上找到有关这些层的文件。需要注意的是，在一个运行中的容器内部，这些层是不可见的。在我的主机上，我发现它们存在于/var/lib/docker/aufs目录下。 </p>
<h1 id="sudo-tree-L-1-var-lib-docker"><a href="#sudo-tree-L-1-var-lib-docker" class="headerlink" title="sudo tree -L 1 /var/lib/docker/"></a>sudo tree -L 1 /var/lib/docker/</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/var/lib/docker/</span><br><span class="line">├── aufs</span><br><span class="line">├── containers</span><br><span class="line">├── graph</span><br><span class="line">├── init</span><br><span class="line">├── linkgraph.db</span><br><span class="line">├── repositories-aufs</span><br><span class="line">├── tmp</span><br><span class="line">├── trust</span><br><span class="line">└── volumes</span><br><span class="line">7 directories, 2 files</span><br></pre></td></tr></table></figure>



<h3 id="Container-Definition"><a href="#Container-Definition" class="headerlink" title="Container Definition"></a>Container Definition</h3><p>容器（container）的定义和镜像（image）几乎一模一样，也是一堆层的统一视角，唯一区别在于容器的最上面那一层是可读可写的。 </p>
<p><a href="http://dockerone.com/uploads/article/20151103/b7fb9d924aa12099369c4793050fcfab.png" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115302_58.png" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>细心的读者可能会发现，容器的定义并没有提及容器是否在运行，没错，这是故意的。正是这个发现帮助我理解了很多困惑。 </p>
<p>要点：容器 = 镜像 + 可读层。并且容器的定义并没有提及是否要运行容器。 </p>
<p>接下来，我们将会讨论运行态容器。 </p>
<h3 id="Running-Container-Definition"><a href="#Running-Container-Definition" class="headerlink" title="Running Container Definition"></a>Running Container Definition</h3><p>一个运行态容器（running container）被定义为一个可读写的统一文件系统加上隔离的进程空间和包含其中的进程。下面这张图片展示了一个运行中的容器。 </p>
<p><a href="http://dockerone.com/uploads/article/20151103/8022edeebeb313742bd615aa695bbad3.png" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115302_576.png" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>正是文件系统隔离技术使得Docker成为了一个前途无量的技术。一个容器中的进程可能会对文件进行修改、删除、创建，这些改变都将作用于可读写层（read-write layer）。下面这张图展示了这个行为。 </p>
<p><a href="http://dockerone.com/uploads/article/20151103/1dc88de5a114b68d05c37aab7e103597.png" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115302_268.png" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>我们可以通过运行以下命令来验证我们上面所说的： </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run ubuntu touch happiness.txt</span><br></pre></td></tr></table></figure>


<p>即便是这个ubuntu容器不再运行，我们依旧能够在主机的文件系统上找到这个新文件。 </p>
<h1 id="find-name-happiness-txt"><a href="#find-name-happiness-txt" class="headerlink" title="find / -name happiness.txt"></a>find / -name happiness.txt</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/var/lib/docker/aufs/diff/860a7b...889/happiness.txt</span><br></pre></td></tr></table></figure>



<h3 id="Image-Layer-Definition"><a href="#Image-Layer-Definition" class="headerlink" title="Image Layer Definition"></a>Image Layer Definition</h3><p>为了将零星的数据整合起来，我们提出了镜像层（image layer）这个概念。下面的这张图描述了一个镜像层，通过图片我们能够发现一个层并不仅仅包含文件系统的改变，它还能包含了其他重要信息。 </p>
<p><a href="http://dockerone.com/uploads/article/20151103/e42d56394306894244af5bc6d757bee1.png" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115302_80.png" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>元数据（metadata）就是关于这个层的额外信息，它不仅能够让Docker获取运行和构建时的信息，还包括父层的层次信息。需要注意，只读层和读写层都包含元数据。 </p>
<p><a href="http://dockerone.com/uploads/article/20151103/5cca590212e2a110be84cbdd3b6101ee.png" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115302_513.png" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>除此之外，每一层都包括了一个指向父层的指针。如果一个层没有这个指针，说明它处于最底层。 </p>
<p><a href="http://dockerone.com/uploads/article/20151103/1ead4d955aeb5d968219794489948fc2.png" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115303_299.png" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>Metadata Location:<br>我发现在我自己的主机上，镜像层（image layer）的元数据被保存在名为”json”的文件中，比如说： </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/var/lib/docker/graph/e809f156dc985.../json</span><br></pre></td></tr></table></figure>


<p>e809f156dc985…就是这层的id </p>
<p>一个容器的元数据好像是被分成了很多文件，但或多或少能够在/var/lib/docker/containers/<id>目录下找到，<id>就是一个可读层的id。这个目录下的文件大多是运行时的数据，比如说网络，日志等等。 </id></id></p>
<h3 id="全局理解（Tying-It-All-Together）"><a href="#全局理解（Tying-It-All-Together）" class="headerlink" title="全局理解（Tying It All Together）"></a>全局理解（Tying It All Together）</h3><p>现在，让我们结合上面提到的实现细节来理解Docker的命令。 </p>
<h4 id="docker-create"><a href="#docker-create" class="headerlink" title="docker create "></a>docker create <image-id></image-id></h4><p><a href="http://dockerone.com/uploads/article/20151031/1397bbddca6651a3ae0316daa8d6d1cd.jpg" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115303_594.jpg" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>docker create 命令为指定的镜像（image）添加了一个可读写层，构成了一个新的容器。注意，这个容器并没有运行。 </p>
<p><a href="http://dockerone.com/uploads/article/20151103/bbe622329b399778b077617ae6468676.png" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115303_843.png" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<h4 id="docker-start"><a href="#docker-start" class="headerlink" title="docker start "></a>docker start <container-id></container-id></h4><p><a href="http://dockerone.com/uploads/article/20151031/3f08537e309b923d049fdde3d3a1f926.jpg" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115303_670.jpg" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>Docker start命令为容器文件系统创建了一个进程隔离空间。注意，每一个容器只能够有一个进程隔离空间。 </p>
<h4 id="docker-run"><a href="#docker-run" class="headerlink" title="docker run "></a>docker run <image-id></image-id></h4><p><a href="http://dockerone.com/uploads/article/20151031/4178f2b64f6a2eeb994866931417f263.jpg" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115303_318.jpg" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>看到这个命令，读者通常会有一个疑问：docker start 和 docker run命令有什么区别。 </p>
<p><a href="http://dockerone.com/uploads/article/20151103/ea18907dedcd8893b39ae1f9e3ad8a3e.png" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115304_352.png" alt="7.png"></a></p>
<p>从图片可以看出，docker run 命令先是利用镜像创建了一个容器，然后运行这个容器。这个命令非常的方便，并且隐藏了两个命令的细节，但从另一方面来看，这容易让用户产生误解。 </p>
<p>题外话：继续我们之前有关于Git的话题，我认为docker run命令类似于git pull命令。git pull命令就是git fetch 和 git merge两个命令的组合，同样的，docker run就是docker create和docker start两个命令的组合。 </p>
<h4 id="docker-ps"><a href="#docker-ps" class="headerlink" title="docker ps"></a>docker ps</h4><p><a href="http://dockerone.com/uploads/article/20151031/fafeb4eb072e64b54b9979930a6d8db7.jpg" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115304_250.jpg" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>docker ps 命令会列出所有运行中的容器。这隐藏了非运行态容器的存在，如果想要找出这些容器，我们需要使用下面这个命令。 </p>
<h4 id="docker-ps-–a"><a href="#docker-ps-–a" class="headerlink" title="docker ps –a"></a>docker ps –a</h4><p><a href="http://dockerone.com/uploads/article/20151031/120d394e57a03a5bb996b23e6e373cf1.jpg" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115304_237.jpg" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>docker ps –a命令会列出所有的容器，不管是运行的，还是停止的。 </p>
<h4 id="docker-images"><a href="#docker-images" class="headerlink" title="docker images"></a>docker images</h4><p><a href="http://dockerone.com/uploads/article/20151031/f8b34de7f7f325e2933aac5cc679e224.jpg" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115304_909.jpg" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>docker images命令会列出了所有顶层（top-level）镜像。实际上，在这里我们没有办法区分一个镜像和一个只读层，所以我们提出了top-level 镜像。只有创建容器时使用的镜像或者是直接pull下来的镜像能被称为顶层（top-level）镜像，并且每一个顶层镜像下面都隐藏了多个镜像层。 </p>
<h4 id="docker-images-–a"><a href="#docker-images-–a" class="headerlink" title="docker images –a"></a>docker images –a</h4><p><a href="http://dockerone.com/uploads/article/20151031/6b3d2d1cae5a26961dc554fc05783b22.jpg" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115305_620.jpg" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>docker images –a命令列出了所有的镜像，也可以说是列出了所有的可读层。如果你想要查看某一个image-id下的所有层，可以使用docker history来查看。 </p>
<h4 id="docker-stop"><a href="#docker-stop" class="headerlink" title="docker stop "></a>docker stop <container-id></container-id></h4><p><a href="http://dockerone.com/uploads/article/20151031/081cf8fbe8ab4dea4130ce2f25eae071.jpg" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115306_454.jpg" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>docker stop命令会向运行中的容器发送一个SIGTERM的信号，然后停止所有的进程。 </p>
<h4 id="docker-kill"><a href="#docker-kill" class="headerlink" title="docker kill "></a>docker kill <container-id></container-id></h4><p><a href="http://dockerone.com/uploads/article/20151031/8aeee0c4c1134ee9d0c2200e03defcf4.jpg" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115306_977.jpg" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>docker kill 命令向所有运行在容器中的进程发送了一个不友好的SIGKILL信号。 </p>
<h4 id="docker-pause"><a href="#docker-pause" class="headerlink" title="docker pause "></a>docker pause <container-id></container-id></h4><p><a href="http://dockerone.com/uploads/article/20151031/2b34576a2187a972d4cc1cf9346658e2.jpg" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115306_230.jpg" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>docker stop和docker kill命令会发送UNIX的信号给运行中的进程，docker pause命令则不一样，它利用了cgroups的特性将运行中的进程空间暂停。具体的内部原理你可以在这里找到：<a href="https://www.kernel.org/doc/Documentation/cgroups/freezer-subsystem.txt" target="_blank" rel="noopener">https://www.kernel.org/doc/Doc … m.txt</a>，但是这种方式的不足之处在于发送一个SIGTSTP信号对于进程来说不够简单易懂，以至于不能够让所有进程暂停。 </p>
<h4 id="docker-rm"><a href="#docker-rm" class="headerlink" title="docker rm "></a>docker rm <container-id></container-id></h4><p><a href="http://dockerone.com/uploads/article/20151031/bba4521356b43813a634a0859fa53743.jpg" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115306_974.jpg" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>docker rm命令会移除构成容器的可读写层。注意，这个命令只能对非运行态容器执行。 </p>
<h4 id="docker-rmi"><a href="#docker-rmi" class="headerlink" title="docker rmi "></a>docker rmi <image-id></image-id></h4><p><a href="http://dockerone.com/uploads/article/20151031/df0fadb17158696cdce49a8e30f8c4c4.jpg" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115307_574.jpg" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>docker rmi 命令会移除构成镜像的一个只读层。你只能够使用docker rmi来移除最顶层（top level layer）（也可以说是镜像），你也可以使用-f参数来强制删除中间的只读层。 </p>
<h4 id="docker-commit"><a href="#docker-commit" class="headerlink" title="docker commit "></a>docker commit <container-id></container-id></h4><p><a href="http://dockerone.com/uploads/article/20151031/f642149d0144c83679dd228c93a91a37.jpg" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115307_730.jpg" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>docker commit命令将容器的可读写层转换为一个只读层，这样就把一个容器转换成了不可变的镜像。 </p>
<p><a href="http://dockerone.com/uploads/article/20151103/a206a291a8d4b9c968061b853f92ad4e.png" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115307_969.png" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<h4 id="docker-build"><a href="#docker-build" class="headerlink" title="docker build"></a>docker build</h4><p><a href="http://dockerone.com/uploads/article/20151031/d569d50a2c6cb4cdb07eb4cfc0712ab0.jpg" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115307_796.jpg" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>docker build命令非常有趣，它会反复的执行多个命令。 </p>
<p><a href="http://dockerone.com/uploads/article/20151103/17f6091cc228e14eb151cc8909b4ab00.png" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115308_396.png" alt="9.png"></a></p>
<p>我们从上图可以看到，build命令根据Dockerfile文件中的FROM指令获取到镜像，然后重复地1）run（create和start）、2）修改、3）commit。在循环中的每一步都会生成一个新的层，因此许多新的层会被创建。 </p>
<h4 id="docker-exec"><a href="#docker-exec" class="headerlink" title="docker exec "></a>docker exec <running-container-id></running-container-id></h4><p><a href="http://dockerone.com/uploads/article/20151031/91b0fd6b6b3c0d372eafbe40221835a8.jpg" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115308_659.jpg" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>docker exec 命令会在运行中的容器执行一个新进程。 </p>
<h4 id="docker-inspect-or"><a href="#docker-inspect-or" class="headerlink" title="docker inspect  or "></a>docker inspect <container-id> or <image-id></image-id></container-id></h4><p><a href="http://dockerone.com/uploads/article/20151031/eb03a3d750a4da43fc5825d8336314c1.jpg" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115308_430.jpg" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>docker inspect命令会提取出容器或者镜像最顶层的元数据。 </p>
<h4 id="docker-save"><a href="#docker-save" class="headerlink" title="docker save "></a>docker save <image-id></image-id></h4><p><a href="http://dockerone.com/uploads/article/20151031/db73c5aad485bbacb3e97d0a8ddcdea4.jpg" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115309_345.jpg" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>docker save命令会创建一个镜像的压缩文件，这个文件能够在另外一个主机的Docker上使用。和export命令不同，这个命令为每一个层都保存了它们的元数据。这个命令只能对镜像生效。 </p>
<h4 id="docker-export"><a href="#docker-export" class="headerlink" title="docker export "></a>docker export <container-id></container-id></h4><p><a href="http://dockerone.com/uploads/article/20151031/a766de204b53f10d5f56c36955b6b0ee.jpg" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115309_215.jpg" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>docker export命令创建一个tar文件，并且移除了元数据和不必要的层，将多个层整合成了一个层，只保存了当前统一视角看到的内容（译者注：expoxt后 的容器再import到Docker中，通过docker images –tree命令只能看到一个镜像；而save后的镜像则不同，它能够看到这个镜像的历史镜像）。 </p>
<h4 id="docker-history"><a href="#docker-history" class="headerlink" title="docker history "></a>docker history <image-id></image-id></h4><p><a href="http://dockerone.com/uploads/article/20151031/f20de692d890a55b84ee5540c62e054e.jpg" target="_blank" rel="noopener"><img src="/2019/11/06/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E9%95%9C%E5%83%8F%E5%8C%BA%E5%88%AB/20151105115309_191.jpg" alt=" 10张图带你深入理解Docker容器和镜像"></a></p>
<p>docker history命令递归地输出指定镜像的历史镜像。</p>
]]></content>
      <categories>
        <category>持续集成</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Helm模板文件chart编写语法总结</title>
    <url>/2019/11/02/Helm%E6%A8%A1%E6%9D%BF%E6%96%87%E4%BB%B6chart%E7%BC%96%E5%86%99%E8%AF%AD%E6%B3%95%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<p><a href="https://whmzsu.github.io/helm-doc-zh-cn/" target="_blank" rel="noopener">helm-charts用户指南</a></p><h2 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h2><p>快速创建一个chart模板,<code>helm create mychart</code>,执行命令后本地生成一个mychart目录.</p><h2 id="chart目录结构"><a href="#chart目录结构" class="headerlink" title="chart目录结构"></a>chart目录结构</h2><ul>
<li>Chart.yaml: 该chart的描述文件,包括ico地址,版本信息等</li>
<li>vakues.yaml: 给模板文件使用的变量</li>
<li>charts: 依赖其他包的charts文件</li>
<li>requirements.yaml: 依赖的charts</li>
<li>README.md: 开发人员自己阅读的文件</li>
<li>templates: 存放k8s模板文件目录<ul>
<li>NOTES.txt 说明文件,helm install之后展示给用户看的内容</li>
<li>deployment.yaml 创建k8s资源的yaml文件</li>
<li>_helpers.tpl: 下划线开头的文件,可以被其他模板引用.</li>
</ul>
</li>
</ul><a id="more"></a>


<p>一个最小的chart目录,只需要包含一个Chart.yaml,和templates目录下一个k8s资源文件.如:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># mychart/Chart.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">appVersion: 2.9.0</span><br><span class="line">version: 1.1.1</span><br><span class="line"></span><br><span class="line"># mychart/templates/configmap.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: mychart-configmap</span><br><span class="line">data:</span><br><span class="line">  myvalue: &quot;Hello World&quot;</span><br></pre></td></tr></table></figure>

<h2 id="helm模板语法"><a href="#helm模板语法" class="headerlink" title="helm模板语法"></a>helm模板语法</h2><ol>
<li><p>模板引用方式</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;&#123; .Release.Name &#125;&#125;</span><br></pre></td></tr></table></figure>
<p>通过双括号注入,小数点开头表示从最顶层命名空间引用.</p>
</li>
<li><p>helm内置对象</p>
<blockquote>
<p>Release, release相关属性<br>Chart, Chart.yaml文件中定义的内容<br>Values, values.yaml文件中定义的内容</p>
</blockquote>
</li>
<li><p>模板中使用管道</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">    name: &#123;&#123; .Release.Name &#125;&#125;-configmap</span><br><span class="line">data:</span><br><span class="line"> myvalue: &quot;Hello World&quot;</span><br><span class="line"> drink: &#123;&#123; .Values.favorite.drink | repeat 5 | quote &#125;&#125;</span><br><span class="line"> food: &#123;&#123; .Values.favorite.food | upper | quote &#125;&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>if语句</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;&#123; if PIPELINE &#125;&#125;</span><br><span class="line"># Do something</span><br><span class="line">&#123;&#123; else if OTHER PIPELINE &#125;&#125;</span><br><span class="line"># Do something else</span><br><span class="line">&#123;&#123; else &#125;&#125;</span><br><span class="line"># Default case</span><br><span class="line">&#123;&#123; end &#125;&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>操作符, and/eq/or/not</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;&#123;/* include the body of this if statement when the variable .Values.fooString exists and is set to &quot;foo&quot; */&#125;&#125;</span><br><span class="line">&#123;&#123; if and .Values.fooString (eq .Values.fooString &quot;foo&quot;) &#125;&#125;</span><br><span class="line">    &#123;&#123; ... &#125;&#125;</span><br><span class="line">&#123;&#123; end &#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123;/* do not include the body of this if statement because unset variables evaluate to false and .Values.setVariable was negated with the not function. */&#125;&#125;</span><br><span class="line">&#123;&#123; if or .Values.anUnsetVariable (not .Values.aSetVariable) &#125;&#125;</span><br><span class="line">   &#123;&#123; ... &#125;&#125;</span><br><span class="line">&#123;&#123; end &#125;&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>控制语句块在渲染后生成模板会多出空行,需要使用</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;&#123;- if ...&#125;&#125;</span><br></pre></td></tr></table></figure>

<p>的方式消除此空行.如:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: &#123;&#123; .Release.Name &#125;&#125;-configmap</span><br><span class="line">data:</span><br><span class="line">  myvalue: &quot;Hello World&quot;</span><br><span class="line">  &#123;&#123;- if eq .Values.favorite.drink &quot;coffee&quot;&#125;&#125;</span><br><span class="line">  mug: true</span><br><span class="line">  &#123;&#123;- end&#125;&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>引入相对命名空间,with命令:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: &#123;&#123; .Release.Name &#125;&#125;-configmap</span><br><span class="line">data:</span><br><span class="line">  myvalue: &quot;Hello World&quot;</span><br><span class="line">  &#123;&#123;- with .Values.favorite &#125;&#125;</span><br><span class="line">  drink: &#123;&#123; .drink | default &quot;tea&quot; | quote &#125;&#125;</span><br><span class="line">  food: &#123;&#123; .food | upper | quote &#125;&#125;</span><br><span class="line">  &#123;&#123;- end &#125;&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>range命令实现循环,如:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># values.yaml</span><br><span class="line">favorite:</span><br><span class="line">  drink: coffee</span><br><span class="line">  food: pizza</span><br><span class="line">pizzaToppings:</span><br><span class="line">  - mushrooms</span><br><span class="line">  - cheese</span><br><span class="line">  - peppers</span><br><span class="line">  - onions</span><br><span class="line"></span><br><span class="line">#configmap.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: &#123;&#123; .Release.Name &#125;&#125;-configmap</span><br><span class="line">data:</span><br><span class="line">  myvalue: &quot;Hello World&quot;</span><br><span class="line">  toppings: |-</span><br><span class="line">    &#123;&#123;- range .Values.pizzaToppings &#125;&#125;</span><br><span class="line">    - &#123;&#123; . &#125;&#125;</span><br><span class="line">    # .表示range的命令空间下的取值</span><br><span class="line">    &#123;&#123;- end &#125;&#125;</span><br><span class="line">    &#123;&#123;- range $key, $val := .Values.favorite &#125;&#125;</span><br><span class="line">    &#123;&#123; $key &#125;&#125;: &#123;&#123; $val | quote &#125;&#125;</span><br><span class="line">    &#123;&#123;- end&#125;&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>变量赋值</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ApiVersion: v1</span><br><span class="line">Kind: ConfigMap</span><br><span class="line">Metadata:</span><br><span class="line">  name: &#123;&#123; .Release.Name &#125;&#125;-configmap</span><br><span class="line">Data:</span><br><span class="line">  myvalue: &quot;Hello World&quot;</span><br><span class="line">  # 由于下方的with语句引入相对命令空间,无法通过.Release引入,提前定义relname变量</span><br><span class="line">  &#123;&#123;- $relname := .Release.Name -&#125;&#125;</span><br><span class="line">  &#123;&#123;- with .Values.favorite &#125;&#125;</span><br><span class="line">  food: &#123;&#123; .food &#125;&#125;</span><br><span class="line">  release: &#123;&#123; $relname &#125;&#125;</span><br><span class="line">  # 或者可以使用$符号,引入全局命名空间</span><br><span class="line">  release: &#123;&#123; $.Release.Name &#125;&#125;</span><br><span class="line">  &#123;&#123;- end &#125;&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>公共模板,define定义,template引入,在templates目录中默认下划线_开头的文件为公共模板(_helpers.tpl)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># _helpers.tpl文件</span><br><span class="line">&#123;&#123;- define &quot;mychart.labels&quot; &#125;&#125;</span><br><span class="line">  labels:</span><br><span class="line">    generator: helm</span><br><span class="line">    date: &#123;&#123; now | htmlDate &#125;&#125;</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line"></span><br><span class="line"># configmap.yaml文件</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: &#123;&#123; .Release.Name &#125;&#125;-configmap</span><br><span class="line">  &#123;&#123;- template &quot;mychart.labels&quot; &#125;&#125;</span><br><span class="line">data:</span><br><span class="line">  myvalue: &quot;Hello World&quot;</span><br></pre></td></tr></table></figure>
</li>
<li><p>template语句的升级版本include,template是语句无法在后面接管道符来对引入变量做定义,<br>include实现了此功能.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># _helpers.tpl文件</span><br><span class="line">&#123;&#123;- define &quot;mychart.app&quot; -&#125;&#125;</span><br><span class="line">app_name: &#123;&#123; .Chart.Name &#125;&#125;</span><br><span class="line">app_version: &quot;&#123;&#123; .Chart.Version &#125;&#125;+&#123;&#123; .Release.Time.Seconds &#125;&#125;&quot;</span><br><span class="line">&#123;&#123;- end -&#125;&#125;</span><br><span class="line"></span><br><span class="line"># configmap.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: &#123;&#123; .Release.Name &#125;&#125;-configmap</span><br><span class="line">  labels:</span><br><span class="line">    &#123;&#123;- include &quot;mychart.app&quot; . | nindent 4 &#125;&#125;</span><br><span class="line">data:</span><br><span class="line">  myvalue: &quot;Hello World&quot;</span><br><span class="line">  &#123;&#123;- range $key, $val := .Values.favorite &#125;&#125;</span><br><span class="line">  &#123;&#123; $key &#125;&#125;: &#123;&#123; $val | quote &#125;&#125;</span><br><span class="line">  &#123;&#123;- end &#125;&#125;</span><br><span class="line">  &#123;&#123;- include &quot;mychart.app&quot; . | nindent 2 &#125;&#125;</span><br><span class="line"></span><br><span class="line"># 如果使用template只能手动空格,不能使用管道后的nindent函数来做缩进</span><br></pre></td></tr></table></figure>
</li>
<li><p>一个坑</p>
<blockquote>
<p><code>helm install stable/drupal --set image=my-registry/drupal:0.1.0 --set livenessProbe.exec.command=[cat,docroot/CHANGELOG.txt] --set livenessProbe.httpGet=null&lt;br/&gt;</code></p>
</blockquote>
</li>
</ol>
<p>livenessProbe在values.yaml中定义了httpGet,需要手动设置为null,然后设置exec的探针.</p>
]]></content>
      <categories>
        <category>持续集成</category>
      </categories>
      <tags>
        <tag>helm</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes排错指南</title>
    <url>/2019/11/02/k8s-troubleshooting/</url>
    <content><![CDATA[<blockquote>
<p>转载自：<a href="https://github.com/imroc/kubernetes-troubleshooting-guide" target="_blank" rel="noopener">https://github.com/imroc/kubernetes-troubleshooting-guide</a></p>
</blockquote><h2 id="分析-ExitCode-定位-Pod-异常退出原因"><a href="#分析-ExitCode-定位-Pod-异常退出原因" class="headerlink" title="分析 ExitCode 定位 Pod 异常退出原因"></a>分析 ExitCode 定位 Pod 异常退出原因</h2><p>使用 <code>kubectl describe pod &lt;pod name&gt;</code> 查看异常 pod 的状态:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Containers:</span><br><span class="line">  kubedns:</span><br><span class="line">    Container ID:  docker://5fb8adf9ee62afc6d3f6f3d9590041818750b392dff015d7091eaaf99cf1c945</span><br><span class="line">    Image:         ccr.ccs.tencentyun.com/library/kubedns-amd64:1.14.4</span><br><span class="line">    Image ID:      docker-pullable://ccr.ccs.tencentyun.com/library/kubedns-amd64@sha256:40790881bbe9ef4ae4ff7fe8b892498eecb7fe6dcc22661402f271e03f7de344</span><br><span class="line">    Ports:         10053/UDP, 10053/TCP, 10055/TCP</span><br><span class="line">    Host Ports:    0/UDP, 0/TCP, 0/TCP</span><br><span class="line">    Args:</span><br><span class="line">      --domain=cluster.local.</span><br><span class="line">      --dns-port=10053</span><br><span class="line">      --config-dir=/kube-dns-config</span><br><span class="line">      --v=2</span><br><span class="line">    State:          Running</span><br><span class="line">      Started:      Tue, 27 Aug 2019 10:58:49 +0800</span><br><span class="line">    Last State:     Terminated</span><br><span class="line">      Reason:       Error</span><br><span class="line">      Exit Code:    255</span><br><span class="line">      Started:      Tue, 27 Aug 2019 10:40:42 +0800</span><br><span class="line">      Finished:     Tue, 27 Aug 2019 10:58:27 +0800</span><br><span class="line">    Ready:          True</span><br><span class="line">    Restart Count:  1</span><br></pre></td></tr></table></figure><a id="more"></a>



<p>在容器列表里看 <code>Last State</code> 字段，其中 <code>ExitCode</code> 即程序上次退出时的状态码，如果不为 0，表示异常退出，我们可以分析下原因。</p>
<h3 id="退出状态码的区间"><a href="#退出状态码的区间" class="headerlink" title="退出状态码的区间"></a>退出状态码的区间</h3><ul>
<li>必须在 0-255 之间</li>
<li>0 表示正常退出</li>
<li>外界中断将程序退出的时候状态码区间在 129-255，(操作系统给程序发送中断信号，比如 <code>kill -9</code> 是 <code>SIGKILL</code>，<code>ctrl+c</code> 是 <code>SIGINT</code>)</li>
<li>一般程序自身原因导致的异常退出状态区间在 1-128 (这只是一般约定，程序如果一定要用129-255的状态码也是可以的)</li>
</ul>
<p>假如写代码指定的退出状态码时不在 0-255 之间，例如: <code>exit(-1)</code>，这时会自动做一个转换，最终呈现的状态码还是会在 0-255 之间。我们把状态码记为 <code>code</code></p>
<ul>
<li>当指定的退出时状态码为负数，那么转换公式如下:</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">256 - (|code| % 256)</span><br></pre></td></tr></table></figure>

<ul>
<li>当指定的退出时状态码为正数，那么转换公式如下:</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">code % 256</span><br></pre></td></tr></table></figure>

<h3 id="常见异常状态码"><a href="#常见异常状态码" class="headerlink" title="常见异常状态码"></a>常见异常状态码</h3><ul>
<li><p>137 (被  <code>SIGKILL</code> 中断信号杀死)</p>
<ul>
<li><p>此状态码一般是因为 pod 中容器内存达到了它的资源限制(<code>resources.limits</code>)，一般是内存溢出(OOM)，CPU达到限制只需要不分时间片给程序就可以。因为限制资源是通过 linux 的 cgroup 实现的，所以 cgroup 会将此容器强制杀掉，类似于 <code>kill -9</code>，此时在 <code>describe pod</code> 中可以看到 Reason 是 <code>OOMKilled</code></p>
</li>
<li><p>还可能是宿主机本身资源不够用了(OOM)，内核会选取一些进程杀掉来释放内存</p>
</li>
<li><p>不管是 cgroup 限制杀掉进程还是因为节点机器本身资源不够导致进程死掉，都可以从系统日志中找到记录:</p>
<blockquote>
<p>ubuntu 的系统日志在 <code>/var/log/syslog</code>，centos 的系统日志在 <code>/var/log/messages</code>，都可以用 <code>journalctl -k</code> 来查看系统日志</p>
</blockquote>
</li>
<li><p>也可能是 livenessProbe (存活检查) 失败，kubelet 杀死的 pod</p>
</li>
<li><p>还可能是被恶意木马进程杀死</p>
</li>
</ul>
</li>
<li><p>1 和 255</p>
<ul>
<li>这种可能是一般错误，具体错误原因只能看容器日志，因为很多程序员写异常退出时习惯用 <code>exit(1)</code> 或 <code>exit(-1)</code>，-1 会根据转换规则转成 255</li>
</ul>
</li>
</ul>
<h3 id="状态码参考"><a href="#状态码参考" class="headerlink" title="状态码参考"></a>状态码参考</h3><p>这里罗列了一些状态码的含义：<a href="http://tldp.org/LDP/abs/html/exitcodes.html" target="_blank" rel="noopener">Appendix E. Exit Codes With Special Meanings</a></p>
<h3 id="Linux-标准中断信号"><a href="#Linux-标准中断信号" class="headerlink" title="Linux 标准中断信号"></a>Linux 标准中断信号</h3><p>Linux 程序被外界中断时会发送中断信号，程序退出时的状态码就是中断信号值加上 128 得到的，比如 <code>SIGKILL</code> 的中断信号值为 9，那么程序退出状态码就为 9+128=137。以下是标准信号值参考：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Signal     Value     Action   Comment</span><br><span class="line">──────────────────────────────────────────────────────────────────────</span><br><span class="line">SIGHUP        1       Term    Hangup detected on controlling terminal</span><br><span class="line">                                     or death of controlling process</span><br><span class="line">SIGINT        2       Term    Interrupt from keyboard</span><br><span class="line">SIGQUIT       3       Core    Quit from keyboard</span><br><span class="line">SIGILL        4       Core    Illegal Instruction</span><br><span class="line">SIGABRT       6       Core    Abort signal from abort(3)</span><br><span class="line">SIGFPE        8       Core    Floating-point exception</span><br><span class="line">SIGKILL       9       Term    Kill signal</span><br><span class="line">SIGSEGV      11       Core    Invalid memory reference</span><br><span class="line">SIGPIPE      13       Term    Broken pipe: write to pipe with no</span><br><span class="line">                                     readers; see pipe(7)</span><br><span class="line">SIGALRM      14       Term    Timer signal from alarm(2)</span><br><span class="line">SIGTERM      15       Term    Termination signal</span><br><span class="line">SIGUSR1   30,10,16    Term    User-defined signal 1</span><br><span class="line">SIGUSR2   31,12,17    Term    User-defined signal 2</span><br><span class="line">SIGCHLD   20,17,18    Ign     Child stopped or terminated</span><br><span class="line">SIGCONT   19,18,25    Cont    Continue if stopped</span><br><span class="line">SIGSTOP   17,19,23    Stop    Stop process</span><br><span class="line">SIGTSTP   18,20,24    Stop    Stop typed at terminal</span><br><span class="line">SIGTTIN   21,21,26    Stop    Terminal input for background process</span><br><span class="line">SIGTTOU   22,22,27    Stop    Terminal output for background process</span><br></pre></td></tr></table></figure>

<h3 id="C-C-退出状态码"><a href="#C-C-退出状态码" class="headerlink" title="C/C++ 退出状态码"></a>C/C++ 退出状态码</h3><p><code>/usr/include/sysexits.h</code> 试图将退出状态码标准化(仅限 C/C++):</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#define EX_OK           0       /* successful termination */</span><br><span class="line"></span><br><span class="line">#define EX__BASE        64      /* base value for error messages */</span><br><span class="line"></span><br><span class="line">#define EX_USAGE        64      /* command line usage error */</span><br><span class="line">#define EX_DATAERR      65      /* data format error */</span><br><span class="line">#define EX_NOINPUT      66      /* cannot open input */</span><br><span class="line">#define EX_NOUSER       67      /* addressee unknown */</span><br><span class="line">#define EX_NOHOST       68      /* host name unknown */</span><br><span class="line">#define EX_UNAVAILABLE  69      /* service unavailable */</span><br><span class="line">#define EX_SOFTWARE     70      /* internal software error */</span><br><span class="line">#define EX_OSERR        71      /* system error (e.g., can&apos;t fork) */</span><br><span class="line">#define EX_OSFILE       72      /* critical OS file missing */</span><br><span class="line">#define EX_CANTCREAT    73      /* can&apos;t create (user) output file */</span><br><span class="line">#define EX_IOERR        74      /* input/output error */</span><br><span class="line">#define EX_TEMPFAIL     75      /* temp failure; user is invited to retry */</span><br><span class="line">#define EX_PROTOCOL     76      /* remote error in protocol */</span><br><span class="line">#define EX_NOPERM       77      /* permission denied */</span><br><span class="line">#define EX_CONFIG       78      /* configuration error */</span><br><span class="line"></span><br><span class="line">#define EX__MAX 78      /* maximum listed value */</span><br></pre></td></tr></table></figure>





<h2 id="使用-systemtap-定位疑难杂症"><a href="#使用-systemtap-定位疑难杂症" class="headerlink" title="使用 systemtap 定位疑难杂症"></a>使用 systemtap 定位疑难杂症</h2><h3 id="Ubuntu"><a href="#Ubuntu" class="headerlink" title="Ubuntu"></a>Ubuntu</h3><p>安装 systemtap:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apt install -y systemtap</span><br></pre></td></tr></table></figure>

<p>运行 <code>stap-prep</code> 检查还有什么需要安装:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ stap-prep</span><br><span class="line">Please install linux-headers-4.4.0-104-generic</span><br><span class="line">You need package linux-image-4.4.0-104-generic-dbgsym but it does not seem to be available</span><br><span class="line"> Ubuntu -dbgsym packages are typically in a separate repository</span><br><span class="line"> Follow https://wiki.ubuntu.com/DebuggingProgramCrash to add this repository</span><br><span class="line"></span><br><span class="line">apt install -y linux-headers-4.4.0-104-generic</span><br></pre></td></tr></table></figure>

<p>提示需要 dbgsym 包但当前已有软件源中并不包含，需要使用第三方软件源安装，下面是 dbgsym 安装方法(参考官方wiki: <a href="https://wiki.ubuntu.com/Kernel/Systemtap" target="_blank" rel="noopener">https://wiki.ubuntu.com/Kernel/Systemtap</a>):</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys C8CAB6595FDFF622</span><br><span class="line"></span><br><span class="line">codename=$(lsb_release -c | awk  &apos;&#123;print $2&#125;&apos;)</span><br><span class="line">sudo tee /etc/apt/sources.list.d/ddebs.list &lt;&lt; EOF</span><br><span class="line">deb http://ddebs.ubuntu.com/ $&#123;codename&#125;      main restricted universe multiverse</span><br><span class="line">deb http://ddebs.ubuntu.com/ $&#123;codename&#125;-security main restricted universe multiverse</span><br><span class="line">deb http://ddebs.ubuntu.com/ $&#123;codename&#125;-updates  main restricted universe multiverse</span><br><span class="line">deb http://ddebs.ubuntu.com/ $&#123;codename&#125;-proposed main restricted universe multiverse</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure>

<p>配置好源后再运行下 <code>stap-prep</code>:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ stap-prep</span><br><span class="line">Please install linux-headers-4.4.0-104-generic</span><br><span class="line">Please install linux-image-4.4.0-104-generic-dbgsym</span><br></pre></td></tr></table></figure>

<p>提示需要装这两个包，我们安装一下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apt install -y linux-image-4.4.0-104-generic-dbgsym</span><br><span class="line">apt install -y linux-headers-4.4.0-104-generic</span><br></pre></td></tr></table></figure>

<h3 id="CentOS"><a href="#CentOS" class="headerlink" title="CentOS"></a>CentOS</h3><p>安装 systemtap:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install -y systemtap</span><br></pre></td></tr></table></figure>

<p>默认没装 <code>debuginfo</code>，我们需要装一下，添加软件源 <code>/etc/yum.repos.d/CentOS-Debug.repo</code>:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[debuginfo]</span><br><span class="line">name=CentOS-$releasever - DebugInfo</span><br><span class="line">baseurl=http://debuginfo.centos.org/$releasever/$basearch/</span><br><span class="line">gpgcheck=0</span><br><span class="line">enabled=1</span><br><span class="line">protect=1</span><br><span class="line">priority=1</span><br></pre></td></tr></table></figure>

<p>执行 <code>stap-prep</code> (会安装 <code>kernel-debuginfo</code>)</p>
<p>最后检查确保 <code>kernel-debuginfo</code> 和 <code>kernel-devel</code> 均已安装并且版本跟当前内核版本相同，如果有多个版本，就删除跟当前内核版本不同的包(通过<code>uname -r</code>查看当前内核版本)。</p>
<p>重点检查是否有多个版本的 <code>kernel-devel</code>:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ rpm -qa | grep kernel-devel</span><br><span class="line">kernel-devel-3.10.0-327.el7.x86_64</span><br><span class="line">kernel-devel-3.10.0-514.26.2.el7.x86_64</span><br><span class="line">kernel-devel-3.10.0-862.9.1.el7.x86_64</span><br></pre></td></tr></table></figure>

<p>如果存在多个，保证只留跟当前内核版本相同的那个，假设当前内核版本是 <code>3.10.0-862.9.1.el7.x86_64</code>，那么使用 rpm 删除多余的版本:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rpm -e kernel-devel-3.10.0-327.el7.x86_64 kernel-devel-3.10.0-514.26.2.el7.x86_64</span><br></pre></td></tr></table></figure>

<h3 id="使用-systemtap-揪出杀死容器的真凶"><a href="#使用-systemtap-揪出杀死容器的真凶" class="headerlink" title="使用 systemtap 揪出杀死容器的真凶"></a>使用 systemtap 揪出杀死容器的真凶</h3><p>Pod 莫名其妙被杀死? 可以使用 systemtap 来监视进程的信号发送，原理是 systemtap 将脚本翻译成 C 代码然后调用 gcc 编译成 linux 内核模块，再通过 <code>modprobe</code> 加载到内核，根据脚本内容在内核做各种 hook，在这里我们就 hook 一下信号的发送，找出是谁 kill 掉了容器进程。</p>
<p>首先，找到被杀死的 pod 又自动重启的容器的当前 pid，describe 一下 pod:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">......</span><br><span class="line">Container ID:  docker://5fb8adf9ee62afc6d3f6f3d9590041818750b392dff015d7091eaaf99cf1c945</span><br><span class="line">......</span><br><span class="line">Last State:     Terminated</span><br><span class="line">  Reason:       Error</span><br><span class="line">  Exit Code:    137</span><br><span class="line">  Started:      Thu, 05 Sep 2019 19:22:30 +0800</span><br><span class="line">  Finished:     Thu, 05 Sep 2019 19:33:44 +0800</span><br></pre></td></tr></table></figure>

<p>拿到容器 id 反查容器的主进程 pid:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ docker inspect -f &quot;&#123;&#123;.State.Pid&#125;&#125;&quot; 5fb8adf9ee62afc6d3f6f3d9590041818750b392dff015d7091eaaf99cf1c945</span><br><span class="line">7942</span><br></pre></td></tr></table></figure>

<p>通过 <code>Exit Code</code> 可以看出容器上次退出的状态码，如果进程是被外界中断信号杀死的，退出状态码将在 129-255 之间，137 表示进程是被 SIGKILL 信号杀死的，但我们从这里并不能看出是被谁杀死的。</p>
<p>如果问题可以复现，我们可以使用下面的 systemtap 脚本来监视容器是被谁杀死的(保存为<code>sg.stp</code>):</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">global target_pid = 7942</span><br><span class="line">probe signal.send&#123;</span><br><span class="line">  if (sig_pid == target_pid) &#123;</span><br><span class="line">    printf(&quot;%s(%d) send %s to %s(%d)\n&quot;, execname(), pid(), sig_name, pid_name, sig_pid);</span><br><span class="line">    printf(&quot;parent of sender: %s(%d)\n&quot;, pexecname(), ppid())</span><br><span class="line">    printf(&quot;task_ancestry:%s\n&quot;, task_ancestry(pid2task(pid()), 1));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>变量 <code>pid</code> 的值替换为查到的容器主进程 pid</li>
</ul>
<p>运行脚本:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">stap sg.stp</span><br></pre></td></tr></table></figure>

<p>当容器进程被杀死时，脚本捕捉到事件，执行输出:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pkill(23549) send SIGKILL to server(7942)</span><br><span class="line">parent of sender: bash(23495)</span><br><span class="line">task_ancestry:swapper/0(0m0.000000000s)=&gt;systemd(0m0.080000000s)=&gt;vGhyM0(19491m2.579563677s)=&gt;sh(33473m38.074571885s)=&gt;bash(33473m38.077072025s)=&gt;bash(33473m38.081028267s)=&gt;bash(33475m4.817798337s)=&gt;pkill(33475m5.202486630s)</span><br></pre></td></tr></table></figure>

<p>通过观察 <code>task_ancestry</code> 可以看到杀死进程的所有父进程，在这里可以看到有个叫 <code>vGhyM0</code> 的奇怪进程名，通常是中了木马，需要安全专家介入继续排查。</p>
<h2 id="非root用户执行docker命令时提示permission-denied"><a href="#非root用户执行docker命令时提示permission-denied" class="headerlink" title="非root用户执行docker命令时提示permission denied"></a>非root用户执行docker命令时提示permission denied</h2><h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><p>摘自docker mannual上的一段话</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Manage Docker as a non-root user</span><br><span class="line"></span><br><span class="line">The docker daemon binds to a Unix socket instead of a TCP port. By default that Unix socket is owned by the user root and other users can only access it using sudo. The docker daemon always runs as the root user.</span><br><span class="line"></span><br><span class="line">If you don’t want to use sudo when you use the docker command, create a Unix group called docker and add users to it. When the docker daemon starts, it makes the ownership of the Unix socket read/writable by the docker group.</span><br></pre></td></tr></table></figure>

<p>大概的意思就是：docker进程使用Unix Socket而不是TCP端口。而默认情况下，Unix socket属于root用户，需要root权限才能访问。</p>
<h3 id="解决方法1"><a href="#解决方法1" class="headerlink" title="解决方法1"></a>解决方法1</h3><p>使用sudo获取管理员权限，运行docker命令</p>
<h3 id="解决方法2"><a href="#解决方法2" class="headerlink" title="解决方法2"></a>解决方法2</h3><p>docker守护进程启动的时候，会默认赋予名字为docker的用户组读写Unix socket的权限，因此只要创建docker用户组，并将当前用户加入到docker用户组中，那么当前用户就有权限访问Unix socket了，进而也就可以执行docker相关命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo groupadd docker     #添加docker用户组</span><br><span class="line">sudo gpasswd -a $USER docker     #将登陆用户加入到docker用户组中</span><br><span class="line">newgrp docker     #更新用户组</span><br><span class="line">docker ps    #测试docker命令是否可以使用sudo正常使用</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>持续集成</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>解决Hexo置顶问题</title>
    <url>/2019/11/01/%E8%A7%A3%E5%86%B3Hexo%E7%BD%AE%E9%A1%B6%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>为了防止每次更新、安装都要修改代码，现在可以直接从仓库里安装了：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ npm uninstall hexo-generator-index --save</span><br><span class="line">$ npm install hexo-generator-index-pin-top --save</span><br></pre></td></tr></table></figure><p>然后在需要置顶的文章的<code>Front-matter</code>中加上<code>top: true</code>即可。</p><a id="more"></a>



<hr>
<p>考虑到之前的博客有置顶文章，所以需要置顶功能。</p>
<p><code>Google</code>了一下解决方案，发现了本博客主题是支持置顶功能的，在需要置顶的<code>Front-matter</code>中加上<code>top: true</code>即可。试了一下，能置顶。。只是文章置顶在某一页而不是首页。。</p>
<p>期间看到了<code>Pacman</code>主题支持置顶，需要在<code>_config.yml</code>中配置好需要置顶的文章，略麻烦。</p>
<p>然后看到了<code>next</code>主题支持置顶，在博文<code>front-matter</code>中加上<code>sticky: Sticky</code>即可置顶，根据<code>Sticky</code>的大小来决定置顶顺序。</p>
<p>想实现<code>next</code>主题那样的功能，参考了一篇博文<a href="http://ziorix.com/2015/09/09/%E6%B7%BB%E5%8A%A0Hexo%E7%BD%AE%E9%A1%B6%E5%8A%9F%E8%83%BD%E7%9A%84%E6%93%8D%E8%9B%8B3%E5%B0%8F%E6%97%B6/" target="_blank" rel="noopener">添加Hexo置顶功能的操蛋3小时</a>，在<code>hexo-generator-index</code>中增加比较函数比较<code>top</code>值，我试了一下<code>Bug</code>还是有的，置顶文章后文章日期有些会乱掉（比较函数条件比较少）。</p>
<p>我自己写了一个比较函数，也有问题，后来查了一下<code>Javascript</code>的<code>sort</code>函数，其比较函数和<code>C++</code>的完全不同= =</p>
<p><code>C++</code>的比较函数：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">template&lt;class T&gt;bool cmp(T a, T b) &#123;    return  a &lt; b; // 升序，降序的话就 b &gt; a&#125;</span><br></pre></td></tr></table></figure>

<p>而<code>Javascript</code>的比较函数：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cmp(var a, var b) &#123;    return  a - b; // 升序，降序的话就 b - a&#125;</span><br></pre></td></tr></table></figure>

<p>用了<code>C++</code>的比较函数，结果当然会出问题，期间都想重写<code>js</code>的排序函数了。。经过修改，已经能完美置顶了，只需要在<code>front-matter</code>中设置需要置顶文章的<code>top</code>值，将会根据<code>top</code>值大小来选择置顶顺序。（大的在前面）</p>
<p>以下是最终的<code>node_modules/hexo-generator-index/lib/generator.js</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&apos;use strict&apos;;</span><br><span class="line">var pagination = require(&apos;hexo-pagination&apos;);</span><br><span class="line">module.exports = function(locals)&#123;</span><br><span class="line">  var config = this.config;</span><br><span class="line">  var posts = locals.posts;</span><br><span class="line">    posts.data = posts.data.sort(function(a, b) &#123;</span><br><span class="line">        if(a.top &amp;&amp; b.top) &#123; // 两篇文章top都有定义</span><br><span class="line">            if(a.top == b.top) return b.date - a.date; // 若top值一样则按照文章日期降序排</span><br><span class="line">            else return b.top - a.top; // 否则按照top值降序排</span><br><span class="line">        &#125;</span><br><span class="line">        else if(a.top &amp;&amp; !b.top) &#123; // 以下是只有一篇文章top有定义，那么将有top的排在前面（这里用异或操作居然不行233）</span><br><span class="line">            return -1;</span><br><span class="line">        &#125;</span><br><span class="line">        else if(!a.top &amp;&amp; b.top) &#123;</span><br><span class="line">            return 1;</span><br><span class="line">        &#125;</span><br><span class="line">        else return b.date - a.date; // 都没定义按照文章日期降序排</span><br><span class="line">    &#125;);</span><br><span class="line">  var paginationDir = config.pagination_dir || &apos;page&apos;;</span><br><span class="line">  return pagination(&apos;&apos;, posts, &#123;</span><br><span class="line">    perPage: config.index_generator.per_page,</span><br><span class="line">    layout: [&apos;index&apos;, &apos;archive&apos;],</span><br><span class="line">    format: paginationDir + &apos;/%d/&apos;,</span><br><span class="line">    data: &#123;</span><br><span class="line">      __index: true</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>博客</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>K8S部署简介</title>
    <url>/2019/10/31/K8S%E9%83%A8%E7%BD%B2%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>当你在Module2创建了一个Deployment之后，Kuebernetes创建会创建一个<strong>Pod</strong>去托管你的应用实例。一个Pod是一种Kubernetes的抽象，这种抽象代表一组一个或者多个应用的容器（例如Docker或者rkt）,和一些这些容器间的共享资源。<br> 这些资源包括：</p><ul>
<li>共享存储，例如Volumes</li>
<li>网络，例如一个唯一的集群IP地址</li>
<li>关于运行中的每个容器的详细信息，例如容器image版本，容器运行端口</li>
</ul><a id="more"></a>

<p><strong>Pod</strong></p>
<p>一个Pod包括一个指定的应用的“逻辑主机”，能够包含不同的彼此紧密耦合的应用容器。例如，一个Pod也许既包括运行了Nodejs应用的容器，又包括用于提供由Node.js Web服务器发布的数据的不同容器。Pod中的容器共享IP地址和端口空间，他们经常被协同定位和协同调度，而且可以运行在相同Node的共享上下文。</p>
<p>Pods是kubernetes平台的最小单元。当我们在Kubernetes创建了一个部署的时候，Deployment创建内部带有容器的Pods(而不是直接创建容器)。每个Pod与调度它的Node都是强关联的，只有终止或者删除Pod才会销毁。一旦Node发生异常，会从集群上对的其他可用Nodes调取相同的Pod。</p>
<p>总结：</p>
<ul>
<li>Pods</li>
<li>Nodes</li>
<li>Kubectl主要命令</li>
</ul>
<blockquote>
<p>Pod是一个包含应用容器（Docker或者rkt）,内部共享存储（volumes），IP地址和它们的运行信息的集合。</p>
</blockquote>
<p><strong>Nodes</strong><br> 一个Pod通常运行在一个Node上。一个Node是一个在Kubernetes上的工作机器，既可以是虚拟机也可以是物理实体机，依赖于整个集群。每个Node都被Master管理着。一个Node可以有多个pod，而且Kubernetes主站可以做集群内部的跨Nodes的自动调度。主站的自动化调度考虑了每个节点的可用资源。</p>
<p>每个Kubernetes节点至少运行：</p>
<ul>
<li>Kubelet ，一个负责k8s的Master与Node之间通信的进程；它管理着Pods和运行在机器上的容器。</li>
<li>一个运行时容器，例如Docker，rkt，负责从源端拉取容器的image，解压容器，运行程序。</li>
</ul>
<blockquote>
<p>如果容器之间是紧耦合并且需要分享类似硬盘之类的资源的话，则只能将容器安排在一个Pod的。</p>
</blockquote>
<p><strong>kubectl</strong></p>
<p>kubectl问题的解决办法<br> 在单元二中，你使用了Kubectl命令行接口。第三单元中你将继续使用它取获取部署的应用的信息和他们的环境的信息。kubectl最常用的操作如下：</p>
<ul>
<li>kubectl get -列举资源</li>
<li>kubectl describe -展示资源的细节信息</li>
<li>kubectl logs -在pod中打印一个容器的日志</li>
<li>kubectl exec -在pod中执行一个命令</li>
</ul>
<p>当应用被部署的时候，你能够使用这些命令去找问题，去看他们当前的状态是什么，他们运行在哪里，以及他们的详细配置是什么。<br> 现在我们知道了更多集群组件和命令行的信息，让我们一起来探索的应用吧。</p>
<blockquote>
<p>一个node指的是一台k8s上的工作机，可以是VM，也可以是物理机，这取决于开发k8s集群是VM集群还是物理机集群。多个Pod可以运行在同一个Node。</p>
</blockquote>
<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p><strong>一、什么是Pod</strong><br>kubernetes中的一切都可以理解为是一种资源对象，pod，rc，service，都可以理解是 一种资源对象。pod的组成示意图如下，由一个叫”pause“的根容器，加上一个或多个用户自定义的容器构造。pause的状态带便了这一组容器的状态，pod里多个业务容器共享pod的Ip和数据卷。在kubernetes环境下，pod是容器的载体，所有的容器都是在pod中被管理，一个或多个容器放在pod里作为一个单元方便管理。</p>
<p>pod是kubernetes可以部署和管理的最小单元，如果想要运行一个容器，先要为这个容器创建一个pod。同时一个pod也可以包含多个容器，之所以多个容器包含在一个pod里，往往是由于业务上的紧密耦合。【<strong>需要注意】</strong>这里说的场景都非必须把不同的容器放在同一个pod里，但是这样往往更便于管理，甚至后面会讲到的，紧密耦合的业务容器放置在同一个容器里通信效率更高。具体怎么使用还要看实际情况,综合权衡。</p>
<p>在Kubrenetes集群中Pod有如下两种使用方式：<br><strong>a）</strong>一个Pod中运行一个容器。这是最常见用法。在这种方式中，你可以把Pod想象成是单个容器的封装，kuberentes管理的是Pod而不是直接管理容器。<br><strong>b）</strong>在一个Pod中同时运行多个容器。当多个应用之间是紧耦合的关系时，可以将多个应用一起放在一个Pod中，同个Pod中的多个容器之间互相访问可以通过localhost来通信（可以把Pod理解成一个虚拟机，共享网络和存储卷）。也就是说一个Pod中也可以同时封装几个需要紧密耦合互相协作的容器，它们之间共享资源。这些在同一个Pod中的容器可以互相协作成为一个service单位 (即一个容器共享文件），另一个“sidecar”容器来更新这些文件。Pod将这些容器的存储资源作为一个实体来管理。</p>
<p>就像每个应用容器，pod被认为是临时实体。在Pod的生命周期中，pod被创建后，被分配一个唯一的ID（UID），调度到节点上，并一致维持期望的状态直到被终结（根据重启策略）或者被删除。如果node死掉了，分配到了这个node上的pod，在经过一个超时时间后会被重新调度到其他node节点上。一个给定的pod（如UID定义的）不会被“重新调度”到新的节点上，而是被一个同样的pod取代，如果期望的话甚至可以是相同的名字，但是会有一个新的UID（查看replication controller获取详情）。</p>
<p><strong>kubernetes为什么使用pod作为最小单元，而不是container</strong><br>直接部署一个容器看起来更简单，但是这里也有更好的原因为什么在容器基础上抽象一层呢？根本原因是为了管理容器，kubernetes需要更多的信息，比如重启策略，它定义了容器终止后要采取的策略;或者是一个可用性探针，从应用程序的角度去探测是否一个进程还存活着。基于这些原因，kubernetes架构师决定使用一个新的实体，也就是pod，而不是重载容器的信息添加更多属性，用来在逻辑上包装一个或者多个容器的管理所需要的信息。</p>
<p><strong>kubernetes为什么允许一个pod里有多个容器</strong><br>pod里的容器运行在一个逻辑上的”主机”上，它们使用相同的网络名称空间 (即同一pod里的容器使用相同的ip和相同的端口段区间) 和相同的IPC名称空间。它们也可以共享存储卷。这些特性使它们可以更有效的通信，并且pod可以使你把紧密耦合的应用容器作为一个单元来管理。也就是说当多个应用之间是紧耦合关系时，可以将多个应用一起放在一个Pod中，同个Pod中的多个容器之间互相访问可以通过localhost来通信（可以把Pod理解成一个虚拟机，共享网络和存储卷）。</p>
<p>因此当一个应用如果需要多个运行在同一主机上的容器时，为什么不把它们放在同一个容器里呢?首先，这样何故违反了一个容器只负责一个应用的原则。这点非常重要，如果我们把多个应用放在同一个容器里，这将使解决问题变得非常麻烦，因为它们的日志记录混合在了一起，并且它们的生命周期也很难管理。因此一个应用使用多个容器将更简单，更透明，并且使应用依赖解偶。并且粒度更小的容器更便于不同的开发团队共享和复用。</p>
<p><strong>【需要注意】</strong>这里说到为了解偶把应用分别放在不同容器里，前面我们也强调为了便于管理管紧耦合的应用把它们的容器放在同一个pod里。一会<strong>强调耦合</strong>，一个<strong>强调解偶</strong>看似矛盾，实际上普遍存在，高内聚低耦合是我们的追求，然而一个应用的业务逻辑模块不可能完全完独立不存在耦合，这就需要我们从实际上来考量，做出决策。</p>
<p>因为，虽然可以使用一个pod来承载一个多层应用，但是更建议使用不同的pod来承载不同的层，因这这样你可以为每一个层单独扩容并且把它们分布到集群的不同节点上。</p>
<p><strong>Pod中如何管理多个容器</strong><br>Pod中可以同时运行多个进程（作为容器运行）协同工作，同一个Pod中的容器会自动的分配到同一个 node 上，同一个Pod中的容器共享资源、网络环境和依赖，它们总是被同时调度。需要注意：一个Pod中同时运行多个容器是一种比较高级的用法。只有当你的容器需要紧密配合协作的时候才考虑用这种模式。</p>
<p>Pod中共享的环境包括Linux的namespace，cgroup和其他可能的隔绝环境，这一点跟Docker容器一致。在Pod的环境中，每个容器中可能还有更小的子隔离环境。Pod中的容器共享IP地址和端口号，它们之间可以通过localhost互相发现。它们之间可以通过进程间通信，需要明白的是同一个Pod下的容器是通过lo网卡进行通信。例如SystemV信号或者POSIX共享内存。不同Pod之间的容器具有不同的IP地址，不能直接通过IPC通信。Pod中的容器也有访问共享volume的权限，这些volume会被定义成pod的一部分并挂载到应用容器的文件系统中。</p>
<p><strong>总而言之。Pod中可以共享两种资源：网络 和 存储</strong><br><strong>1.</strong> 网络：每个Pod都会被分配一个唯一的IP地址。Pod中的所有容器共享网络空间，包括IP地址和端口。Pod内部的容器可以使用localhost互相通信。Pod中的容器与外界通信时，必须分配共享网络资源（例如使用宿主机的端口映射）。<br><strong>2.</strong> 存储：可以Pod指定多个共享的Volume。Pod中的所有容器都可以访问共享的volume。Volume也可以用来持久化Pod中的存储资源，以防容器重启后文件丢失。</p>
<p><strong>容器的依赖关系和启动顺序</strong><br>当前,同一个pod里的所有容器都是并行启动并且没有办法确定哪一个容器必须早于哪一个容器启动。如果要想确保第一个容器早于第二个容器启动，那么就要使用到”init container”了。</p>
<p><strong>同一pod的容器间网络通信</strong><br>同一pod下的容器使用相同的网络名称空间,这就意味着他们可以通过”localhost”来进行通信,它们共享同一个Ip和相同的端口空间。</p>
<p><strong>同一个pod暴露多个容器</strong><br>通常pod里的容器监听不同的端口,想要被外部访问都需要暴露出去.你可以通过在一个服务里暴露多个端口或者使用不同的服务来暴露不同的端口来实现。</p>
<p><strong>二、如何使用Pod</strong><br>通常把Pod分为两类：<br><strong>-</strong>  自主式Pod ：这种Pod本身是不能自我修复的，当Pod被创建后（不论是由你直接创建还是被其他Controller），都会被Kuberentes调度到集群的Node上。直到Pod的进程终止、被删掉、因为缺少资源而被驱逐、或者Node故障之前这个Pod都会一直保持在那个Node上。Pod不会自愈。如果Pod运行的Node故障，或者是调度器本身故障，这个Pod就会被删除。同样的，如果Pod所在Node缺少资源或者Pod处于维护状态，Pod也会被驱逐。<br><strong>-</strong>  控制器管理的Pod：Kubernetes使用更高级的称为Controller的抽象层，来管理Pod实例。Controller可以创建和管理多个Pod，提供副本管理、滚动升级和集群级别的自愈能力。例如，如果一个Node故障，Controller就能自动将该节点上的Pod调度到其他健康的Node上。虽然可以直接使用Pod，但是在Kubernetes中通常是使用Controller来管理Pod的。如下图：</p>
<p>每个Pod都有一个特殊的被称为”根容器”的Pause 容器。 Pause容器对应的镜像属于Kubernetes平台的一部分，除了Pause容器，每个Pod还包含一个或者多个紧密相关的用户业务容器。</p>
<p><img src="/2019/10/31/K8S%E9%83%A8%E7%BD%B2%E7%AE%80%E4%BB%8B/907596-20190822141807065-1338384811-1572435175011.png" alt="img"></p>
<p><strong>Kubernetes设计这样的Pod概念和特殊组成结构有什么用意呢？</strong><br><strong>原因一</strong>：在一组容器作为一个单元的情况下，难以对整体的容器简单地进行判断及有效地进行行动。比如一个容器死亡了，此时是算整体挂了么？那么引入与业务无关的Pause容器作为Pod的根容器，以它的状态代表着整个容器组的状态，这样就可以解决该问题。<br><strong>原因二</strong>：Pod里的多个业务容器共享Pause容器的IP，共享Pause容器挂载的Volume，这样简化了业务容器之间的通信问题，也解决了容器之间的文件共享问题。</p>
<p><strong>1. Pod的持久性和终止</strong><br><strong>-  Pod的持久性</strong><br>Pod在设计上就不是作为持久化实体的。在调度失败、节点故障、缺少资源或者节点维护的状态下都会死掉会被驱逐。通常，用户不需要手动直接创建Pod，而是应该使用controller（例如Deployments），即使是在创建单个Pod的情况下。Controller可以提供集群级别的自愈功能、复制和升级管理。</p>
<p><strong>-  Pod的终止</strong><br>因为Pod作为在集群的节点上运行的进程，所以在不再需要的时候能够优雅的终止掉是十分必要的（比起使用发送KILL信号这种暴力的方式）。用户需要能够放松删除请求，并且知道它们何时会被终止，是否被正确的删除。用户想终止程序时发送删除pod的请求，在pod可以被强制删除前会有一个宽限期，会发送一个TERM请求到每个容器的主进程。一旦超时，将向主进程发送KILL信号并从API server中删除。如果kubelet或者container manager在等待进程终止的过程中重启，在重启后仍然会重试完整的宽限期。</p>
<p>示例流程如下：</p>
<ul>
<li>用户发送删除pod的命令，默认宽限期是30秒；</li>
<li>在Pod超过该宽限期后API server就会更新Pod的状态为”dead”；</li>
<li>在客户端命令行上显示的Pod状态为”terminating”；</li>
<li>跟第三步同时，当kubelet发现pod被标记为”terminating”状态时，开始停止pod进程：</li>
</ul>
<ol>
<li>如果在pod中定义了preStop hook，在停止pod前会被调用。如果在宽限期过后，preStop hook依然在运行，第二步会再增加2秒的宽限期；</li>
<li>向Pod中的进程发送TERM信号；</li>
</ol>
<ul>
<li>跟第三步同时，该Pod将从该service的端点列表中删除，不再是replication controller的一部分。关闭的慢的pod将继续处理load balancer转发的流量；</li>
<li>过了宽限期后，将向Pod中依然运行的进程发送SIGKILL信号而杀掉进程。</li>
<li>Kublete会在API server中完成Pod的的删除，通过将优雅周期设置为0（立即删除）。Pod在API中消失，并且在客户端也不可见。</li>
</ul>
<p>删除宽限期默认是30秒。 kubectl delete命令支持 –grace-period=<seconds> 选项，允许用户设置自己的宽限期。如果设置为0将强制删除pod。在kubectl&gt;=1.5版本的命令中，你必须同时使用 –force 和 –grace-period=0 来强制删除pod。</seconds></p>
<p>Pod的强制删除是通过在集群和etcd中将其定义为删除状态。当执行强制删除命令时，API server不会等待该pod所运行在节点上的kubelet确认，就会立即将该pod从API server中移除，这时就可以创建跟原pod同名的pod了。这时，在节点上的pod会被立即设置为terminating状态，不过在被强制删除之前依然有一小段优雅删除周期。<strong>【需要注意：</strong>如果删除一个pod后，再次查看发现pod还在，这是因为在deployment.yaml文件中定义了副本数量！还需要删除deployment才行。即：”kubectl delete pod pod-name -n namespace” &amp;&amp; “kubectl delete deployment deployment-name -n namespace”】</p>
<p><strong>2.  Pause容器</strong><br>Pause容器，又叫Infra容器。我们检查node节点的时候会发现每个node节点上都运行了很多的pause容器，例如如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@k8s-node01 ~]# docker ps |grep pause</span><br><span class="line">0cbf85d4af9e    k8s.gcr.io/pause:3.1   &quot;/pause&quot;     7 days ago  Up 7 days   k8s_POD_myapp-848b5b879b-ksgnv_default_0af41a40-a771-11e8-84d2-000c2972dc1f_0</span><br><span class="line">d6e4d77960a7    k8s.gcr.io/pause:3.1   &quot;/pause&quot;     7 days ago  Up 7 days   k8s_POD_myapp-848b5b879b-5f69p_default_09bc0ba1-a771-11e8-84d2-000c2972dc1f_0</span><br><span class="line">5f7777c55d2a    k8s.gcr.io/pause:3.1   &quot;/pause&quot;     7 days ago  Up 7 days   k8s_POD_kube-flannel-ds-pgpr7_kube-system_23dc27e3-a5af-11e8-84d2-000c2972dc1f_1</span><br><span class="line">8e56ef2564c2    k8s.gcr.io/pause:3.1   &quot;/pause&quot;     7 days ago  Up 7 days   k8s_POD_client2_default_17dad486-a769-11e8-84d2-000c2972dc1f_1</span><br><span class="line">7815c0d69e99    k8s.gcr.io/pause:3.1   &quot;/pause&quot;     7 days ago  Up 7 days   k8s_POD_nginx-deploy-5b595999-872c7_default_7e9df9f3-a6b6-11e8-84d2-000c2972dc1f_2</span><br><span class="line">b4e806fa7083    k8s.gcr.io/pause:3.1   &quot;/pause&quot;     7 days ago  Up 7 days   k8s_POD_kube-proxy-vxckf_kube-system_23dc0141-a5af-11e8-84d2-000c2972dc1f_2</span><br></pre></td></tr></table></figure>



<p>kubernetes中的pause容器主要为每个业务容器提供以下功能：<br>-  在pod中担任Linux命名空间共享的基础；<br>-  启用pid命名空间，开启init进程；</p>
<p><img src="/2019/10/31/K8S%E9%83%A8%E7%BD%B2%E7%AE%80%E4%BB%8B/907596-20190807115119558-339829150-1572435175045.png" alt="img"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">示例如下：</span><br><span class="line">[root@k8s-node01 ~]# docker run -d --name pause -p 8880:80 k8s.gcr.io/pause:3.1</span><br><span class="line"> </span><br><span class="line">[root@k8s-node01 ~]# docker run -d --name nginx -v `pwd`/nginx.conf:/etc/nginx/nginx.conf --net=container:pause --ipc=container:pause --pid=container:pause nginx</span><br><span class="line"> </span><br><span class="line">[root@k8s-node01 ~]#  docker run -d --name ghost --net=container:pause --ipc=container:pause --pid=container:pause ghost</span><br><span class="line"> </span><br><span class="line">现在访问http://****:8880/就可以看到ghost博客的界面了。</span><br><span class="line"> </span><br><span class="line">解析说明：</span><br><span class="line">pause容器将内部的80端口映射到宿主机的8880端口，pause容器在宿主机上设置好了网络namespace后，nginx容器加入到该网络namespace中，我们看到nginx容器启动的时候指定了</span><br><span class="line">--net=container:pause，ghost容器同样加入到了该网络namespace中，这样三个容器就共享了网络，互相之间就可以使用localhost直接通信，</span><br><span class="line">--ipc=contianer:pause --pid=container:pause就是三个容器处于同一个namespace中，init进程为pause</span><br><span class="line"> </span><br><span class="line">这时我们进入到ghost容器中查看进程情况。</span><br><span class="line">[root@k8s-node01 ~]# docker exec -it ghost /bin/bash</span><br><span class="line">root@d3057ceb54bc:/var/lib/ghost# ps axu</span><br><span class="line">USER        PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</span><br><span class="line">root          1  0.0  0.0   1012     4 ?        Ss   03:48   0:00 /pause</span><br><span class="line">root          6  0.0  0.0  32472   780 ?        Ss   03:53   0:00 nginx: master process nginx -g daemon off;</span><br><span class="line">systemd+     11  0.0  0.1  32932  1700 ?        S    03:53   0:00 nginx: worker process</span><br><span class="line">node         12  0.4  7.5 1259816 74868 ?       Ssl  04:00   0:07 node current/index.js</span><br><span class="line">root         77  0.6  0.1  20240  1896 pts/0    Ss   04:29   0:00 /bin/bash</span><br><span class="line">root         82  0.0  0.1  17496  1156 pts/0    R+   04:29   0:00 ps axu</span><br><span class="line"> </span><br><span class="line">在ghost容器中同时可以看到pause和nginx容器的进程，并且pause容器的PID是1。而在kubernetes中容器的PID=1的进程即为容器本身的业务进程。</span><br></pre></td></tr></table></figure>



<p><strong>3.  Init容器</strong><br>Pod 能够具有多个容器，应用运行在容器里面，但是它也可能有一个或多个<strong>先于</strong>应用容器启动的 Init 容器。init容器是一种专用的容器，在应用容器启动之前运行，可以包含普通容器映像中不存在的应用程序或安装脚本。init容器会优先启动，待里面的任务完成后容器就会退出。    init容器配置示例如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: init-demo</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: nginx</span><br><span class="line">    image: nginx</span><br><span class="line">    ports:</span><br><span class="line">    - containerPort: 80</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: workdir</span><br><span class="line">      mountPath: /usr/share/nginx/html</span><br><span class="line">  # These containers are run during pod initialization</span><br><span class="line">  initContainers:</span><br><span class="line">  - name: install</span><br><span class="line">    image: busybox</span><br><span class="line">    command:</span><br><span class="line">    - wget</span><br><span class="line">    - &quot;-O&quot;</span><br><span class="line">    - &quot;/work-dir/index.html&quot;</span><br><span class="line">    - http://kubernetes.io</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: workdir</span><br><span class="line">      mountPath: &quot;/work-dir&quot;</span><br><span class="line">  dnsPolicy: Default</span><br><span class="line">  volumes:</span><br><span class="line">  - name: workdir</span><br><span class="line">    emptyDir: &#123;&#125;</span><br></pre></td></tr></table></figure>



<ol>
<li>理解init容器</li>
</ol>
<ul>
<li>它们总是运行到完成。</li>
<li>每个都必须在下一个启动之前成功完成。</li>
<li>如果 Pod 的 Init 容器失败，Kubernetes 会不断地重启该 Pod，直到 Init 容器成功为止。然而，如果 Pod 对应的 restartPolicy 为 Never，它不会重新启动。</li>
<li>Init 容器支持应用容器的全部字段和特性，但不支持 Readiness Probe，因为它们必须在 Pod 就绪之前运行完成。</li>
<li>如果为一个 Pod 指定了多个 Init 容器，那些容器会按顺序一次运行一个。 每个 Init 容器必须运行成功，下一个才能够运行。</li>
<li>因为 Init 容器可能会被重启、重试或者重新执行，所以 Init 容器的代码应该是幂等的。 特别地，被写到 EmptyDirs 中文件的代码，应该对输出文件可能已经存在做好准备。</li>
<li>在 Pod 上使用 activeDeadlineSeconds，在容器上使用 livenessProbe，这样能够避免 Init 容器一直失败。 这就为 Init 容器活跃设置了一个期限。</li>
<li>在 Pod 中的每个 app 和 Init 容器的名称必须唯一；与任何其它容器共享同一个名称，会在验证时抛出错误。</li>
<li>对 Init 容器 spec 的修改，被限制在容器 image 字段中。 更改 Init 容器的 image 字段，等价于重启该 Pod。</li>
</ul>
<p>一个pod可以包含多个普通容器和多个init容器，在Pod中所有容器的名称必须唯一，init容器在普通容器启动前顺序执行，如果init容器失败，则认为pod失败，K8S会根据pod的重启策略来重启这个容器，直到成功。</p>
<p>Init容器需要在pod.spec中的initContainers数组中定义（与3pod.spec.containers数组相似）。init容器的状态在.status.initcontainerStatus字段中作为容器状态的数组返回（与status.containerStatus字段类似）。init容器支持普通容器的所有字段和功能，除了readinessprobe。Init 容器只能修改image 字段，修改image 字段等于重启 Pod，Pod 重启所有Init 容器必须重新执行。 </p>
<p>如果Pod的Init容器失败，Kubernetes会不断地重启该Pod，直到Init容器成功为止。然而如果Pod对应的restartPolicy为Never，则它不会重新启动。所以在Pod上使用activeDeadlineSeconds，在容器上使用livenessProbe，相当于为Init容器活跃设置了一个期限，能够避免Init容器一直失败。</p>
<p><strong>2.  Init容器与普通容器的不同之处</strong><br>Init 容器与普通的容器非常像，除了如下两点：<br>- Init 容器总是运行到成功完成为止。<br>- 每个 Init 容器都必须在下一个 Init 容器启动之前成功完成。</p>
<p>Init 容器支持应用容器的全部字段和特性，包括资源限制、数据卷和安全设置。 然而，Init 容器对资源请求和限制的处理稍有不同， 而且 Init 容器不支持 Readiness Probe，因为它们必须在 Pod 就绪之前运行完成。如果为一个 Pod 指定了多个 Init 容器，那些容器会按顺序一次运行一个。 每个 Init 容器必须运行成功，下一个才能够运行。 当所有的 Init 容器运行完成时，Kubernetes 初始化 Pod 并像平常一样运行应用容器。</p>
<ol start="3">
<li>Init 容器能做什么<br>因为 Init 容器具有与应用容器分离的单独镜像，它们的启动相关代码具有如下优势：</li>
</ol>
<ul>
<li>它们可以包含并运行实用工具，处于安全考虑，是不建议在应用容器镜像中包含这些实用工具的。</li>
<li>它们可以包含实用工具和定制化代码来安装，但不能出现在应用镜像中。例如创建镜像没必要FROM另一个镜像，只需要在安装中使用类似sed，awk、 python 或dig这样的工具。</li>
<li>应用镜像可以分离出创建和部署的角色，而没有必要联合它们构建一个单独的镜像。</li>
<li>它们使用 Linux Namespace，所以对应用容器具有不同的文件系统视图。因此，它们能够具有访问 Secret 的权限，而应用容器不能够访问。</li>
<li>它们在应用容器启动之前运行完成，然而应用容器并行运行，所以 Init 容器提供了一种简单的方式来阻塞或延迟应用容器的启动，直到满足了一组先决条件。</li>
</ul>
<p><strong>4.  静态pod</strong><br>静态Pod是由kubelet进行管理，仅存在于特定Node上的Pod。它们不能通过API Server进行管理，无法与ReplicationController、Deployment或DaemonSet进行关联，并且kubelet也无法对其健康检查。静态Pod总是由kubelet创建，并且总在kubelet所在的Node上运行。创建静态Pod的方式：<strong>使用配置文件方式</strong> 或 <strong>HTTP方式</strong>。一般常使用的是配置文件方式。</p>
<p>-  通过配置文件创建<br>配置文件只是特定目录中json或yaml格式的标准pod定义。它通过在kubelet守护进程中添加配置参数–pod-manifest-path=<the directory> 来运行静态Pod，kubelet经常会它定期扫描目录；例如，如何将一个简单web服务作为静态pod启动？</the></p>
<p>选择运行静态pod的节点服务器，不一定是node节点，只要有kubelet进程所在的节点都可以运行静态pod。可以在某个节点上创建一个放置一个Web服务器pod定义的描述文件文件夹，例如/etc/kubelet.d/static-web.yaml</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># mkdir /etc/kubelet.d/</span><br><span class="line"># vim /etc/kubelet.d/static-web.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: static-web</span><br><span class="line">  labels:</span><br><span class="line">    role: myrole</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">    - name: web</span><br><span class="line">      image: nginx</span><br><span class="line">      ports:</span><br><span class="line">        - name: web</span><br><span class="line">          containerPort: 80</span><br><span class="line">          protocol: TCP&lt;br&gt;</span><br><span class="line">#ls /etc/kubelet.d/</span><br><span class="line">static-web.yaml</span><br></pre></td></tr></table></figure>



<p>通过使用–pod-manifest-path=/etc/kubelet.d/参数运行它，在节点上配置我的kubelet守护程序以使用此目录。比如这里kubelet启动参数位/etc/systemd/system/kubelet.service.d/10-kubelet.conf, 修改配置，然后将参数加入到现有参数配置项中(安装方式不尽相同，但是道理一样)。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># vim /etc/systemd/system/kubelet.service.d/10-kubelet.conf</span><br><span class="line">······</span><br><span class="line">······</span><br><span class="line">Environment=&quot;KUBELET_EXTRA_ARGS=--cluster-dns=10.96.0.10 --cluster-domain=cluster.local --pod-manifest-path=/etc/kubelet.d/&quot;</span><br><span class="line">······</span><br><span class="line">······</span><br></pre></td></tr></table></figure>



<p>保存退出，reload一下systemd daeomon ,重启kubelet服务进程</p>
<p><code>#systemctl daemon-reload</code></p>
<p><code># systemctl restart kubelet</code></p>
<p>前面说了，当kubelet启动时，它会自动启动在指定的目录–pod-manifest-path=或–manifest-url=参数中定义的所有pod ，即我们的static-web。接着在该节点上检查是否创建成功：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># kubectl get pods -o wide</span><br><span class="line">NAME                READY     STATUS    RESTARTS   AGE       IP            NODE   </span><br><span class="line">static-web-k8s-m1   1/1       Running   0          2m        10.244.2.32   k8s-m1</span><br></pre></td></tr></table></figure>



<p>上面也提到了，它不归任何部署方式来管理，即使我们尝试kubelet命令去删除</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># kubectl delete pod static-web-k8s-m1</span><br><span class="line">pod &quot;static-web-k8s-m1&quot; deleted</span><br><span class="line"> </span><br><span class="line"># kubectl get pods -o wide</span><br><span class="line">NAME                READY     STATUS    RESTARTS   AGE       IP        NODE      NOMINATED NODE</span><br><span class="line">static-web-k8s-m1   0/1       Pending   0          2s        &lt;none&gt;    k8s-m1    &lt;none&gt;</span><br></pre></td></tr></table></figure>



<p>可以看出静态pod通过这种方式是没法删除的</p>
<p>那我如何去删除或者说是动态的添加一个pod呢？这种机制已经知道，kubelet进程会定期扫描配置的目录（/etc/kubelet.d在我的示例）以进行更改，并在文件出现/消失在此目录中时添加/删除pod。</p>
<p><strong>5. Pod容器共享Volume</strong><br>同一个Pod中的多个容器可以共享Pod级别的存储卷Volume,Volume可以定义为各种类型，多个容器各自进行挂载，将Pod的Volume挂载为容器内部需要的目录。例如：Pod级别的Volume:”app-logs”,用于tomcat向其中写日志文件，busybox读日志文件。</p>
<p><img src="/2019/10/31/K8S%E9%83%A8%E7%BD%B2%E7%AE%80%E4%BB%8B/907596-20190806180355283-1507086359-1572435175020.png" alt="img"></p>
<p>pod-volumes-applogs.yaml文件的配置内容</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: volume-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: tomcat</span><br><span class="line">    image: tomcat</span><br><span class="line">    ports:</span><br><span class="line">    - containerPort: 8080</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: app-logs</span><br><span class="line">      mountPath: /usr/local/tomcat/logs</span><br><span class="line">  - name: busybox</span><br><span class="line">    image: busybox</span><br><span class="line">    command: [&quot;sh&quot;,&quot;-c&quot;,&quot;tailf /logs/catalina*.log&quot;]</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: app-logs</span><br><span class="line">      mountPath: /logs</span><br><span class="line">  volumes:</span><br><span class="line">  - name: app-logs</span><br><span class="line">    emptuDir: &#123;&#125;</span><br></pre></td></tr></table></figure>



<p>查看日志</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># kubectl logs &lt;pod_name&gt; -c &lt;container_name&gt;</span><br><span class="line"># kubectl exec -it &lt;pod_name&gt; -c &lt;container_name&gt; – tail /usr/local/tomcat/logs/catalina.xx.log</span><br></pre></td></tr></table></figure>

<p><strong>6. Pod的配置管理</strong><br>Kubernetes v1.2的版本提供统一的集群配置管理方案 – ConfigMap：容器应用的配置管理</p>
<p>ConfigMap使用场景：<br>-  生成为容器内的环境变量。<br>-  设置容器启动命令的启动参数（需设置为环境变量）。<br>-  以Volume的形式挂载为容器内部的文件或目录。</p>
<p>ConfigMap以一个或多个key:value的形式保存在kubernetes系统中供应用使用，既可以表示一个变量的值（例如：apploglevel=info），也可以表示完整配置文件的内容（例如：server.xml=&lt;?xml…&gt;…）。可以通过yaml配置文件或者使用kubectl create configmap命令的方式创建ConfigMap。</p>
<p><strong>3.1）创建ConfigMap</strong><br>通过yaml文件方式<br>cm-appvars.yaml</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: cm-appvars</span><br><span class="line">data:</span><br><span class="line">  apploglevel: info</span><br><span class="line">  appdatadir: /var/data</span><br></pre></td></tr></table></figure>



<p>常用命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># kubectl create -f cm-appvars.yaml</span><br><span class="line"></span><br><span class="line"># kubectl get configmap</span><br><span class="line"></span><br><span class="line"># kubectl describe configmap cm-appvars</span><br><span class="line"></span><br><span class="line"># kubectl get configmap cm-appvars -o yaml</span><br></pre></td></tr></table></figure>



<p>通过kubectl命令行方式<br>通过kubectl create configmap创建，使用参数–from-file或–from-literal指定内容，可以在一行中指定多个参数。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）通过–from-file参数从文件中进行创建，可以指定key的名称，也可以在一个命令行中创建包含多个key的ConfigMap。</span><br><span class="line"># kubectl create configmap NAME --from-file=[key=]source --from-file=[key=]source</span><br><span class="line"> </span><br><span class="line">2）通过–from-file参数从目录中进行创建，该目录下的每个配置文件名被设置为key，文件内容被设置为value。</span><br><span class="line"># kubectl create configmap NAME --from-file=config-files-dir</span><br><span class="line"> </span><br><span class="line">3）通过–from-literal从文本中进行创建，直接将指定的key=value创建为ConfigMap的内容。</span><br><span class="line"># kubectl create configmap NAME --from-literal=key1=value1 --from-literal=key2=value2</span><br></pre></td></tr></table></figure>



<p><strong>容器应用对ConfigMap的使用有两种方法：</strong><br>- 通过环境变量获取ConfigMap中的内容。<br>- 通过Volume挂载的方式将ConfigMap中的内容挂载为容器内部的文件或目录。</p>
<p>通过环境变量的方式<br>ConfigMap的yaml文件: cm-appvars.yaml</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: cm-appvars</span><br><span class="line">data:</span><br><span class="line">  apploglevel: info</span><br><span class="line">  appdatadir: /var/data</span><br></pre></td></tr></table></figure>



<p>Pod的yaml文件：cm-test-pod.yaml</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: cm-test-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: cm-test</span><br><span class="line">    image: busybox</span><br><span class="line">    command: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;env|grep APP&quot;]</span><br><span class="line">    env:</span><br><span class="line">    - name: APPLOGLEVEL</span><br><span class="line">      valueFrom:</span><br><span class="line">        configMapKeyRef:</span><br><span class="line">          name: cm-appvars</span><br><span class="line">          key: apploglevel</span><br><span class="line">    - name: APPDATADIR</span><br><span class="line">      valueFrom:</span><br><span class="line">        configMapKeyRef:</span><br><span class="line">          name: cm-appvars</span><br><span class="line">          key: appdatadir</span><br></pre></td></tr></table></figure>



<p>创建命令：<br># kubectl create -f cm-test-pod.yaml<br># kubectl get pods –show-all<br># kubectl logs cm-test-pod</p>
<p>使用ConfigMap的限制条件</p>
<ul>
<li>ConfigMap必须在Pod之前创建</li>
<li>ConfigMap也可以定义为属于某个Namespace。只有处于相同Namespace中的Pod可以引用它。</li>
<li>kubelet只支持可以被API Server管理的Pod使用ConfigMap。静态Pod无法引用。</li>
<li>在Pod对ConfigMap进行挂载操作时，容器内只能挂载为“目录”，无法挂载为文件。</li>
</ul>
<p><strong>7. Pod的生命周期</strong></p>
<p><strong>-  Pod的状态</strong><br>pod从创建到最后的创建成功会分别处于不同的阶段，下面是Pod的生命周期示意图，从图中可以看到Pod状态的变化：</p>
<p><img src="/2019/10/31/K8S%E9%83%A8%E7%BD%B2%E7%AE%80%E4%BB%8B/907596-20190807200525601-1625049545-1572435175028.png" alt="img"></p>
<p>挂起或等待中 (Pending)：API Server创建了Pod资源对象并已经存入了etcd中，但是它并未被调度完成，或者仍然处于从仓库下载镜像的过程中。这时候Pod 已被 Kubernetes 系统接受，但有一个或者多个容器镜像尚未创建。等待时间包括调度 Pod 的时间和通过网络下载镜像的时间，这可能需要花点时间。创建pod的请求已经被k8s接受，但是容器并没有启动成功，可能处在：写数据到etcd，调度，pull镜像，启动容器这四个阶段中的任何一个阶段，pending伴随的事件通常会有：ADDED, Modified这两个事件的产生。<br>运行中 (Running)：该 Pod 已经被调度到了一个node节点上，Pod 中所有的容器都已被kubelet创建完成。至少有一个容器正在运行，或者正处于启动或重启状态。<br>正常终止 (Succeeded)：pod中的所有的容器已经正常的自行退出，并且k8s永远不会自动重启这些容器，一般会是在部署job的时候会出现。<br>异常停止 (Failed)：Pod 中的所有容器都已终止了，并且至少有一个容器是因为失败终止。也就是说，容器以非0状态退出或者被系统终止。<br>未知状态 (Unkonwn)：出于某种原因，无法获得Pod的状态，通常是由于与Pod主机通信时出错。</p>
<p><strong>-  Pod的创建过程</strong><br>Pod是Kubernetes的基础单元，了解其创建的过程，更有助于理解系统的运作。创建Pod的整个流程的时序图如下：</p>
<p><img src="/2019/10/31/K8S%E9%83%A8%E7%BD%B2%E7%AE%80%E4%BB%8B/907596-20190822142318956-312003948-1572435175036.png" alt="img"></p>
<p>① 用户通过kubectl客户端提交Pod Spec给API Server。<br>② API Server尝试将Pod对象的相关信息存储到etcd中，等待写入操作完成，API Server返回确认信息到客户端。<br>③ API Server开始反映etcd中的状态变化。<br>④ 所有的Kubernetes组件通过”watch”机制跟踪检查API Server上的相关信息变动。<br>⑤ kube-scheduler（调度器）通过其”watcher”检测到API Server创建了新的Pod对象但是没有绑定到任何工作节点。<br>⑥ kube-scheduler为Pod对象挑选一个工作节点并将结果信息更新到API Server。<br>⑦ 调度结果新消息由API Server更新到etcd，并且API Server也开始反馈该Pod对象的调度结果。<br>⑧ Pod被调度到目标工作节点上的kubelet尝试在当前节点上调用docker engine进行启动容器，并将容器的状态结果返回到API Server。<br>⑨ API Server将Pod信息存储到etcd系统中。<br>⑩ 在etcd确认写入操作完成，API Server将确认信息发送到相关的kubelet。</p>
<p>Pod常规的排查：<a href="https://feisky.gitbooks.io/kubernetes/troubleshooting/pod.html" target="_blank" rel="noopener">见这里</a></p>
<p>一个pod的完整创建，通常会伴随着各种事件的产生，kubernetes事件的种类总共只有4种：<br>Added EventType = “ADDED”<br>Modified EventType = “MODIFIED”<br>Deleted EventType = “DELETED”<br>Error EventType = “ERROR”</p>
<p>PodStatus 有一组PodConditions。 PodCondition中的ConditionStatus，它代表了当前pod是否处于某一个阶段（PodScheduled，Ready，Initialized，Unschedulable），”true” 表示处于，”false”表示不处于。PodCondition数组的每个元素都有一个类型字段和一个状态字段。</p>
<p>类型字段 PodConditionType  是一个字符串，可能的值是:<br>PodScheduled：pod正处于调度中，刚开始调度的时候，hostip还没绑定上，持续调度之后，有合适的节点就会绑定hostip，然后更新etcd数据<br>Ready: pod 已经可以开始服务，譬如被加到负载均衡里面<br>Initialized：所有pod 中的初始化容器已经完成了<br>Unschedulable：限制不能被调度，譬如现在资源不足</p>
<p>状态字段 ConditionStatus  是一个字符串，可能的值为True，False和Unknown</p>
<p>Pod的ERROR事件的情况大概有：<br>CrashLoopBackOff： 容器退出，kubelet正在将它重启<br>InvalidImageName： 无法解析镜像名称<br>ImageInspectError： 无法校验镜像<br>ErrImageNeverPull： 策略禁止拉取镜像<br>ImagePullBackOff： 正在重试拉取<br>RegistryUnavailable： 连接不到镜像中心<br>ErrImagePull： 通用的拉取镜像出错<br>CreateContainerConfigError： 不能创建kubelet使用的容器配置<br>CreateContainerError： 创建容器失败<br>m.internalLifecycle.PreStartContainer  执行hook报错<br>RunContainerError： 启动容器失败<br>PostStartHookError： 执行hook报错<br>ContainersNotInitialized： 容器没有初始化完毕<br>ContainersNotReady： 容器没有准备完毕<br>ContainerCreating：容器创建中<br>PodInitializing：pod 初始化中<br>DockerDaemonNotReady：docker还没有完全启动<br>NetworkPluginNotReady： 网络插件还没有完全启动</p>
<p><strong>-  Pod的重启策略</strong><br>PodSpec 中有一个 restartPolicy 字段，可能的值为 <strong>Always</strong>、<strong>OnFailure</strong> 和 <strong>Never</strong>。默认为 Always。 restartPolicy 适用于 Pod 中的所有容器。restartPolicy 仅指通过同一节点上的 kubelet 重新启动容器。失败的容器由 kubelet 以五分钟为上限的指数退避延迟（10秒，20秒，40秒…）重新启动，并在成功执行十分钟后重置。pod一旦绑定到一个节点，Pod 将永远不会重新绑定到另一个节点（除非删除这个pod，或pod所在的node节点发生故障或该node从集群中退出，则pod才会被调度到其他node节点上）。</p>
<p><img src="/2019/10/31/K8S%E9%83%A8%E7%BD%B2%E7%AE%80%E4%BB%8B/907596-20190807102156539-458120197-1572435175038.png" alt="img"></p>
<p><strong>说明：</strong> 可以管理Pod的控制器有Replication Controller，Job，DaemonSet，及kubelet（静态Pod）。<br>-  RC和DaemonSet：必须设置为Always，需要保证该容器持续运行。<br>-  Job：OnFailure或Never，确保容器执行完后不再重启。<br>-  kubelet：在Pod失效的时候重启它，不论RestartPolicy设置为什么值，并且不会对Pod进行健康检查。</p>
<p><strong>-  常见的状态转换场景</strong></p>
<p><img src="/2019/10/31/K8S%E9%83%A8%E7%BD%B2%E7%AE%80%E4%BB%8B/907596-20190807102716040-1569177475-1572435175048.png" alt="img"></p>
<p><strong>8.  Pod健康检查 (存活性探测)</strong><br>在pod生命周期中可以做的一些事情。主容器启动前可以完成初始化容器，初始化容器可以有多个，他们是串行执行的，执行完成后就推出了，在主程序刚刚启动的时候可以指定一个post start 主程序启动开始后执行一些操作，在主程序结束前可以指定一个 pre stop 表示主程序结束前执行的一些操作。Pod启动后的健康状态可以由两类探针来检测：<strong>Liveness Probe（存活性探测） 和 Readiness Probe（就绪性探测）</strong>。如下图：</p>
<p><img src="/2019/10/31/K8S%E9%83%A8%E7%BD%B2%E7%AE%80%E4%BB%8B/907596-20190808105616189-1181682733-1572435175060.png" alt="img"></p>
<p><strong>-  Liveness Probe</strong><br><strong>1.</strong> 用于判断容器是否存活（running状态）。<br><strong>2.</strong> 如果LivenessProbe探针探测到容器非健康，则kubelet将杀掉该容器，并根据容器的重启策略做相应处理。<br><strong>3.</strong> 如果容器不包含LivenessProbe探针，则kubelet认为该探针的返回值永远为“success”。</p>
<p>livenessProbe：指示容器是否正在运行。如果存活探测失败，则 kubelet 会杀死容器，并且容器将受到其 重启策略 的影响。如果容器不提供存活探针，则默认状态为 Success。Kubelet使用liveness probe（存活探针）来确定何时重启容器。例如，当应用程序处于运行状态但无法做进一步操作，liveness探针将捕获到deadlock，重启处于该状态下的容器，使应用程序在存在bug的情况下依然能够继续运行下去（谁的程序还没几个bug呢）。</p>
<p><strong>-  Readiness Probe</strong><br><strong>1.</strong> 用于判断容器是否启动完成（read状态），可以接受请求。<br><strong>2.</strong> 如果ReadnessProbe探针检测失败，则Pod的状态将被修改。Endpoint Controller将从Service的Endpoint中删除包含该容器所在Pod的Endpoint。</p>
<p>readinessProbe：指示容器是否准备好服务请求。如果就绪探测失败，端点控制器将从与 Pod 匹配的所有 Service 的端点中删除该 Pod 的 IP 地址。初始延迟之前的就绪状态默认为 Failure。如果容器不提供就绪探针，则默认状态为 Success。Kubelet使用readiness probe（就绪探针）来确定容器是否已经就绪可以接受流量。只有当Pod中的容器都处于就绪状态时kubelet才会认定该Pod处于就绪状态。该信号的作用是控制哪些Pod应该作为service的后端。如果Pod处于非就绪状态，那么它们将会被从service的load balancer中移除。</p>
<p><strong>Kubelet 可以选择是否执行在容器上运行的两种探针执行和做出反应，每次探测都将获得以下三种结果之一：</strong><br>成功：容器通过了诊断。<br>失败：容器未通过诊断。<br>未知：诊断失败，因此不会采取任何行动。</p>
<p><strong>探针是由 kubelet 对容器执行的定期诊断。要执行诊断，kubelet 调用由容器实现的Handler。其存活性探测的方法有以下三种：</strong><br>- ExecAction：在容器内执行指定命令。如果命令退出时返回码为 0 则认为诊断成功。<br>- TCPSocketAction：对指定端口上的容器的 IP 地址进行 TCP 检查。如果端口打开，则诊断被认为是成功的。<br>- HTTPGetAction：对指定的端口和路径上的容器的 IP 地址执行 HTTP Get 请求。如果响应的状态码大于等于200 且小于 400，则诊断被认为是成功的。</p>
<p><strong>-  定义LivenessProbe命令</strong><br>许多长时间运行的应用程序最终会转换到broken状态，除非重新启动，否则无法恢复。Kubernetes提供了Liveness Probe来检测和补救这种情况。<strong>LivenessProbe三种实现方式：</strong></p>
<p>1）ExecAction：在一个容器内部执行一个命令，如果该命令状态返回值为0，则表明容器健康。（即定义Exec liveness探针）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    test: liveness-exec</span><br><span class="line">  name: liveness-exec</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: liveness-exec-demo</span><br><span class="line">    image: busybox</span><br><span class="line">    args: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;touch /tmp/healthy;sleep 60;rm -rf /tmp/healthy;&quot;sleep 600]</span><br><span class="line">    livenessProbe:</span><br><span class="line">      exec:</span><br><span class="line">        command: [&quot;test&quot;,&quot;-e&quot;,&quot;/tmp/healthy&quot;]</span><br><span class="line">      initialDelaySeconds: 5</span><br><span class="line">      periodSeconds: 5</span><br></pre></td></tr></table></figure>



<p>上面的资源清单中定义了一个Pod 对象， 基于 busybox 镜像 启动 一个 运行“ touch/ tmp/ healthy； sleep 60； rm- rf/ tmp/ healthy； sleep 600” 命令 的 容器， 此 命令 在 容器 启动 时 创建/ tmp/ healthy 文件， 并于 60 秒 之后 将其 删除。 periodSeconds 规定kubelet要每隔5秒执行一次liveness probe， initialDelaySeconds 告诉kubelet在第一次执行probe之前要的等待5秒钟。存活性探针探针检测命令是在容器中执行 “test -e /tmp/healthy”命令检查/ tmp/healthy 文件的存在性。如果命令执行成功，将返回0，表示 成功 通过 测试，则kubelet就会认为该容器是活着的并且很健康。如果返回非0值，kubelet就会杀掉这个容器并重启它。</p>
<p>2）TCPSocketAction：通过容器IP地址和端口号执行TCP检查，如果能够建立TCP连接，则表明容器健康。这种方式使用TCP Socket，使用此配置，kubelet将尝试在指定端口上打开容器的套接字。 如果可以建立连接，容器被认为是健康的，如果不能就认为是失败的。（即定义TCP liveness探针）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    test: liveness-tcp</span><br><span class="line">  name: liveness-tcp</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: liveness-tcp-demo</span><br><span class="line">    image: nginx:1.12-alpine</span><br><span class="line">    ports:</span><br><span class="line">    - name: http</span><br><span class="line">      containerPort: 80</span><br><span class="line">    livenessProbe:</span><br><span class="line">      tcpSocket:</span><br><span class="line">        port: http</span><br></pre></td></tr></table></figure>



<p>上面的资源清单文件，向Pod IP的80/tcp端口发起连接请求，并根据连接建立的状态判断Pod存活状态。</p>
<p>3）HTTPGetAction：通过容器IP地址、端口号及路径调用HTTP Get方法，如果响应的状态码大于等于200且小于等于400，则认为容器健康。（即定义HTTP请求的liveness探针）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    test: liveness-http</span><br><span class="line">  name: liveness-http</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: liveness-http-demo</span><br><span class="line">    image: nginx:1.12-alpine</span><br><span class="line">    ports:</span><br><span class="line">    - name: http</span><br><span class="line">      containerPort: 80</span><br><span class="line">    lifecycle:</span><br><span class="line">      postStart:</span><br><span class="line">        exec:</span><br><span class="line">          command: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;echo healthy &gt; /usr/share/nginx/html/healthy&quot;]</span><br><span class="line">    livenessProbe:</span><br><span class="line">      httpGet:</span><br><span class="line">        path: /healthy</span><br><span class="line">        port: http</span><br><span class="line">        scheme: HTTP</span><br><span class="line">    initialDelaySeconds: 3</span><br><span class="line">    periodSeconds: 3</span><br></pre></td></tr></table></figure>



<p>上面 清单 文件 中 定义 的 httpGet 测试 中， 请求 的 资源 路径 为“/ healthy”， 地址 默认 为 Pod IP， 端口 使用 了 容器 中 定义 的 端口 名称 HTTP， 这也 是 明确 为 容器 指明 要 暴露 的 端口 的 用途 之一。livenessProbe 指定kubelete需要每隔3秒执行一次liveness probe。initialDelaySeconds 指定kubelet在该执行第一次探测之前需要等待3秒钟。该探针将向容器中的server的默认http端口发送一个HTTP GET请求。如果server的/healthz路径的handler返回一个成功的返回码，kubelet就会认定该容器是活着的并且很健康。如果返回失败的返回码，kubelet将杀掉该容器并重启它。任何大于200小于400的返回码都会认定是成功的返回码。其他返回码都会被认为是失败的返回码。</p>
<p><strong>-  定义ReadinessProbe命令</strong><br>有时，应用程序暂时无法对外部流量提供服务。 例如，应用程序可能需要在启动期间加载大量数据或配置文件。 在这种情况下，你不想杀死应用程序，但你也不想发送请求。 Kubernetes提供了readiness probe来检测和减轻这些情况。 Pod中的容器可以报告自己还没有准备，不能处理Kubernetes服务发送过来的流量。Readiness probe的配置跟liveness probe很像。唯一的不同是使用 readinessProbe而不是livenessProbe。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    test: readiness-exec</span><br><span class="line">  name: readiness-exec</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: readiness-demo</span><br><span class="line">    image: busybox</span><br><span class="line">    args: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;touch /tmp/healthy;sleep 60;rm -rf /tmp/healthy;&quot;sleep 600]</span><br><span class="line">    readinessProbe:</span><br><span class="line">      exec:</span><br><span class="line">        command: [&quot;test&quot;,&quot;-e&quot;,&quot;/tmp/healthy&quot;]</span><br><span class="line">      initialDelaySeconds: 5</span><br><span class="line">      periodSeconds: 5</span><br></pre></td></tr></table></figure>



<p>上面定义的是一个exec的Readiness探针，另外Readiness probe的HTTP和TCP的探测器配置跟liveness probe一样。Readiness和livenss probe可以并行用于同一容器。 使用两者可以确保流量无法到达未准备好的容器，并且容器在失败时重新启动。</p>
<p><strong>-  配置Probe</strong><br>Probe中有很多精确和详细的配置，通过它们你能准确的控制liveness和readiness检查：<br>initialDelaySeconds：容器启动后第一次执行探测是需要等待多少秒。即启动容器后首次进行健康检查的等待时间，单位为秒。<br>periodSeconds：执行探测的频率。默认是10秒，最小1秒。<br>timeoutSeconds：探测超时时间。默认1秒，最小1秒。即健康检查发送请求后等待响应的时间，如果超时响应kubelet则认为容器非健康，重启该容器，单位为秒。<br>successThreshold：探测失败后，最少连续探测成功多少次才被认定为成功。默认是1。对于liveness必须是1。最小值是1。<br>failureThreshold：探测成功后，最少连续探测失败多少次才被认定为失败。默认是3。最小值是1。</p>
<p>HTTP probe中可以给 httpGet设置其他配置项：<br>host：连接的主机名，默认连接到pod的IP。你可能想在http header中设置”Host”而不是使用IP。<br>scheme：连接使用的schema，默认HTTP。<br>path: 访问的HTTP server的path。<br>httpHeaders：自定义请求的header。HTTP运行重复的header。<br>port：访问的容器的端口名字或者端口号。端口号必须介于1和65525之间。</p>
<p>对于HTTP探测器，kubelet向指定的路径和端口发送HTTP请求以执行检查。 Kubelet将probe发送到容器的IP地址，除非地址被httpGet中的可选host字段覆盖。 在大多数情况下，不想设置主机字段。 有一种情况下可以设置它， 假设容器在127.0.0.1上侦听，并且Pod的hostNetwork字段为true。 然后，在httpGet下的host应该设置为127.0.0.1。 如果你的pod依赖于虚拟主机，这可能是更常见的情况，你不应该是用host，而是应该在httpHeaders中设置Host头。</p>
<ul>
<li>Liveness Probe和Readiness Probe使用场景</li>
<li>如果容器中的进程能够在遇到问题或不健康的情况下自行崩溃，则不一定需要存活探针; kubelet 将根据 Pod 的restartPolicy 自动执行正确的操作。</li>
<li>如果希望容器在探测失败时被杀死并重新启动，那么请指定一个存活探针，并指定restartPolicy 为 Always 或 OnFailure。</li>
<li>如果要仅在探测成功时才开始向 Pod 发送流量，请指定就绪探针。在这种情况下，就绪探针可能与存活探针相同，但是 spec 中的就绪探针的存在意味着 Pod 将在没有接收到任何流量的情况下启动，并且只有在探针探测成功后才开始接收流量。</li>
<li>如果你希望容器能够自行维护，您可以指定一个就绪探针，该探针检查与存活探针不同的端点。</li>
</ul>
<p><strong>请注意：</strong>如果你只想在 Pod 被删除时能够排除请求，则不一定需要使用就绪探针；在删除 Pod 时，Pod 会自动将自身置于未完成状态，无论就绪探针是否存在。当等待 Pod 中的容器停止时，Pod 仍处于未完成状态。</p>
<p><strong>9.  Pod调度</strong><br>在kubernetes集群中，Pod（container）是应用的载体，一般通过RC、Deployment、DaemonSet、Job等对象来完成Pod的调度与自愈功能。</p>
<p><strong>0.  Pod的生命</strong><br>一般来说，Pod 不会消失，直到人为销毁它们。这可能是一个人或控制器。这个规则的唯一例外是成功或失败的 phase 超过一段时间（由 master 确定）的Pod将过期并被自动销毁。有三种可用的控制器：<br>-  使用 Job 运行预期会终止的 Pod，例如批量计算。Job 仅适用于重启策略为 OnFailure 或 Never 的 Pod。<br>-  对预期不会终止的 Pod 使用 ReplicationController、ReplicaSet 和 Deployment ，例如 Web 服务器。 ReplicationController 仅适用于具有 restartPolicy 为 Always 的 Pod。<br>-  提供特定于机器的系统服务，使用 DaemonSet 为每台机器运行一个 Pod 。</p>
<p>所有这三种类型的控制器都包含一个 PodTemplate。建议创建适当的控制器，让它们来创建 Pod，而不是直接自己创建 Pod。这是因为单独的 Pod 在机器故障的情况下没有办法自动复原，而控制器却可以。如果节点死亡或与集群的其余部分断开连接，则 Kubernetes 将应用一个策略将丢失节点上的所有 Pod 的 phase 设置为 Failed。</p>
<p><strong>1.  RC、Deployment：全自动调度</strong><br>RC的功能即保持集群中始终运行着指定个数的Pod。在调度策略上主要有：<br>-   系统内置调度算法  [最优Node]<br>-   NodeSelector   [定向调度]<br>-   NodeAffinity  [亲和性调度]</p>
<p>-  NodeSelector  [定向调度]<br>kubernetes中kube-scheduler负责实现Pod的调度，内部系统通过一系列算法最终计算出最佳的目标节点。如果需要将Pod调度到指定Node上，则可以通过Node的标签（Label）和Pod的nodeSelector属性相匹配来达到目的。</p>
<p><strong>1.</strong> kubectl label nodes {node-name} {label-key}={label-value}<br><strong>2.</strong> nodeSelector:<br>{label-key}:{label-value}</p>
<p>如果给多个Node打了相同的标签，则scheduler会根据调度算法从这组Node中选择一个可用的Node来调度。<br>如果Pod的nodeSelector的标签在Node中没有对应的标签，则该Pod无法被调度成功。</p>
<p>Node标签的使用场景：<br>对集群中不同类型的Node打上不同的标签，可控制应用运行Node的范围。例如：role=frontend;role=backend;role=database。</p>
<p>-  NodeAffinity [亲和性调度]<br>NodeAffinity意为Node亲和性调度策略，NodeSelector为精确匹配，NodeAffinity为条件范围匹配，通过In（属于）、NotIn（不属于）、Exists（存在一个条件）、DoesNotExist（不存在）、Gt（大于）、Lt（小于）等操作符来选择Node，使调度更加灵活。</p>
<p><strong>1.</strong> RequiredDuringSchedulingRequiredDuringExecution：类似于NodeSelector，但在Node不满足条件时，系统将从该Node上移除之前调度上的Pod。<br><strong>2.</strong> RequiredDuringSchedulingIgnoredDuringExecution：与上一个类似，区别是在Node不满足条件时，系统不一定从该Node上移除之前调度上的Pod。<br><strong>3.</strong> PreferredDuringSchedulingIgnoredDuringExecution：指定在满足调度条件的Node中，哪些Node应更优先地进行调度。同时在Node不满足条件时，系统不一定从该Node上移除之前调度上的Pod。</p>
<p>如果同时设置了NodeSelector和NodeAffinity，则系统将需要同时满足两者的设置才能进行调度。</p>
<p><strong>2.  DaemonSet：特定场景调度</strong><br>DaemonSet是kubernetes1.2版本新增的一种资源对象，用于管理在集群中每个Node上仅运行一份Pod的副本实例。</p>
<p><img src="/2019/10/31/K8S%E9%83%A8%E7%BD%B2%E7%AE%80%E4%BB%8B/907596-20190807110231622-921561421-1572435175067.png" alt="img"></p>
<p>该用法适用的应用场景：<br><strong>1.</strong>  在每个Node上运行一个GlusterFS存储或者Ceph存储的daemon进程。<br><strong>2.</strong>  在每个Node上运行一个日志采集程序：fluentd或logstach。<br><strong>3.</strong>  在每个Node上运行一个健康程序，采集该Node的运行性能数据，例如：Prometheus Node Exportor、collectd、New Relic agent或Ganglia gmond等。</p>
<p>DaemonSet的Pod调度策略与RC类似，除了使用系统内置算法在每台Node上进行调度，也可以通过NodeSelector或NodeAffinity来指定满足条件的Node范围进行调度。</p>
<p><strong>3.  Job：批处理调度</strong><br>kubernetes从1.2版本开始支持批处理类型的应用，可以通过kubernetes Job资源对象来定义并启动一个批处理任务。批处理任务通常并行（或串行）启动多个计算进程去处理一批工作项（work item），处理完后，整个批处理任务结束。</p>
<p>批处理的三种模式：</p>
<p><img src="/2019/10/31/K8S%E9%83%A8%E7%BD%B2%E7%AE%80%E4%BB%8B/907596-20190807110527368-1482246320-1572435175056.png" alt="img"></p>
<p>批处理按任务实现方式不同分为以下几种模式：<br><strong>1.</strong> Job Template Expansion模式<br>一个Job对象对应一个待处理的Work item，有几个Work item就产生几个独立的Job，通过适用于Work item数量少，每个Work item要处理的数据量比较大的场景。例如有10个文件（Work item）,每个文件（Work item）为100G。<br><strong>2.</strong> Queue with Pod Per Work Item<br>采用一个任务队列存放Work item，一个Job对象作为消费者去完成这些Work item，其中Job会启动N个Pod，每个Pod对应一个Work item。<br><strong>3.</strong> Queue with Variable Pod Count<br>采用一个任务队列存放Work item，一个Job对象作为消费者去完成这些Work item，其中Job会启动N个Pod，每个Pod对应一个Work item。但Pod的数量是可变的。</p>
<p>Job的三种类型<br><strong>1.</strong> Non-parallel Jobs<br>通常一个Job只启动一个Pod,除非Pod异常才会重启该Pod,一旦此Pod正常结束，Job将结束。<br><strong>2.</strong> Parallel Jobs with a fixed completion count<br>并行Job会启动多个Pod，此时需要设定Job的.spec.completions参数为一个正数，当正常结束的Pod数量达到该值则Job结束。<br><strong>3.</strong> Parallel Jobs with a work queue<br>任务队列方式的并行Job需要一个独立的Queue，Work item都在一个Queue中存放，不能设置Job的.spec.completions参数。</p>
<p>此时Job的特性：</p>
<ul>
<li>每个Pod能独立判断和决定是否还有任务项需要处理;</li>
<li>如果某个Pod正常结束，则Job不会再启动新的Pod;</li>
<li>如果一个Pod成功结束，则此时应该不存在其他Pod还在干活的情况，它们应该都处于即将结束、退出的状态;</li>
<li>如果所有的Pod都结束了，且至少一个Pod成功结束，则整个Job算是成功结束;</li>
</ul>
<p><strong>10.  Pod伸缩</strong><br>kubernetes中RC是用来保持集群中始终运行指定数目的实例，通过RC的scale机制可以完成Pod的扩容和缩容（伸缩）。</p>
<p><strong>1.  手动伸缩（scale）</strong></p>
<p><code># kubectl scale rc redis-slave --replicas=3</code></p>
<p><strong>2.  自动伸缩（HPA）</strong><br>Horizontal Pod Autoscaler（HPA）控制器用于实现基于CPU使用率进行自动Pod伸缩的功能。HPA控制器基于Master的kube-controller-manager服务启动参数–horizontal-pod-autoscaler-sync-period定义是时长（默认30秒），周期性监控目标Pod的CPU使用率，并在满足条件时对ReplicationController或Deployment中的Pod副本数进行调整，以符合用户定义的平均Pod CPU使用率。Pod CPU使用率来源于heapster组件，因此需安装该组件。</p>
<p>HPA可以通过kubectl autoscale命令进行快速创建或者使用yaml配置文件进行创建。创建之前需已存在一个RC或Deployment对象，并且该RC或Deployment中的Pod必须定义resources.requests.cpu的资源请求值，以便heapster采集到该Pod的CPU。</p>
<p>-  通过kubectl autoscale创建。</p>
<p>例如php-apache-rc.yaml</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ReplicationController</span><br><span class="line">metadata:</span><br><span class="line">  name: php-apache</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: php-apache</span><br><span class="line">      labels:</span><br><span class="line">        app: php-apache</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: php-apache</span><br><span class="line">        image: gcr.io/google_containers/hpa-example</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 200m</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br></pre></td></tr></table></figure>



<p>创建php-apache的RC</p>
<p><code>kubectl create -f php-apache-rc.yaml</code></p>
<p>php-apache-svc.yaml</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: php-apache</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">  selector:</span><br><span class="line">    app: php-apache</span><br></pre></td></tr></table></figure>



<p>创建php-apache的Service</p>
<p><code>kubectl create -f php-apache-svc.yaml</code></p>
<p>创建HPA控制器</p>
<p><code>kubectl autoscale rc php-apache --min=1 --max=10 --cpu-percent=50</code></p>
<p>-  通过yaml配置文件创建</p>
<p>hpa-php-apache.yaml</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: HorizontalPodAutoscaler</span><br><span class="line">metadata:</span><br><span class="line">  name: php-apache</span><br><span class="line">spec:</span><br><span class="line">  scaleTargetRef:</span><br><span class="line">    apiVersion: v1</span><br><span class="line">    kind: ReplicationController</span><br><span class="line">    name: php-apache</span><br><span class="line">  minReplicas: 1</span><br><span class="line">  maxReplicas: 10</span><br><span class="line">  targetCPUUtilizationPercentage: 50</span><br></pre></td></tr></table></figure>



<p>创建hpa</p>
<p><code>kubectl create -f hpa-php-apache.yaml</code></p>
<p>查看hpa</p>
<p><code>kubectl get hpa</code></p>
<p><strong>11. Pod滚动升级和回滚</strong><br>Kubernetes是一个很好的容器应用集群管理工具，尤其是采用ReplicationController这种自动维护应用生命周期事件的对象后，将容器应用管理的技巧发挥得淋漓尽致。在容器应用管理的诸多特性中，有一个特性是最能体现Kubernetes强大的集群应用管理能力的，那就是滚动升级。</p>
<p>滚动升级的精髓在于升级过程中依然能够保持服务的连续性，使外界对于升级的过程是无感知的。整个过程中会有三个状态：全部旧实例，新旧实例皆有，全部新实例。旧实例个数逐渐减少，新实例个数逐渐增加，最终达到旧实例个数为0，新实例个数达到理想的目标值。</p>
<p><strong>1.  使用kubectl rolling-update命令完成RC的滚动升级 和 回滚</strong><br>kubernetes中的RC的滚动升级通过执行 kubectl rolling-update 命令完成，该命令创建一个新的RC（与旧的RC在同一个命名空间中），然后自动控制旧的RC中的Pod副本数逐渐减少为0，同时新的RC中的Pod副本数从0逐渐增加到目标值，来完成Pod的升级。 需要注意的是：新旧RC要再同一个命名空间内。但滚动升级中Pod副本数（包括新Pod和旧Pod）保持原预期值。</p>
<p>1.1  通过配置文件实现<br>redis-master-controller-v2.yaml</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ReplicationController</span><br><span class="line">metadata:</span><br><span class="line">  name: redis-master-v2</span><br><span class="line">  labels:</span><br><span class="line">    name: redis-master</span><br><span class="line">    version: v2</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    name: redis-master</span><br><span class="line">    version: v2</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        name: redis-master</span><br><span class="line">        version: v2</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: master</span><br><span class="line">        image: kubeguide/redis-master:2.0</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 6379</span><br></pre></td></tr></table></figure>



<p>注意事项：<br>-  RC的名字（name）不能与旧RC的名字相同<br>-  在selector中应至少有一个Label与旧的RC的Label不同，以标识其为新的RC。例如本例中新增了version的Label。</p>
<p>运行kubectl rolling-update</p>
<p><code>kubectl rolling-update redis-master -f redis-master-controller-v2.yaml</code></p>
<p>1.2  通过kubectl rolling-update命令实现</p>
<p><code>kubectl rolling-update redis-master --image=redis-master:2.0</code></p>
<p>与使用配置文件实现不同在于，该执行结果旧的RC被删除，新的RC仍使用旧的RC的名字。</p>
<p><strong>1.3  通过kubectl rolling-update加参数–rollback实现回滚操作</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl rolling-update redis-master --image=kubeguide/redis-master:2.0 --rollback</span><br></pre></td></tr></table></figure>



<p>rollback原理很简单，kubernetes记录了各个版本的PodTemplate,把旧的PodTemplate覆盖新的Template即可。 </p>
<p><strong>2.  通过Deployment的滚动升级 和 回滚</strong><br>采用RS来管理Pod实例。如果当前集群中的Pod实例数少于目标值，RS会拉起新的Pod，反之，则根据策略删除多余的Pod。Deployment正是利用了这样的特性，通过控制两个RS里面的Pod，从而实现升级。滚动升级是一种平滑过渡式的升级，在升级过程中，服务仍然可用，这是kubernetes作为应用服务化管理的关键一步！！服务无处不在，并且按需使用。Kubernetes Deployment滚动更新机制不同于ReplicationController rolling update，Deployment rollout还提供了滚动进度查询，滚动历史记录，回滚等能力，无疑是使用Kubernetes进行应用滚动发布的首选。配置示例如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deployment</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        images: nginx:1.7.9</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br></pre></td></tr></table></figure>



<p>2.1  通过kubectl set image命令为Deployment设置新的镜像名称</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1</span><br></pre></td></tr></table></figure>

<p>2.2  使用kubectl edit命令修改Deployment的配置<br>将spec.template.spec.containers[0].images 从nginx:1.7.9 更改为1.9.1;  保存退出后，kubernetes会自动升级镜像。</p>
<p>2.3  通过”kubectl rollout status”可以查看deployment的<strong>更新过程</strong></p>
<p>在Deployment的定义中，可以通过spec.strategy指定Pod更新的策略：<br>- Recreate(重建)： 设置spec.strategy.type=Recreate,表示Deployment在更新Pod时，会先杀掉所有正在运行的Pod,然后创建新的Pod.<br>- RollingUpdate(滚动更新)：以滚动更新的方式来逐个更新Pod,可以通过设置spec.strategy.rollingUpdate下的两个参数（maxUnavailable和maxSurge）来控制滚动更新的过程。</p>
<p>通常来说，不鼓励更新Deployment的标签选择器，因为这样会导致Deployment选择的Pod列表发生变化，也可能与其它控制器产生冲突。</p>
<p>Deployment滚动升级的过程大致为：</p>
<ul>
<li>查找新的RS和旧的RS，并计算出新的Revision（这是Revision的最大值）；</li>
<li>对新的RS进行扩容操作；</li>
<li>对旧的RS进行缩容操作；</li>
<li>完成之后，删掉旧的RS；</li>
<li>通过Deployment状态到etcd;</li>
</ul>
<p><strong>2.4  Deployment的回滚</strong><br>所有Deployment的发布历史记录都保留在系统中，如果要进行回滚：<br>-  用 kubectl rollout history 命令检查这个Deployment部署的历史记录<br>-  用 kubectl rollout undo deployment/nginx-deployment 撤销本次发布回滚到上一个部署版本<br>-  用 kubectl rollout undo deployment/nginx-deployment –to-revision=2 回滚到指定版本</p>
<p><strong>2.5  暂停和恢复Deployment的部署操作，以完成复杂的修改</strong><br>对应一次复杂的Deployment配置修改，为了避免频繁触发Deployment的更新操作，可以暂停Deployment的更新操作，然后进行配置修改，再回复Deployment.一次性触发完整的更新操作。使用命令：kubectl rollout pause deployment/nginx-deployment</p>
<p>Kubernetes滚动升级和回滚操作分享 （Deployment的rollout方式）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">产品部署完成上线之后，经常遇到需要升级服务的要求（只考虑更新镜像），以往比较粗糙的操作流程大致如下：</span><br><span class="line">方式一：找到 master具体调度到的所有目标node，删除其对应的镜像文件</span><br><span class="line">方式二：修改 file.yaml中镜像拉取策略为Always</span><br><span class="line">  </span><br><span class="line">删掉旧pod，并重新创建</span><br><span class="line"># kubectl delete -f /path/file.yaml</span><br><span class="line"># kubectl create -f /path/file.yaml</span><br><span class="line"> </span><br><span class="line">但是这样有一个比较棘手的问题，就是如果升级失败的回滚策略。因此想到利用kubernetes自身的滚动升级的工具，部署及升级流程如下：</span><br><span class="line"> </span><br><span class="line">1）在初次创建的时候，尽量加入参数--record，这样k8s会记录下本次启动的脚本 。</span><br><span class="line"># kubectl create -f /path/file.yaml --record</span><br><span class="line"> </span><br><span class="line">2）执行查看发布的历史记录，会显示现在已经记录的脚本及其序号。</span><br><span class="line">查看历史记录</span><br><span class="line"># kubectl rollout history deployment deploy-apigw</span><br><span class="line"> </span><br><span class="line">3）升级命令执行后会输出&quot;xxx image updated&quot;</span><br><span class="line">升级镜像</span><br><span class="line"># kubectl set image deployment/deploy-name containerName=newIMG:version</span><br><span class="line"># kubectl set image controllerType/controllerInstanceName underInstanceContainerName=image:version</span><br><span class="line"> </span><br><span class="line">4）查看pod状态，如果失败需要回滚操作</span><br><span class="line">回滚到上一个操作版本</span><br><span class="line"># kubectl rollout undo deployment/deploy-name</span><br><span class="line"> </span><br><span class="line">回滚到指定版本，版本号由第二步查看获得</span><br><span class="line"># kubectl rollout undo deployment/deploy-name --to-revision=3</span><br><span class="line"> </span><br><span class="line">需要注意：执行rollout undo操作之后，版本号会移动，需要确认版本号无误再undo</span><br></pre></td></tr></table></figure>



<p><strong>3.  其它管理对象的更新策略</strong><br>3.1  DaemonSet的更新策略<br>- OnDelete: 默认配置。只有旧的Pod被用户手动删除后，才触发新建操作。<br>- RollingUpdate: 旧版本的Pod将被自动杀掉，然后自动创建新版本的DaemonSet Pod.</p>
<p>3.2  StatefulSet的更新策略<br>StatefulSet的更新策略正逐渐向Deployment和DaemonSet的更新策略看齐。</p>
<p><strong>12.  资源需求和资源限制</strong><br>在Docker的范畴内，我们知道可以对运行的容器进行请求或消耗的资源进行限制。而在Kubernetes中也有同样的机制，容器或Pod可以进行申请和消耗的计算资源就是CPU和内存，这也是目前仅有的受支持的两种类型。相比较而言，CPU属于可压缩资源，即资源额度可按需收缩；而内存则是不可压缩型资源，对其执行收缩操作可能会导致某种程度的问题。</p>
<p>资源的隔离目前是属于容器级别，CPU和内存资源的配置需要Pod中的容器spec字段下进行定义。其具体字段，可以使用”requests”进行定义请求的确保资源可用量。也就是说容器的运行可能用不到这样的资源量，但是必须确保有这么多的资源供给。而”limits”是用于限制资源可用的最大值，属于硬限制。</p>
<p>在Kubernetes中，1个单位的CPU相当于虚拟机的1颗虚拟CPU（vCPU）或者是物理机上一个超线程的CPU，它支持分数计量方式，一个核心（1core）相当于1000个微核心（millicores），因此500m相当于是0.5个核心，即二分之一个核心。内存的计量方式也是一样的，默认的单位是字节，也可以使用E、P、T、G、M和K作为单位后缀，或者是Ei、Pi、Ti、Gi、Mi、Ki等形式单位后缀。</p>
<p><strong>-  容器的资源需求，资源限制</strong><br><strong>requests：需求</strong>，最低保障；<br><strong>limits：限制</strong>，硬限制；</p>
<p><strong>-  CPU</strong><br>1 颗逻辑 CPU<br>1=1000，millicores (微核心)<br>500m=0.5CPU</p>
<p><strong>-  资源需求</strong><br>自主式pod要求为stress容器确保128M的内存及五分之一个cpu核心资源可用，它运行stress-ng镜像启动一个进程进行内存性能压力测试，满载测试时它也会尽可能多地占用cpu资源，另外再启动一个专用的cpu压力测试进程。stress-ng是一个多功能系统压力测试工具，master/worker模型，master为主进程，负责生成和控制子进程，worker是负责执行各类特定测试的子进程。</p>
<p>集群中的每个节点都拥有定量的cpu和内存资源，调度pod时，仅那些被请求资源的余量可容纳当前调度的pod的请求量的节点才可作为目标节点。也就是说，kubernetes的调度器会根据容器的requests属性中定义的资源需求量来判定仅哪些节点可接受运行相关的pod资源，而对于一个节点的资源来说，每运行一个pod对象，其requestes中定义的请求量都要被预留，直到被所有pod对象瓜分完毕为止。</p>
<p>资源需求配置示例:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: nginx</span><br><span class="line">    image: nginx</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        memory: &quot;128Mi&quot;</span><br><span class="line">        cpu: &quot;200m&quot;</span><br></pre></td></tr></table></figure>



<p>上面的配置清单中，nginx请求的CPU资源大小为200m，这意味着一个CPU核心足以满足nginx以最快的方式运行，其中对内存的期望可用大小为128Mi，实际运行时不一定会用到这么多的资源。考虑到内存的资源类型，在超出指定大小运行时存在会被OOM killer杀死的可能性，于是该请求值属于理想中使用的内存上限。</p>
<p><strong>-  资源限制</strong><br>容器的资源需求仅能达到为其保证可用的最少资源量的目的，它并不会限制容器的可用资源上限，因此对因应用程序自身存在bug等多种原因而导致的系统资源被长期占用的情况则无计可施，这就需要通过limits属性定义资源的最大可用量。资源分配时，可压缩型资源cpu的控制阈可自由调节，容器进程无法获得超出其cpu配额的可用时间。不过，如果进程申请分配超出其limits属性定义的硬限制的内存资源时，它将被OOM killer杀死。不过，随后可能会被其控制进程所重启。例如，容器进程的pod对象会被杀死并重启（重启策略为always或onfailure时），或者是容器进程的子进程被其父进程所重启。也就是说，CPU是属于可压缩资源，可进行自由地调节。内存属于硬限制性资源，当进程申请分配超过limit属性定义的内存大小时，该Pod将被OOM killer杀死。</p>
<p>与requests不同的是，limits并不会影响pod的调度结果，也就是说，一个节点上的所有pod对象的limits数量之和可以大于节点所拥有的资源量，即支持资源的过载使用。不过，这么一来一旦资源耗尽，尤其是内存资源耗尽，则必然会有容器因OOMKilled而终止。另外，kubernetes仅会确保pod能够获得他们请求的cpu时间额度，他们能否获得额外的cpu时间，则取决于其他正在运行的作业对cpu资源的占用情况。例如，对于总数为1000m的cpu来说，容器a请求使用200m，容器b请求使用500m，在不超出它们各自的最大限额的前提下，余下的300m在双方都需要时会以2:5的方式进行配置。</p>
<p>资源限制配置示例:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@k8s-master ~]# vim memleak-pod.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: memleak-pod</span><br><span class="line">  labels:</span><br><span class="line">    app: memleak</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: simmemleak</span><br><span class="line">    image: saadali/simmemleak</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        memory: &quot;64Mi&quot;</span><br><span class="line">        cpu: &quot;1&quot;</span><br><span class="line">      limits:</span><br><span class="line">        memory: &quot;64Mi&quot;</span><br><span class="line">        cpu: &quot;1&quot;</span><br><span class="line"> </span><br><span class="line">[root@k8s-master ~]# kubectl apply -f memleak-pod.yaml</span><br><span class="line">pod/memleak-pod created</span><br><span class="line">[root@k8s-master ~]# kubectl get pods -l app=memleak</span><br><span class="line">NAME          READY     STATUS      RESTARTS   AGE</span><br><span class="line">memleak-pod   0/1       OOMKilled   2          12s</span><br><span class="line">[root@k8s-master ~]# kubectl get pods -l app=memleak</span><br><span class="line">NAME          READY     STATUS             RESTARTS   AGE</span><br><span class="line">memleak-pod   0/1       CrashLoopBackOff   2          28s</span><br></pre></td></tr></table></figure>



<p>Pod资源默认的重启策略为Always，在上面例子中memleak因为内存限制而终止会立即重启，此时该Pod会被OOM killer杀死，在多次重复因为内存资源耗尽重启会触发Kunernetes系统的重启延迟，每次重启的时间会不断拉长，后面看到的Pod的状态通常为”CrashLoopBackOff”。</p>
<p><strong>-  容器的可见资源</strong><br>对于容器中运行top等命令观察资源可用量信息时，即便定义了requests和limits属性，虽然其可用资源受限于此两个属性的定义，但容器中可见资源量依然是节点级别可用总量。</p>
<p><strong>-  Pod的服务质量类别（QoS）</strong><br>这里还需要明确的是，kubernetes允许节点资源对limits的过载使用，这意味着节点无法同时满足其上的所有pod对象以资源满载的方式运行。在一个Kubernetes集群上，运行的Pod众多，那么当node节点都无法满足多个Pod对象的资源使用时 (节点内存资源紧缺时)，应该按照什么样的顺序去终止这些Pod对象呢？kubernetes无法自行对此做出决策，它需要借助于pod对象的优先级来判定终止Pod的优先问题。根据pod对象的requests和limits属性，kubernetes将pod对象归类到<strong>BestEffort</strong>、<strong>Burstable</strong>和<strong>Guaranteed</strong>三个服务质量类别：<br>Guaranteed：每个容器都为cpu资源设置了具有相同值的requests和limits属性，以及每个容器都为内存资源设置了具有相同值的requests和limits属性的pod资源会自动归属于此类别，这类pod资源具有最高优先级.<br>Burstable：至少有一个容器设置了cpu或内存资源的requests属性，但不满足Guaranteed类别要求的pod资源将自动归属此类别，它们具有中等优先级。<br>BestEffort：未为任何一个容器设置requests和limits属性的pod资源将自动归属于此类别，它们的优先级为最低级别。</p>
<p>内存资源紧缺时，BestEfford类别的容器将首当其冲地终止，因为系统不为其提供任何级别的资源保证，但换来的好处是：它们能够在可用时做到尽可能多地占用资源。若已然不存在BestEfford类别的容器，则接下来是有着中等优先级的Burstable类别的pod被终止。Guaranteed类别的容器拥有最高优先级，它们不会被杀死，除非其内存资源需求超限，或者OOM时没有其他更低优先级的pod资源存在。</p>
<p>每个运行状态的容器都有其OOM得分，得分越高越会被优先杀死。OOM得分主要根据两个维度进行计算：由QoS类别继承而来的默认分值和容器的可用内存资源比例。同等类别的pod资源的默认分值相同。同等级别优先级的pod资源在OOM时，与自身requests属性相比，其内存占用比例最大的pod对象将被首先杀死。需要特别说明的是，OOM是内存耗尽时的处理机制，它们与可压缩型资源cpu无关，因此cpu资源的需求无法得到保证时，pod仅仅是暂时获取不到相应的资源而已。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">查看 Qos</span><br><span class="line">[root@k8s-master01 ~]# kubectl describe pod/prometheus-858989bcfb-ml5gk -n kube-system|grep &quot;QoS Class&quot;</span><br><span class="line">QoS Class:       Burstable</span><br></pre></td></tr></table></figure>



<p><strong>13.  Pod持久存储方式</strong><br>volume是kubernetes Pod中多个容器访问的共享目录。volume被定义在pod上，被这个pod的多个容器挂载到相同或不同的路径下。volume的生命周期与pod的生命周期相同，pod内的容器停止和重启时一般不会影响volume中的数据。所以一般volume被用于持久化pod产生的数据。Kubernetes提供了众多的volume类型，包括emptyDir、hostPath、nfs、glusterfs、cephfs、ceph rbd等。</p>
<p><strong>1.  emptyDir</strong><br>emptyDir类型的volume在pod分配到node上时被创建，kubernetes会在node上自动分配 一个目录，因此无需指定宿主机node上对应的目录文件。这个目录的初始内容为空，当Pod从node上移除时，emptyDir中的数据会被永久删除。emptyDir Volume主要用于某些应用程序无需永久保存的临时目录，多个容器的共享目录等。下面是pod挂载emptyDir的示例:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: test-pd</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: gcr.io/google_containers/test-webserver</span><br><span class="line">    name: test-container</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /cache</span><br><span class="line">      name: cache-volume</span><br><span class="line">  volumes:</span><br><span class="line">  - name: cache-volume</span><br><span class="line">    emptyDir: &#123;&#125;</span><br></pre></td></tr></table></figure>



<p><strong>2.  hostPath</strong><br>hostPath Volume为pod挂载宿主机上的目录或文件，使得容器可以使用宿主机的高速文件系统进行存储。缺点是，在k8s中，pod都是动态在各node节点上调度。当一个pod在当前node节点上启动并通过hostPath存储了文件到本地以后，下次调度到另一个节点上启动时，就无法使用在之前节点上存储的文件。下面是pod挂载hostPath的示例:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: test-pd</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: gcr.io/google_containers/test-webserver</span><br><span class="line">    name: test-container</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /test-pd</span><br><span class="line">      name: test-volume</span><br><span class="line">  volumes:</span><br><span class="line">  - name: test-volume</span><br><span class="line">    hostPath:</span><br><span class="line">      # directory location on host</span><br><span class="line">      path: /data</span><br></pre></td></tr></table></figure>



<p><strong>3.  pod持久存储</strong><br><strong>方式一： pod直接挂载nfs-server</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">volumes:</span><br><span class="line">  - name: nfs</span><br><span class="line">    nfs:</span><br><span class="line">      server: 192.168.1.1</span><br><span class="line">      path:&quot;/&quot;</span><br></pre></td></tr></table></figure>



<p>静态提供：管理员手动创建多个PV，供PVC使用。<br>动态提供：动态创建PVC特定的PV，并绑定。</p>
<p><strong>方式二： 手动创建PV</strong><br>Persistent Volume(持久化卷)简称PV，是一个Kubernetes资源对象，我们可以单独创建一个PV，它不和Pod直接发生关系，而是通过Persistent Volume Claim，简称PVC来实现动态绑定, 我们会在Pod定义里指定创建好的PVC, 然后PVC会根据Pod的要求去自动绑定合适的PV给Pod使用。</p>
<p><strong>持久化卷下PV和PVC概念</strong><br>Persistent Volume（PV）是由管理员设置的存储，它是群集的一部分。就像节点是集群中的资源一样，PV 也是集群中的资源。 PV 是 Volume 之类的卷插件，但具有独立于使用 PV 的 Pod 的生命周期。此 API 对象包含存储实现的细节，即 NFS、iSCSI 或特定于云供应商的存储系统。</p>
<p>PersistentVolumeClaim（PVC）是用户存储的请求。它与 Pod 相似，Pod 消耗节点资源，PVC 消耗 PV 资源。Pod 可以请求特定级别的资源（CPU 和内存）。PVC声明可以请求特定的大小和访问模式（例如，可以以读/写一次或只读多次模式挂载）。</p>
<p><strong>它和普通Volume的区别是什么呢？</strong><br>普通Volume和使用它的Pod之间是一种静态绑定关系，在定义Pod的文件里，同时定义了它使用的Volume。Volume是Pod的附属品，我们无法单独创建一个Volume，因为它不是一个独立的Kubernetes资源对象。</p>
<p>配置示例:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pv.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  name: pv003</span><br><span class="line">spec:</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 5Gi</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  nfs:</span><br><span class="line">    path: /somepath</span><br><span class="line">    server: 192.168.1.1</span><br></pre></td></tr></table></figure>



<p>查看PV</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># kubectl get pv</span><br><span class="line">NAME                                       CAPACITY   ACCESSMODES   RECLAIMPOLICY   STATUS    CLAIM                             STORAGECLASS     REASON    AGE</span><br><span class="line">nfs-pv-heketi                              300Mi      ROX           Retain          Bound     default/nfs-pvc-heketi                                       7d</span><br><span class="line">pvc-02b8a30d-8e28-11e7-a07a-025622f1d9fa   50Gi       RWX           Retain          Bound     kube-public/jenkins-pvc           heketi-storage             5d</span><br></pre></td></tr></table></figure>



<p>PV可以设置三种回收策略：保留（Retain），回收（Recycle）和删除（Delete）。<br>保留策略：允许人工处理保留的数据。<br>删除策略：将删除pv和外部关联的存储资源，需要插件支持。<br>回收策略：将执行清除操作，之后可以被新的pvc使用，需要插件支持。</p>
<p>PV的状态:<br>Available ：资源尚未被claim使用<br>Bound ：已经绑定到某个pvc上<br>Released ： 对应的pvc被删除,但是资源还没有被集群回收<br>Failed ： 自动回收失败</p>
<p>PV访问权限<br>ReadWriteOnce ： 被单个节点mount为读写rw模式<br>ReadOnlyMany ： 被多个节点mount为只读ro模式<br>ReadWriteMany ： 被多个节点mount为读写rw模式</p>
<p>配置示例</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pv的配置定义</span><br><span class="line"># pvc.yaml</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: myclaim</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 5Gi</span><br><span class="line"> </span><br><span class="line">pod配置文件中应用pv</span><br><span class="line"># mypod.yaml</span><br><span class="line">volumes:</span><br><span class="line">  - name: mypod</span><br><span class="line">    persistentVolumeClaim:</span><br><span class="line">      claimName: myclaim</span><br></pre></td></tr></table></figure>



<p><strong>kubernetes 快速批量创建 PV &amp; PVC 脚本</strong><br>-  快速批量创建nfs pv</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for` `i ``in` `&#123;3..6&#125;; ``do</span><br><span class="line">cat` `&lt;&lt;EOF` `| kubectl apply -f -</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  ``name: pv00$&#123;i&#125;</span><br><span class="line">spec:</span><br><span class="line">  ``capacity:</span><br><span class="line">    ``storage: 100Gi</span><br><span class="line">  ``accessModes:</span><br><span class="line">    ``- ReadWriteOnce  #这里根据需要配置ReadWriteOnce或者ReadWriteMany</span><br><span class="line">  ``persistentVolumeReclaimPolicy: Recycle</span><br><span class="line">  ``nfs:</span><br><span class="line">    ``path: /volume1/harbor/nfs$&#123;i&#125;</span><br><span class="line">    ``server: 192.168.2.4</span><br><span class="line">EOF</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<p>​     </p>
<p>-  快速批量创建nfs pvc</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for i in &#123;3..6&#125;; do</span><br><span class="line">cat &lt;&lt;EOF | kubectl delete -f -</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata: </span><br><span class="line">  name: pvc00$&#123;i&#125;-claim</span><br><span class="line">spec: </span><br><span class="line">  accessModes:  </span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  resources:   </span><br><span class="line">    requests:     </span><br><span class="line">      storage: 100Gi</span><br><span class="line">EOF</span><br><span class="line">done</span><br></pre></td></tr></table></figure>



<p><strong>14.  Pod水平自动扩展（HPA）</strong><br>Kubernetes有一个强大的功能，它能在运行的服务上进行编码并配置弹性伸缩。如果没有弹性伸缩功能，就很难适应部署的扩展和满足SLAs。这一功能称为Horizontal Pod Autoscaler (HPA)，这是kubernetes的一个很重要的资源对象。HPA是Kubernetes中弹性伸缩API组下的一个API资源。当前稳定的版本是autoscaling/v1，它只提供了对CPU自动缩放的支持。</p>
<p>Horizontal Pod Autoscaling，即pod的水平自动扩展。自动扩展主要分为两种，其一为水平扩展，针对于实例数目的增减；其二为垂直扩展，即单个实例可以使用的资源的增减。HPA属于水平自动扩展。HPA的操作对象是RC、RS或Deployment对应的Pod，根据观察到的CPU等实际使用量与用户的期望值进行比对，做出是否需要增减实例数量的决策。</p>
<p><strong>1.  为什么使用HPA</strong><br>使用HPA，可以根据资源的使用情况或者自定义的指标，实现部署的自动扩展和缩减，让部署的规模接近于实际服务的负载。HPA可以为您的服务带来两个直接的帮助：<br>- 在需要计算和内存资源时提供资源，在不需要时释放它们<br>- 按需增加/降低性能以实现SLA</p>
<p><strong>2.  HPA原理</strong><br>它根据Pod当前系统的负载来自动水平扩容，如果系统负载超过预定值，就开始增加Pod的个数，如果低于某个值，就自动减少Pod的个数。目前Kubernetes的HPA只能根据CPU等资源使用情况去度量系统的负载。HPA会根据监测到的CPU/内存利用率（资源指标），或基于第三方指标应用程序（如Prometheus等）提供的自定义指标，自动调整副本控制器、部署或者副本集合的pods数量（定义最小和最大pods数）。HPA是一种控制回路，它的周期由Kubernetes的controller manager 的–horizontal-pod-autoscaler-sync-period标志控制（默认值是30s）。</p>
<p><img src="/2019/10/31/K8S%E9%83%A8%E7%BD%B2%E7%AE%80%E4%BB%8B/907596-20190808181956206-983371113-1572435175067.png" alt="img"></p>
<p>在一般情况下HPA是由kubectl来提供支持的。可以使用kubectl进行创建、管理和删除：<br><strong>创建HPA</strong><br>- 带有manifest: “kubectl create -f <hpa_manifest>“<br>- 没有manifest(只支持CPU)：”kubectl autoscale deployment hello-world –min=2 –man=5 –-cpu-percent=50”</hpa_manifest></p>
<p><strong>获取hpa信息</strong><br>- 基本信息: “kubectl get hpa hello-world”<br>- 细节描述: “kubectl describe hpa hello-world”</p>
<p><strong>删除hpa</strong><br># kubectl delete hpa hello-world</p>
<p>下面是一个HPA manifest定义的例子：</p>
<p><img src="/2019/10/31/K8S%E9%83%A8%E7%BD%B2%E7%AE%80%E4%BB%8B/907596-20190808184025296-452606415-1572435175071.png" alt="img"></p>
<p>这里使用了autoscaling/v2beta1版本，用到了cpu和内存指标<br>控制hello-world项目部署的自动缩放<br>定义了副本的最小值1<br>定义了副本的最大值10<br>当满足时调整大小：<br>- CPU使用率超过50%<br>- 内存使用超过100Mi</p>
<p><strong>3.  HPA条件</strong><br>HPA通过定期（定期轮询的时间通过–horizontal-pod-autoscaler-sync-period选项来设置，默认的时间为30秒）通过Status.PodSelector来查询pods的状态，获得pod的CPU使用率。然后，通过现有pods的CPU使用率的平均值（计算方式是最近的pod使用量（最近一分钟的平均值，从heapster中获得）除以设定的每个Pod的CPU使用率限额）跟目标使用率进行比较，并且在扩容时，还要遵循预先设定的副本数限制：MinReplicas &lt;= Replicas &lt;= MaxReplicas。</p>
<p>计算扩容后Pod的个数：sum(最近一分钟内某个Pod的CPU使用率的平均值)/CPU使用上限的整数+1</p>
<ol start="4">
<li>HPA流程</li>
</ol>
<ul>
<li>创建HPA资源，设定目标CPU使用率限额，以及最大、最小实例数</li>
<li>收集一组中（PodSelector）每个Pod最近一分钟内的CPU使用率，并计算平均值</li>
<li>读取HPA中设定的CPU使用限额</li>
<li>计算：平均值之和/限额，求出目标调整的实例个数</li>
<li>目标调整的实例数不能超过1中设定的最大、最小实例数，如果没有超过，则扩容；超过，则扩容至最大的实例个数</li>
<li>回到2，不断循环</li>
</ul>
<p><strong>5.  HPA例外</strong><br>考虑到自动扩展的决策可能需要一段时间才会生效，甚至在短时间内会引入一些噪声。例如当pod所需要的CPU负荷过大，从而运行一个新的pod进行分流，在创建过程中，系统的CPU使用量可能会有一个攀升的过程。所以，在每一次作出决策后的一段时间内，将不再进行扩展决策。对于ScaleUp (纵向扩展)而言，这个时间段为3分钟，Scaledown为5分钟。</p>
<p>HPA允许一定范围内的CPU使用量的不稳定，只有 avg(CurrentPodsConsumption) / Target 小于90%或者大于110%时才会触发扩容或缩容，避免频繁扩容、缩容造成颠簸。</p>
<p><strong>【扩展】</strong><br>Scale Up (纵向扩展) ：主要是利用现有的存储系统，通过不断增加存储容量来满足数据增长的需求。但是这种方式只增加了容量，而带宽和计算能力并没有相应的增加。所以，整个存储系统很快就会达到性能瓶颈，需要继续扩展。</p>
<p>Scale-out (横向扩展)：通常是以节点为单位，每个节点往往将包含容量、处理能力和I / O带宽。一个节点被添加到存储系统，系统中的三种资源将同时升级。这种方式容量增长和性能扩展(即增加额外的控制器)是同时进行。而且，Scale-out架构的存储系统在扩展之后，从用户的视角看起来仍然是一个单一的系统，这一点与我们将多个相互独立的存储系统简单的叠加在一个机柜中是完全不同的。所以scale out方式使得存储系统升级工作大大简化，用户能够真正实现按需购买，降低TCO。</p>
<p><strong>6.  为什么HPA选择相对比率</strong><br>为了简便，选用了相对比率（90%的CPU资源）而不是0.6个CPU core来描述扩容、缩容条件。如果选择使用绝对度量，用户需要保证目标（限额）要比请求使用的低，否则，过载的Pod未必能够消耗那么多，从而自动扩容永远不会被触发：假设设置CPU为1个核，那么这个pod只能使用1个核，可能Pod在过载的情况下也不能完全利用这个核，所以扩容不会发生。在修改申请资源时，还有同时调整扩容的条件，比如将1个core变为1.2core，那么扩容条件应该同步改为1.2core，这样的话，就真是太麻烦了，与自动扩容的目标相悖。</p>
<p><strong>7.  安装需求</strong><br>在HPA可以在Kubernetes集群上使用之前，有一些元素需要在系统中安装和配置。检查确定Kubernetes集群服务正在运行并且至少包含了这些标志:<br>kube-api：requestheader-client-ca-file<br>kubelet：read-only-port 在端口10255<br>kube-controller：可选，只在需要和默认值不同时使用<br>horizontal-pod-autoscaler-downscale-delay：”5m0s”<br>horizontal-pod-autoscaler-upscale-delay：”3m0s”<br>horizontal-pod-autoscaler-sync-period： “30s”</p>
<p>HPA的实例说明：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）创建Deployment</span><br><span class="line">[root@k8s-master01 ~]# cat &lt;&lt; EOF &gt; lykops-hpa-deploy.yaml</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: lykops-hpa-deploy</span><br><span class="line">  labels:</span><br><span class="line">    software: apache</span><br><span class="line">    project: lykops</span><br><span class="line">    app: hpa</span><br><span class="line">    version: v1     </span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      name: lykops-hpa-deploy</span><br><span class="line">      software: apache</span><br><span class="line">      project: lykops</span><br><span class="line">      app: hpa</span><br><span class="line">      version: v1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        name: lykops-hpa-deploy</span><br><span class="line">        software: apache</span><br><span class="line">        project: lykops</span><br><span class="line">        app: hpa</span><br><span class="line">        version: v1</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: lykops-hpa-deploy</span><br><span class="line">        image: web:apache</span><br><span class="line">        command: [ &quot;sh&quot;, &quot;/etc/run.sh&quot; ]</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">          name: http</span><br><span class="line">          protocol: TCP</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 0.001</span><br><span class="line">            memory: 4Mi</span><br><span class="line">          limits:</span><br><span class="line">            cpu: 0.01</span><br><span class="line">            memory: 16Mi</span><br><span class="line">EOF</span><br><span class="line"> </span><br><span class="line">创建这个实例</span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f lykops-hpa-deploy.yaml --record</span><br><span class="line"> </span><br><span class="line">2）创建service</span><br><span class="line">[root@k8s-master01 ~]#</span><br><span class="line">cat &lt;&lt; EOF &gt; lykops-hpa-deploy-svc.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: lykops-hpa-svc</span><br><span class="line">  labels:</span><br><span class="line">    software: apache</span><br><span class="line">    project: lykops</span><br><span class="line">    app: hpa</span><br><span class="line">    version: v1</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    software: apache</span><br><span class="line">    project: lykops</span><br><span class="line">    app: hpa</span><br><span class="line">    version: v1</span><br><span class="line">    name: lykops-hpa-deploy</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 80</span><br><span class="line">    protocol: TCP</span><br><span class="line">EOF</span><br><span class="line"> </span><br><span class="line">创建这个service</span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f lykops-hpa-deploy-svc.yaml</span><br><span class="line"> </span><br><span class="line">3）创建HPA</span><br><span class="line">[root@k8s-master01 ~]# cat &lt;&lt; EOF &gt; lykops-hpa.yaml</span><br><span class="line">apiVersion: autoscaling/v1</span><br><span class="line">kind: HorizontalPodAutoscaler</span><br><span class="line">metadata:</span><br><span class="line">  name: lykops-hpa</span><br><span class="line">  labels:</span><br><span class="line">    software: apache</span><br><span class="line">    project: lykops</span><br><span class="line">    app: hpa</span><br><span class="line">    version: v1</span><br><span class="line">spec:</span><br><span class="line">  scaleTargetRef:</span><br><span class="line">    apiVersion: v1</span><br><span class="line">    kind: Deployment</span><br><span class="line">    name: lykops-hpa-deploy</span><br><span class="line">    #这里只能为这三项</span><br><span class="line">  minReplicas: 1</span><br><span class="line">  maxReplicas: 10</span><br><span class="line">  targetCPUUtilizationPercentage: 5</span><br><span class="line">EOF</span><br><span class="line"> </span><br><span class="line">创建这个HPA</span><br><span class="line">[root@k8s-master01 ~]# kubectl create -f lykops-hpa.yaml</span><br><span class="line"> </span><br><span class="line">4）测试</span><br><span class="line">多台机器不断访问service的clusterIP地址，然后可以看出是否增加pod数了</span><br></pre></td></tr></table></figure>



<h2 id="kubectl命令"><a href="#kubectl命令" class="headerlink" title="kubectl命令"></a>kubectl命令</h2><h3 id="1-查看类命令"><a href="#1-查看类命令" class="headerlink" title="1. 查看类命令"></a>1. 查看类命令</h3><p>获取节点相应服务的信息</p>
<blockquote>
<p>kubectl get nodes</p>
</blockquote>
<p>如果需要按selector名来查找相应的pod信息， 可以通过以下命令查看：</p>
<blockquote>
<p>kubectl get pod –selector name=tomcat</p>
</blockquote>
<p>查看K8S集群信息</p>
<blockquote>
<p>kubectl cluster-info</p>
</blockquote>
<p>查看各组件信息</p>
<blockquote>
<p>kubectl -s <a href="http://localhost:8080/" target="_blank" rel="noopener">http://localhost:8080</a> get componentstatuses</p>
</blockquote>
<p>查看pods所在的运行节点</p>
<blockquote>
<p>kubectl get pods -o wide</p>
</blockquote>
<p>如果需要通过某个命名空间查找节点信息， 可以通过以下命令查看：</p>
<blockquote>
<p>kubectl get pods -o wide -n kube-system</p>
<ul>
<li>-o wide 选项表示展示更多的Pod节点信息</li>
<li>-n &lt;命名空间&gt; 表示查询该命名空间下的Pod节点信息</li>
</ul>
</blockquote>
<p>如果需要查找所有命名空间下的所有Pod信息， 可以通过以下命令：</p>
<blockquote>
<p>kubectl get pods –all-namespaces<br>或<br>kubectl get pods -o wide –all-namespaces #列出更多的详细信息</p>
</blockquote>
<p>查看pods定义的详细信息</p>
<blockquote>
<p>kubectl get pods -o yaml</p>
</blockquote>
<p>查看运行的pod的环境变量</p>
<blockquote>
<p>kubectl exec &lt;pod名称&gt; env</p>
</blockquote>
<p>查看指定pod的日志</p>
<blockquote>
<p>kubectl logs -f pods/&lt;pod名称&gt; -n kube-system</p>
</blockquote>
<p>查看集群节点信息</p>
<blockquote>
<p>kubectl get nodes</p>
</blockquote>
<p>如果需要查看集群名称为<code>zone</code>下的集群节点信息, 可以使用以下命令：</p>
<blockquote>
<p>kubectl get nodes -l zone</p>
</blockquote>
<p>查看某个命名空间(如kube-system)下的所有service</p>
<blockquote>
<p>kubectl get services kubernetes-dashboard -n kube-system</p>
</blockquote>
<p>查看某个命名空间(如kube-system)下的所有发布信息</p>
<blockquote>
<p>kubectl get deployment kubernetes-dashboard -n kube-system</p>
</blockquote>
<p>查看资源信息</p>
<ul>
<li>根据service名查看资源信息</li>
</ul>
<blockquote>
<ul>
<li>kubectl describe service/kubernetes-dashboard –namespace=”kube-system”</li>
</ul>
</blockquote>
<ul>
<li>根据pod名称查看资源信息</li>
</ul>
<blockquote>
<ul>
<li>kubectl describe pods/kubernetes-dashboard-349859023-g6q8c –namespace=”kube-system”</li>
<li>kubectl describe pod nginx-772ai</li>
</ul>
</blockquote>
<h3 id="2-操作类命令"><a href="#2-操作类命令" class="headerlink" title="2. 操作类命令"></a>2. 操作类命令</h3><p>创建资源</p>
<blockquote>
<p>kubectl create -f &lt;文件名.yaml&gt;</p>
</blockquote>
<p>重建资源</p>
<blockquote>
<p>kubectl replace -f &lt;文件名  [–force]</p>
</blockquote>
<p>删除资源</p>
<blockquote>
<ul>
<li>强制删除某个文件名命名节点 <code>kubectl delete -f &lt;文件名&gt;</code></li>
<li>删除某个Pod命令节点 <code>kubectl delete pod &lt;pod名&gt;</code></li>
<li>删除某个Replication Controller命名节点 <code>kubectl delete rc &lt;rc名&gt;</code></li>
<li>删除某个服务命名节点 <code>kubectl delete service &lt;service名&gt;</code></li>
<li>删除所有Pod节点 <code>kubectl delete pod --all</code></li>
</ul>
</blockquote>
<p>动态伸缩操作</p>
<ul>
<li>为Replcation Controller名称为<code>nginx</code>动态扩展5个服务节点</li>
</ul>
<blockquote>
<p>kubectl scale rc nginx –replicas=5</p>
</blockquote>
<ul>
<li>为<code>redis-slave</code>部署5 个服务节点</li>
</ul>
<blockquote>
<p>kubectl scale deployment redis-slave –replicas=5</p>
</blockquote>
<ul>
<li>为<code>redis-slave-deployment.yaml</code>部署脚本下的服务扩展2个节点</li>
</ul>
<blockquote>
<p>kubectl scale –replicas=2 -f redis-slave-deployment.yaml</p>
</blockquote>
<p>进入Pod节点容器内进行操作</p>
<blockquote>
<p>kubectl exec -it redis-master-1033017107-q47hh /bin/bash</p>
</blockquote>
<p>滚动升级</p>
<ul>
<li>配置文件滚动升级</li>
</ul>
<blockquote>
<p>kubectl rolling-update redis-master -f redis-master-controller-v2.yaml</p>
</blockquote>
<ul>
<li>命令升级</li>
</ul>
<blockquote>
<p>kubectl rolling-update redis-master –image=redis-master:2.0</p>
</blockquote>
<ul>
<li>Pod版本回滚</li>
</ul>
<blockquote>
<p>kubectl rolling-update redis-master –image=redis-master:1.0 –rollback</p>
</blockquote>
<h3 id="3-更多操作命令"><a href="#3-更多操作命令" class="headerlink" title="3. 更多操作命令"></a>3. 更多操作命令</h3><p><a href="http://docs.kubernetes.org.cn/" target="_blank" rel="noopener">Kubernetes</a></p>
<h2 id="Kubernetes-Service"><a href="#Kubernetes-Service" class="headerlink" title="Kubernetes Service"></a>Kubernetes Service</h2><p>在K8S集群中，Pod有用独立的IP，也具有独立的生命周期。一旦某个Node节点发生故障，ReplicationController会将该节点上的Pod迁移到集群中其他Node节点上。对于有多个Pod，为前端应用提供相同的服务，这时前端其实不关心调用的后台具体哪个Pod，这时就要用到Service。</p>
<blockquote>
<p>A Service in Kubernetes is an abstraction which defines a logical set of Pods and a policy by which to access them.</p>
</blockquote>
<p>Kubernetes中的Service是集群中一组Pod以及访问策略的抽象。可以通过YAML、JSON定义，目标Pods通常通过LabelSelector定义。通过<code>type</code>字段，服务定义了应用暴露的几种方式：</p>
<ul>
<li>ClusterIP，默认的方式，通过集群IP来对外提供服务，这种方式只能在集群内部访问。</li>
<li>NodePort，利用NAT技术在Node的指定端口上提供对外服务。外部应用通过<em>:</em>的方式访问。</li>
<li>LoadBalancer，利用外部的负载均衡设施进行服务的访问。</li>
<li>ExternalName，这是1.7版本之后 kube-dns 提供的功能。</li>
</ul>
<p>服务提供了在一组Pods之间分配流量的功能，同时也是因为服务这个抽象层的存在，Kubernetes才能够在不影响应用的情况下进行扩缩容。通常Service通过label和selector来确定可操作的对象。label可以在对象创建时指定，也可以在运行时修改。</p>
<h3 id="查看服务状态"><a href="#查看服务状态" class="headerlink" title="查看服务状态"></a>查看服务状态</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl get services</span><br><span class="line">NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   44s</span><br></pre></td></tr></table></figure>

<h3 id="对外部暴露服务"><a href="#对外部暴露服务" class="headerlink" title="对外部暴露服务"></a>对外部暴露服务</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl expose deployment/kubernetes-bootcamp --type=&quot;NodePort&quot; --port 8080</span><br><span class="line">service &quot;kubernetes-bootcamp&quot; exposed</span><br><span class="line">$ kubectl get servicesNAME                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)     AGE</span><br><span class="line">kubernetes            ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP     2m</span><br><span class="line">kubernetes-bootcamp   NodePort    10.99.175.225   &lt;none&gt;        8080:32172/TCP   5s</span><br></pre></td></tr></table></figure>

<h3 id="查看服务详细信息"><a href="#查看服务详细信息" class="headerlink" title="查看服务详细信息"></a>查看服务详细信息</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl describe service/kubernetes-bootcamp</span><br><span class="line">Name:                     kubernetes-bootcamp</span><br><span class="line">Namespace:                default</span><br><span class="line">Labels:                   run=kubernetes-bootcamp</span><br><span class="line">Annotations:              &lt;none&gt;</span><br><span class="line">Selector:                 run=kubernetes-bootcamp</span><br><span class="line">Type:                     NodePort</span><br><span class="line">IP:                       10.99.175.225</span><br><span class="line">Port:                     &lt;unset&gt;  8080/TCP</span><br><span class="line">TargetPort:               8080/TCP</span><br><span class="line">NodePort:                 &lt;unset&gt;  32172/TCP</span><br><span class="line">Endpoints:                172.18.0.2:8080</span><br><span class="line">Session Affinity:         None</span><br><span class="line">External Traffic Policy:  Cluster</span><br><span class="line">Events:                   &lt;none&gt;</span><br></pre></td></tr></table></figure>

<p>这个例子中Node没有外部IP，所以显示为空。利用内部IP测试。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ curl 172.17.0.11:32172</span><br><span class="line">Hello Kubernetes bootcamp! | Running on: kubernetes-bootcamp-5c69669756-hmc69 | v=1</span><br></pre></td></tr></table></figure>

<h3 id="通过标签查询Pod和Service"><a href="#通过标签查询Pod和Service" class="headerlink" title="通过标签查询Pod和Service"></a>通过标签查询Pod和Service</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl get pods -l run=kubernetes-bootcamp</span><br><span class="line">NAME                                   READY     STATUS    RESTARTS   AGE</span><br><span class="line">kubernetes-bootcamp-5c69669756-hmc69   1/1       Running   0          8m</span><br><span class="line">$ kubectl get services -l = run=kubernetes-bootcamp</span><br><span class="line">error: name cannot be provided when a selector is specified</span><br><span class="line">$ kubectl get services -l run=kubernetes-bootcamp</span><br><span class="line">NAME                  TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">kubernetes-bootcamp   NodePort   10.99.175.225   &lt;none&gt;        8080:32172/TCP   6m</span><br></pre></td></tr></table></figure>

<h3 id="新增标签"><a href="#新增标签" class="headerlink" title="新增标签"></a>新增标签</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl label pod $POD_NAME app=v1</span><br><span class="line">pod &quot;kubernetes-bootcamp-5c69669756-hmc69&quot; labeled</span><br><span class="line">$ kubectl describe pods $POD_NAME</span><br><span class="line">Name:           kubernetes-bootcamp-5c69669756-hmc69</span><br><span class="line">Namespace:      default</span><br><span class="line">Node:           minikube/172.17.0.11</span><br><span class="line">Start Time:     Tue, 17 Jul 2018 05:20:35 +0000</span><br><span class="line">Labels:         app=v1</span><br><span class="line">                pod-template-hash=1725225312</span><br><span class="line">                run=kubernetes-bootcamp</span><br><span class="line">$ kubectl get pods -l app=v1</span><br><span class="line">NAME                                   READY     STATUS    RESTARTS   AGE</span><br><span class="line">kubernetes-bootcamp-5c69669756-hmc69   1/1       Running   0          11m</span><br></pre></td></tr></table></figure>

<h3 id="删除服务"><a href="#删除服务" class="headerlink" title="删除服务"></a>删除服务</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl get services</span><br><span class="line">NAME                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)     AGE</span><br><span class="line">kubernetes            ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP     12m</span><br><span class="line">kubernetes-bootcamp   NodePort    10.99.175.225   &lt;none&gt;        8080:32172/TCP   10m</span><br><span class="line">$ kubectl delete service -l run=kubernetes-bootcamp</span><br><span class="line">service &quot;kubernetes-bootcamp&quot; deleted</span><br><span class="line">$ kubectl get services</span><br><span class="line">NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   12m</span><br></pre></td></tr></table></figure>

<h2 id="helm"><a href="#helm" class="headerlink" title="helm"></a>helm</h2><p>Helm 是 Kubernetes 生态系统中的一个软件包管理工具。本文将介绍 Helm 中的相关概念和基本工作原理，并通过一个具体的示例学习如何使用 Helm 打包、分发、安装、升级及回退 Kubernetes 应用。</p>
<h3 id="Kubernetes-应用部署的挑战"><a href="#Kubernetes-应用部署的挑战" class="headerlink" title="Kubernetes 应用部署的挑战"></a>Kubernetes 应用部署的挑战</h3><p>Kubernetes 是一个提供了基于容器的应用集群管理解决方案，Kubernetes 为容器化应用提供了部署运行、资源调度、服务发现和动态伸缩等一系列完整功能。</p>
<p>Kubernetes 的核心设计理念是: 用户定义要部署的应用程序的规则，而 Kubernetes 则负责按照定义的规则部署并运行应用程序。如果应用程序出现问题导致偏离了定义的规格，Kubernetes 负责对其进行自动修正。例如：定义的应用规则要求部署两个实例（Pod），其中一个实例异常终止了，Kubernetes 会检查到并重新启动一个新的实例。</p>
<p>用户通过使用 Kubernetes API 对象来描述应用程序规则，包括 Pod、Service、Volume、Namespace、ReplicaSet、Deployment、Job等等。一般这些资源对象的定义需要写入一系列的 YAML 文件中，然后通过 Kubernetes 命令行工具 Kubectl 调 Kubernetes API 进行部署。</p>
<p>以一个典型的三层应用 Wordpress 为例，该应用程序就涉及到多个 Kubernetes API 对象，而要描述这些 Kubernetes API 对象就可能要同时维护多个 YAML 文件。</p>
<p><img src="/2019/10/31/K8S%E9%83%A8%E7%BD%B2%E7%AE%80%E4%BB%8B/helm01-1572568214793.png" alt="img"></p>
<p>从上图可以看到，在进行 Kubernetes 软件部署时，我们面临下述几个问题：</p>
<ul>
<li>如何管理、编辑和更新这些这些分散的 Kubernetes 应用配置文件。</li>
<li>如何把一套相关的配置文件作为一个应用进行管理。</li>
<li>如何分发和重用 Kubernetes 的应用配置。</li>
</ul>
<p>Helm 的出现就是为了很好地解决上面这些问题。</p>
<h3 id="Helm-是什么？"><a href="#Helm-是什么？" class="headerlink" title="Helm 是什么？"></a>Helm 是什么？</h3><p>Helm 是 <a href="https://deis.com/" target="_blank" rel="noopener">Deis</a> 开发的一个用于 Kubernetes 应用的包管理工具，主要用来管理 Charts。有点类似于 Ubuntu 中的 APT 或 CentOS 中的 YUM。</p>
<p>Helm Chart 是用来封装 Kubernetes 原生应用程序的一系列 YAML 文件。可以在你部署应用的时候自定义应用程序的一些 Metadata，以便于应用程序的分发。</p>
<p>对于应用发布者而言，可以通过 Helm 打包应用、管理应用依赖关系、管理应用版本并发布应用到软件仓库。</p>
<p>对于使用者而言，使用 Helm 后不用需要编写复杂的应用部署文件，可以以简单的方式在 Kubernetes 上查找、安装、升级、回滚、卸载应用程序。</p>
<h3 id="Helm-组件及相关术语"><a href="#Helm-组件及相关术语" class="headerlink" title="Helm 组件及相关术语"></a>Helm 组件及相关术语</h3><ul>
<li>Helm</li>
</ul>
<p>Helm 是一个命令行下的客户端工具。主要用于 Kubernetes 应用程序 Chart 的创建、打包、发布以及创建和管理本地和远程的 Chart 仓库。</p>
<ul>
<li>Tiller</li>
</ul>
<p>Tiller 是 Helm 的服务端，部署在 Kubernetes 集群中。Tiller 用于接收 Helm 的请求，并根据 Chart 生成 Kubernetes 的部署文件（ Helm 称为 Release ），然后提交给 Kubernetes 创建应用。Tiller 还提供了 Release 的升级、删除、回滚等一系列功能。</p>
<ul>
<li>Chart</li>
</ul>
<p>Helm 的软件包，采用 TAR 格式。类似于 APT 的 DEB 包或者 YUM 的 RPM 包，其包含了一组定义 Kubernetes 资源相关的 YAML 文件。</p>
<ul>
<li>Repoistory</li>
</ul>
<p>Helm 的软件仓库，Repository 本质上是一个 Web 服务器，该服务器保存了一系列的 Chart 软件包以供用户下载，并且提供了一个该 Repository 的 Chart 包的清单文件以供查询。Helm 可以同时管理多个不同的 Repository。</p>
<ul>
<li>Release</li>
</ul>
<p>使用 <code>helm install</code> 命令在 Kubernetes 集群中部署的 Chart 称为 Release。</p>
<blockquote>
<p>注：需要注意的是：Helm 中提到的 Release 和我们通常概念中的版本有所不同，这里的 Release 可以理解为 Helm 使用 Chart 包部署的一个应用实例。</p>
</blockquote>
<h3 id="Helm-工作原理"><a href="#Helm-工作原理" class="headerlink" title="Helm 工作原理"></a>Helm 工作原理</h3><p>这张图描述了 Helm 的几个关键组件 Helm（客户端）、Tiller（服务器）、Repository（Chart 软件仓库）、Chart（软件包）之间的关系。</p>
<p><img src="/2019/10/31/K8S%E9%83%A8%E7%BD%B2%E7%AE%80%E4%BB%8B/helm02-1572568214827.png" alt="img"></p>
<p><strong>Chart Install 过程</strong></p>
<ul>
<li>Helm 从指定的目录或者 TAR 文件中解析出 Chart 结构信息。</li>
<li>Helm 将指定的 Chart 结构和 Values 信息通过 gRPC 传递给 Tiller。</li>
<li>Tiller 根据 Chart 和 Values 生成一个 Release。</li>
<li>Tiller 将 Release 发送给 Kubernetes 用于生成 Release。</li>
</ul>
<p><strong>Chart Update 过程</strong></p>
<ul>
<li>Helm 从指定的目录或者 TAR 文件中解析出 Chart 结构信息。</li>
<li>Helm 将需要更新的 Release 的名称、Chart 结构和 Values 信息传递给 Tiller。</li>
<li>Tiller 生成 Release 并更新指定名称的 Release 的 History。</li>
<li>Tiller 将 Release 发送给 Kubernetes 用于更新 Release。</li>
</ul>
<p><strong>Chart Rollback 过程</strong></p>
<ul>
<li>Helm 将要回滚的 Release 的名称传递给 Tiller。</li>
<li>Tiller 根据 Release 的名称查找 History。</li>
<li>Tiller 从 History 中获取上一个 Release。</li>
<li>Tiller 将上一个 Release 发送给 Kubernetes 用于替换当前 Release。</li>
</ul>
<p><strong>Chart 处理依赖说明</strong></p>
<p>Tiller 在处理 Chart 时，直接将 Chart 以及其依赖的所有 Charts 合并为一个 Release，同时传递给 Kubernetes。因此 Tiller 并不负责管理依赖之间的启动顺序。Chart 中的应用需要能够自行处理依赖关系。</p>
<h3 id="部署-Helm"><a href="#部署-Helm" class="headerlink" title="部署 Helm"></a>部署 Helm</h3><h4 id="安装-Helm-客户端"><a href="#安装-Helm-客户端" class="headerlink" title="安装 Helm 客户端"></a>安装 Helm 客户端</h4><p>Helm 的安装方式很多，这里采用二进制的方式安装。更多安装方法可以参考 Helm 的<a href="https://docs.helm.sh/using_helm/#installing-helm" target="_blank" rel="noopener">官方帮助文档</a>。</p>
<ul>
<li>使用官方提供的脚本一键安装</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ curl https://raw.githubusercontent.com/kubernetes/helm/master/scripts/get &gt; get_helm.sh</span><br><span class="line">$ chmod 700 get_helm.sh</span><br><span class="line">$ ./get_helm.sh</span><br></pre></td></tr></table></figure>

<ul>
<li>手动下载安装</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 下载 Helm </span><br><span class="line">$ wget https://storage.googleapis.com/kubernetes-helm/helm-v2.9.1-linux-amd64.tar.gz</span><br><span class="line"># 解压 Helm</span><br><span class="line">$ tar -zxvf helm-v2.9.1-linux-amd64.tar.gz</span><br><span class="line"># 复制客户端执行文件到 bin 目录下</span><br><span class="line">$ cp linux-amd64/helm /usr/local/bin/</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注：<a href="http://storage.googleapis.com/" target="_blank" rel="noopener">storage.googleapis.com</a> 默认是不能访问的，该问题请自行解决。</p>
</blockquote>
<h4 id="安装-Helm-服务器端-Tiller"><a href="#安装-Helm-服务器端-Tiller" class="headerlink" title="安装 Helm 服务器端 Tiller"></a>安装 Helm 服务器端 Tiller</h4><p>Tiller 是以 Deployment 方式部署在 Kubernetes 集群中的，只需使用以下指令便可简单的完成安装。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm init</span><br></pre></td></tr></table></figure>

<p>由于 Helm 默认会去 <a href="http://storage.googleapis.com/" target="_blank" rel="noopener">storage.googleapis.com</a> 拉取镜像，如果你当前执行的机器不能访问该域名的话可以使用以下命令来安装：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 使用阿里云镜像安装并把默认仓库设置为阿里云上的镜像仓库</span><br><span class="line">$ helm init --upgrade --tiller-image registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.9.1 --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts</span><br></pre></td></tr></table></figure>

<h5 id="给-Tiller-授权"><a href="#给-Tiller-授权" class="headerlink" title="给 Tiller 授权"></a>给 Tiller 授权</h5><p>因为 Helm 的服务端 Tiller 是一个部署在 Kubernetes 中 Kube-System Namespace 下 的 Deployment，它会去连接 Kube-Api 在 Kubernetes 里创建和删除应用。</p>
<p>而从 Kubernetes 1.6 版本开始，API Server 启用了 RBAC 授权。目前的 Tiller 部署时默认没有定义授权的 ServiceAccount，这会导致访问 API Server 时被拒绝。所以我们需要明确为 Tiller 部署添加授权。</p>
<ul>
<li>创建 Kubernetes 的服务帐号和绑定角色</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl get deployment --all-namespaces</span><br><span class="line">NAMESPACE     NAME                   DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">kube-system   tiller-deploy          1         1         1            1           1h</span><br><span class="line">$ kubectl create serviceaccount --namespace kube-system tiller</span><br><span class="line">$ kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller</span><br></pre></td></tr></table></figure>

<ul>
<li>为 Tiller 设置帐号</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 使用 kubectl patch 更新 API 对象</span><br><span class="line">$ kubectl patch deploy --namespace kube-system tiller-deploy -p &apos;&#123;&quot;spec&quot;:&#123;&quot;template&quot;:&#123;&quot;spec&quot;:&#123;&quot;serviceAccount&quot;:&quot;tiller&quot;&#125;&#125;&#125;&#125;&apos;</span><br><span class="line">deployment.extensions &quot;tiller-deploy&quot; patched</span><br></pre></td></tr></table></figure>

<ul>
<li>查看是否授权成功</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl get deploy --namespace kube-system   tiller-deploy  --output yaml|grep  serviceAccount</span><br><span class="line">serviceAccount: tiller</span><br><span class="line">serviceAccountName: tiller</span><br></pre></td></tr></table></figure>

<h5 id="验证-Tiller-是否安装成功"><a href="#验证-Tiller-是否安装成功" class="headerlink" title="验证 Tiller 是否安装成功"></a>验证 Tiller 是否安装成功</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl -n kube-system get pods|grep tiller</span><br><span class="line">tiller-deploy-6d68f5c78f-nql2z          1/1       Running   0          5m</span><br><span class="line"></span><br><span class="line">$ helm version</span><br><span class="line">Client: &amp;version.Version&#123;SemVer:&quot;v2.9.1&quot;, GitCommit:&quot;20adb27c7c5868466912eebdf6664e7390ebe710&quot;, GitTreeState:&quot;clean&quot;&#125;</span><br><span class="line">Server: &amp;version.Version&#123;SemVer:&quot;v2.9.1&quot;, GitCommit:&quot;20adb27c7c5868466912eebdf6664e7390ebe710&quot;, GitTreeState:&quot;clean&quot;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="卸载-Helm-服务器端-Tiller"><a href="#卸载-Helm-服务器端-Tiller" class="headerlink" title="卸载 Helm 服务器端 Tiller"></a>卸载 Helm 服务器端 Tiller</h4><p>如果你需要在 Kubernetes 中卸载已部署的 Tiller，可使用以下命令完成卸载。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm reset</span><br></pre></td></tr></table></figure>

<h3 id="构建一个-Helm-Chart"><a href="#构建一个-Helm-Chart" class="headerlink" title="构建一个 Helm Chart"></a>构建一个 Helm Chart</h3><p>下面我们通过一个完整的示例来学习如何使用 Helm 创建、打包、分发、安装、升级及回退Kubernetes应用。</p>
<h4 id="创建一个名为-mychart-的-Chart"><a href="#创建一个名为-mychart-的-Chart" class="headerlink" title="创建一个名为 mychart 的 Chart"></a>创建一个名为 mychart 的 Chart</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm create mychart</span><br></pre></td></tr></table></figure>

<p>该命令创建了一个 mychart 目录，该目录结构如下所示。这里我们主要关注目录中的 Chart.yaml、values.yaml、NOTES.txt 和 Templates 目录。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ tree mychart/</span><br><span class="line">mychart/</span><br><span class="line">├── charts</span><br><span class="line">├── Chart.yaml</span><br><span class="line">├── templates</span><br><span class="line">│   ├── deployment.yaml</span><br><span class="line">│   ├── _helpers.tpl</span><br><span class="line">│   ├── ingress.yaml</span><br><span class="line">│   ├── NOTES.txt</span><br><span class="line">│   └── service.yaml</span><br><span class="line">└── values.yaml</span><br><span class="line"></span><br><span class="line">2 directories, 7 files</span><br></pre></td></tr></table></figure>

<ul>
<li>Chart.yaml 用于描述这个 Chart的相关信息，包括名字、描述信息以及版本等。</li>
<li>values.yaml 用于存储 templates 目录中模板文件中用到变量的值。</li>
<li>NOTES.txt 用于介绍 Chart 部署后的一些信息，例如：如何使用这个 Chart、列出缺省的设置等。</li>
<li>Templates 目录下是 YAML 文件的模板，该模板文件遵循 Go template 语法。</li>
</ul>
<p>Templates 目录下 YAML 文件模板的值默认都是在 values.yaml 里定义的，比如在 deployment.yaml 中定义的容器镜像。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">image: &quot;&#123;&#123; .Values.image.repository &#125;&#125;:&#123;&#123; .Values.image.tag &#125;&#125;&quot;</span><br></pre></td></tr></table></figure>

<p>其中的 <code>.Values.image.repository</code> 的值就是在 values.yaml 里定义的 nginx，<code>.Values.image.tag</code> 的值就是 stable。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cat mychart/values.yaml|grep repository</span><br><span class="line">repository: nginx</span><br><span class="line"></span><br><span class="line">$ cat mychart/values.yaml|grep tag</span><br><span class="line">tag: stable</span><br></pre></td></tr></table></figure>

<p>以上两个变量值是在 <code>create chart</code> 的时候就自动生成的默认值，你可以根据实际情况进行修改。</p>
<blockquote>
<p>如果你需要了解更多关于 Go 模板的相关信息，可以查看 <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> 的一个关于 <a href="https://gohugo.io/templates/go-templates/" target="_blank" rel="noopener">Go 模板</a> 的介绍。</p>
</blockquote>
<h4 id="编写应用的介绍信息"><a href="#编写应用的介绍信息" class="headerlink" title="编写应用的介绍信息"></a>编写应用的介绍信息</h4><p>打开 Chart.yaml, 填写你部署的应用的详细信息，以 mychart 为例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cat mychart/Chart.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">appVersion: &quot;1.0&quot;</span><br><span class="line">description: A Helm chart for Kubernetes</span><br><span class="line">name: mychart</span><br><span class="line">version: 0.1.0</span><br></pre></td></tr></table></figure>

<h4 id="编写应用具体部署信息"><a href="#编写应用具体部署信息" class="headerlink" title="编写应用具体部署信息"></a>编写应用具体部署信息</h4><p>编辑 values.yaml，它默认会在 Kubernetes 部署一个 Nginx。下面是 mychart 应用的 values.yaml 文件的内容：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cat mychart/values.yaml</span><br><span class="line"># Default values for mychart.</span><br><span class="line"># This is a YAML-formatted file.</span><br><span class="line"># Declare variables to be passed into your templates.</span><br><span class="line"></span><br><span class="line">replicaCount: 1</span><br><span class="line"></span><br><span class="line">image:</span><br><span class="line">  repository: nginx</span><br><span class="line">  tag: stable</span><br><span class="line">  pullPolicy: IfNotPresent</span><br><span class="line"></span><br><span class="line">service:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  port: 80</span><br><span class="line"></span><br><span class="line">ingress:</span><br><span class="line">  enabled: false</span><br><span class="line">  annotations: &#123;&#125;</span><br><span class="line">    # kubernetes.io/ingress.class: nginx</span><br><span class="line">    # kubernetes.io/tls-acme: &quot;true&quot;</span><br><span class="line">  path: /</span><br><span class="line">  hosts:</span><br><span class="line">    - chart-example.local</span><br><span class="line">  tls: []</span><br><span class="line">  #  - secretName: chart-example-tls</span><br><span class="line">  #    hosts:</span><br><span class="line">  #      - chart-example.local</span><br><span class="line"></span><br><span class="line">resources: &#123;&#125;</span><br><span class="line">  # We usually recommend not to specify default resources and to leave this as a conscious</span><br><span class="line">  # choice for the user. This also increases chances charts run on environments with little</span><br><span class="line">  # resources, such as Minikube. If you do want to specify resources, uncomment the following</span><br><span class="line">  # lines, adjust them as necessary, and remove the curly braces after &apos;resources:&apos;.</span><br><span class="line">  # limits:</span><br><span class="line">  #  cpu: 100m</span><br><span class="line">  #  memory: 128Mi</span><br><span class="line">  # requests:</span><br><span class="line">  #  cpu: 100m</span><br><span class="line">  #  memory: 128Mi</span><br><span class="line"></span><br><span class="line">nodeSelector: &#123;&#125;</span><br><span class="line"></span><br><span class="line">tolerations: []</span><br><span class="line"></span><br><span class="line">affinity: &#123;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="检查依赖和模板配置是否正确"><a href="#检查依赖和模板配置是否正确" class="headerlink" title="检查依赖和模板配置是否正确"></a>检查依赖和模板配置是否正确</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm lint mychart/</span><br><span class="line">==&gt; Linting .</span><br><span class="line">[INFO] Chart.yaml: icon is recommended</span><br><span class="line"></span><br><span class="line">1 chart(s) linted, no failures</span><br></pre></td></tr></table></figure>

<p>如果文件格式错误，可以根据提示进行修改。</p>
<h4 id="将应用打包"><a href="#将应用打包" class="headerlink" title="将应用打包"></a>将应用打包</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm package mychart</span><br><span class="line">Successfully packaged chart and saved it to: /home/k8s/mychart-0.1.0.tgz</span><br></pre></td></tr></table></figure>

<p>mychart 目录会被打包为一个 mychart-0.1.0.tgz 格式的压缩包，该压缩包会被放到当前目录下，并同时被保存到了 Helm 的本地缺省仓库目录中。</p>
<p>如果你想看到更详细的输出，可以加上 <code>--debug</code> 参数来查看打包的输出，输出内容应该类似如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm package mychart --debug</span><br><span class="line">Successfully packaged chart and saved it to: /home/k8s/mychart-0.1.0.tgz</span><br><span class="line">[debug] Successfully saved /home/k8s/mychart-0.1.0.tgz to /home/k8s/.helm/repository/local</span><br></pre></td></tr></table></figure>

<h4 id="将应用发布到-Repository"><a href="#将应用发布到-Repository" class="headerlink" title="将应用发布到 Repository"></a>将应用发布到 Repository</h4><p>虽然我们已经打包了 Chart 并发布到了 Helm 的本地目录中，但通过 <code>helm search</code> 命令查找，并不能找不到刚才生成的 mychart包。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm search mychart</span><br><span class="line">No results found</span><br></pre></td></tr></table></figure>

<p>这是因为 Repository 目录中的 Chart 包还没有被 Helm 管理。通过 <code>helm repo list</code> 命令可以看到目前 Helm 中已配置的 Repository 的信息。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm repo list</span><br><span class="line">NAME    URL</span><br><span class="line">stable  https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注：新版本中执行 helm init 命令后默认会配置一个名为 local 的本地仓库。</p>
</blockquote>
<p>我们可以在本地启动一个 Repository Server，并将其加入到 Helm Repo 列表中。Helm Repository 必须以 Web 服务的方式提供，这里我们就使用 <code>helm serve</code> 命令启动一个 Repository Server，该 Server 缺省使用 <code>$HOME/.helm/repository/local</code> 目录作为 Chart 存储，并在 8879 端口上提供服务。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm serve &amp;</span><br><span class="line">Now serving you on 127.0.0.1:8879</span><br></pre></td></tr></table></figure>

<p>默认情况下该服务只监听 127.0.0.1，如果你要绑定到其它网络接口，可使用以下命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm serve --address 192.168.100.211:8879 &amp;</span><br></pre></td></tr></table></figure>

<p>如果你想使用指定目录来做为 Helm Repository 的存储目录，可以加上 <code>--repo-path</code> 参数：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm serve --address 192.168.100.211:8879 --repo-path /data/helm/repository/ --url http://192.168.100.211:8879/charts/</span><br></pre></td></tr></table></figure>

<p>通过 <code>helm repo index</code> 命令将 Chart 的 Metadata 记录更新在 index.yaml 文件中:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 更新 Helm Repository 的索引文件</span><br><span class="line">$ cd /home/k8s/.helm/repository/local</span><br><span class="line">$ helm repo index --url=http://192.168.100.211:8879 .</span><br></pre></td></tr></table></figure>

<p>完成启动本地 Helm Repository Server 后，就可以将本地 Repository 加入 Helm 的 Repo 列表。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm repo add local http://127.0.0.1:8879</span><br><span class="line">&quot;local&quot; has been added to your repositories</span><br></pre></td></tr></table></figure>

<p>现在再次查找 mychart 包，就可以搜索到了。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm repo update</span><br><span class="line">$ helm search mychart</span><br><span class="line">NAME         	CHART VERSION	APP VERSION	DESCRIPTION</span><br><span class="line">local/mychart	0.1.0        	1.0        	A Helm chart for Kubernetes</span><br></pre></td></tr></table></figure>

<h4 id="在-Kubernetes-中部署应用"><a href="#在-Kubernetes-中部署应用" class="headerlink" title="在 Kubernetes 中部署应用"></a>在 Kubernetes 中部署应用</h4><h5 id="部署一个应用"><a href="#部署一个应用" class="headerlink" title="部署一个应用"></a>部署一个应用</h5><p>Chart 被发布到仓储后，就可以通过 <code>helm install</code> 命令部署该 Chart。</p>
<ul>
<li>检查配置和模板是否有效</li>
</ul>
<p>当使用 <code>helm install</code> 命令部署应用时，实际上就是将 templates 目录下的模板文件渲染成 Kubernetes 能够识别的 YAML 格式。</p>
<p>在部署前我们可以使用 <code>helm install --dry-run --debug &lt;chart_dir&gt; --name &lt;release_name&gt;</code>命令来验证 Chart 的配置。该输出中包含了模板的变量配置与最终渲染的 YAML 文件。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm install --dry-run --debug local/mychart --name mike-test</span><br><span class="line">[debug] Created tunnel using local port: &apos;46649&apos;</span><br><span class="line"></span><br><span class="line">[debug] SERVER: &quot;127.0.0.1:46649&quot;</span><br><span class="line"></span><br><span class="line">[debug] Original chart version: &quot;&quot;</span><br><span class="line">[debug] Fetched local/mychart to /home/k8s/.helm/cache/archive/mychart-0.1.0.tgz</span><br><span class="line"></span><br><span class="line">[debug] CHART PATH: /home/k8s/.helm/cache/archive/mychart-0.1.0.tgz</span><br><span class="line"></span><br><span class="line">NAME:   mike-test</span><br><span class="line">REVISION: 1</span><br><span class="line">RELEASED: Mon Jul 23 10:39:49 2018</span><br><span class="line">CHART: mychart-0.1.0</span><br><span class="line">USER-SUPPLIED VALUES:</span><br><span class="line">&#123;&#125;</span><br><span class="line"></span><br><span class="line">COMPUTED VALUES:</span><br><span class="line">affinity: &#123;&#125;</span><br><span class="line">image:</span><br><span class="line">  pullPolicy: IfNotPresent</span><br><span class="line">  repository: nginx</span><br><span class="line">  tag: stable</span><br><span class="line">ingress:</span><br><span class="line">  annotations: &#123;&#125;</span><br><span class="line">  enabled: false</span><br><span class="line">  hosts:</span><br><span class="line">  - chart-example.local</span><br><span class="line">  path: /</span><br><span class="line">  tls: []</span><br><span class="line">nodeSelector: &#123;&#125;</span><br><span class="line">replicaCount: 1</span><br><span class="line">resources: &#123;&#125;</span><br><span class="line">service:</span><br><span class="line">  port: 80</span><br><span class="line">  type: ClusterIP</span><br><span class="line">tolerations: []</span><br><span class="line"></span><br><span class="line">HOOKS:</span><br><span class="line">MANIFEST:</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"># Source: mychart/templates/service.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: mike-test-mychart</span><br><span class="line">  labels:</span><br><span class="line">    app: mychart</span><br><span class="line">    chart: mychart-0.1.0</span><br><span class="line">    release: mike-test</span><br><span class="line">    heritage: Tiller</span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  ports:</span><br><span class="line">    - port: 80</span><br><span class="line">      targetPort: http</span><br><span class="line">      protocol: TCP</span><br><span class="line">      name: http</span><br><span class="line">  selector:</span><br><span class="line">    app: mychart</span><br><span class="line">    release: mike-test</span><br><span class="line">---</span><br><span class="line"># Source: mychart/templates/deployment.yaml</span><br><span class="line">apiVersion: apps/v1beta2</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: mike-test-mychart</span><br><span class="line">  labels:</span><br><span class="line">    app: mychart</span><br><span class="line">    chart: mychart-0.1.0</span><br><span class="line">    release: mike-test</span><br><span class="line">    heritage: Tiller</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: mychart</span><br><span class="line">      release: mike-test</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: mychart</span><br><span class="line">        release: mike-test</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: mychart</span><br><span class="line">          image: &quot;nginx:stable&quot;</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - name: http</span><br><span class="line">              containerPort: 80</span><br><span class="line">              protocol: TCP</span><br><span class="line">          livenessProbe:</span><br><span class="line">            httpGet:</span><br><span class="line">              path: /</span><br><span class="line">              port: http</span><br><span class="line">          readinessProbe:</span><br><span class="line">            httpGet:</span><br><span class="line">              path: /</span><br><span class="line">              port: http</span><br><span class="line">          resources:</span><br><span class="line">            &#123;&#125;</span><br></pre></td></tr></table></figure>

<p>验证完成没有问题后，我们就可以使用以下命令将其部署到 Kubernetes 上了。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 部署时需指定 Chart 名及 Release（部署的实例）名。</span><br><span class="line">$ helm install local/mychart --name mike-test</span><br><span class="line">NAME:   mike-test</span><br><span class="line">LAST DEPLOYED: Mon Jul 23 10:41:20 2018</span><br><span class="line">NAMESPACE: default</span><br><span class="line">STATUS: DEPLOYED</span><br><span class="line"></span><br><span class="line">RESOURCES:</span><br><span class="line">==&gt; v1/Service</span><br><span class="line">NAME               TYPE       CLUSTER-IP      EXTERNAL-IP  PORT(S)  AGE</span><br><span class="line">mike-test-mychart  ClusterIP  10.254.120.177  &lt;none&gt;       80/TCP   1s</span><br><span class="line"></span><br><span class="line">==&gt; v1beta2/Deployment</span><br><span class="line">NAME               DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE</span><br><span class="line">mike-test-mychart  1        0        0           0          0s</span><br><span class="line"></span><br><span class="line">==&gt; v1/Pod(related)</span><br><span class="line">NAME                                READY  STATUS   RESTARTS  AGE</span><br><span class="line">mike-test-mychart-6d56f8c8c9-d685v  0/1    Pending  0         0s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">NOTES:</span><br><span class="line">1. Get the application URL by running these commands:</span><br><span class="line">  export POD_NAME=$(kubectl get pods --namespace default -l &quot;app=mychart,release=mike-test&quot; -o jsonpath=&quot;&#123;.items[0].metadata.name&#125;&quot;)</span><br><span class="line">  echo &quot;Visit http://127.0.0.1:8080 to use your application&quot;</span><br><span class="line">  kubectl port-forward $POD_NAME 8080:80</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注：helm install 默认会用到 socat，需要在所有节点上安装 socat 软件包。</p>
</blockquote>
<p>完成部署后，现在 Nginx 就已经部署到 Kubernetes 集群上。在本地主机上执行提示中的命令后，就可在本机访问到该 Nginx 实例。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ export POD_NAME=$(kubectl get pods --namespace default -l &quot;app=mychart,release=mike-test&quot; -o jsonpath=&quot;&#123;.items[0].metadata.name&#125;&quot;)</span><br><span class="line">$ echo &quot;Visit http://127.0.0.1:8080 to use your application&quot;</span><br><span class="line">$ kubectl port-forward $POD_NAME 8080:80</span><br></pre></td></tr></table></figure>

<p>在本地访问 Nginx</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ curl http://127.0.0.1:8080</span><br><span class="line">.....</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;</span><br><span class="line">&lt;p&gt;If you see this page, the nginx web server is successfully installed and</span><br><span class="line">working. Further configuration is required.&lt;/p&gt;</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<p>使用下面的命令列出的所有已部署的 Release 以及其对应的 Chart。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm list</span><br><span class="line">NAME     	REVISION	UPDATED                 	STATUS  	CHART        	NAMESPACE</span><br><span class="line">mike-test	1       	Mon Jul 23 10:41:20 2018	DEPLOYED	mychart-0.1.0	default</span><br></pre></td></tr></table></figure>

<p>你还可以使用 <code>helm status</code> 查询一个特定的 Release 的状态。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm status mike-test</span><br><span class="line">LAST DEPLOYED: Mon Jul 23 10:41:20 2018</span><br><span class="line">NAMESPACE: default</span><br><span class="line">STATUS: DEPLOYED</span><br><span class="line"></span><br><span class="line">RESOURCES:</span><br><span class="line">==&gt; v1/Pod(related)</span><br><span class="line">NAME                                READY  STATUS   RESTARTS  AGE</span><br><span class="line">mike-test-mychart-6d56f8c8c9-d685v  1/1    Running  0         1m</span><br><span class="line"></span><br><span class="line">==&gt; v1/Service</span><br><span class="line">NAME               TYPE       CLUSTER-IP      EXTERNAL-IP  PORT(S)  AGE</span><br><span class="line">mike-test-mychart  ClusterIP  10.254.120.177  &lt;none&gt;       80/TCP   1m</span><br><span class="line"></span><br><span class="line">==&gt; v1beta2/Deployment</span><br><span class="line">NAME               DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE</span><br><span class="line">mike-test-mychart  1        1        1           1          1m</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">NOTES:</span><br><span class="line">1. Get the application URL by running these commands:</span><br><span class="line">  export POD_NAME=$(kubectl get pods --namespace default -l &quot;app=mychart,release=mike-test&quot; -o jsonpath=&quot;&#123;.items[0].metadata.name&#125;&quot;)</span><br><span class="line">  echo &quot;Visit http://127.0.0.1:8080 to use your application&quot;</span><br><span class="line">  kubectl port-forward $POD_NAME 8080:80</span><br></pre></td></tr></table></figure>

<h5 id="升级和回退一个应用"><a href="#升级和回退一个应用" class="headerlink" title="升级和回退一个应用"></a>升级和回退一个应用</h5><p>从上面 <code>helm list</code> 输出的结果中我们可以看到有一个 Revision（更改历史）字段，该字段用于表示某一个 Release 被更新的次数，我们可以用该特性对已部署的 Release 进行回滚。</p>
<ul>
<li>修改 Chart.yaml 文件</li>
</ul>
<p>将版本号从 0.1.0 修改为 0.2.0, 然后使用 <code>helm package</code> 命令打包并发布到本地仓库。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cat mychart/Chart.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">appVersion: &quot;1.0&quot;</span><br><span class="line">description: A Helm chart for Kubernetes</span><br><span class="line">name: mychart</span><br><span class="line">version: 0.2.0</span><br><span class="line"></span><br><span class="line">$ helm package mychart</span><br><span class="line">Successfully packaged chart and saved it to: /home/k8s/mychart-0.2.0.tgz</span><br></pre></td></tr></table></figure>

<ul>
<li>查询本地仓库中的 Chart 信息</li>
</ul>
<p>我们可以看到在本地仓库中 mychart 有两个版本。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm search mychart -l</span><br><span class="line">NAME         	CHART VERSION	APP VERSION	DESCRIPTION</span><br><span class="line">local/mychart	0.2.0        	1.0        	A Helm chart for Kubernetes</span><br><span class="line">local/mychart	0.1.0        	1.0        	A Helm chart for Kubernetes</span><br></pre></td></tr></table></figure>

<ul>
<li>升级一个应用</li>
</ul>
<p>现在用 <code>helm upgrade</code> 命令将已部署的 mike-test 升级到新版本。你可以通过 <code>--version</code> 参数指定需要升级的版本号，如果没有指定版本号，则缺省使用最新版本。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm upgrade mike-test local/mychart</span><br><span class="line">Release &quot;mike-test&quot; has been upgraded. Happy Helming!</span><br><span class="line">LAST DEPLOYED: Mon Jul 23 10:50:25 2018</span><br><span class="line">NAMESPACE: default</span><br><span class="line">STATUS: DEPLOYED</span><br><span class="line"></span><br><span class="line">RESOURCES:</span><br><span class="line">==&gt; v1/Pod(related)</span><br><span class="line">NAME                                READY  STATUS   RESTARTS  AGE</span><br><span class="line">mike-test-mychart-6d56f8c8c9-d685v  1/1    Running  0         9m</span><br><span class="line"></span><br><span class="line">==&gt; v1/Service</span><br><span class="line">NAME               TYPE       CLUSTER-IP      EXTERNAL-IP  PORT(S)  AGE</span><br><span class="line">mike-test-mychart  ClusterIP  10.254.120.177  &lt;none&gt;       80/TCP   9m</span><br><span class="line"></span><br><span class="line">==&gt; v1beta2/Deployment</span><br><span class="line">NAME               DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE</span><br><span class="line">mike-test-mychart  1        1        1           1          9m</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">NOTES:</span><br><span class="line">1. Get the application URL by running these commands:</span><br><span class="line">  export POD_NAME=$(kubectl get pods --namespace default -l &quot;app=mychart,release=mike-test&quot; -o jsonpath=&quot;&#123;.items[0].metadata.name&#125;&quot;)</span><br><span class="line">  echo &quot;Visit http://127.0.0.1:8080 to use your application&quot;</span><br><span class="line">  kubectl port-forward $POD_NAME 8080:80</span><br></pre></td></tr></table></figure>

<p>完成后，可以看到已部署的 mike-test 被升级到 0.2.0 版本。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm list</span><br><span class="line">NAME     	REVISION	UPDATED                 	STATUS  	CHART        	NAMESPACE</span><br><span class="line">mike-test	2       	Mon Jul 23 10:50:25 2018	DEPLOYED	mychart-0.2.0	default</span><br></pre></td></tr></table></figure>

<ul>
<li>回退一个应用</li>
</ul>
<p>如果更新后的程序由于某些原因运行有问题，需要回退到旧版本的应用。首先我们可以使用 <code>helm history</code> 命令查看一个 Release 的所有变更记录。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm history mike-test</span><br><span class="line">REVISION	UPDATED                 	STATUS    	CHART        	DESCRIPTION</span><br><span class="line">1       	Mon Jul 23 10:41:20 2018	SUPERSEDED	mychart-0.1.0	Install complete</span><br><span class="line">2       	Mon Jul 23 10:50:25 2018	DEPLOYED  	mychart-0.2.0	Upgrade complete</span><br></pre></td></tr></table></figure>

<p>其次，我们可以使用下面的命令对指定的应用进行回退。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm rollback mike-test 1</span><br><span class="line">Rollback was a success! Happy Helming!</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注：其中的参数 1 是 helm history 查看到 Release 的历史记录中 REVISION 对应的值。</p>
</blockquote>
<p>最后，我们使用 <code>helm list</code> 和 <code>helm history</code> 命令都可以看到 mychart 的版本已经回退到 0.1.0 版本。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm list</span><br><span class="line">NAME     	REVISION	UPDATED                 	STATUS  	CHART        	NAMESPACE</span><br><span class="line">mike-test	3       	Mon Jul 23 10:53:42 2018	DEPLOYED	mychart-0.1.0	default</span><br><span class="line"></span><br><span class="line">$ helm history mike-test</span><br><span class="line">REVISION	UPDATED                 	STATUS    	CHART        	DESCRIPTION</span><br><span class="line">1       	Mon Jul 23 10:41:20 2018	SUPERSEDED	mychart-0.1.0	Install complete</span><br><span class="line">2       	Mon Jul 23 10:50:25 2018	SUPERSEDED	mychart-0.2.0	Upgrade complete</span><br><span class="line">3       	Mon Jul 23 10:53:42 2018	DEPLOYED  	mychart-0.1.0	Rollback to 1</span><br></pre></td></tr></table></figure>

<h5 id="删除一个应用"><a href="#删除一个应用" class="headerlink" title="删除一个应用"></a>删除一个应用</h5><p>如果需要删除一个已部署的 Release，可以利用 <code>helm delete</code> 命令来完成删除。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm delete mike-test</span><br><span class="line">release &quot;mike-test&quot; deleted</span><br></pre></td></tr></table></figure>

<p>确认应用是否删除，该应用已被标记为 DELETED 状态。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm ls -a mike-test</span><br><span class="line">NAME     	REVISION	UPDATED                 	STATUS 	CHART        	NAMESPACE</span><br><span class="line">mike-test	3       	Mon Jul 23 10:53:42 2018	DELETED	mychart-0.1.0	default</span><br></pre></td></tr></table></figure>

<p>也可以使用 <code>--deleted</code> 参数来列出已经删除的 Release</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm ls --deleted</span><br><span class="line">NAME     	REVISION	UPDATED                 	STATUS 	CHART        	NAMESPACE</span><br><span class="line">mike-test	3       	Mon Jul 23 10:53:42 2018	DELETED	mychart-0.1.0	default</span><br></pre></td></tr></table></figure>

<p>从上面的结果也可以看出，默认情况下已经删除的 Release 只是将状态标识为 DELETED 了 ，但该 Release 的历史信息还是继续被保存的。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm hist mike-test</span><br><span class="line">REVISION	UPDATED                 	STATUS    	CHART        	DESCRIPTION</span><br><span class="line">1       	Mon Jul 23 10:41:20 2018	SUPERSEDED	mychart-0.1.0	Install complete</span><br><span class="line">2       	Mon Jul 23 10:50:25 2018	SUPERSEDED	mychart-0.2.0	Upgrade complete</span><br><span class="line">3       	Mon Jul 23 10:53:42 2018	DELETED   	mychart-0.1.0	Deletion complete</span><br></pre></td></tr></table></figure>

<p>如果要移除指定 Release 所有相关的 Kubernetes 资源和 Release 的历史记录，可以用如下命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm delete --purge mike-test</span><br><span class="line">release &quot;mike-test&quot; deleted</span><br></pre></td></tr></table></figure>

<p>再次查看已删除的 Release，已经无法找到相关信息。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm hist mike-test</span><br><span class="line">Error: release: &quot;mike-test&quot; not found</span><br><span class="line"></span><br><span class="line"># helm ls 命令也已均无查询记录。</span><br><span class="line">$ helm ls --deleted</span><br><span class="line">$ helm ls -a mike-test</span><br></pre></td></tr></table></figure>

<h3 id="Helm-部署应用实例"><a href="#Helm-部署应用实例" class="headerlink" title="Helm 部署应用实例"></a>Helm 部署应用实例</h3><h4 id="部署-Wordpress"><a href="#部署-Wordpress" class="headerlink" title="部署 Wordpress"></a>部署 Wordpress</h4><p>这里以一个典型的三层应用 Wordpress 为例，包括 MySQL、PHP 和 Apache。</p>
<p>由于测试环境没有可用的 PersistentVolume（持久卷，简称 PV），这里暂时将其关闭。关于 Persistent Volumes 的相关信息我们会在后续的相关文章进行讲解。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm install --name wordpress-test --set &quot;persistence.enabled=false,mariadb.persistence.enabled=false,serviceType=NodePort&quot;  stable/wordpress</span><br><span class="line"></span><br><span class="line">NAMESPACE: default</span><br><span class="line">STATUS: DEPLOYED</span><br><span class="line"></span><br><span class="line">RESOURCES:</span><br><span class="line">==&gt; v1beta1/Deployment</span><br><span class="line">NAME                      DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE</span><br><span class="line">wordpress-test-mariadb    1        1        1           1          26m</span><br><span class="line">wordpress-test-wordpress  1        1        1           1          26m</span><br><span class="line"></span><br><span class="line">==&gt; v1/Pod(related)</span><br><span class="line">NAME                                       READY  STATUS   RESTARTS  AGE</span><br><span class="line">wordpress-test-mariadb-84b866bf95-n26ff    1/1    Running  1         26m</span><br><span class="line">wordpress-test-wordpress-5ff8c64b6c-sgtvv  1/1    Running  6         26m</span><br><span class="line"></span><br><span class="line">==&gt; v1/Secret</span><br><span class="line">NAME                      TYPE    DATA  AGE</span><br><span class="line">wordpress-test-mariadb    Opaque  2     26m</span><br><span class="line">wordpress-test-wordpress  Opaque  2     26m</span><br><span class="line"></span><br><span class="line">==&gt; v1/ConfigMap</span><br><span class="line">NAME                          DATA  AGE</span><br><span class="line">wordpress-test-mariadb        1     26m</span><br><span class="line">wordpress-test-mariadb-tests  1     26m</span><br><span class="line"></span><br><span class="line">==&gt; v1/Service</span><br><span class="line">NAME                      TYPE       CLUSTER-IP     EXTERNAL-IP  PORT(S)                   AGE</span><br><span class="line">wordpress-test-mariadb    ClusterIP  10.254.99.67   &lt;none&gt;       3306/TCP                  26m</span><br><span class="line">wordpress-test-wordpress  NodePort   10.254.175.16  &lt;none&gt;       80:8563/TCP,443:8839/TCP  26m</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">NOTES:</span><br><span class="line">1. Get the WordPress URL:</span><br><span class="line"></span><br><span class="line">  Or running:</span><br><span class="line"></span><br><span class="line">  export NODE_PORT=$(kubectl get --namespace default -o jsonpath=&quot;&#123;.spec.ports[0].nodePort&#125;&quot; services wordpress-test-wordpress)</span><br><span class="line">  export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=&quot;&#123;.items[0].status.addresses[0].address&#125;&quot;)</span><br><span class="line">  echo http://$NODE_IP:$NODE_PORT/admin</span><br><span class="line"></span><br><span class="line">2. Login with the following credentials to see your blog</span><br><span class="line"></span><br><span class="line">  echo Username: user</span><br><span class="line">  echo Password: $(kubectl get secret --namespace default wordpress-test-wordpress -o jsonpath=&quot;&#123;.data.wordpress-password&#125;&quot; | base64 --decode)</span><br></pre></td></tr></table></figure>

<h4 id="访问-Wordpress"><a href="#访问-Wordpress" class="headerlink" title="访问 Wordpress"></a>访问 Wordpress</h4><p>部署完成后，我们可以通过上面的提示信息生成相应的访问地址和用户名、密码等相关信息。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 生成 Wordpress 管理后台地址</span><br><span class="line">$ export NODE_PORT=$(kubectl get --namespace default -o jsonpath=&quot;&#123;.spec.ports[0].nodePort&#125;&quot; services wordpress-test-wordpress)</span><br><span class="line">$ export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=&quot;&#123;.items[0].status.addresses[0].address&#125;&quot;)</span><br><span class="line">$ echo http://$NODE_IP:$NODE_PORT/admin</span><br><span class="line">http://192.168.100.211:8433/admin</span><br><span class="line"></span><br><span class="line"># 生成 Wordpress 管理帐号和密码</span><br><span class="line">$ echo Username: user</span><br><span class="line">Username: user</span><br><span class="line">$ echo Password: $(kubectl get secret --namespace default wordpress-test-wordpress -o jsonpath=&quot;&#123;.data.wordpress-password&#125;&quot; | base64 --decode)</span><br><span class="line">Password: 9jEXJgnVAY</span><br></pre></td></tr></table></figure>

<p>给一张访问效果图吧：</p>
<p><img src="/2019/10/31/K8S%E9%83%A8%E7%BD%B2%E7%AE%80%E4%BB%8B/helm03.png" alt="img"></p>
<h3 id="Helm-其它使用技巧"><a href="#Helm-其它使用技巧" class="headerlink" title="Helm 其它使用技巧"></a>Helm 其它使用技巧</h3><ul>
<li>如何设置 helm 命令自动补全？</li>
</ul>
<p>为了方便 <code>helm</code> 命令的使用，Helm 提供了自动补全功能，如果使用 ZSH 请执行：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ source &lt;(helm completion zsh)</span><br></pre></td></tr></table></figure>

<p>如果使用 BASH 请执行：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ source &lt;(helm completion bash)</span><br></pre></td></tr></table></figure>

<ul>
<li>如何使用第三方的 Chart 存储库？</li>
</ul>
<p>随着 Helm 越来越普及，除了使用预置官方存储库，三方仓库也越来越多了（前提是网络是可达的）。你可以使用如下命令格式添加三方 Chart 存储库。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm repo add 存储库名 存储库URL</span><br><span class="line">$ helm repo update</span><br></pre></td></tr></table></figure>

<p>一些三方存储库资源:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Prometheus Operator</span><br><span class="line">https://github.com/coreos/prometheus-operator/tree/master/helm</span><br><span class="line"></span><br><span class="line"># Bitnami Library for Kubernetes</span><br><span class="line">https://github.com/bitnami/charts</span><br><span class="line"></span><br><span class="line"># Openstack-Helm</span><br><span class="line">https://github.com/att-comdev/openstack-helm</span><br><span class="line">https://github.com/sapcc/openstack-helm</span><br><span class="line"></span><br><span class="line"># Tick-Charts</span><br><span class="line">https://github.com/jackzampolin/tick-charts</span><br></pre></td></tr></table></figure>

<ul>
<li>Helm 如何结合 CI/CD ？</li>
</ul>
<p>采用 Helm 可以把零散的 Kubernetes 应用配置文件作为一个 Chart 管理，Chart 源码可以和源代码一起放到 Git 库中管理。通过把 Chart 参数化，可以在测试环境和生产环境采用不同的 Chart 参数配置。</p>
<p>下图是采用了 Helm 的一个 CI/CD 流程</p>
<p><img src="/2019/10/31/K8S%E9%83%A8%E7%BD%B2%E7%AE%80%E4%BB%8B/helm04-1572568214885.png" alt="img"></p>
<ul>
<li>Helm 如何管理多环境下 (Test、Staging、Production) 的业务配置？</li>
</ul>
<p>Chart 是支持参数替换的，可以把业务配置相关的参数设置为模板变量。使用 <code>helm install</code> 命令部署的时候指定一个参数值文件，这样就可以把业务参数从 Chart 中剥离了。例如： <code>helm install --values=values-production.yaml wordpress</code>。</p>
<ul>
<li>Helm 如何解决服务依赖？</li>
</ul>
<p>在 Chart 里可以通过 requirements.yaml 声明对其它 Chart 的依赖关系。如下面声明表明 Chart 依赖 Apache 和 MySQL 这两个第三方 Chart。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dependencies:</span><br><span class="line">- name: mariadb</span><br><span class="line">  version: 2.1.1</span><br><span class="line">  repository: https://kubernetes-charts.storage.googleapis.com/</span><br><span class="line">  condition: mariadb.enabled</span><br><span class="line">  tags:</span><br><span class="line">    - wordpress-database</span><br><span class="line">- name: apache</span><br><span class="line">    version: 1.4.0</span><br><span class="line">    repository: https://kubernetes-charts.storage.googleapis.com/</span><br></pre></td></tr></table></figure>

<ul>
<li>如何让 Helm 连接到指定 Kubernetes 集群？</li>
</ul>
<p>Helm 默认使用和 kubectl 命令相同的配置访问 Kubernetes 集群，其配置默认在 <code>~/.kube/config</code> 中。</p>
<ul>
<li>如何在部署时指定命名空间？</li>
</ul>
<p><code>helm install</code> 默认情况下是部署在 default 这个命名空间的。如果想部署到指定的命令空间，可以加上 <code>--namespace</code> 参数，比如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm install local/mychart --name mike-test --namespace mynamespace</span><br></pre></td></tr></table></figure>

<ul>
<li>如何查看已部署应用的详细信息？</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm get wordpress-test</span><br></pre></td></tr></table></figure>

<p>默认情况下会显示最新的版本的相关信息，如果想要查看指定发布版本的信息可加上 <code>--revision</code> 参数。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ helm get  --revision 1  wordpress-test</span><br></pre></td></tr></table></figure>

<h3 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h3><p><a href="http://t.cn/RgEE0dm" target="_blank" rel="noopener">http://t.cn/RgEE0dm</a><br><a href="http://t.cn/RgE3MyP" target="_blank" rel="noopener">http://t.cn/RgE3MyP</a><br><a href="http://t.cn/RgpiUAz" target="_blank" rel="noopener">http://t.cn/RgpiUAz</a></p>
<p><a href="https://github.com/helm/charts" target="_blank" rel="noopener">helm/charts</a></p>
<h2 id="补充说明"><a href="#补充说明" class="headerlink" title="补充说明"></a>补充说明</h2><h3 id="正确删除一个Pod"><a href="#正确删除一个Pod" class="headerlink" title="正确删除一个Pod"></a>正确删除一个Pod</h3><blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;1、先删除pod</span><br><span class="line">&gt;2、再删除对应的deployment</span><br><span class="line">&gt;否则只是删除pod是不管用的，还会看到pod，因为deployment.yaml文件中定义了副本数量</span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="K8S命令补全"><a href="#K8S命令补全" class="headerlink" title="K8S命令补全"></a>K8S命令补全</h3><blockquote>
<ol>
<li>yum -y install  bash-completion</li>
<li>chmod +x /usr/share/bash-completion/bash_completion</li>
<li>/usr/share/bash-completion/bash_completion</li>
<li>source /usr/share/bash-completion/bash_completion</li>
<li>source &lt;(kubectl completion bash)</li>
</ol>
</blockquote>
<h3 id="Kubernetes-问题定位技巧：容器内抓包"><a href="#Kubernetes-问题定位技巧：容器内抓包" class="headerlink" title="Kubernetes 问题定位技巧：容器内抓包"></a>Kubernetes 问题定位技巧：容器内抓包</h3><p>在使用 kubernetes 跑应用的时候，可能会遇到一些网络问题，比较常见的是服务端无响应(超时)或回包内容不正常，如果没找出各种配置上有问题，这时我们需要确认数据包到底有没有最终被路由到容器里，或者报文到达容器的内容和出容器的内容符不符合预期，通过分析报文可以进一步缩小问题范围。那么如何在容器内抓包呢？本文提供实用的脚本一键进入容器网络命名空间(netns)，使用宿主机上的tcpdump进行抓包。</p>
<h4 id="使用脚本一键进入-pod-netns-抓包"><a href="#使用脚本一键进入-pod-netns-抓包" class="headerlink" title="使用脚本一键进入 pod netns 抓包"></a>使用脚本一键进入 pod netns 抓包</h4><ul>
<li>发现某个服务不通，最好将其副本数调为1，并找到这个副本 pod 所在节点和 pod 名称</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pod -o wide</span><br></pre></td></tr></table></figure>

<ul>
<li>登录 pod 所在节点，将如下脚本粘贴到 shell (注册函数到当前登录的 shell，我们后面用)</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">e</span></span>() &#123;</span><br><span class="line">    <span class="built_in">set</span> -eu</span><br><span class="line">    ns=<span class="variable">$&#123;2-"default"&#125;</span></span><br><span class="line">    pod=`kubectl -n <span class="variable">$ns</span> describe pod <span class="variable">$1</span> | grep -A10 <span class="string">"^Containers:"</span> | grep -Eo <span class="string">'docker://.*$'</span> | head -n 1 | sed <span class="string">'s/docker:\/\/\(.*\)$/\1/'</span>`</span><br><span class="line">    pid=`docker inspect -f &#123;&#123;.State.Pid&#125;&#125; <span class="variable">$pod</span>`</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"entering pod netns for <span class="variable">$ns</span>/<span class="variable">$1</span>"</span></span><br><span class="line">    cmd=<span class="string">"nsenter -n --target <span class="variable">$pid</span>"</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$cmd</span></span><br><span class="line">    <span class="variable">$cmd</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>一键进入 pod 所在的 netns，格式：<code>e POD_NAME NAMESPACE</code>，示例：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">e istio-galley-58c7c7c646-m6568 istio-system</span><br><span class="line">e proxy-5546768954-9rxg6 <span class="comment"># 省略 NAMESPACE 默认为 default</span></span><br></pre></td></tr></table></figure>

<ul>
<li>这时已经进入 pod 的 netns，可以执行宿主机上的 <code>ip a</code> 或 <code>ifconfig</code> 来查看容器的网卡，执行 <code>netstat -tunlp</code> 查看当前容器监听了哪些端口，再通过 <code>tcpdump</code> 抓包：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump -i eth0 -w test.pcap port 80</span><br></pre></td></tr></table></figure>

<ul>
<li><code>ctrl-c</code> 停止抓包，再用 <code>scp</code> 或 <code>sz</code> 将抓下来的包下载到本地使用 <code>wireshark</code> 分析，提供一些常用的 <code>wireshark</code> 过滤语法：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用 telnet 连上并发送一些测试文本，比如 "lbtest"，</span></span><br><span class="line"><span class="comment"># 用下面语句可以看发送的测试报文有没有到容器</span></span><br><span class="line">tcp contains <span class="string">"lbtest"</span></span><br><span class="line"><span class="comment"># 如果容器提供的是http服务，可以使用 curl 发送一些测试路径的请求，</span></span><br><span class="line"><span class="comment"># 通过下面语句过滤 uri 看报文有没有都容器</span></span><br><span class="line">http.request.uri==<span class="string">"/mytest"</span></span><br></pre></td></tr></table></figure>

<h4 id="脚本原理"><a href="#脚本原理" class="headerlink" title="脚本原理"></a>脚本原理</h4><p>我们解释下步骤二中用到的脚本的原理 - 查看指定 pod 运行的容器 ID</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl describe pod &lt;pod&gt; -n mservice</span><br></pre></td></tr></table></figure>

<ul>
<li>获得容器进程的 pid</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker inspect -f &#123;&#123;.State.Pid&#125;&#125; &lt;container&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>进入该容器的 network namespace</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nsenter -n --target &lt;PID&gt;</span><br></pre></td></tr></table></figure>

<p>依赖宿主机的命名：<code>kubectl</code>, <code>docker</code>, <code>nsenter</code>, <code>grep</code>, <code>head</code>, <code>sed</code></p>
<h3 id="Kubernetes的三种外部访问方式：NodePort、LoadBalancer和Ingress"><a href="#Kubernetes的三种外部访问方式：NodePort、LoadBalancer和Ingress" class="headerlink" title="Kubernetes的三种外部访问方式：NodePort、LoadBalancer和Ingress"></a>Kubernetes的三种外部访问方式：NodePort、LoadBalancer和Ingress</h3><p><strong>注意</strong>：这里说的每一点都基于Google Kubernetes Engine。如果你用 minikube 或其它工具，以预置型模式（om prem）运行在其它云上，对应的操作可能有点区别。我不会太深入技术细节，如果你有兴趣了解更多，官方文档[1]是一个非常棒的资源。</p>
<h4 id="ClusterIP"><a href="#ClusterIP" class="headerlink" title="ClusterIP"></a>ClusterIP</h4><p>ClusterIP 服务是 Kubernetes 的默认服务。它给你一个集群内的服务，集群内的其它应用都可以访问该服务。集群外部无法访问它。</p>
<p>ClusterIP 服务的 YAML 文件类似如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1kind: Servicemetadata:   name: my-internal-serviceselector:     app: my-appspec: type: ClusterIP ports:   - name: http   port: 80   targetPort: 80   protocol: TCP</span><br></pre></td></tr></table></figure>



<p>如果 从Internet 没法访问 ClusterIP 服务，那么我们为什么要讨论它呢？那是因为我们可以通过 Kubernetes 的 proxy 模式来访问该服务！</p>
<p><img src="/2019/10/31/K8S%E9%83%A8%E7%BD%B2%E7%AE%80%E4%BB%8B/1.jpg" alt="img">K8S部署简介ernetes proxy 模式：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl proxy --port=8080</span><br></pre></td></tr></table></figure>



<p>这样你可以通过Kubernetes API，使用如下模式来访问这个服务：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://localhost:8080/api/v1/proxy/namespaces//services/:/</span><br></pre></td></tr></table></figure>



<p>要访问我们上面定义的服务，你可以使用如下地址：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://localhost:8080/api/v1/proxy/namespaces/default/services/my-internal-service:http/</span><br></pre></td></tr></table></figure>



<p><strong>何时使用这种方式？</strong></p>
<p>有一些场景下，你得使用 Kubernetes 的 proxy 模式来访问你的服务：</p>
<ul>
<li>由于某些原因，你需要调试你的服务，或者需要直接通过笔记本电脑去访问它们。</li>
<li>容许内部通信，展示内部仪表盘等。</li>
</ul>
<p>这种方式要求我们运行 kubectl 作为一个未认证的用户，因此我们不能用这种方式把服务暴露到 internet 或者在生产环境使用。</p>
<h4 id="NodePort"><a href="#NodePort" class="headerlink" title="NodePort"></a>NodePort</h4><p>NodePort 服务是引导外部流量到你的服务的最原始方式。NodePort，正如这个名字所示，在所有节点（虚拟机）上开放一个特定端口，任何发送到该端口的流量都被转发到对应服务。</p>
<p><img src="/2019/10/31/K8S%E9%83%A8%E7%BD%B2%E7%AE%80%E4%BB%8B/2.jpg" alt="img">K8S部署简介rt 服务的 YAML 文件类似如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1kind: Servicemetadata:   name: my-nodeport-serviceselector:     app: my-appspec: type: NodePort ports:   - name: http   port: 80   targetPort: 80   nodePort: 30036   protocol: TCP</span><br></pre></td></tr></table></figure>



<p>NodePort 服务主要有两点区别于普通的“ClusterIP”服务。第一，它的类型是“NodePort”。有一个额外的端口，称为 nodePort，它指定节点上开放的端口值 。如果你不指定这个端口，系统将选择一个随机端口。大多数时候我们应该让 Kubernetes 来选择端口，因为如评论中 thockin 所说，用户自己来选择可用端口代价太大。</p>
<p><strong>何时使用这种方式？</strong></p>
<p>这种方法有许多缺点：</p>
<ol>
<li>每个端口只能是一种服务</li>
<li>端口范围只能是 30000-32767</li>
<li>如果节点/VM 的 IP 地址发生变化，你需要能处理这种情况</li>
</ol>
<p>基于以上原因，我不建议在生产环境上用这种方式暴露服务。如果你运行的服务不要求一直可用，或者对成本比较敏感，你可以使用这种方法。这样的应用的最佳例子是 demo 应用，或者某些临时应用。</p>
<h4 id="LoadBalancer"><a href="#LoadBalancer" class="headerlink" title="LoadBalancer"></a>LoadBalancer</h4><p>LoadBalancer 服务是暴露服务到 internet 的标准方式。在 GKE 上，这种方式会启动一个 Network Load Balancer[2]，它将给你一个单独的 IP 地址，转发所有流量到你的服务。</p>
<p><img src="/2019/10/31/K8S%E9%83%A8%E7%BD%B2%E7%AE%80%E4%BB%8B/3.jpg" alt="img">K8S部署简介这种方式？**</p>
<p>如果你想要直接暴露服务，这就是默认方式。所有通往你指定的端口的流量都会被转发到对应的服务。它没有过滤条件，没有路由等。这意味着你几乎可以发送任何种类的流量到该服务，像 HTTP，TCP，UDP，Websocket，gRPC 或其它任意种类。</p>
<p>这个方式的最大缺点是每一个用 LoadBalancer 暴露的服务都会有它自己的 IP 地址，每个用到的 LoadBalancer 都需要付费，这将是非常昂贵的。</p>
<h4 id="Ingress"><a href="#Ingress" class="headerlink" title="Ingress"></a>Ingress</h4><p>有别于以上所有例子，Ingress 事实上不是一种服务类型。相反，它处于多个服务的前端，扮演着“智能路由”或者集群入口的角色。</p>
<p>你可以用 Ingress 来做许多不同的事情，各种不同类型的 Ingress 控制器也有不同的能力。</p>
<p>GKE 上的默认 ingress 控制器是启动一个 HTTP(S) Load Balancer[3]。它允许你基于路径或者子域名来路由流量到后端服务。例如，你可以将任何发往域名 foo.yourdomain.com 的流量转到 foo 服务，将路径 yourdomain.com/bar/path 的流量转到 bar 服务。</p>
<p><img src="/2019/10/31/K8S%E9%83%A8%E7%BD%B2%E7%AE%80%E4%BB%8B/4.jpg" alt="img">K8S部署简介 L7 HTTP Load Balancer[4]生成的 Ingress 对象的 YAML 文件类似如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line"> name: my-ingress</span><br><span class="line">spec:</span><br><span class="line"> backend:</span><br><span class="line">   serviceName: other</span><br><span class="line">   servicePort: 8080</span><br><span class="line"> rules:</span><br><span class="line"></span><br><span class="line"> - host: foo.mydomain.com</span><br><span class="line">      http:</span><br><span class="line">           paths:</span><br><span class="line">           - backend:</span><br><span class="line">               serviceName: foo</span><br><span class="line">               servicePort: 8080</span><br><span class="line"> - host: mydomain.com</span><br><span class="line">      http:</span><br><span class="line">           paths:</span><br><span class="line">         - path: /bar/*</span><br><span class="line">              ackend:</span><br><span class="line">                       serviceName: bar</span><br><span class="line">                       servicePort: 8080</span><br></pre></td></tr></table></figure>


<p><strong>何时使用这种方式？</strong></p>
<p>Ingress 可能是暴露服务的最强大方式，但同时也是最复杂的。Ingress 控制器有各种类型，包括 Google Cloud Load Balancer， Nginx，Contour，Istio，等等。它还有各种插件，比如 cert-manager[5]，它可以为你的服务自动提供 SSL 证书。</p>
<p>如果你想要使用同一个 IP 暴露多个服务，这些服务都是使用相同的七层协议（典型如 HTTP），那么Ingress 就是最有用的。如果你使用本地的 GCP 集成，你只需要为一个负载均衡器付费，且由于 Ingress是“智能”的，你还可以获取各种开箱即用的特性（比如 SSL、认证、路由等等）。</p>
<p>相关链接：</p>
<ol>
<li><a href="https://kubernetes.io/docs/concepts/services-networking/service/" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/services-networking/service/</a></li>
<li><a href="https://cloud.google.com/compute/docs/load-balancing/network/" target="_blank" rel="noopener">https://cloud.google.com/compute/docs/load-balancing/network/</a></li>
<li><a href="https://cloud.google.com/compute/docs/load-balancing/http/" target="_blank" rel="noopener">https://cloud.google.com/compute/docs/load-balancing/http/</a></li>
<li><a href="https://cloud.google.com/compute/docs/load-balancing/http/" target="_blank" rel="noopener">https://cloud.google.com/compute/docs/load-balancing/http/</a></li>
<li><a href="https://github.com/jetstack/cert-manager" target="_blank" rel="noopener">https://github.com/jetstack/cert-manager</a></li>
</ol>
<p>原文链接：<a href="https://medium.com/google-cloud/kubernetes-nodeport-vs-loadbalancer-vs-ingress-when-should-i-use-what-922f010849e0" target="_blank" rel="noopener">https://medium.com/google-cloud/kubernetes-nodeport-vs-loadbalancer-vs-ingress-when-should-i-use-what-922f010849e0</a></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a href="https://kubernetes.io/docs/tutorials/kubernetes-basics/explore/explore-intro/" target="_blank" rel="noopener">Viewing Pods and Nodes</a></li>
<li><a href="https://www.cnblogs.com/cocowool/p/k8s_base_concept.html" target="_blank" rel="noopener">Kubernetes基础</a></li>
<li><a href="https://kubernetes.io/docs/tutorials/kubernetes-basics/expose/expose-intro/" target="_blank" rel="noopener">Using a Service to Expose Your App</a></li>
</ol>
]]></content>
      <categories>
        <category>持续集成</category>
      </categories>
      <tags>
        <tag>K8S</tag>
      </tags>
  </entry>
  <entry>
    <title>终于有人把Docker讲清楚了</title>
    <url>/2019/10/31/%E7%BB%88%E4%BA%8E%E6%9C%89%E4%BA%BA%E6%8A%8ADocker%E8%AE%B2%E6%B8%85%E6%A5%9A%E4%BA%86/</url>
    <content><![CDATA[<h2 id="终于有人把-Docker-讲清楚了"><a href="#终于有人把-Docker-讲清楚了" class="headerlink" title="终于有人把 Docker 讲清楚了"></a>终于有人把 Docker 讲清楚了</h2><p><img src="/2019/10/31/%E7%BB%88%E4%BA%8E%E6%9C%89%E4%BA%BA%E6%8A%8ADocker%E8%AE%B2%E6%B8%85%E6%A5%9A%E4%BA%86/640.webp" alt="img"></p><blockquote>
<p>作者 | 乐章</p>
<p>来源 | cnblogs.com/zhangxingeng/p/11236968.html</p>
<p>编辑：Java技术栈（id：javastack）</p>
</blockquote><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a><strong>一、简介</strong></h2><h3 id><a href="#" class="headerlink" title></a></h3><h3 id="1、了解Docker的前生LXC"><a href="#1、了解Docker的前生LXC" class="headerlink" title="1、了解Docker的前生LXC"></a><strong>1、了解Docker的前生LXC</strong></h3><p>LXC为Linux Container的简写。可以提供轻量级的虚拟化，以便隔离进程和资源，而且不需要提供指令解释机制以及全虚拟化的其他复杂性。相当于C++中的NameSpace。容器有效地将由单个操作系统管理的资源划分到孤立的组中，以更好地在孤立的组之间平衡有冲突的资源使用需求。</p><a id="more"></a>


<p>与传统虚拟化技术相比，它的优势在于：</p>
<p>（1）与宿主机使用同一个内核，性能损耗小；</p>
<p>（2）不需要指令级模拟；</p>
<p>（3）不需要即时(Just-in-time)编译；</p>
<p>（4）容器可以在CPU核心的本地运行指令，不需要任何专门的解释机制；</p>
<p>（5）避免了准虚拟化和系统调用替换中的复杂性；</p>
<p>（6）轻量级隔离，在隔离的同时还提供共享机制，以实现容器与宿主机的资源共享。</p>
<p>总结：Linux Container是一种轻量级的虚拟化的手段。</p>
<p>Linux Container提供了在单一可控主机节点上支持多个相互隔离的server container同时执行的机制。Linux Container有点像chroot，提供了一个拥有自己进程和网络空间的虚拟环境，但又有别于虚拟机，因为lxc是一种操作系统层次上的资源的虚拟化。</p>
<h3 id="2、LXC与docker什么关系？"><a href="#2、LXC与docker什么关系？" class="headerlink" title="2、LXC与docker什么关系？"></a><strong>2、LXC与docker什么关系？</strong></h3><p>docker并不是LXC替代品，docker底层使用了LXC来实现，LXC将linux进程沙盒化，使得进程之间相互隔离，并且能够课哦内阁制各进程的资源分配。</p>
<p>在LXC的基础之上，docker提供了一系列更强大的功能。</p>
<h3 id="3、什么是docker"><a href="#3、什么是docker" class="headerlink" title="3、什么是docker"></a><strong>3、什么是docker</strong></h3><p>docker是一个开源的应用容器引擎，基于go语言开发并遵循了apache2.0协议开源。</p>
<p>docker可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的linux服务器，也可以实现虚拟化。</p>
<p>容器是完全使用沙箱机制，相互之间不会有任何接口（类iphone的app），并且容器开销极其低。</p>
<h3 id="-1"><a href="#-1" class="headerlink" title></a></h3><h3 id="4、docker官方文档"><a href="#4、docker官方文档" class="headerlink" title="4、docker官方文档"></a><strong>4、docker官方文档</strong></h3><p><a href="https://docs.docker.com/" target="_blank" rel="noopener">https://docs.docker.com/</a></p>
<h3 id="-2"><a href="#-2" class="headerlink" title></a></h3><h3 id="5、为什么docker越来越受欢迎"><a href="#5、为什么docker越来越受欢迎" class="headerlink" title="5、为什么docker越来越受欢迎"></a><strong>5、为什么docker越来越受欢迎</strong></h3><p>官方话语：</p>
<ul>
<li>容器化越来越受欢迎，因为容器是：</li>
</ul>
<ul>
<li><ul>
<li>灵活：即使是最复杂的应用也可以集装箱化。</li>
<li>轻量级：容器利用并共享主机内核。</li>
<li>可互换：您可以即时部署更新和升级。</li>
<li>便携式：您可以在本地构建，部署到云，并在任何地方运行。</li>
<li>可扩展：您可以增加并自动分发容器副本。</li>
<li>可堆叠：您可以垂直和即时堆叠服务。</li>
</ul>
</li>
</ul>
<h3 id="-3"><a href="#-3" class="headerlink" title></a></h3><ul>
<li><h3 id="镜像和容器（contalners）"><a href="#镜像和容器（contalners）" class="headerlink" title="镜像和容器（contalners）"></a>镜像和容器（contalners）</h3></li>
</ul>
<p>通过镜像启动一个容器，一个镜像是一个可执行的包，其中包括运行应用程序所需要的所有内容包含代码，运行时间，库、环境变量、和配置文件。</p>
<p>容器是镜像的运行实例，当被运行时有镜像状态和用户进程，可以使用docker ps 查看。</p>
<ul>
<li><h3 id="容器和虚拟机"><a href="#容器和虚拟机" class="headerlink" title="容器和虚拟机"></a>容器和虚拟机</h3></li>
</ul>
<p>容器时在linux上本机运行，并与其他容器共享主机的内核，它运行的一个独立的进程，不占用其他任何可执行文件的内存，非常轻量。</p>
<p>虚拟机运行的是一个完成的操作系统，通过虚拟机管理程序对主机资源进行虚拟访问，相比之下需要的资源更多。</p>
<p> <img src="/2019/10/31/%E7%BB%88%E4%BA%8E%E6%9C%89%E4%BA%BA%E6%8A%8ADocker%E8%AE%B2%E6%B8%85%E6%A5%9A%E4%BA%86/640.webp" alt="img"></p>
<h3 id="-4"><a href="#-4" class="headerlink" title></a></h3><h3 id="6、docker版本"><a href="#6、docker版本" class="headerlink" title="6、docker版本"></a><strong>6、docker版本</strong></h3><p>Docker Community Edition（CE）社区版</p>
<p>Enterprise Edition(EE) 商业版</p>
<h3 id="-5"><a href="#-5" class="headerlink" title></a></h3><h3 id="7、docker和openstack的几项对比"><a href="#7、docker和openstack的几项对比" class="headerlink" title="7、docker和openstack的几项对比"></a><strong>7、docker和openstack的几项对比</strong></h3><p><img src="/2019/10/31/%E7%BB%88%E4%BA%8E%E6%9C%89%E4%BA%BA%E6%8A%8ADocker%E8%AE%B2%E6%B8%85%E6%A5%9A%E4%BA%86/640.webp" alt="img"></p>
<h3 id="8、容器在内核中支持2种重要技术"><a href="#8、容器在内核中支持2种重要技术" class="headerlink" title="8、容器在内核中支持2种重要技术"></a><strong>8、容器在内核中支持2种重要技术</strong></h3><p>docker本质就是宿主机的一个进程，docker是通过namespace实现资源隔离，通过cgroup实现资源限制，通过写时复制技术（copy-on-write）实现了高效的文件操作（类似虚拟机的磁盘比如分配500g并不是实际占用物理磁盘500g）</p>
<p>1）namespaces 名称空间</p>
<p><img src="/2019/10/31/%E7%BB%88%E4%BA%8E%E6%9C%89%E4%BA%BA%E6%8A%8ADocker%E8%AE%B2%E6%B8%85%E6%A5%9A%E4%BA%86/640-1572599922202.webp" alt="img"></p>
<p> 2）control Group 控制组</p>
<p>cgroup的特点是：　　　　　　</p>
<ul>
<li>cgroup的api以一个伪文件系统的实现方式，用户的程序可以通过文件系统实现cgroup的组件管理</li>
<li>cgroup的组件管理操作单元可以细粒度到线程级别，另外用户可以创建和销毁cgroup，从而实现资源载分配和再利用</li>
<li>所有资源管理的功能都以子系统的方式实现，接口统一子任务创建之初与其父任务处于同一个cgroup的控制组</li>
</ul>
<p>四大功能：</p>
<ul>
<li>资源限制：可以对任务使用的资源总额进行限制</li>
<li>优先级分配：通过分配的cpu时间片数量以及磁盘IO带宽大小，实际上相当于控制了任务运行优先级</li>
<li>资源统计：可以统计系统的资源使用量，如cpu时长，内存用量等</li>
<li>任务控制：cgroup可以对任务执行挂起、恢复等操作</li>
</ul>
<h3 id="-6"><a href="#-6" class="headerlink" title></a></h3><h3 id="9、了解docker三个重要概念"><a href="#9、了解docker三个重要概念" class="headerlink" title="9、了解docker三个重要概念"></a><strong>9、了解docker三个重要概念</strong></h3><p>1）image镜像</p>
<p>docker镜像就是一个只读模板，比如，一个镜像可以包含一个完整的centos，里面仅安装apache或用户的其他应用，镜像可以用来创建docker容器，另外docker提供了一个很简单的机制来创建镜像或者更新现有的镜像，用户甚至可以直接从其他人那里下周一个已经做好的镜像来直接使用</p>
<p>2）container容器</p>
<p>docker利用容器来运行应用，容器是从镜像创建的运行实例，它可以被启动，开始、停止、删除、每个容器都是互相隔离的，保证安全的平台，可以吧容器看做是要给简易版的linux环境（包括root用户权限、镜像空间、用户空间和网络空间等）和运行再其中的应用程序</p>
<p>3）repostory仓库</p>
<p>仓库是集中存储镜像文件的沧桑，registry是仓库主从服务器，实际上参考注册服务器上存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签（tag）</p>
<p>仓库分为两种，公有参考，和私有仓库，最大的公开仓库是docker Hub，存放了数量庞大的镜像供用户下周，国内的docker pool，这里仓库的概念与Git类似，registry可以理解为github这样的托管服务。</p>
<h3 id="-7"><a href="#-7" class="headerlink" title></a></h3><h3 id="10、docker的主要用途"><a href="#10、docker的主要用途" class="headerlink" title="10、docker的主要用途"></a><strong>10、docker的主要用途</strong></h3><p>官方就是Bulid 、ship、run any app/any where，编译、装载、运行、任何app/在任意地放都能运行。</p>
<p>就是实现了应用的封装、部署、运行的生命周期管理只要在glibc的环境下，都可以运行。</p>
<p>运维生成环境中：docker化。</p>
<ul>
<li>发布服务不用担心服务器的运行环境，所有的服务器都是自动分配docker，自动部署，自动安装，自动运行</li>
<li>再不用担心其他服务引擎的磁盘问题，cpu问题，系统问题了</li>
<li>资源利用更出色</li>
<li>自动迁移，可以制作镜像，迁移使用自定义的镜像即可迁移，不会出现什么问题</li>
<li>管理更加方便了</li>
</ul>
<h3 id="-8"><a href="#-8" class="headerlink" title></a></h3><h3 id="11、docker改变了什么"><a href="#11、docker改变了什么" class="headerlink" title="11、docker改变了什么"></a><strong>11、docker改变了什么</strong></h3><ul>
<li>面向产品：产品交付</li>
<li>面向开发：简化环境配置</li>
<li>面向测试：多版本测试</li>
<li>面向运维：环境一致性</li>
<li>面向架构：自动化扩容（微服务）</li>
</ul>
<h2 id="二、docker架构"><a href="#二、docker架构" class="headerlink" title="二、docker架构"></a><strong>二、docker架构</strong></h2><h3 id="-9"><a href="#-9" class="headerlink" title></a></h3><h3 id="1、总体架构"><a href="#1、总体架构" class="headerlink" title="1、总体架构"></a><strong>1、总体架构</strong></h3><p><img src="/2019/10/31/%E7%BB%88%E4%BA%8E%E6%9C%89%E4%BA%BA%E6%8A%8ADocker%E8%AE%B2%E6%B8%85%E6%A5%9A%E4%BA%86/640-1572599922216.webp" alt="img"></p>
<ul>
<li>distribution 负责与docker registry交互，上传洗澡镜像以及v2 registry 有关的源数据</li>
<li>registry负责docker registry有关的身份认证、镜像查找、镜像验证以及管理registry mirror等交互操作</li>
<li>image 负责与镜像源数据有关的存储、查找，镜像层的索引、查找以及镜像tar包有关的导入、导出操作</li>
<li>reference负责存储本地所有镜像的repository和tag名，并维护与镜像id之间的映射关系</li>
<li>layer模块负责与镜像层和容器层源数据有关的增删改查，并负责将镜像层的增删改查映射到实际存储镜像层文件的graphdriver模块</li>
<li>graghdriver是所有与容器镜像相关操作的执行者</li>
</ul>
<h3 id="-10"><a href="#-10" class="headerlink" title></a></h3><h3 id="2、docker架构2"><a href="#2、docker架构2" class="headerlink" title="2、docker架构2"></a><strong>2、docker架构2</strong></h3><p>如果觉得上面架构图比较乱可以看这个架构：</p>
<h3 id="-11"><a href="#-11" class="headerlink" title></a><img src="/2019/10/31/%E7%BB%88%E4%BA%8E%E6%9C%89%E4%BA%BA%E6%8A%8ADocker%E8%AE%B2%E6%B8%85%E6%A5%9A%E4%BA%86/640-1572599922229.webp" alt="img"></h3><p>从上图不难看出，用户是使用Docker Client与Docker Daemon建立通信，并发送请求给后者。</p>
<p>而Docker Daemon作为Docker架构中的主体部分，首先提供Server的功能使其可以接受Docker Client的请求；而后Engine执行Docker内部的一系列工作，每一项工作都是以一个Job的形式的存在。</p>
<p>Job的运行过程中，当需要容器镜像时，则从Docker Registry中下载镜像，并通过镜像管理驱动graphdriver将下载镜像以Graph的形式存储；当需要为Docker创建网络环境时，通过网络管理驱动networkdriver创建并配置Docker容器网络环境；当需要限制Docker容器运行资源或执行用户指令等操作时，则通过execdriver来完成。</p>
<p>而libcontainer是一项独立的容器管理包，networkdriver以及execdriver都是通过libcontainer来实现具体对容器进行的操作。当执行完运行容器的命令后，一个实际的Docker容器就处于运行状态，该容器拥有独立的文件系统，独立并且安全的运行环境等。</p>
<h3 id="3、docker架构3"><a href="#3、docker架构3" class="headerlink" title="3、docker架构3"></a><strong>3、docker架构3</strong></h3><p>再来看看另外一个架构，这个个架构就简单清晰指明了server/client交互，容器和镜像、数据之间的一些联系。</p>
<p><img src="/2019/10/31/%E7%BB%88%E4%BA%8E%E6%9C%89%E4%BA%BA%E6%8A%8ADocker%E8%AE%B2%E6%B8%85%E6%A5%9A%E4%BA%86/640-1572599922232.webp" alt="img"></p>
<p>这个架构图更加清晰了架构</p>
<p>docker daemon就是docker的守护进程即server端，可以是远程的，也可以是本地的，这个不是C/S架构吗，客户端Docker client 是通过rest api进行通信。</p>
<p>docker cli 用来管理容器和镜像，客户端提供一个只读镜像，然后通过镜像可以创建多个容器，这些容器可以只是一个RFS（Root file system根文件系统），也可以ishi一个包含了用户应用的RFS，容器再docker client中只是要给进程，两个进程之间互不可见。</p>
<p>用户不能与server直接交互，但可以通过与容器这个桥梁来交互，由于是操作系统级别的虚拟技术，中间的损耗几乎可以不计。</p>
<h2 id="三、docker架构2各个模块的功能（带完善）"><a href="#三、docker架构2各个模块的功能（带完善）" class="headerlink" title="三、docker架构2各个模块的功能（带完善）"></a><strong>三、docker架构2各个模块的功能（带完善）</strong></h2><p>主要的模块有：Docker Client、Docker Daemon、Docker Registry、Graph、Driver、libcontainer以及Docker container。　　　</p>
<h3 id="-12"><a href="#-12" class="headerlink" title></a></h3><h3 id="1、docker-client"><a href="#1、docker-client" class="headerlink" title="1、docker client"></a><strong>1、docker client</strong></h3><p>docker client 是docker架构中用户用来和docker daemon建立通信的客户端，用户使用的可执行文件为docker，通过docker命令行工具可以发起众多管理container的请求。</p>
<p>docker client可以通过一下三宗方式和docker daemon建立通信：tcp://host:port;unix:path_to_socket;fd://socketfd。，docker client可以通过设置命令行flag参数的形式设置安全传输层协议(TLS)的有关参数，保证传输的安全性。</p>
<p>docker client发送容器管理请求后，由docker daemon接受并处理请求，当docker client 接收到返回的请求相应并简单处理后，docker client 一次完整的生命周期就结束了，当需要继续发送容器管理请求时，用户必须再次通过docker可以执行文件创建docker client。</p>
<h3 id="-13"><a href="#-13" class="headerlink" title></a></h3><h3 id="2、docker-daemon"><a href="#2、docker-daemon" class="headerlink" title="2、docker daemon"></a><strong>2、docker daemon</strong></h3><p>docker daemon 是docker架构中一个常驻在后台的系统进程，功能是：接收处理docker client发送的请求。该守护进程在后台启动一个server，server负载接受docker client发送的请求；接受请求后，server通过路由与分发调度，找到相应的handler来执行请求。</p>
<p>docker daemon启动所使用的可执行文件也为docker，与docker client启动所使用的可执行文件docker相同，在docker命令执行时，通过传入的参数来判别docker daemon与docker client。</p>
<p>docker daemon的架构可以分为：docker server、engine、job。daemon</p>
<h3 id="-14"><a href="#-14" class="headerlink" title></a></h3><h3 id="3、docker-server"><a href="#3、docker-server" class="headerlink" title="3、docker server"></a><strong>3、docker server</strong></h3><p>docker server在docker架构中时专门服务于docker client的server，该server的功能时：接受并调度分发docker client发送的请求，架构图如下：</p>
<p>　　　　<img src="/2019/10/31/%E7%BB%88%E4%BA%8E%E6%9C%89%E4%BA%BA%E6%8A%8ADocker%E8%AE%B2%E6%B8%85%E6%A5%9A%E4%BA%86/640-1572599922233.webp" alt="img"></p>
<p>在Docker的启动过程中，通过包gorilla/mux（golang的类库解析），创建了一个mux.Router，提供请求的路由功能。在Golang中，gorilla/mux是一个强大的URL路由器以及调度分发器。该mux.Router中添加了众多的路由项，每一个路由项由HTTP请求方法（PUT、POST、GET或DELETE）、URL、Handler三部分组成。</p>
<p>若Docker Client通过HTTP的形式访问Docker Daemon，创建完mux.Router之后，Docker将Server的监听地址以及mux.Router作为参数，创建一个httpSrv=http.Server{}，最终执行httpSrv.Serve()为请求服务。</p>
<p>在Server的服务过程中，Server在listener上接受Docker Client的访问请求，并创建一个全新的goroutine来服务该请求。在goroutine中，首先读取请求内容，然后做解析工作，接着找到相应的路由项，随后调用相应的Handler来处理该请求，最后Handler处理完请求之后回复该请求。</p>
<p>需要注意的是：Docker Server的运行在Docker的启动过程中，是靠一个名为”serveapi”的job的运行来完成的。原则上，Docker Server的运行是众多job中的一个，但是为了强调Docker Server的重要性以及为后续job服务的重要特性，将该”serveapi”的job单独抽离出来分析，理解为Docker Server。</p>
<h3 id="-15"><a href="#-15" class="headerlink" title></a></h3><h3 id="4、engine"><a href="#4、engine" class="headerlink" title="4、engine"></a><strong>4、engine</strong></h3><p>Engine是Docker架构中的运行引擎，同时也Docker运行的核心模块。它扮演Docker container存储仓库的角色，并且通过执行job的方式来操纵管理这些容器。</p>
<p>在Engine数据结构的设计与实现过程中，有一个handler对象。该handler对象存储的都是关于众多特定job的handler处理访问。举例说明，Engine的handler对象中有一项为：{“create”: daemon.ContainerCreate,}，则说明当名为”create”的job在运行时，执行的是daemon.ContainerCreate的handler。</p>
<h3 id="-16"><a href="#-16" class="headerlink" title></a></h3><h3 id="5、job"><a href="#5、job" class="headerlink" title="5、job"></a><strong>5、job</strong></h3><p>一个Job可以认为是Docker架构中Engine内部最基本的工作执行单元。Docker可以做的每一项工作，都可以抽象为一个job。例如：在容器内部运行一个进程，这是一个job；创建一个新的容器，这是一个job，从Internet上下载一个文档，这是一个job；包括之前在Docker Server部分说过的，创建Server服务于HTTP的API，这也是一个job，等等。</p>
<p>Job的设计者，把Job设计得与Unix进程相仿。比如说：Job有一个名称，有参数，有环境变量，有标准的输入输出，有错误处理，有返回状态等。</p>
<h3 id="-17"><a href="#-17" class="headerlink" title></a></h3><h3 id="6、docker-registry"><a href="#6、docker-registry" class="headerlink" title="6、docker registry"></a><strong>6、docker registry</strong></h3><p>Docker Registry是一个存储容器镜像的仓库。而容器镜像是在容器被创建时，被加载用来初始化容器的文件架构与目录。</p>
<p>在Docker的运行过程中，Docker Daemon会与Docker Registry通信，并实现搜索镜像、下载镜像、上传镜像三个功能，这三个功能对应的job名称分别为”search”，”pull” 与 “push”。</p>
<p>其中，在Docker架构中，Docker可以使用公有的Docker Registry，即大家熟知的Docker Hub，如此一来，Docker获取容器镜像文件时，必须通过互联网访问Docker Hub；同时Docker也允许用户构建本地私有的Docker Registry，这样可以保证容器镜像的获取在内网完成。</p>
<h3 id="-18"><a href="#-18" class="headerlink" title></a></h3><h3 id="7、Graph"><a href="#7、Graph" class="headerlink" title="7、Graph"></a><strong>7、Graph</strong></h3><p>Graph在Docker架构中扮演已下载容器镜像的保管者，以及已下载容器镜像之间关系的记录者。一方面，Graph存储着本地具有版本信息的文件系统镜像，另一方面也通过GraphDB记录着所有文件系统镜像彼此之间的关系。</p>
<p>Graph的架构如下：</p>
<p><img src="/2019/10/31/%E7%BB%88%E4%BA%8E%E6%9C%89%E4%BA%BA%E6%8A%8ADocker%E8%AE%B2%E6%B8%85%E6%A5%9A%E4%BA%86/640-1572599922235.webp" alt="img"></p>
<p>其中，GraphDB是一个构建在SQLite之上的小型图数据库，实现了节点的命名以及节点之间关联关系的记录。它仅仅实现了大多数图数据库所拥有的一个小的子集，但是提供了简单的接口表示节点之间的关系。</p>
<p>同时在Graph的本地目录中，关于每一个的容器镜像，具体存储的信息有：该容器镜像的元数据，容器镜像的大小信息，以及该容器镜像所代表的具体rootfs。</p>
<p><strong>8、driver</strong></p>
<p>Driver是Docker架构中的驱动模块。通过Driver驱动，Docker可以实现对Docker容器执行环境的定制。由于Docker运行的生命周期中，并非用户所有的操作都是针对Docker容器的管理，另外还有关于Docker运行信息的获取，Graph的存储与记录等。因此，为了将Docker容器的管理从Docker Daemon内部业务逻辑中区分开来，设计了Driver层驱动来接管所有这部分请求。</p>
<p>在Docker Driver的实现中，可以分为以下三类驱动：graphdriver、networkdriver和execdriver。</p>
<p>graphdriver主要用于完成容器镜像的管理，包括存储与获取。即当用户需要下载指定的容器镜像时，graphdriver将容器镜像存储在本地的指定目录；同时当用户需要使用指定的容器镜像来创建容器的rootfs时，graphdriver从本地镜像存储目录中获取指定的容器镜像。</p>
<p>在graphdriver的初始化过程之前，有4种文件系统或类文件系统在其内部注册，它们分别是aufs、btrfs、vfs和devmapper。而Docker在初始化之时，通过获取系统环境变量”DOCKER_DRIVER”来提取所使用driver的指定类型。而之后所有的graph操作，都使用该driver来执行。</p>
<p>graphdriver的架构如下：</p>
<p><img src="/2019/10/31/%E7%BB%88%E4%BA%8E%E6%9C%89%E4%BA%BA%E6%8A%8ADocker%E8%AE%B2%E6%B8%85%E6%A5%9A%E4%BA%86/640-1572600680712.webp" alt="img"></p>
<p>networkdriver的用途是完成Docker容器网络环境的配置，其中包括Docker启动时为Docker环境创建网桥；Docker容器创建时为其创建专属虚拟网卡设备；以及为Docker容器分配IP、端口并与宿主机做端口映射，设置容器防火墙策略等。networkdriver的架构如下：</p>
<p><img src="/2019/10/31/%E7%BB%88%E4%BA%8E%E6%9C%89%E4%BA%BA%E6%8A%8ADocker%E8%AE%B2%E6%B8%85%E6%A5%9A%E4%BA%86/640-1572600696159.webp" alt="img"></p>
<p>execdriver作为Docker容器的执行驱动，负责创建容器运行命名空间，负责容器资源使用的统计与限制，负责容器内部进程的真正运行等。在execdriver的实现过程中，原先可以使用LXC驱动调用LXC的接口，来操纵容器的配置以及生命周期，而现在execdriver默认使用native驱动，不依赖于LXC。</p>
<p>具体体现在Daemon启动过程中加载的ExecDriverflag参数，该参数在配置文件已经被设为”native”。这可以认为是Docker在1.2版本上一个很大的改变，或者说Docker实现跨平台的一个先兆。execdriver架构如下：</p>
<p><img src="/2019/10/31/%E7%BB%88%E4%BA%8E%E6%9C%89%E4%BA%BA%E6%8A%8ADocker%E8%AE%B2%E6%B8%85%E6%A5%9A%E4%BA%86/640-1572600706623.webp" alt="img"></p>
<h3 id="9、libcontainer"><a href="#9、libcontainer" class="headerlink" title="9、libcontainer"></a><strong>9、libcontainer</strong></h3><p>libcontainer是Docker架构中一个使用Go语言设计实现的库，设计初衷是希望该库可以不依靠任何依赖，直接访问内核中与容器相关的API。</p>
<p>正是由于libcontainer的存在，Docker可以直接调用libcontainer，而最终操纵容器的namespace、cgroups、apparmor、网络设备以及防火墙规则等。这一系列操作的完成都不需要依赖LXC或者其他包。libcontainer架构如下：</p>
<p><img src="/2019/10/31/%E7%BB%88%E4%BA%8E%E6%9C%89%E4%BA%BA%E6%8A%8ADocker%E8%AE%B2%E6%B8%85%E6%A5%9A%E4%BA%86/640-1572600714042.webp" alt="img"></p>
<p>另外，libcontainer提供了一整套标准的接口来满足上层对容器管理的需求。或者说，libcontainer屏蔽了Docker上层对容器的直接管理。又由于libcontainer使用Go这种跨平台的语言开发实现，且本身又可以被上层多种不同的编程语言访问，因此很难说，未来的Docker就一定会紧紧地和Linux捆绑在一起。而于此同时，Microsoft在其著名云计算平台Azure中，也添加了对Docker的支持，可见Docker的开放程度与业界的火热度。</p>
<p>暂不谈Docker，由于libcontainer的功能以及其本身与系统的松耦合特性，很有可能会在其他以容器为原型的平台出现，同时也很有可能催生出云计算领域全新的项目。</p>
<h3 id="10、docker-container"><a href="#10、docker-container" class="headerlink" title="10、docker container"></a><strong>10、docker container</strong></h3><p>Docker container（Docker容器）是Docker架构中服务交付的最终体现形式。</p>
<p>Docker按照用户的需求与指令，订制相应的Docker容器：</p>
<ul>
<li>用户通过指定容器镜像，使得Docker容器可以自定义rootfs等文件系统；</li>
<li>用户通过指定计算资源的配额，使得Docker容器使用指定的计算资源；</li>
<li>用户通过配置网络及其安全策略，使得Docker容器拥有独立且安全的网络环境；</li>
<li>用户通过指定运行的命令，使得Docker容器执行指定的工作。</li>
</ul>
<p><img src="/2019/10/31/%E7%BB%88%E4%BA%8E%E6%9C%89%E4%BA%BA%E6%8A%8ADocker%E8%AE%B2%E6%B8%85%E6%A5%9A%E4%BA%86/640-1572600728419.webp" alt="img"></p>
<h2 id="四、docker简单使用"><a href="#四、docker简单使用" class="headerlink" title="四、docker简单使用"></a><strong>四、docker简单使用</strong></h2><h3 id="1、安装"><a href="#1、安装" class="headerlink" title="1、安装"></a><strong>1、安装</strong></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install docker -y systemctl enable dockersystemctl start docker</span><br></pre></td></tr></table></figure>

<p>注意：启动前应当设置源</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim /usr/lib/systemd/system/docker.service</span><br></pre></td></tr></table></figure>



<p>这里设置阿里的，注册阿里云账户号每个用户都有：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@web1 ~]# vim /usr/lib/systemd/system/docker.service</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Docker Application Container Engine</span><br><span class="line">Documentation=http://docs.docker.com</span><br><span class="line">After=network.target</span><br><span class="line">Wants=docker-storage-setup.service</span><br><span class="line">Requires=docker-cleanup.timer</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">NotifyAccess=main</span><br><span class="line">EnvironmentFile=-/run/containers/registries.conf</span><br><span class="line">EnvironmentFile=-/etc/sysconfig/docker</span><br><span class="line">EnvironmentFile=-/etc/sysconfig/docker-storage</span><br><span class="line">EnvironmentFile=-/etc/sysconfig/docker-network</span><br><span class="line">Environment=GOTRACEBACK=crash</span><br><span class="line">Environment=DOCKER_HTTP_HOST_COMPAT=1</span><br><span class="line">Environment=PATH=/usr/libexec/docker:/usr/bin:/usr/sbin</span><br><span class="line">ExecStart=/usr/bin/dockerd-current --registry-mirror=https://rfcod7oz.mirror.aliyuncs.com  #这个值可以登陆阿里云账号请参考下图</span><br><span class="line">          --add-runtime docker-runc=/usr/libexec/docker/docker-runc-current </span><br><span class="line">          --default-runtime=docker-runc </span><br><span class="line">          --exec-opt native.cgroupdriver=systemd </span><br><span class="line">          --userland-proxy-path=/usr/libexec/docker/docker-proxy-current </span><br><span class="line">          --init-path=/usr/libexec/docker/docker-init-current </span><br><span class="line">          --seccomp-profile=/etc/docker/seccomp.json </span><br><span class="line">          $OPTIONS </span><br><span class="line">          $DOCKER_STORAGE_OPTIONS </span><br><span class="line">          $DOCKER_NETWORK_OPTIONS </span><br><span class="line">          $ADD_REGISTRY </span><br><span class="line">          $BLOCK_REGISTRY </span><br><span class="line">          $INSECURE_REGISTRY </span><br><span class="line">          $REGISTRIES</span><br><span class="line">ExecReload=/bin/kill -s HUP $MAINPID</span><br><span class="line">LimitNOFILE=1048576</span><br><span class="line">LimitNPROC=1048576</span><br><span class="line">LimitCORE=infinity</span><br><span class="line">TimeoutStartSec=0</span><br><span class="line">Restart=on-abnormal</span><br><span class="line">KillMode=process</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>

<p>　　<img src="/2019/10/31/%E7%BB%88%E4%BA%8E%E6%9C%89%E4%BA%BA%E6%8A%8ADocker%E8%AE%B2%E6%B8%85%E6%A5%9A%E4%BA%86/640-1572601422584.webp" alt="img">　</p>
<h3 id="2、docker版本查询"><a href="#2、docker版本查询" class="headerlink" title="2、docker版本查询"></a><strong>2、docker版本查询</strong></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@web1 ~]# docker version</span><br></pre></td></tr></table></figure>



<h3 id="3、搜索下载镜像"><a href="#3、搜索下载镜像" class="headerlink" title="3、搜索下载镜像"></a><strong>3、搜索下载镜像</strong></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull alpine　　　　　　　　　　#下载镜像docker search nginx　　　　　　　　　 #查看镜像docker pull nginx</span><br></pre></td></tr></table></figure>



<h3 id="4、查看已经下载的镜像"><a href="#4、查看已经下载的镜像" class="headerlink" title="4、查看已经下载的镜像"></a><strong>4、查看已经下载的镜像</strong></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@web1 ~]# docker imagesREPOSITORY          TAG                 IMAGE ID            CREATED             SIZEzxg/my_nginx        v1                  b164f4c07c64        8 days ago          126 MBzxg/my_nginx        latest              f07837869dfc        8 days ago          126 MBdocker.io/nginx     latest              e445ab08b2be        2 weeks ago         126 MBdocker.io/alpine    latest              b7b28af77ffe        3 weeks ago         5.58 MBdocker.io/centos    latest              9f38484d220f        4 months ago        202 MB[root@web1 ~]#</span><br></pre></td></tr></table></figure>



<h3 id="5、导出镜像"><a href="#5、导出镜像" class="headerlink" title="5、导出镜像"></a><strong>5、导出镜像</strong></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker  save nginx &gt;/tmp/nginx.tar.gz</span><br></pre></td></tr></table></figure>



<h3 id="6、删除镜像"><a href="#6、删除镜像" class="headerlink" title="6、删除镜像"></a><strong>6、删除镜像</strong></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker rmi -f nginx</span><br></pre></td></tr></table></figure>



<h3 id="7、导入镜像"><a href="#7、导入镜像" class="headerlink" title="7、导入镜像"></a><strong>7、导入镜像</strong></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker load &lt;/tmp/nginx.tar.gz</span><br></pre></td></tr></table></figure>

<h3 id="-19"><a href="#-19" class="headerlink" title></a></h3><h3 id="8、默认配置文件"><a href="#8、默认配置文件" class="headerlink" title="8、默认配置文件"></a><strong>8、默认配置文件</strong></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim /usr/lib/systemd/system/docker.service</span><br></pre></td></tr></table></figure>



<p>如果更改存储目录就添加　　</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--graph=/opt/docker</span><br></pre></td></tr></table></figure>





<p>如果更改DNS——默认采用宿主机的dns</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--dns=xxxx的方式指定</span><br></pre></td></tr></table></figure>



<h3 id="9、运行hello-world"><a href="#9、运行hello-world" class="headerlink" title="9、运行hello world"></a><strong>9、运行hello world</strong></h3><p>这里用centos镜像echo一个hello word</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@web1 overlay2]#  docker images</span><br></pre></td></tr></table></figure>



<h3 id="10、运行一个容器-run"><a href="#10、运行一个容器-run" class="headerlink" title="10、运行一个容器-run"></a><strong>10、运行一个容器-run</strong></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@web1 overlay2]# docker run -it alpine sh   #运行并进入alpine</span><br></pre></td></tr></table></figure>



<p>后台运行（-d后台运行）（–name添加一个名字）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@web1 overlay2]# docker run -it -d --name test1</span><br></pre></td></tr></table></figure>



<p>还有一种-rm参数，ctrl+c后就删除，可以测试环境用，生成环境用的少</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@web1 overlay2]# docker run -it  --rm --name centos nginx</span><br></pre></td></tr></table></figure>



<h3 id="11、如何进入容器"><a href="#11、如何进入容器" class="headerlink" title="11、如何进入容器"></a><strong>11、如何进入容器</strong></h3><p>三种方法，上面已经演示了一种</p>
<p>第一种，需要容器本身的pid及util-linux，不推荐，暂时不演示了</p>
<p>第二种，不分配bash终端的一种实施操作，不推荐，这种操作如果在开一个窗口也能看到操作的指令，所有人都能看到。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@web1 overlay2]# docker ps</span><br><span class="line">[root@web1 overlay2]# docker attach mynginx</span><br></pre></td></tr></table></figure>



<p>第三种：exec方式，终端时分开的，推荐</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@web1 overlay2]# docker exec -it mynginx sh</span><br></pre></td></tr></table></figure>



<h3 id="12、查看docker进程及删除容器"><a href="#12、查看docker进程及删除容器" class="headerlink" title="12、查看docker进程及删除容器"></a><strong>12、查看docker进程及删除容器</strong></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@web1 overlay2]# docker ps -a 　　　　　　#-a :显示所有的容器，包括未运行的CONTAINER ID      [root@web1 overlay2]# docker rm 9fc796e928d7 #rm时删除一个或多个容器9fc796e928d7</span><br></pre></td></tr></table></figure>



<h3 id="13、查看容器详细信息"><a href="#13、查看容器详细信息" class="headerlink" title="13、查看容器详细信息"></a><strong>13、查看容器详细信息</strong></h3><p>并不需要进入到容器里面，通过查看详细信息看到了刚才运行的nginx，宿主机curl ip地址访问一下运行情况。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@web1 overlay2]#  docker inspect mynginx</span><br><span class="line">[root@web1 overlay2]#</span><br></pre></td></tr></table></figure>



<h3 id="14、查看日志"><a href="#14、查看日志" class="headerlink" title="14、查看日志"></a><strong>14、查看日志</strong></h3><p>-f  挂起这个终端，动态查看日志</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@web1 ~]# docker logs  -f mynginx</span><br></pre></td></tr></table></figure>



<p><strong>参考文章：</strong></p>
<p><a href="https://cloud.tencent.com/developer/article/1006116" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1006116</a>  </p>
<p><a href="https://yq.aliyun.com/articles/65145" target="_blank" rel="noopener">https://yq.aliyun.com/articles/65145</a></p>
<p><a href="https://blog.51cto.com/10085711/2068290" target="_blank" rel="noopener">https://blog.51cto.com/10085711/2068290</a></p>
<p><a href="https://www.cnblogs.com/zuxing/articles/8717415.html" target="_blank" rel="noopener">https://www.cnblogs.com/zuxing/articles/8717415.html</a></p>
]]></content>
      <categories>
        <category>持续集成</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>sourcetree3免注册登录bitbucket教程</title>
    <url>/2019/10/31/sourcetree3%E5%85%8D%E6%B3%A8%E5%86%8C%E7%99%BB%E5%BD%95bitbucket%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="Sourcetree下载"><a href="#Sourcetree下载" class="headerlink" title="Sourcetree下载"></a>Sourcetree下载</h2><p>Sourcetree：一个用于Windows和Mac的免费Git客户端。<br>官网：<a href="https://www.sourcetreeapp.com/" target="_blank" rel="noopener">Sourcetree | Free Git GUI for Mac and Windows</a></p>
<a id="more"></a>

<p>下载之后，双击打开安装程序，新版本安装界面如下，提示需要登录bitbucket账号后才能继续安装</p>
<p>旧版 sourcetree 只需要手动添加 一个 accounts.json 文件就能实现免注册登录，而新版本则需要再修改 user.config 文件中的配置。</p>
<h2 id="添加-accounts-json-文件"><a href="#添加-accounts-json-文件" class="headerlink" title="添加 accounts.json 文件"></a>添加 accounts.json 文件</h2><p><code>%LocalAppData%\Atlassian\SourceTree\accounts.json</code><br>在以上目录位置创建一个accounts.json文件，内容如下：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">[</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">"$id"</span>: <span class="string">"1"</span>,</span><br><span class="line">    <span class="attr">"$type"</span>: <span class="string">"SourceTree.Api.Host.Identity.Model.IdentityAccount, SourceTree.Api.Host.Identity"</span>,</span><br><span class="line">    <span class="attr">"Authenticate"</span>: <span class="literal">true</span>,</span><br><span class="line">    <span class="attr">"HostInstance"</span>: &#123;</span><br><span class="line">      <span class="attr">"$id"</span>: <span class="string">"2"</span>,</span><br><span class="line">      <span class="attr">"$type"</span>: <span class="string">"SourceTree.Host.Atlassianaccount.AtlassianAccountInstance, SourceTree.Host.AtlassianAccount"</span>,</span><br><span class="line">      <span class="attr">"Host"</span>: &#123;</span><br><span class="line">        <span class="attr">"$id"</span>: <span class="string">"3"</span>,</span><br><span class="line">        <span class="attr">"$type"</span>: <span class="string">"SourceTree.Host.Atlassianaccount.AtlassianAccountHost, SourceTree.Host.AtlassianAccount"</span>,</span><br><span class="line">        <span class="attr">"Id"</span>: <span class="string">"atlassian account"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"BaseUrl"</span>: <span class="string">"https://id.atlassian.com/"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"Credentials"</span>: &#123;</span><br><span class="line">      <span class="attr">"$id"</span>: <span class="string">"4"</span>,</span><br><span class="line">      <span class="attr">"$type"</span>: <span class="string">"SourceTree.Model.BasicAuthCredentials, SourceTree.Api.Account"</span>,</span><br><span class="line">      <span class="attr">"Username"</span>: <span class="string">""</span>,</span><br><span class="line">      <span class="attr">"Email"</span>: <span class="literal">null</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"IsDefault"</span>: <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>



<h2 id="修改-user-config-文件配置"><a href="#修改-user-config-文件配置" class="headerlink" title="修改 user.config 文件配置"></a>修改 user.config 文件配置</h2><p>该文件所在路径：<br><code>%LocalAppData%\Atlassian\SourceTree.exe_Url_xxxxxxxxxx\3.1.2.3027\user.config</code></p>
<p>记事本打开 user.config，在<code>&lt;SourceTree.Properties.Settings&gt;</code>添加以下内容并保存即可。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;setting name=&quot;AgreedToEULAVersion&quot; serializeAs=&quot;String&quot;&gt;</span><br><span class="line">    &lt;value&gt;20160201&lt;/value&gt;</span><br><span class="line">&lt;/setting&gt;</span><br></pre></td></tr></table></figure>

<p>最后再次打开 sourcetree 安装程序。</p>
]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>sourcetree</tag>
      </tags>
  </entry>
  <entry>
    <title>docker使用说明</title>
    <url>/2019/10/30/docker%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/</url>
    <content><![CDATA[<h2 id="查看docker运行信息"><a href="#查看docker运行信息" class="headerlink" title="查看docker运行信息"></a>查看docker运行信息</h2><p>docker inspect 会返回一个 JSON 文件记录着 Docker 容器的配置和状态信息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker inspect NAMES </span><br><span class="line"># 查看容器所有状态信息；</span><br><span class="line"></span><br><span class="line">docker inspect --format=&apos;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&apos; ID/NAMES</span><br><span class="line"># 查看 容器ip 地址</span><br><span class="line"></span><br><span class="line">docker inspect --format &apos;&#123;&#123;.Name&#125;&#125; &#123;&#123;.State.Running&#125;&#125;&apos; NAMES</span><br><span class="line"># 容器运行状态</span><br></pre></td></tr></table></figure>

<a id="more"></a>

<p><strong>查看进程信息</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker top NAMES</span><br></pre></td></tr></table></figure>

<p><strong>查看端口；(使用容器ID 或者 容器名称)</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker port ID/NAMES</span><br></pre></td></tr></table></figure>

<p><strong>查看IP地址 也可以直接通过用 远程执行命令也可以</strong>（Centos7）；</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker exec -it ID/NAMES ip addr</span><br></pre></td></tr></table></figure>



<h2 id="docker-的安装及使用"><a href="#docker-的安装及使用" class="headerlink" title="docker 的安装及使用"></a>docker 的安装及使用</h2><h3 id="简单介绍"><a href="#简单介绍" class="headerlink" title="简单介绍"></a>简单介绍</h3><blockquote>
<p>docker 是一个开源的软件部署解决方案<br>docker 也是轻量级的应用容器框架<br>docker 可以打包、发布、运行任何的应用</p>
</blockquote>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><ul>
<li>阿里云</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun</span><br></pre></td></tr></table></figure>

<ul>
<li>daocloud</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -sSL https://get.daocloud.io/docker | sh</span><br></pre></td></tr></table></figure>

<p>安装后将会自动重启</p>
<h3 id="卸载"><a href="#卸载" class="headerlink" title="卸载"></a>卸载</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get remove docker docker-engine</span><br><span class="line">rm -fr /var/lib/docker/</span><br></pre></td></tr></table></figure>

<h3 id="配置加速器"><a href="#配置加速器" class="headerlink" title="配置加速器"></a>配置加速器</h3><p>下面是我的配置，实际使用需要根据自己的账号去查看自己的地址</p>
<ul>
<li><a href="https://www.daocloud.io/mirror#accelerator-doc" target="_blank" rel="noopener">DaoCloud</a></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://ced808ab.m.daocloud.io</span><br><span class="line">sudo systemctl restart docker.service</span><br></pre></td></tr></table></figure>

<ul>
<li><a href="https://cr.console.aliyun.com/cn-hangzhou/mirrors" target="_blank" rel="noopener">阿里云</a></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo mkdir -p /etc/docker</span><br><span class="line">sudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;registry-mirrors&quot;: [&quot;https://dist7hw1.mirror.aliyuncs.com&quot;]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure>

<h3 id="基础命令"><a href="#基础命令" class="headerlink" title="基础命令"></a>基础命令</h3><ul>
<li><p>查看版本:<code>docker -v</code> //文章使用版本：Docker version 18.06.0-ce, build 0ffa825</p>
</li>
<li><p>查看镜像：<code>docker images</code></p>
</li>
<li><p>查看容器：<code>docker ps</code></p>
</li>
<li><p>启动 docker 服务：<code>sudo service docker start</code></p>
</li>
<li><p>停止 docker 服务：<code>sudo service docker stop</code></p>
</li>
<li><p>重启 docker 服务：<code>sudo service docker restart</code></p>
</li>
<li><p>进入一个运行中的容器：<code>docker exec -it 容器Id /bin/bash</code></p>
</li>
</ul>
<h3 id="通过-Dockerfile-使用-nginx"><a href="#通过-Dockerfile-使用-nginx" class="headerlink" title="通过 Dockerfile 使用 nginx"></a>通过 Dockerfile 使用 nginx</h3><p>通过下面的一个脚本可以简单快速的创建一个镜像并运行起来<br>大概看下应该就可以大概明白镜像的基本使用了</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &apos;0.创建测试目录及代码&apos;</span><br><span class="line">mkdir dockerfiletest</span><br><span class="line">cd dockerfiletest</span><br><span class="line">mkdir dist</span><br><span class="line">echo &apos;hello world&apos;&gt;./dist/index.html</span><br><span class="line"></span><br><span class="line">echo &apos;1.创建Dockerfile&apos;</span><br><span class="line">echo &apos;</span><br><span class="line">From daocloud.io/library/nginx:1.13.0-alpine</span><br><span class="line">COPY dist/ /usr/share/nginx/html/</span><br><span class="line">&apos;&gt;./Dockerfile</span><br><span class="line"></span><br><span class="line">echo &apos;2.构建镜像&apos;</span><br><span class="line">docker build -t dockerfiletest .</span><br><span class="line"></span><br><span class="line">echo &apos;3.运行镜像&apos;</span><br><span class="line">docker run -p 3344:80 dockerfiletest</span><br></pre></td></tr></table></figure>

<p>下面分步拆解下</p>
<h4 id="1-添加-Dockerfile-文件"><a href="#1-添加-Dockerfile-文件" class="headerlink" title="1.添加 Dockerfile 文件"></a>1.添加 Dockerfile 文件</h4><p>详细请参考：<a href="https://hub.daocloud.io/repos/2b7310fb-1a50-48f2-9586-44622a2d1771" target="_blank" rel="noopener">https://hub.daocloud.io/repos/2b7310fb-1a50-48f2-9586-44622a2d1771</a></p>
<p>html 的简单部署</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">From daocloud.io/library/nginx:1.13.0-alpine</span><br><span class="line"># 将发布目录的文件拷贝到镜像中</span><br><span class="line">COPY dist/ /usr/share/nginx/html/</span><br></pre></td></tr></table></figure>

<p>若要使用自己的配置脚本，比如 vue 的配置,可以将自己的配置文件复制到容器中</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">From daocloud.io/library/nginx:1.13.0-alpine</span><br><span class="line"># 删除镜像中 nginx 的默认配置</span><br><span class="line">RUN rm /etc/nginx/conf.d/default.conf</span><br><span class="line"># 复制 default.conf 到镜像中</span><br><span class="line">ADD default.conf /etc/nginx/conf.d/</span><br><span class="line"># 将发布目录的文件拷贝到镜像中</span><br><span class="line">COPY dist/ /usr/share/nginx/html/</span><br></pre></td></tr></table></figure>

<p>nginx 中 vue history 模式的配置 如下，可参考</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    location / &#123;</span><br><span class="line">        root /usr/share/nginx/html/;</span><br><span class="line">        index index.html;</span><br><span class="line">        try_files $uri $uri/ /index.html;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><del>若是将<code>/usr/share/nginx/html/</code>和<code>/etc/nginx/conf.d/</code>挂载到本地，这样应该能够灵活使用 docker 安装的 nginx 了(未实践过)</del></p>
<h4 id="2-构建镜像"><a href="#2-构建镜像" class="headerlink" title="2.构建镜像"></a>2.构建镜像</h4><p>构建参数说明参考：<a href="http://www.runoob.com/docker/docker-build-command.html" target="_blank" rel="noopener">http://www.runoob.com/docker/docker-build-command.html</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker build -t docker-nginx-test .</span><br></pre></td></tr></table></figure>

<h4 id="3-运行镜像"><a href="#3-运行镜像" class="headerlink" title="3.运行镜像"></a>3.运行镜像</h4><p>–name 服务名<br>-d 后台运行<br>-p 暴露端口:nginx 端口<br>docker-nginx-test 镜像名/IMAGE ID</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run --name dockertest -d -p 4455:80 docker-nginx-test</span><br></pre></td></tr></table></figure>

<h4 id="4-测试访问"><a href="#4-测试访问" class="headerlink" title="4.测试访问"></a>4.测试访问</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@ubuntu:~# curl http://localhost:4455</span><br><span class="line">hello world</span><br></pre></td></tr></table></figure>

<blockquote>
<p>现在，可以通过 IP+端口的形式在外网访问站点了，但在实际使用肯定还需要绑定域名等一些操作<br>最简单的是我认为是使用 nginx 去做代理<br>目前我们公司使用的 <a href="https://traefik.io/" target="_blank" rel="noopener">traefik</a> ，最爽的莫过于 https 的支持，可以了解一下</p>
</blockquote>
<h4 id="5-基础操作"><a href="#5-基础操作" class="headerlink" title="5.基础操作"></a>5.基础操作</h4><p>1 <strong>docker images</strong> 查看镜像信息列表 镜像是静态的</p>
<p>2 <strong>docker ps -a</strong> 查看运行中的所有容器</p>
<p>3 <strong>docker pull  [images]:[version]</strong>从dockerhub拉取指定镜像</p>
<p>4 <strong>docker run -p 8000:80 -tdi –privileged [imageID] [command]</strong>  后台启动docker,并指定宿主机端口和docker映射端口。</p>
<p> <strong>-i:</strong>以交互模式运行容器，通常与 -t 同时使用；</p>
<p> <strong>-d:</strong>后台运行容器，并返回容器ID；</p>
<p><strong>-t:</strong>为容器重新分配一个伪输入终端，通常与 -i 同时使用；</p>
<p><strong>–privileged</strong> 容器将拥有访问主机所有设备的权限</p>
<p>通常情况下 [command] 填下 <strong>/bin/bash</strong> 即可。</p>
<p>完整参数：</p>
<ul>
<li><strong>-a stdin:</strong> 指定标准输入输出内容类型，可选 STDIN/STDOUT/STDERR 三项；</li>
<li><strong>-d:</strong> 后台运行容器，并返回容器ID；</li>
<li><strong>-i:</strong> 以交互模式运行容器，通常与 -t 同时使用；</li>
<li><strong>-P:</strong> 随机端口映射，容器内部端口<strong>随机</strong>映射到主机的高端口</li>
<li><strong>-p:</strong> 指定端口映射，格式为：<strong>主机(宿主)端口:容器端口</strong></li>
<li><strong>-t:</strong> 为容器重新分配一个伪输入终端，通常与 -i 同时使用；</li>
<li><strong>–name=”nginx-lb”:</strong> 为容器指定一个名称；</li>
<li><strong>–dns 8.8.8.8:</strong> 指定容器使用的DNS服务器，默认和宿主一致；</li>
<li><strong>–dns-search example.com:</strong> 指定容器DNS搜索域名，默认和宿主一致；</li>
<li><strong>-h “mars”:</strong> 指定容器的hostname；</li>
<li><strong>-e username=”ritchie”:</strong> 设置环境变量；</li>
<li><strong>–env-file=[]:</strong> 从指定文件读入环境变量；</li>
<li><strong>–cpuset=”0-2” or –cpuset=”0,1,2”:</strong> 绑定容器到指定CPU运行；</li>
<li><strong>-m :</strong>设置容器使用内存最大值；</li>
<li><strong>–net=”bridge”:</strong> 指定容器的网络连接类型，支持 bridge/host/none/container: 四种类型；</li>
<li><strong>–link=[]:</strong> 添加链接到另一个容器；</li>
<li><strong>–expose=[]:</strong> 开放一个端口或一组端口；</li>
<li><strong>–volume , -v:</strong> 绑定一个卷</li>
</ul>
<p>特殊情况下，如需要在centos镜像中使用<strong>systemctl</strong> . 则应添加<strong>–privileged</strong> 并设置[command ]为 <strong>init</strong>。</p>
<p>5 当镜像通过run 启动后，便会载入到一个动态的container(容器)中运行，此时若需要进入终端交互模式：</p>
<p><strong>sudo docker exec -it [containerID] /bin/bash</strong></p>
<p>交互模式中，使用  ctrl+p+q退出交互 保持运行,使用 exit命令退出并停止容器。</p>
<p>6 在容器非交互模式下，通过docker  start/stop 命令来启动/停止已部署的容器服务。</p>
<p>7 <strong>docker rm [containerID]</strong> 删除容器</p>
<p>8 <strong>docker rmi [imageID]</strong> 删除镜像</p>
<p>9 <strong>docker cp [YourHostFilePath] [containerID]:[DockerPath]</strong>  将宿主机内的指定文件传输至容器内部的指定地址。</p>
<p>10 <strong>docker logs -f  [containerID]  –tail 10 -t</strong> 查看日志，使用 <code>-f</code> 参数后，就可以查看实时日志了，</p>
<p>使用 <code>--tail</code> 参数可以精确控制日志的输出行数， <code>-t</code> 参数则可以显示日志的输出时间。</p>
<h4 id="6-镜像制作"><a href="#6-镜像制作" class="headerlink" title="6.镜像制作"></a>6.镜像制作</h4><p>1  <strong>docker commit [containerID] [ImageName]:[Version]</strong> 将修改后的容器重新打包成镜像</p>
<p>2 <strong>docker commit -a “runoob.com” -m “my apache” a404c6c174a2 mymysql:v1</strong> 将容器a404c6c174a2 保存为新的镜像,并添加提交人信息和说明信息。</p>
<p><strong>-a</strong> :提交的镜像作者；</p>
<p> <strong>-c</strong> :使用Dockerfile指令来创建镜像；</p>
<p> <strong>-m</strong> :提交时的说明文字；</p>
<p> <strong>-p</strong> :在commit时，将容器暂停。</p>
<p>3 <strong>docker push [ImageID] [repertory_address]</strong>提交镜像到云仓库</p>
<p>作者：爱睡觉的树</p>
<p>链接：</p>
<p><a href="https://www.jianshu.com/p/a84e8cf33b34" target="_blank" rel="noopener">https://www.jianshu.com/p/a84e8cf33b34</a></p>
<p>来源：简书</p>
<p>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
<h2 id="docker-compose-的安装及使用"><a href="#docker-compose-的安装及使用" class="headerlink" title="docker-compose 的安装及使用"></a>docker-compose 的安装及使用</h2><h3 id="简单介绍-1"><a href="#简单介绍-1" class="headerlink" title="简单介绍"></a>简单介绍</h3><blockquote>
<p>Docker Compose 是一个用来定义和运行复杂应用的 Docker 工具。<br>使用 Docker Compose 不再需要使用 shell 脚本来启动容器。(通过 docker-compose.yml 配置)</p>
</blockquote>
<h3 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h3><p>可以通过修改 URL 中的版本，自定义您需要的版本。</p>
<ul>
<li>Github源</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo curl -L https://github.com/docker/compose/releases/download/1.22.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose</span><br><span class="line">sudo chmod +x /usr/local/bin/docker-compose</span><br></pre></td></tr></table></figure>

<ul>
<li>Daocloud镜像</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -L https://get.daocloud.io/docker/compose/releases/download/1.22.0/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose</span><br><span class="line">chmod +x /usr/local/bin/docker-compose</span><br></pre></td></tr></table></figure>

<h3 id="卸载-1"><a href="#卸载-1" class="headerlink" title="卸载"></a>卸载</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo rm /usr/local/bin/docker-compose</span><br></pre></td></tr></table></figure>

<h3 id="基础命令-1"><a href="#基础命令-1" class="headerlink" title="基础命令"></a>基础命令</h3><p>需要在 docker-compose.yml 所在文件夹中执行命令</p>
<p>使用 docker-compose 部署项目的简单步骤</p>
<ul>
<li>停止现有 docker-compose 中的容器：<code>docker-compose down</code></li>
<li>重新拉取镜像：<code>docker-compose pull</code></li>
<li>后台启动 docker-compose 中的容器：<code>docker-compose up -d</code></li>
</ul>
<p>下面将介绍 <code>docker-compose</code> 子命令的使用。也可以通过运行 <code>docker-compose --help</code>来查看这些信息。</p>
<ul>
<li><a href="#build">build</a></li>
<li><a href="#help">help</a></li>
<li><a href="#kill">kill</a></li>
<li><a href="#ps">ps</a></li>
<li><a href="#restart">restart</a></li>
<li><a href="#run">run</a></li>
<li><a href="#start">start</a></li>
<li><a href="#up">up</a></li>
<li><a href="#logs">logs</a></li>
<li><a href="#port">port</a></li>
<li><a href="#pull">pull</a></li>
<li><a href="#rm">rm</a></li>
<li><a href="#scale">scale</a></li>
<li><a href="#stop">stop</a></li>
</ul>
<h4 id="build"><a href="#build" class="headerlink" title="build"></a>build</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">用法：build [options] [SERVICE...]</span><br><span class="line">选项：</span><br><span class="line">	--force-rm  总是移除构建过程中产生的中间项容器</span><br><span class="line">	--no-cache  构建镜像过程中不使用Cache</span><br><span class="line">	--pull      总是尝试获取更新版本的镜像</span><br></pre></td></tr></table></figure>

<p>构建服务并打上<code>project_service</code>风格的标签（如：<code>composetest_db</code>）。如果你更改了服务的<code>Dockerfile</code>或者构建目录下的内容，需要运行<code>docker-compose build</code>重新构建服务。</p>
<h4 id="help"><a href="#help" class="headerlink" title="help"></a>help</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">用法：help COMMAND</span><br></pre></td></tr></table></figure>

<p>显示命令的帮助信息及用法教程。</p>
<h4 id="kill"><a href="#kill" class="headerlink" title="kill"></a>kill</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">用法：kill [options] [SERVICE...]</span><br><span class="line">选项：</span><br><span class="line">	-s SIGNAL         SIGNAL 是发送给容器的信号量，默认是 SIGKILL</span><br></pre></td></tr></table></figure>

<p>通过发送<code>SIGKILL</code>信号来强制终止运行中的容器，也可以发送指定的信号量，例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ docker-compose kill -s SIGINT</span><br></pre></td></tr></table></figure>

<h4 id="ps"><a href="#ps" class="headerlink" title="ps"></a>ps</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">用法：ps [options] [SERVICE...]</span><br><span class="line">选项：</span><br><span class="line">	-q		仅仅显示容器ID</span><br></pre></td></tr></table></figure>

<p>列出容器。</p>
<h4 id="restart"><a href="#restart" class="headerlink" title="restart"></a>restart</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">用法：restart [options] [SERVICE...]</span><br><span class="line">选项：</span><br><span class="line">	-t, --timeout TIMEOUT      设置关闭服务的超时时间，单位为秒，默认为10</span><br></pre></td></tr></table></figure>

<p>重启服务。</p>
<h4 id="run"><a href="#run" class="headerlink" title="run"></a>run</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">用法：run [options] [-e KEY=VAL...] SERVICE [COMMAND] [ARGS...]</span><br><span class="line">选项：</span><br><span class="line">	-d                    分离模式：在后台运行容器，只打印新的容器名称</span><br><span class="line">	--entrypoint CMD      覆盖镜像的入口点（CMD ...）</span><br><span class="line">	-e KEY=VAL            设置环境变量，可以使用多次</span><br><span class="line">	-u, --user=&quot;&quot;         通过指定的用户名或用户id来运行</span><br><span class="line">	--no-deps             不启动link连接的服务</span><br><span class="line">	--rm                  运行结束后移除容器，在分离模式下将被忽略</span><br><span class="line">	-p, --publish=[]      将容器暴露端口映射到主机端口</span><br><span class="line">	--service-ports       通过服务映射到主机的端口执行命令</span><br><span class="line">	-T                    禁用pseudo-tty分配，默认会分配一个TTY</span><br></pre></td></tr></table></figure>

<p>对服务运行的命令。例如，以下命令启动web服务并运行bash命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ docker-compose run web bash</span><br></pre></td></tr></table></figure>

<p><code>run</code>命令，将使用服务中已经定义的配置来创建运行一个新的容器。也就是说，如此创建的容器，将会使用相同的挂载卷、容器连接等相同的配置，但它们依旧可以存在差异。</p>
<p>第一个区别是，可以使用<code>run</code>命令覆盖服务中指定的运行命令。例如，<code>web</code>服务中的配置指定的运行命令为<code>bash</code>，那么<code>docker-compose run web python app.py</code>将使用<code>python app.py</code>来覆盖它。</p>
<p>第二个区别是，<code>docker-compose run</code>命令不会创建任何服务配置中指定的端口映射，这样可以防止多个容器映射同一端口的冲突。如果你需要使得服务的端口创建并映射到主机，需要指定<code>--service-ports</code>标记，如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ docker-compose run --service-ports web python manage.py shell</span><br></pre></td></tr></table></figure>

<p>或者可以手动指定端口映射，和使用<code>docker run</code>一样，使用<code>--publish</code>或<code>-p</code>选项：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ docker-compose run --publish 8080:80 -p 2022:22 -p 127.0.0.1:2021:21 web python manage.py shell</span><br></pre></td></tr></table></figure>

<p>如果启动一个带有容器连接的服务，<code>run</code>命令将首先检查连接到的服务是否已运行，如果是停止状态，将会启动它，直到所有的相关服务都处于正在运行状态，才会执行你创建的命令。例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ docker-compose run db psql -h db -U docker</span><br></pre></td></tr></table></figure>

<p>这将创建一个与PostgreSQL容器<code>db</code>交互服务。</p>
<p>如果你不希望启动相关联容器，可以使用<code>--no-deps</code>标记：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ docker-compose run --no-deps web python manage.py shell</span><br></pre></td></tr></table></figure>

<h4 id="start"><a href="#start" class="headerlink" title="start"></a>start</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">用法：start [SERVICE...]</span><br></pre></td></tr></table></figure>

<p>启动服务中已经存在的容器。</p>
<h4 id="up"><a href="#up" class="headerlink" title="up"></a>up</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">用法：up [options] [SERVICE...]</span><br><span class="line">选项：</span><br><span class="line">	-d                     分离模式：在后台运行容器，只打印新的容器名称</span><br><span class="line">	--no-color             单色输出</span><br><span class="line">	--no-deps              不启动link连接的服务</span><br><span class="line">	--force-recreate       强制重新创建容器，即使镜像没有任何改变。与--no-recreate会冲突</span><br><span class="line">	--no-recreate          如果对应容器已经存在,不重新创建它。与--force-recreate会冲突</span><br><span class="line">	--no-build             不构建镜像，即使缺失</span><br><span class="line">	-t, --timeout TIMEOUT  为容器设置关闭超时时间，单位：秒 (默认为 10)</span><br></pre></td></tr></table></figure>

<p>对服务，构建镜像、(重新)创建容器、启动容器。</p>
<p>该命令还将启动任何相关的且没有被启动的服务。</p>
<p><code>docker-compose up</code>命令将显示所有容器的输出，命令结束时，所有容器都将关闭。运行<code>docker-compose up -d</code>将在后台启动运行容器。</p>
<p>如果服务中已经存在运行中的容器了，并且在容器创建后更改服务配置或者镜像，<code>docker-compose up</code>命令将会停止当前容器（保存挂载卷）并重新构建启动容器。当然，也可以通过<code>--no-recreate</code>选项来避免重新构建。</p>
<p>使用<code>--force-recreate</code>标记，可以强制停止并重构所有容器。</p>
<h4 id="logs"><a href="#logs" class="headerlink" title="logs"></a>logs</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">用法：logs [options] [SERVICE...]</span><br><span class="line">选项：</span><br><span class="line">	--no-color  单色输出</span><br></pre></td></tr></table></figure>

<p>显示服务输出的日志内容。</p>
<h4 id="port"><a href="#port" class="headerlink" title="port"></a>port</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">用法：port [options] SERVICE PRIVATE_PORT</span><br><span class="line">选项：</span><br><span class="line">	--protocol=proto  tcp 或 udp [默认为 tcp]</span><br><span class="line">	--index=index     对应实例服务的第几个容器[默认为 1]</span><br></pre></td></tr></table></figure>

<p>打印服务中端口绑定对应的主机端口。</p>
<h4 id="pull"><a href="#pull" class="headerlink" title="pull"></a>pull</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">用法：pull [options] [SERVICE...]</span><br><span class="line">选项：</span><br><span class="line">	--ignore-pull-failures 尽可能拉取服务，忽略拉取失败</span><br></pre></td></tr></table></figure>

<p>拉取服务镜像。</p>
<h4 id="rm"><a href="#rm" class="headerlink" title="rm"></a>rm</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">用法：rm [options] [SERVICE...]</span><br><span class="line">选项:</span><br><span class="line">	-f, --force   强制删除，不询问确认信息</span><br><span class="line">	-v            移除容器挂载的卷</span><br></pre></td></tr></table></figure>

<p>删除停止的服务容器。</p>
<h4 id="scale"><a href="#scale" class="headerlink" title="scale"></a>scale</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">用法：scale [SERVICE=NUM...]</span><br></pre></td></tr></table></figure>

<p>设置一个服务需要运行的容器数量。<br>参数形式为<code>service=num</code>。例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ docker-compose scale web=2 worker=3</span><br></pre></td></tr></table></figure>

<h4 id="stop"><a href="#stop" class="headerlink" title="stop"></a>stop</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">用法：stop [options] [SERVICE...]</span><br><span class="line">选项：</span><br><span class="line">	-t, --timeout TIMEOUT      设置关闭容器的超时时间</span><br></pre></td></tr></table></figure>

<p>停止容器而不移除，可以通<code>docker-compose start</code>重新启动。</p>
<h3 id="通过-docker-compose-yml-部署应用"><a href="#通过-docker-compose-yml-部署应用" class="headerlink" title="通过 docker-compose.yml 部署应用"></a>通过 docker-compose.yml 部署应用</h3><p>我将上面所创建的镜像推送到了阿里云，在此使用它</p>
<h4 id="1-新建-docker-compose-yml-文件"><a href="#1-新建-docker-compose-yml-文件" class="headerlink" title="1.新建 docker-compose.yml 文件"></a>1.新建 docker-compose.yml 文件</h4><p>通过以下配置，在运行后可以创建两个站点(只为演示)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">version: &quot;3&quot;</span><br><span class="line">services:</span><br><span class="line">  web1:</span><br><span class="line">    image: registry.cn-hangzhou.aliyuncs.com/yimo_public/docker-nginx-test:latest</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;4466:80&quot;</span><br><span class="line">  web2:</span><br><span class="line">    image: registry.cn-hangzhou.aliyuncs.com/yimo_public/docker-nginx-test:latest</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;4477:80&quot;</span><br></pre></td></tr></table></figure>

<p>此处只是简单演示写法，说明 docker-compose 的方便</p>
<h4 id="2-构建完成，后台运行镜像"><a href="#2-构建完成，后台运行镜像" class="headerlink" title="2.构建完成，后台运行镜像"></a>2.构建完成，后台运行镜像</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker-compose up -d</span><br></pre></td></tr></table></figure>

<p>运行后就可以使用 ip+port 访问这两个站点了</p>
<h4 id="3-镜像更新重新部署"><a href="#3-镜像更新重新部署" class="headerlink" title="3.镜像更新重新部署"></a>3.镜像更新重新部署</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker-compose down</span><br><span class="line">docker-compose pull</span><br><span class="line">docker-compose up -d</span><br></pre></td></tr></table></figure>



<h2 id="详细命名说明"><a href="#详细命名说明" class="headerlink" title="详细命名说明"></a>详细命名说明</h2><h3 id="1、Docker安装"><a href="#1、Docker安装" class="headerlink" title="1、Docker安装"></a>1、Docker安装</h3><p>系统环境：docker最低支持centos7且在64位平台上，内核版本在3.10以上</p>
<p>版本：社区版，企业版（包含了一些收费服务）</p>
<p>官方版安装教程（英文）</p>
<blockquote>
<p><a href="https://docs.docker.com/install/linux/docker-ce/centos/#upgrade-docker-after-using-the-convenience-script" target="_blank" rel="noopener">https://docs.docker.com/install/linux/docker-ce/centos/#upgrade-docker-after-using-the-convenience-script</a></p>
</blockquote>
<p>博主版安装教程：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 安装docker</span><br><span class="line">yum install docker</span><br><span class="line"># 启动docker </span><br><span class="line">systemctl start/status docker </span><br><span class="line"># 查看docker启动状态</span><br><span class="line">docker version</span><br></pre></td></tr></table></figure>

<p><strong>配置加速器</strong></p>
<p>简介：DaoCloud 加速器 是广受欢迎的 Docker 工具，解决了国内用户访问 Docker Hub 缓慢的问题。DaoCloud 加速器结合国内的 CDN 服务与协议层优化，成倍的提升了下载速度。</p>
<p>DaoCloud官网：</p>
<blockquote>
<p><a href="https://www.daocloud.io/mirror#accelerator-doc" target="_blank" rel="noopener">https://www.daocloud.io/mirror#accelerator-doc</a></p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 一条命令加速（记得重启docker）</span><br><span class="line">curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://95822026.m.daocloud.io</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="2、Docker基础命令"><a href="#2、Docker基础命令" class="headerlink" title="2、Docker基础命令"></a>2、Docker基础命令</h3><p>docker –help（中文注解）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Usage:</span><br><span class="line">docker [OPTIONS] COMMAND [arg...]</span><br><span class="line">       docker daemon [ --help | ... ]</span><br><span class="line">       docker [ --help | -v | --version ]</span><br><span class="line">A</span><br><span class="line">self-sufficient runtime for containers.</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  --config=~/.docker              Location of client config files  #客户端配置文件的位置</span><br><span class="line">  -D, --debug=false               Enable debug mode  #启用Debug调试模式</span><br><span class="line">  -H, --host=[]                   Daemon socket(s) to connect to  #守护进程的套接字（Socket）连接</span><br><span class="line">  -h, --help=false                Print usage  #打印使用</span><br><span class="line">  -l, --log-level=info            Set the logging level  #设置日志级别</span><br><span class="line">  --tls=false                     Use TLS; implied by--tlsverify  #</span><br><span class="line">  --tlscacert=~/.docker/ca.pem    Trust certs signed only by this CA  #信任证书签名CA</span><br><span class="line">  --tlscert=~/.docker/cert.pem    Path to TLS certificate file  #TLS证书文件路径</span><br><span class="line">  --tlskey=~/.docker/key.pem      Path to TLS key file  #TLS密钥文件路径</span><br><span class="line">  --tlsverify=false               Use TLS and verify the remote  #使用TLS验证远程</span><br><span class="line">  -v, --version=false             Print version information and quit  #打印版本信息并退出</span><br><span class="line"></span><br><span class="line">Commands:</span><br><span class="line">    attach    Attach to a running container  #当前shell下attach连接指定运行镜像</span><br><span class="line">    build     Build an image from a Dockerfile  #通过Dockerfile定制镜像</span><br><span class="line">    commit    Create a new image from a container&apos;s changes  #提交当前容器为新的镜像</span><br><span class="line">    cp    Copy files/folders from a container to a HOSTDIR or to STDOUT  #从容器中拷贝指定文件或者目录到宿主机中</span><br><span class="line">    create    Create a new container  #创建一个新的容器，同run 但不启动容器</span><br><span class="line">    diff    Inspect changes on a container&apos;s filesystem  #查看docker容器变化</span><br><span class="line">    events    Get real time events from the server#从docker服务获取容器实时事件</span><br><span class="line">    exec    Run a command in a running container#在已存在的容器上运行命令</span><br><span class="line">    export    Export a container&apos;s filesystem as a tar archive  #导出容器的内容流作为一个tar归档文件(对应import)</span><br><span class="line">    history    Show the history of an image  #展示一个镜像形成历史</span><br><span class="line">    images    List images  #列出系统当前镜像</span><br><span class="line">    import    Import the contents from a tarball to create a filesystem image  #从tar包中的内容创建一个新的文件系统映像(对应export)</span><br><span class="line">    info    Display system-wide information  #显示系统相关信息</span><br><span class="line">    inspect    Return low-level information on a container or image  #查看容器详细信息</span><br><span class="line">    kill    Kill a running container  #kill指定docker容器</span><br><span class="line">    load    Load an image from a tar archive or STDIN  #从一个tar包中加载一个镜像(对应save)</span><br><span class="line">    login    Register or log in to a Docker registry#注册或者登陆一个docker源服务器</span><br><span class="line">    logout    Log out from a Docker registry  #从当前Docker registry退出</span><br><span class="line">    logs    Fetch the logs of a container  #输出当前容器日志信息</span><br><span class="line">    pause    Pause all processes within a container#暂停容器</span><br><span class="line">    port    List port mappings or a specific mapping for the CONTAINER  #查看映射端口对应的容器内部源端口</span><br><span class="line">    ps    List containers  #列出容器列表</span><br><span class="line">    pull    Pull an image or a repository from a registry  #从docker镜像源服务器拉取指定镜像或者库镜像</span><br><span class="line">    push    Push an image or a repository to a registry  #推送指定镜像或者库镜像至docker源服务器</span><br><span class="line">    rename    Rename a container  #重命名容器</span><br><span class="line">    restart    Restart a running container  #重启运行的容器</span><br><span class="line">    rm    Remove one or more containers  #移除一个或者多个容器</span><br><span class="line">    rmi    Remove one or more images  #移除一个或多个镜像(无容器使用该镜像才可以删除，否则需要删除相关容器才可以继续或者-f强制删除)</span><br><span class="line">    run    Run a command in a new container  #创建一个新的容器并运行一个命令</span><br><span class="line">    save    Save an image(s) to a tar archive#保存一个镜像为一个tar包(对应load)</span><br><span class="line">    search    Search the Docker Hub for images  #在docker</span><br><span class="line">hub中搜索镜像</span><br><span class="line">    start    Start one or more stopped containers#启动容器</span><br><span class="line">    stats    Display a live stream of container(s) resource usage statistics  #统计容器使用资源</span><br><span class="line">    stop    Stop a running container  #停止容器</span><br><span class="line">    tag         Tag an image into a repository  #给源中镜像打标签</span><br><span class="line">    top       Display the running processes of a container #查看容器中运行的进程信息</span><br><span class="line">    unpause    Unpause all processes within a container  #取消暂停容器</span><br><span class="line">    version    Show the Docker version information#查看容器版本号</span><br><span class="line">    wait         Block until a container stops, then print its exit code  #截取容器停止时的退出状态值</span><br><span class="line"></span><br><span class="line">Run &apos;docker COMMAND --help&apos; for more information on a command.  #运行docker命令在帮助可以获取更多信息</span><br><span class="line">docker search  hello-docker  # 搜索hello-docker的镜像</span><br><span class="line">docker search centos # 搜索centos镜像</span><br><span class="line">docker pull hello-docker # 获取centos镜像</span><br><span class="line">docker run  hello-world   #运行一个docker镜像，产生一个容器实例（也可以通过镜像id前三位运行）</span><br><span class="line">docker image ls  # 查看本地所有镜像</span><br><span class="line">docker images  # 查看docker镜像</span><br><span class="line">docker image rmi hello-docker # 删除centos镜像</span><br><span class="line">docker ps  #列出正在运行的容器（如果创建容器中没有进程正在运行，容器就会立即停止）</span><br><span class="line">docker ps -a  # 列出所有运行过的容器记录</span><br><span class="line">docker save centos &gt; /opt/centos.tar.gz  # 导出docker镜像至本地</span><br><span class="line">docker load &lt; /opt/centos.tar.gz   #导入本地镜像到docker镜像库</span><br><span class="line">docker stop  `docker ps -aq`  # 停止所有正在运行的容器</span><br><span class="line">docker  rm `docker ps -aq`    # 一次性删除所有容器记录</span><br><span class="line">docker rmi  `docker images -aq`   # 一次性删除所有本地的镜像记录</span><br></pre></td></tr></table></figure>

<h4 id="2-1-启动容器的两种方式"><a href="#2-1-启动容器的两种方式" class="headerlink" title="2.1 启动容器的两种方式"></a>2.1 启动容器的两种方式</h4><p>容器是运行应用程序的，所以必须得先有一个操作系统为基础</p>
<p>1、基于镜像新建一个容器并启动</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 1. 后台运行一个docker</span><br><span class="line">docker run -d centos /bin/sh -c &quot;while true;do echo 正在运行; sleep 1;done&quot;</span><br><span class="line">    # -d  后台运行容器</span><br><span class="line">    # /bin/sh  指定使用centos的bash解释器</span><br><span class="line">    # -c 运行一段shell命令</span><br><span class="line">    # &quot;while true;do echo 正在运行; sleep 1;done&quot;  在linux后台，每秒中打印一次正在运行</span><br><span class="line">docker ps  # 检查容器进程</span><br><span class="line">docker  logs  -f  容器id/名称  # 不间断打印容器的日志信息 </span><br><span class="line">docker stop centos  # 停止容器</span><br><span class="line"></span><br><span class="line"># 2. 启动一个bash终端,允许用户进行交互</span><br><span class="line">docker run --name mydocker -it centos /bin/bash  </span><br><span class="line">    # --name  给容器定义一个名称</span><br><span class="line">    # -i  让容器的标准输入保持打开</span><br><span class="line">    # -t 让Docker分配一个伪终端,并绑定到容器的标准输入上</span><br><span class="line">    # /bin/bash 指定docker容器，用shell解释器交互</span><br></pre></td></tr></table></figure>

<p>当利用docker run来创建容器时，Docker在后台运行的步骤如下：</p>
<blockquote>
<ol>
<li>检查本地是否存在指定的镜像，不存在就从公有仓库下载</li>
<li>利用镜像创建并启动一个容器</li>
<li>分配一个文件系统，并在只读的镜像层外面挂在一层可读写层</li>
<li>从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去</li>
<li>从地址池配置一个ip地址给容器</li>
<li>执行用户指定的应用程序</li>
<li>执行完毕后容器被终止</li>
</ol>
</blockquote>
<p>2、将一个终止状态(stopped)的容器重新启动</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# docker ps -a  # 先查询记录</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                        PORTS                    NAMES</span><br><span class="line">ee92fcf6f32d        centos              &quot;/bin/bash&quot;              4 days ago          Exited (137) 3 days ago                                kickass_raman</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# docker start ee9  # 再启动这个容器</span><br><span class="line">ee9</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# docker exec -it  ee9 /bin/bash  # 进入容器交互式界面</span><br><span class="line">[root@ee92fcf6f32d /]#   # 注意看用户名，已经变成容器用户名</span><br></pre></td></tr></table></figure>

<h4 id="2-2-提交创建自定义镜像"><a href="#2-2-提交创建自定义镜像" class="headerlink" title="2.2 提交创建自定义镜像"></a>2.2 提交创建自定义镜像</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 1.我们进入交互式的centos容器中，发现没有vim命令</span><br><span class="line">    docker run -it centos</span><br><span class="line"># 2.在当前容器中，安装一个vim</span><br><span class="line">    yum install -y vim</span><br><span class="line"># 3.安装好vim之后，exit退出容器</span><br><span class="line">    exit</span><br><span class="line"># 4.查看刚才安装好vim的容器记录</span><br><span class="line">    docker container ls -a</span><br><span class="line"># 5.提交这个容器，创建新的image</span><br><span class="line">    docker commit 059fdea031ba chaoyu/centos-vim</span><br><span class="line"># 6.查看镜像文件</span><br><span class="line">    docker images</span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">chaoyu/centos-vim   latest              fd2685ae25fe        5 minutes ago</span><br></pre></td></tr></table></figure>

<h4 id="2-3-外部访问容器"><a href="#2-3-外部访问容器" class="headerlink" title="2.3 外部访问容器"></a>2.3 外部访问容器</h4><p>容器中可以运行网络应用，但是要让外部也可以访问这些应用，可以通过-p或-P参数指定端口映射。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -d -P training/webapp python app.py</span><br><span class="line">  # -P 参数会随机映射端口到容器开放的网络端口</span><br><span class="line"></span><br><span class="line"># 检查映射的端口</span><br><span class="line">docker ps -l</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED            STATUS              PORTS                     NAMES</span><br><span class="line">cfd632821d7a        training/webapp     &quot;python app.py&quot;     21 seconds ago      Up 20 seconds       0.0.0.0:32768-&gt;5000/tcp   brave_fermi</span><br><span class="line">#宿主机ip:32768 映射容器的5000端口</span><br><span class="line"></span><br><span class="line"># 查看容器日志信息</span><br><span class="line">docker logs -f cfd  # #不间断显示log</span><br><span class="line"></span><br><span class="line"># 也可以通过-p参数指定映射端口</span><br><span class="line">docker run -d -p 9000:5000 training/webapp python app.py</span><br></pre></td></tr></table></figure>

<p>打开浏览器访问服务器的9000端口， 内容显示 Hello world！表示正常启动</p>
<p>(如果访问失败的话，检查自己的防火墙，以及云服务器的安全组)</p>
<hr>
<h3 id="3、利用dockerfile定制镜像"><a href="#3、利用dockerfile定制镜像" class="headerlink" title="3、利用dockerfile定制镜像"></a>3、利用dockerfile定制镜像</h3><p>镜像是容器的基础，每次执行docker run的时候都会指定哪个镜像作为容器运行的基础。我们之前的例子都是使用来自docker hub的镜像，直接使用这些镜像只能满足一定的需求，当镜像无法满足我们的需求时，就得自定制这些镜像。</p>
<blockquote>
<p>镜像的定制就是定制每一层所添加的配置、文件。如果可以吧每一层修改、安装、构建、操作的命令都写入到一个脚本，用脚本来构建、定制镜像，这个脚本就是dockerfile。</p>
<p>Dockerfile 是一个文本文件，其内包含了一条条的指令(Instruction)，每一条指令 构建一层，因此每一条指令的内容，就是描述该层应当如何构建。</p>
</blockquote>
<p>参数详解</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM scratch #制作base image 基础镜像，尽量使用官方的image作为base image</span><br><span class="line">FROM centos #使用base image</span><br><span class="line">FROM ubuntu:14.04 #带有tag的base image</span><br><span class="line"></span><br><span class="line">LABEL version=“1.0” #容器元信息，帮助信息，Metadata，类似于代码注释</span><br><span class="line">LABEL maintainer=“yc_uuu@163.com&quot;</span><br><span class="line"></span><br><span class="line">#对于复杂的RUN命令，避免无用的分层，多条命令用反斜线换行，合成一条命令！</span><br><span class="line">RUN yum update &amp;&amp; yum install -y vim </span><br><span class="line">    Python-dev #反斜线换行</span><br><span class="line">RUN /bin/bash -c &quot;source $HOME/.bashrc;echo $HOME”</span><br><span class="line"></span><br><span class="line">WORKDIR /root #相当于linux的cd命令，改变目录，尽量使用绝对路径！！！不要用RUN cd</span><br><span class="line">WORKDIR /test # 如果没有就自动创建</span><br><span class="line">WORKDIR demo # 再进入demo文件夹</span><br><span class="line">RUN pwd     # 打印结果应该是/test/demo</span><br><span class="line"></span><br><span class="line">ADD and COPY </span><br><span class="line">ADD hello /  # 把本地文件添加到镜像中，吧本地的hello可执行文件拷贝到镜像的/目录</span><br><span class="line">ADD test.tar.gz /  # 添加到根目录并解压</span><br><span class="line"></span><br><span class="line">WORKDIR /root</span><br><span class="line">ADD hello test/  # 进入/root/ 添加hello可执行命令到test目录下，也就是/root/test/hello 一个绝对路径</span><br><span class="line">COPY hello test/  # 等同于上述ADD效果</span><br><span class="line"></span><br><span class="line">ADD与COPY</span><br><span class="line">   - 优先使用COPY命令</span><br><span class="line">    -ADD除了COPY功能还有解压功能</span><br><span class="line">添加远程文件/目录使用curl或wget</span><br><span class="line"></span><br><span class="line">ENV # 环境变量，尽可能使用ENV增加可维护性</span><br><span class="line">ENV MYSQL_VERSION 5.6 # 设置一个mysql常量</span><br><span class="line">RUN yum install -y mysql-server=“$&#123;MYSQL_VERSION&#125;”</span><br></pre></td></tr></table></figure>

<p>进阶知识(了解)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">VOLUME and EXPOSE </span><br><span class="line">存储和网络</span><br><span class="line"></span><br><span class="line">RUN and CMD and ENTRYPOINT</span><br><span class="line">RUN：执行命令并创建新的Image Layer</span><br><span class="line">CMD：设置容器启动后默认执行的命令和参数</span><br><span class="line">ENTRYPOINT：设置容器启动时运行的命令</span><br><span class="line"></span><br><span class="line">Shell格式和Exec格式</span><br><span class="line">RUN yum install -y vim</span><br><span class="line">CMD echo ”hello docker”</span><br><span class="line">ENTRYPOINT echo “hello docker”</span><br><span class="line"></span><br><span class="line">Exec格式</span><br><span class="line">RUN [“apt-get”,”install”,”-y”,”vim”]</span><br><span class="line">CMD [“/bin/echo”,”hello docker”]</span><br><span class="line">ENTRYPOINT [“/bin/echo”,”hello docker”]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">通过shell格式去运行命令，会读取$name指令，而exec格式是仅仅的执行一个命令，而不是shell指令</span><br><span class="line">cat Dockerfile</span><br><span class="line">    FROM centos</span><br><span class="line">    ENV name Docker</span><br><span class="line">    ENTRYPOINT [“/bin/echo”,”hello $name”]#这个仅仅是执行echo命令，读取不了shell变量</span><br><span class="line">    ENTRYPOINT  [“/bin/bash”,”-c”,”echo hello $name&quot;]</span><br><span class="line"></span><br><span class="line">CMD</span><br><span class="line">容器启动时默认执行的命令</span><br><span class="line">如果docker run指定了其他命令(docker run -it [image] /bin/bash )，CMD命令被忽略</span><br><span class="line">如果定义多个CMD，只有最后一个执行</span><br><span class="line"></span><br><span class="line">ENTRYPOINT</span><br><span class="line">让容器以应用程序或服务形式运行</span><br><span class="line">不会被忽略，一定会执行</span><br><span class="line">最佳实践：写一个shell脚本作为entrypoint</span><br><span class="line">COPY docker-entrypoint.sh /usr/local/bin</span><br><span class="line">ENTRYPOINT [“docker-entrypoint.sh]</span><br><span class="line">EXPOSE 27017</span><br><span class="line">CMD [“mongod”]</span><br><span class="line"></span><br><span class="line">[root@master home]# more Dockerfile</span><br><span class="line">FROm centos</span><br><span class="line">ENV name Docker</span><br><span class="line">#CMD [&quot;/bin/bash&quot;,&quot;-c&quot;,&quot;echo hello $name&quot;]</span><br><span class="line">ENTRYPOINT [&quot;/bin/bash&quot;,&quot;-c&quot;,&quot;echo hello $name”]</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="4、发布到仓库"><a href="#4、发布到仓库" class="headerlink" title="4、发布到仓库"></a>4、发布到仓库</h3><h4 id="4-1-docker-hub共有镜像发布"><a href="#4-1-docker-hub共有镜像发布" class="headerlink" title="4.1 docker hub共有镜像发布"></a>4.1 docker hub共有镜像发布</h4><p>docker提供了一个类似于github的仓库docker hub，官方网站（需注册使用）</p>
<blockquote>
<p><a href="https://hub.docker.com/" target="_blank" rel="noopener">https://hub.docker.com/</a></p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 注册docker id后，在linux中登录dockerhub</span><br><span class="line">    docker login</span><br><span class="line"></span><br><span class="line"># 注意要保证image的tag是账户名，如果镜像名字不对，需要改一下tag</span><br><span class="line">    docker tag chaoyu/centos-vim peng104/centos-vim</span><br><span class="line">    # 语法是：docker tag   仓库名   peng104/仓库名</span><br><span class="line"></span><br><span class="line"># 推送docker image到dockerhub</span><br><span class="line">    docker push peng104/centps-cmd-exec:latest</span><br><span class="line"></span><br><span class="line"># 去dockerhub中检查镜像</span><br><span class="line"># 先删除本地镜像，然后再测试下载pull 镜像文件</span><br><span class="line">    docker pull peng104/centos-entrypoint-exec</span><br></pre></td></tr></table></figure>

<h4 id="4-2-私有仓库"><a href="#4-2-私有仓库" class="headerlink" title="4.2 私有仓库"></a>4.2 私有仓库</h4><p>docker hub 是公开的，其他人也是可以下载，并不安全，因此还可以使用docker registry官方提供的私有仓库</p>
<p>用法详解：</p>
<blockquote>
<p><a href="https://yeasy.gitbooks.io/docker_practice/repository/registry.html" target="_blank" rel="noopener">https://yeasy.gitbooks.io/docker_practice/repository/registry.html</a></p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 1.下载一个docker官方私有仓库镜像</span><br><span class="line">    docker pull registry</span><br><span class="line"># 2.运行一个docker私有容器仓库</span><br><span class="line">docker run -d -p 5000:5000 -v /opt/data/registry:/var/lib/registry  registry</span><br><span class="line">    -d 后台运行 </span><br><span class="line">    -p  端口映射 宿主机的5000:容器内的5000</span><br><span class="line">    -v  数据卷挂载  宿主机的 /opt/data/registry :/var/lib/registry </span><br><span class="line">    registry  镜像名</span><br><span class="line">    /var/lib/registry  存放私有仓库位置</span><br><span class="line"># Docker 默认不允许非 HTTPS 方式推送镜像。我们可以通过 Docker 的配置选项来取消这个限制</span><br><span class="line"># 3.修改docker的配置文件，让他支持http方式，上传私有镜像</span><br><span class="line">    vim /etc/docker/daemon.json </span><br><span class="line">    # 写入如下内容</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;registry-mirrors&quot;: [&quot;http://f1361db2.m.daocloud.io&quot;],</span><br><span class="line">        &quot;insecure-registries&quot;:[&quot;192.168.11.37:5000&quot;]</span><br><span class="line">    &#125;</span><br><span class="line"># 4.修改docker的服务配置文件</span><br><span class="line">    vim /lib/systemd/system/docker.service</span><br><span class="line"># 找到[service]这一代码区域块，写入如下参数</span><br><span class="line">    [Service]</span><br><span class="line">    EnvironmentFile=-/etc/docker/daemon.json</span><br><span class="line"># 5.重新加载docker服务</span><br><span class="line">    systemctl daemon-reload</span><br><span class="line"># 6.重启docker服务</span><br><span class="line">    systemctl restart docker</span><br><span class="line">    # 注意:重启docker服务，所有的容器都会挂掉</span><br><span class="line"></span><br><span class="line"># 7.修改本地镜像的tag标记，往自己的私有仓库推送</span><br><span class="line">    docker tag docker.io/peng104/hello-world-docker 192.168.11.37:5000/peng-hello</span><br><span class="line">    # 浏览器访问http://192.168.119.10:5000/v2/_catalog查看仓库</span><br><span class="line"># 8.下载私有仓库的镜像</span><br><span class="line">    docker pull 192.168.11.37:5000/peng-hello</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="5、实例演示"><a href="#5、实例演示" class="headerlink" title="5、实例演示"></a>5、实例演示</h3><p>编写dockerfile，构建自己的镜像，运行flask程序。</p>
<p>确保app.py和dockerfile在同一个目录！</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 1.准备好app.py的flask程序</span><br><span class="line">    [root@localhost ~]# cat app.py</span><br><span class="line">    from flask import Flask</span><br><span class="line">    app=Flask(__name__)</span><br><span class="line">    @app.route(&apos;/&apos;)</span><br><span class="line">    def hello():</span><br><span class="line">        return &quot;hello docker&quot;</span><br><span class="line">    if __name__==&quot;__main__&quot;:</span><br><span class="line">        app.run(host=&apos;0.0.0.0&apos;,port=8080)</span><br><span class="line">    [root@master home]# ls</span><br><span class="line">    app.py  Dockerfile</span><br><span class="line"></span><br><span class="line"># 2.编写dockerfile</span><br><span class="line">    [root@localhost ~]# cat Dockerfile</span><br><span class="line">    FROM python:2.7</span><br><span class="line">    LABEL maintainer=&quot;温而新&quot;</span><br><span class="line">    RUN pip install flask</span><br><span class="line">    COPY app.py /app/</span><br><span class="line">    WORKDIR /app</span><br><span class="line">    EXPOSE 8080</span><br><span class="line">    CMD [&quot;python&quot;,&quot;app.py&quot;]</span><br><span class="line"></span><br><span class="line"># 3.构建镜像image,找到当前目录的Dockerfile，开始构建</span><br><span class="line">    docker build -t peng104/flask-hello-docker .</span><br><span class="line"></span><br><span class="line"># 4.查看创建好的images</span><br><span class="line">    docker image ls</span><br><span class="line"></span><br><span class="line"># 5.启动此flask-hello-docker容器，映射一个端口供外部访问</span><br><span class="line">    docker run -d -p 8080:8080 peng104/flask-hello-docker</span><br><span class="line"></span><br><span class="line"># 6.检查运行的容器</span><br><span class="line">    docker container ls</span><br><span class="line"></span><br><span class="line"># 7.推送这个镜像到私有仓库</span><br><span class="line">    docker tag  peng104/flask-hello-docker   192.168.11.37:5000/peng-flaskweb</span><br><span class="line">    docker push 192.168.11.37:5000/peng-flaskweb</span><br></pre></td></tr></table></figure>



<h2 id="补充一些用法"><a href="#补充一些用法" class="headerlink" title="补充一些用法"></a>补充一些用法</h2><h3 id="挂载宿主机目录"><a href="#挂载宿主机目录" class="headerlink" title="挂载宿主机目录"></a>挂载宿主机目录</h3><p>docker可以支持把一个宿主机上的目录挂载到镜像里。</p>
<p><code>docker run -it -v /home/dock/Downloads:/usr/Downloads ubuntu64 /bin/bash</code><br>通过-v参数，冒号前为宿主机目录，必须为绝对路径，冒号后为镜像内挂载的路径。</p>
<p>现在镜像内就可以共享宿主机里的文件了。</p>
<p>默认挂载的路径权限为读写。如果指定为只读可以用：ro<br><code>docker run -it -v /home/dock/Downloads:/usr/Downloads:ro ubuntu64 /bin/bash</code></p>
<p>docker还提供了一种高级的用法。叫数据卷。</p>
<p>数据卷：“其实就是一个正常的容器，专门用来提供数据卷供其它容器挂载的”。感觉像是由一个容器定义的一个数据挂载信息。其他的容器启动可以直接挂载数据卷容器中定义的挂载信息。</p>
<p>看示例：<br><code>docker run -v /home/dock/Downloads:/usr/Downloads --name dataVol ubuntu64 /bin/bash</code><br>创建一个普通的容器。用–name给他指定了一个名（不指定的话会生成一个随机的名子）。</p>
<p>再创建一个新的容器，来使用这个数据卷。<br><code>docker run -it --volumes-from dataVol ubuntu64 /bin/bash --volumes-from用来指定要从哪个数据卷来挂载数据。</code></p>
<p>生成的docker镜像保存下来：docker save -o test.tar test:1.0<br> 导入docker镜像：docker load -i test.tar</p>
<h3 id="Docker容器内外互相拷贝数据"><a href="#Docker容器内外互相拷贝数据" class="headerlink" title="Docker容器内外互相拷贝数据"></a>Docker容器内外互相拷贝数据</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">从容器内拷贝文件到主机上</span><br><span class="line">docker cp &lt;containerId&gt;:/file/path/within/container /host/path/target </span><br><span class="line"></span><br><span class="line">从主机上拷贝文件到容器内</span><br><span class="line">参考自：</span><br><span class="line">http://stackoverflow.com/questions/22907231/copying-files-from-host-to-docker-container</span><br><span class="line">1.用-v挂载主机数据卷到容器内</span><br><span class="line">docker run -v /path/to/hostdir:/mnt $container</span><br><span class="line">在容器内拷贝</span><br><span class="line">cp /mnt/sourcefile /path/to/destfile</span><br><span class="line">2.直接在主机上拷贝到容器物理存储系统</span><br><span class="line">A. 获取容器名称或者id :</span><br><span class="line">$ docker ps</span><br><span class="line">B. 获取整个容器的id</span><br><span class="line">$ docker inspect -f   &apos;&#123;&#123;.Id&#125;&#125;&apos;  步骤A获取的名称或者id</span><br><span class="line">C. 在主机上拷贝文件:</span><br><span class="line">$ sudo cp path-file-host /var/lib/docker/aufs/mnt/FULL_CONTAINER_ID/PATH-NEW-FILE </span><br><span class="line">或者</span><br><span class="line">$ sudo cp path-file-host /var/lib/docker/devicemapper/mnt/123abc&lt;&lt;id&gt;&gt;/rootfs/root</span><br><span class="line"></span><br><span class="line">例子：</span><br><span class="line">$ docker ps</span><br><span class="line">CONTAINER ID      IMAGE    COMMAND       CREATED      STATUS       PORTS        NAMES</span><br><span class="line">d8e703d7e303   solidleon/ssh:latest      /usr/sbin/sshd -D                      cranky_pare</span><br><span class="line"></span><br><span class="line">$ docker inspect -f   &apos;&#123;&#123;.Id&#125;&#125;&apos; cranky_pare</span><br><span class="line">or </span><br><span class="line">$ docker inspect -f   &apos;&#123;&#123;.Id&#125;&#125;&apos; d8e703d7e303</span><br><span class="line">d8e703d7e3039a6df6d01bd7fb58d1882e592a85059eb16c4b83cf91847f88e5</span><br><span class="line"></span><br><span class="line">$ sudo cp file.txt /var/lib/docker/aufs/mnt/**d8e703d7e3039a6df6d01bd7fb58d1882e592a85059eb16c4b83cf91847f88e5</span><br><span class="line"></span><br><span class="line">3.用输入输出符</span><br><span class="line">docker run -i ubuntu /bin/bash -c &apos;cat &gt; /path/to/container/file&apos; &lt; /path/to/host/file/</span><br><span class="line"></span><br><span class="line">或者</span><br><span class="line"></span><br><span class="line">docker exec -it &lt;container_id&gt; bash -c &apos;cat &gt; /path/to/container/file&apos; &lt; /path/to/host/file/</span><br></pre></td></tr></table></figure>

<p><strong>总结一下</strong></p>
<blockquote>
<p>从主机复制到容器<code>sudo docker cp host_path containerID:container_path</code></p>
<p>从容器复制到主机<code>sudo docker cp containerID:container_path host_path</code></p>
<p>容器ID的查询方法想必大家都清楚:<code>docker ps -a</code></p>
</blockquote>
<h3 id="docker-运行容器时为容器起别名"><a href="#docker-运行容器时为容器起别名" class="headerlink" title="docker 运行容器时为容器起别名"></a>docker 运行容器时为容器起别名</h3><blockquote>
<p>docker run –name=mydemo -p  -d 2222:80 imagename</p>
<p>–name: 指定容器名称</p>
<p>-p:指定容器端口号</p>
<p>-d:指定容器后台运行</p>
</blockquote>
<h3 id="docker一些有用的清理命令"><a href="#docker一些有用的清理命令" class="headerlink" title="docker一些有用的清理命令"></a>docker一些有用的清理命令</h3><p>以下命令参考自这篇<a href="http://blog.loof.fr/2016/05/docker-cleanup.html#" target="_blank" rel="noopener">文章</a>：</p>
<p>（1）清除已经终止的<code>container</code>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker rm -v $(docker ps --filter status=exited -q)</span><br></pre></td></tr></table></figure>

<p>（2）清除已经没用的<code>volume</code>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker volume rm $(docker volume ls -q -f &apos;dangling=true&apos;)</span><br></pre></td></tr></table></figure>

<p>（3）清除已经没用的<code>image</code>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker rmi $(docker images -f &quot;dangling=true&quot; -q)</span><br></pre></td></tr></table></figure>

<p>（4）清除所有的<code>container</code>（包括正在运行的和已经退出的）：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker rm -f $(docker ps -a | awk &apos;NR &gt; 1 &#123;print $1&#125;&apos;)</span><br></pre></td></tr></table></figure>



<h3 id="在docker-container中执行命令的脚本"><a href="#在docker-container中执行命令的脚本" class="headerlink" title="在docker container中执行命令的脚本"></a>在docker container中执行命令的脚本</h3><p>下面脚本的功能是循环地在各个<code>container</code>中执行命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/bash -x</span><br><span class="line"></span><br><span class="line">for i in &#123;1..2&#125;</span><br><span class="line">do</span><br><span class="line">        docker exec -i hammerdb_net$&#123;i&#125; bash &lt;&lt;-EOF</span><br><span class="line">        su oracle</span><br><span class="line">        source /tmp/ora_env</span><br><span class="line">        cd /data/oracle/tablespaces/</span><br><span class="line">        rm -f *.html</span><br><span class="line">        ./create_awr.sh</span><br><span class="line">        mv awr.html awr_$&#123;i&#125;.html</span><br><span class="line">        EOF</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<p>需要注意的是在<code>do</code>和<code>done</code>之间应该使用<code>tab</code>而不是空格。</p>
]]></content>
      <categories>
        <category>持续集成</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo静态页面图片无法显示的解决方案</title>
    <url>/2019/10/05/Hexo%E9%9D%99%E6%80%81%E9%A1%B5%E9%9D%A2%E5%9B%BE%E7%89%87%E6%97%A0%E6%B3%95%E6%98%BE%E7%A4%BA%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url>
    <content><![CDATA[<p>首先我们需要安装一个图片路径转换的插件，这个插件名字是hexo-asset-image</p><blockquote>
<p>npm install hexo-asset-image –save</p>
</blockquote><p>打开_config.yml文件，修改下述内容</p><blockquote>
<p>post_asset_folder: true</p>
</blockquote><p><strong>注：如以下方法不能解决图片显示问题</strong></p><p>请按下以修改文件：</p><a id="more"></a>





<p>打开/node_modules/hexo-asset-image/index.js，将内容更换为下面的代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&apos;use strict&apos;;</span><br><span class="line">var cheerio = require(&apos;cheerio&apos;);</span><br><span class="line"></span><br><span class="line">// http://stackoverflow.com/questions/14480345/how-to-get-the-nth-occurrence-in-a-string</span><br><span class="line">function getPosition(str, m, i) &#123;</span><br><span class="line">  return str.split(m, i).join(m).length;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">hexo.extend.filter.register(&apos;after_post_render&apos;, function(data)&#123;</span><br><span class="line">  var config = hexo.config;</span><br><span class="line">  if(config.post_asset_folder)&#123;</span><br><span class="line">    var link = data.permalink;</span><br><span class="line">    var beginPos = getPosition(link, &apos;/&apos;, 3) + 1;</span><br><span class="line">    // In hexo 3.1.1, the permalink of &quot;about&quot; page is like &quot;.../about/index.html&quot;.</span><br><span class="line">    var endPos = link.lastIndexOf(&apos;/&apos;) + 1;</span><br><span class="line">    link = link.substring(beginPos, endPos);</span><br><span class="line"></span><br><span class="line">    var toprocess = [&apos;excerpt&apos;, &apos;more&apos;, &apos;content&apos;];</span><br><span class="line">    for(var i = 0; i &lt; toprocess.length; i++)&#123;</span><br><span class="line">      var key = toprocess[i];</span><br><span class="line"></span><br><span class="line">      var $ = cheerio.load(data[key], &#123;</span><br><span class="line">        ignoreWhitespace: false,</span><br><span class="line">        xmlMode: false,</span><br><span class="line">        lowerCaseTags: false,</span><br><span class="line">        decodeEntities: false</span><br><span class="line">      &#125;);</span><br><span class="line"></span><br><span class="line">      $(&apos;img&apos;).each(function()&#123;</span><br><span class="line">        if ($(this).attr(&apos;src&apos;))&#123;</span><br><span class="line">            // For windows style path, we replace &apos;\&apos; to &apos;/&apos;.</span><br><span class="line">            var src = $(this).attr(&apos;src&apos;).replace(&apos;\\&apos;, &apos;/&apos;);</span><br><span class="line">            if(!/http[s]*.*|\/\/.*/.test(src) &amp;&amp;</span><br><span class="line">               !/^\s*\//.test(src)) &#123;</span><br><span class="line">              // For &quot;about&quot; page, the first part of &quot;src&quot; can&apos;t be removed.</span><br><span class="line">              // In addition, to support multi-level local directory.</span><br><span class="line">              var linkArray = link.split(&apos;/&apos;).filter(function(elem)&#123;</span><br><span class="line">                return elem != &apos;&apos;;</span><br><span class="line">              &#125;);</span><br><span class="line">              var srcArray = src.split(&apos;/&apos;).filter(function(elem)&#123;</span><br><span class="line">                return elem != &apos;&apos; &amp;&amp; elem != &apos;.&apos;;</span><br><span class="line">              &#125;);</span><br><span class="line">              if(srcArray.length &gt; 1)</span><br><span class="line">                srcArray.shift();</span><br><span class="line">              src = srcArray.join(&apos;/&apos;);</span><br><span class="line">              $(this).attr(&apos;src&apos;, config.root + link + src);</span><br><span class="line">              console.info&amp;&amp;console.info(&quot;update link as:--&gt;&quot;+config.root + link + src);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;else&#123;</span><br><span class="line">            console.info&amp;&amp;console.info(&quot;no src attr, skipped...&quot;);</span><br><span class="line">            console.info&amp;&amp;console.info($(this));</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;);</span><br><span class="line">      data[key] = $.html();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>博客</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>最简便的方法基于Next主题搭建Hexo+Github博客</title>
    <url>/2019/10/01/%E6%9C%80%E7%AE%80%E4%BE%BF%E7%9A%84%E6%96%B9%E6%B3%95%E5%9F%BA%E4%BA%8ENext%E4%B8%BB%E9%A2%98%E6%90%AD%E5%BB%BAHexo+Github%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Hexo，反正我第一眼看到就喜欢上了它的简约，<a href="http://geoffen.github.io/">感受一下吧</a>。<br>如果你喜欢写作，我觉得你可以试试gitbook或者跟着本文搭建一个属于自己的博客空间（即使你不是IT行业的一员），不再受限于第三方博客地址，当然Hexo搭建的博客也是基于github托管的，但是并不需要你购买域名。<br>经过两天的探索加爬坑，终于把博客在git上安家了，感谢开源的大哥大姐们，由于并非js开发，所以遇到了很多坑，于是也想整理一篇比较完整的博客。</p>
<p>ps:我选择的主题是<a href="https://github.com/iissnan/hexo-theme-next" target="_blank" rel="noopener">Next</a></p>
<a id="more"></a>

<h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><h3 id="安装Node-js"><a href="#安装Node-js" class="headerlink" title="安装Node.js"></a>安装Node.js</h3><p><a href="https://nodejs.org/download/" target="_blank" rel="noopener">下载Node.js</a><br>参考地址：<a href="http://www.w3cschool.cc/nodejs/nodejs-install-setup.html" target="_blank" rel="noopener">安装Node.js</a></p>
<h3 id="安装Git"><a href="#安装Git" class="headerlink" title="安装Git"></a>安装Git</h3><p>下载地址：<a href="http://git-scm.com/download/" target="_blank" rel="noopener">http://git-scm.com/download/</a></p>
<h3 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cd d:/hexo</span><br><span class="line">$ npm install hexo-cli -g</span><br><span class="line">$ hexo init blog</span><br><span class="line">$ cd blog</span><br><span class="line">$ npm install</span><br><span class="line">$ hexo g # 或者hexo generate</span><br><span class="line">$ hexo s # 或者hexo server，可以在http://localhost:4000/ 查看</span><br></pre></td></tr></table></figure>

<p>这里有必要提下Hexo常用的几个命令：</p>
<ol>
<li>hexo generate (hexo g) 生成静态文件，会在当前目录下生成一个新的叫做public的文件夹</li>
<li>hexo server (hexo s) 启动本地web服务，用于博客的预览</li>
<li>hexo deploy (hexo d) 部署播客到远端（比如github, heroku等平台）</li>
</ol>
<p>另外还有其他几个常用命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ hexo new &quot;postName&quot; #新建文章</span><br><span class="line">$ hexo new page &quot;pageName&quot; #新建页面</span><br></pre></td></tr></table></figure>

<p>常用简写</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ hexo n == hexo new</span><br><span class="line">$ hexo g == hexo generate</span><br><span class="line">$ hexo s == hexo server</span><br><span class="line">$ hexo d == hexo deploy</span><br></pre></td></tr></table></figure>

<p>常用组合</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ hexo d -g #生成部署</span><br><span class="line">$ hexo s -g #生成预览</span><br></pre></td></tr></table></figure>

<p>现在我们打开<a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000/</a> 已经可以看到一篇内置的blog了。</p>
<h3 id="Hexo主题设置"><a href="#Hexo主题设置" class="headerlink" title="Hexo主题设置"></a>Hexo主题设置</h3><p>这里以主题yilia为例进行说明。</p>
<h4 id="安装主题"><a href="#安装主题" class="headerlink" title="安装主题"></a>安装主题</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ hexo clean</span><br><span class="line">$ git clone https://github.com/litten/hexo-theme-yilia.git themes/yilia</span><br></pre></td></tr></table></figure>

<h4 id="启用主题"><a href="#启用主题" class="headerlink" title="启用主题"></a>启用主题</h4><p>修改Hexo目录下的_config.yml配置文件中的theme属性，将其设置为yilia。</p>
<h4 id="更新主题"><a href="#更新主题" class="headerlink" title="更新主题"></a>更新主题</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cd themes/yilia</span><br><span class="line">$ git pull</span><br><span class="line">$ hexo g # 生成</span><br><span class="line">$ hexo s # 启动本地web服务器</span><br></pre></td></tr></table></figure>

<p>现在打开<a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000/</a> ，会看到我们已经应用了一个新的主题。</p>
<h3 id="hexo部署"><a href="#hexo部署" class="headerlink" title="hexo部署"></a>hexo部署</h3><h4 id="使用hexo-deploy部署"><a href="#使用hexo-deploy部署" class="headerlink" title="使用hexo deploy部署"></a>使用hexo deploy部署</h4><p>hexo deploy可以部署到很多平台，具体可以<a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">参考这个链接</a>. 如果部署到github，需要在配置文件_config.xml中作如下修改：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repo: git@github.com:geoffen/geoffen.github.io.git</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure>

<p>然后在命令行中执行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo d</span><br></pre></td></tr></table></figure>

<p>即可完成部署。</p>
<p>注意需要提前安装一个扩展：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>

<h3 id="使用git命令行部署"><a href="#使用git命令行部署" class="headerlink" title="使用git命令行部署"></a>使用git命令行部署</h3><p>不幸的是，上述命令虽然简单方便，但是偶尔会有莫名其妙的问题出现，因此，我们也可以追本溯源，使用git命令来完成部署的工作。</p>
<h4 id="clone-github-repo"><a href="#clone-github-repo" class="headerlink" title="clone github repo"></a>clone github repo</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cd d:/hexo/blog</span><br><span class="line"></span><br><span class="line">$ git clone https://github.com/geoffen/geoffen.github.io.git .deploy/geoffen.github.io</span><br></pre></td></tr></table></figure>

<p>将我们之前创建的repo克隆到本地，新建一个目录叫做.deploy用于存放克隆的代码。</p>
<h4 id="创建一个deploy脚本文件"><a href="#创建一个deploy脚本文件" class="headerlink" title="创建一个deploy脚本文件"></a>创建一个deploy脚本文件</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo generate</span><br><span class="line">cp -R public/* .deploy/geoffen.github.io</span><br><span class="line">cd .deploy/geoffen.github.io</span><br><span class="line">git add .</span><br><span class="line">git commit -m “update”</span><br><span class="line">git push origin master</span><br></pre></td></tr></table></figure>

<p>简单解释一下，hexo generate生成public文件夹下的新内容，然后将其拷贝至geoffen.github.io的git目录下，然后使用git commit命令提交代码到geoffen.github.io这个repo的master branch上。</p>
<p>需要部署的时候，执行这段脚本就可以了（比如可以将其保存为deploy.sh）。执行过程中可能需要让你输入Github账户的用户名及密码，按照提示操作即可。</p>
<h3 id="添加插件"><a href="#添加插件" class="headerlink" title="添加插件"></a>添加插件</h3><p>添加sitemap和feed插件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ npm install hexo-generator-feed</span><br><span class="line">$ npm install hexo-generator-sitemap</span><br></pre></td></tr></table></figure>

<p>修改_config.yml，增加以下内容</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Extensions</span><br><span class="line">Plugins:</span><br><span class="line">- hexo-generator-feed</span><br><span class="line">- hexo-generator-sitemap</span><br><span class="line"></span><br><span class="line">#Feed Atom</span><br><span class="line">feed:</span><br><span class="line">  type: atom</span><br><span class="line">  path: atom.xml</span><br><span class="line">  limit: 20</span><br><span class="line"></span><br><span class="line">#sitemap</span><br><span class="line">sitemap:</span><br><span class="line">  path: sitemap.xml</span><br></pre></td></tr></table></figure>

<p>配完之后，就可以访问<code>http://geoffen.github.io/atom.xml</code>和<code>http://geoffen.github.io/sitemap.xml</code>，发现这两个文件已经成功生成了。</p>
<h3 id="添加404公益"><a href="#添加404公益" class="headerlink" title="添加404公益"></a>添加404公益</h3><p>GitHub Pages有提供制作404页面的指引：<a href="https://help.github.com/articles/custom-404-pages" target="_blank" rel="noopener">Custom 404 Pages</a>。</p>
<p>直接在根目录下创建自己的404.html或者404.md就可以。但是自定义404页面仅对绑定顶级域名的项目才起作用，GitHub默认分配的二级域名是不起作用的，使用hexo server在本机调试也是不起作用的。</p>
<p>推荐使用<a href="http://www.qq.com/404/" target="_blank" rel="noopener">腾讯公益404</a>。</p>
<h3 id="添加about页面"><a href="#添加about页面" class="headerlink" title="添加about页面"></a>添加about页面</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ hexo new page &quot;about&quot;</span><br></pre></td></tr></table></figure>

<p>之后在sourceaboutindex.md目录下会生成一个index.md文件，打开输入个人信息即可，如果想要添加版权信息，可以在文件末尾添加：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;div style=&quot;font-size:12px;border-bottom: #ddd 1px solid; BORDER-LEFT: #ddd 1px solid; BACKGROUND: #f6f6f6; HEIGHT: 120px; BORDER-TOP: #ddd 1px solid; BORDER-RIGHT: #ddd 1px solid&quot;&gt;</span><br><span class="line">&lt;div style=&quot;MARGIN-TOP: 10px; FLOAT: left; MARGIN-LEFT: 5px; MARGIN-RIGHT: 10px&quot;&gt;</span><br><span class="line">&lt;IMG alt=&quot;&quot; src=&quot;https://avatars1.githubusercontent.com/u/168751?v=3&amp;s=140&quot; width=90 height=100&gt;</span><br><span class="line">&lt;/div&gt;</span><br><span class="line">&lt;div style=&quot;LINE-HEIGHT: 200%; MARGIN-TOP: 10px; COLOR: #000000&quot;&gt;</span><br><span class="line">本文链接：&lt;a href=&quot;&lt;%= post.link %&gt;&quot;&gt;&lt;%= post.title %&gt;&lt;/a&gt; &lt;br/&gt;</span><br><span class="line">作者： </span><br><span class="line">&lt;a href=&quot;http://geoffen.github.io/&quot;&gt;令狐葱&lt;/a&gt; &lt;br/&gt;出处： </span><br><span class="line">&lt;a href=&quot;http://geoffen.github.io/&quot;&gt;http://geoffen.github.io/&lt;/a&gt;</span><br><span class="line">&lt;br/&gt;本文基于&lt;a target=&quot;_blank&quot; title=&quot;Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt; 知识共享署名-相同方式共享 4.0 &lt;/a&gt;</span><br><span class="line">国际许可协议发布，欢迎转载，演绎或用于商业目的，但是必须保留本文的署名 </span><br><span class="line">&lt;a href=&quot;http://geoffen.github.io/&quot;&gt;令狐葱&lt;/a&gt;及链接。</span><br><span class="line">&lt;/div&gt;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure>



<h3 id="添加Fork-me-on-Github"><a href="#添加Fork-me-on-Github" class="headerlink" title="添加Fork me on Github"></a>添加Fork me on Github</h3><p><a href="https://github.com/blog/273-github-ribbons" target="_blank" rel="noopener">获取代码</a>，选择你喜欢的代码添加到hexo/themes/yilia/layout/layout.ejs的末尾即可，注意要将代码里的you改成你的Github账号名。</p>
<h3 id="添加支付宝捐赠按钮及二维码支付"><a href="#添加支付宝捐赠按钮及二维码支付" class="headerlink" title="添加支付宝捐赠按钮及二维码支付"></a>添加支付宝捐赠按钮及二维码支付</h3><p>支付宝捐赠按钮在D:/hexo/themes/yilia/layout_widget目录下新建一个zhifubao.ejs文件，内容如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;p class=&quot;asidetitle&quot;&gt;打赏他&lt;/p&gt;</span><br><span class="line">&lt;div&gt;</span><br><span class="line">&lt;form action=&quot;https://shenghuo.alipay.com/send/payment/fill.htm&quot; method=&quot;POST&quot; target=&quot;_blank&quot; accept-charset=&quot;GBK&quot;&gt;</span><br><span class="line">    &lt;br/&gt;</span><br><span class="line">    &lt;input name=&quot;optEmail&quot; type=&quot;hidden&quot; value=&quot;your 支付宝账号&quot; /&gt;</span><br><span class="line">    &lt;input name=&quot;payAmount&quot; type=&quot;hidden&quot; value=&quot;默认捐赠金额(元)&quot; /&gt;</span><br><span class="line">    &lt;input id=&quot;title&quot; name=&quot;title&quot; type=&quot;hidden&quot; value=&quot;博主，打赏你的！&quot; /&gt;</span><br><span class="line">    &lt;input name=&quot;memo&quot; type=&quot;hidden&quot; value=&quot;你Y加油，继续写博客！&quot; /&gt;</span><br><span class="line">    &lt;input name=&quot;pay&quot; type=&quot;image&quot; value=&quot;转账&quot; src=&quot;http://7xig3q.com1.z0.glb.clouddn.com/alipay-donate-website.png&quot; /&gt;</span><br><span class="line">&lt;/form&gt;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure>

<p>添加完该文件之后，要在D:/hexo/themes/yilia/_config.yml文件中启用，如下所示，添加zhifubao</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">widgets:</span><br><span class="line">- category</span><br><span class="line">- tag</span><br><span class="line">- links</span><br><span class="line">- tagcloud</span><br><span class="line">- zhifubao</span><br><span class="line">- rss</span><br></pre></td></tr></table></figure>

<p>或者</p>
<p>很简单，打开主题配置文件_config.yml<br>添加字段：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">reward_comment: 坚持原创技术分享，您的支持将鼓励我继续创作！</span><br><span class="line">alipay: http://ww3.sinaimg.cn/small/937882b5jw1f4dalzfc5nj20p00vu0um.jpg</span><br></pre></td></tr></table></figure>

<p><code>alipay:</code> 填写的是支付宝或者微信的收款二维码图片地址。</p>
<h2 id="生成部署三部曲"><a href="#生成部署三部曲" class="headerlink" title="生成部署三部曲"></a>生成部署三部曲</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo clean #清空缓存</span><br><span class="line">hexo g #生成静态网页</span><br><span class="line">hexo d #部署到github</span><br></pre></td></tr></table></figure>



<h2 id="主题优化"><a href="#主题优化" class="headerlink" title="主题优化"></a>主题优化</h2><p><a href="http://chaserr.github.io/" target="_blank" rel="noopener">样式预览</a></p>
<h3 id="Next主题的安装使用"><a href="#Next主题的安装使用" class="headerlink" title="Next主题的安装使用"></a>Next主题的安装使用</h3><p>首先从github上clone到本地，在终端cd / 切换到你通过Hexo init生成的根目录，<br>然后在终端输入命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ git clone https://github.com/iissnan/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure>

<p>进入站点的全局配置文件：_config.yml<br>找到theme字段：设置为</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">theme: next</span><br></pre></td></tr></table></figure>

<p>到这里可以验证一下主题是否被启用。终端输入：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo s -- debug</span><br></pre></td></tr></table></figure>

<p>然后本地访问<a href="http://localhost:4000%EF%BC%8C%E7%9C%8B%E7%9C%8B%E6%95%88%E6%9E%9C%EF%BC%8C%E5%9C%A8%E6%B2%A1%E6%9C%89%E9%83%A8%E7%BD%B2%E5%88%B0github%E4%B8%8A%E4%B9%8B%E5%89%8D%EF%BC%8C%E4%B8%80%E8%88%AC%E9%83%BD%E5%8F%AF%E4%BB%A5%E8%BF%99%E6%A0%B7%E5%9C%A8%E6%9C%AC%E5%9C%B0%E8%BF%9B%E8%A1%8C%E9%A2%84%E8%A7%88%E3%80%82/" target="_blank" rel="noopener">http://localhost:4000，看看效果，在没有部署到github上之前，一般都可以这样在本地进行预览。</a></p>
<p>关于站点全局_config.yml配置文件的其他一些参数：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Site</span><br><span class="line">title: 朝夕 #博客名</span><br><span class="line">subtitle: 朝闻道，夕死可以。 #博客副标题</span><br><span class="line">description: #给搜索引擎看的，对站点的描述，可以自定义</span><br><span class="line">author: 童星 #作者名称，显示在网站最底部</span><br><span class="line">language: zh-Hans #语言选择，这里表示中文</span><br><span class="line">email: #你的联系邮箱</span><br><span class="line">timezone:</span><br><span class="line"></span><br><span class="line"># URL</span><br><span class="line">## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;</span><br><span class="line">url: chaserr.github.io  #可以填写你的站点域名</span><br><span class="line">root: /</span><br><span class="line">permalink: :year/:month/:day/:title/</span><br><span class="line">permalink_defaults:</span><br><span class="line"></span><br><span class="line"># Directory</span><br><span class="line">source_dir: source</span><br><span class="line">public_dir: public</span><br><span class="line">tag_dir: tags</span><br><span class="line">archive_dir: archives</span><br><span class="line">category_dir: categories</span><br><span class="line">code_dir: downloads/code</span><br><span class="line">i18n_dir: :lang</span><br><span class="line">skip_render:</span><br><span class="line"></span><br><span class="line"># Writing , 设置生成博文的默认格式</span><br><span class="line">new_post_name: :title.md # File name of new posts</span><br><span class="line">default_layout: post #默认布局</span><br><span class="line">titlecase: false # Transform title into titlecase</span><br><span class="line">external_link: true # Open external links in new tab</span><br><span class="line">filename_case: 0 #把文件名称转换为（1）小写或者大写</span><br><span class="line">render_drafts: #显示草稿</span><br><span class="line">post_asset_folder: false  #启动Asset文件夹</span><br><span class="line">relative_link: false #把链接改为与根目录相对位置</span><br><span class="line">future: true #显示未来的文章</span><br><span class="line">highlight: #代码块的设置</span><br><span class="line">  enable: true</span><br><span class="line">  line_number: true</span><br><span class="line">  auto_detect: false</span><br><span class="line">  tab_replace:</span><br></pre></td></tr></table></figure>

<p>默认的大致就这些，另外给主题添加相关功能的时候后面会慢慢加上其他一些参数。</p>
<h4 id="给站点添加rss和sitemap功能"><a href="#给站点添加rss和sitemap功能" class="headerlink" title="给站点添加rss和sitemap功能"></a>给站点添加rss和sitemap功能</h4><p>打开终端，切换到站点根目录，输入：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ npm install hexo-generator-feed</span><br><span class="line">$ npm install hexo-generator-sitemap</span><br></pre></td></tr></table></figure>

<p>在全局配置文件_config.yml进行插件配置：（为防止好找，在最下面进行配置）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#插件配置</span><br><span class="line">plugins: hexo-generator-feed </span><br><span class="line">#- hexo-generator-sitemap </span><br><span class="line"></span><br><span class="line">feed:</span><br><span class="line">  type: atom ##feed类型 atom或者rss2</span><br><span class="line">  path: atom.xml ##feed路径</span><br><span class="line">  limit: 20  ##feed文章最小数量</span><br></pre></td></tr></table></figure>

<h4 id="给站点添加本地搜索功能"><a href="#给站点添加本地搜索功能" class="headerlink" title="给站点添加本地搜索功能"></a>给站点添加本地搜索功能</h4><ul>
<li>使用swiftype添加站内搜索</li>
</ul>
<p>去swiftype官网注册一个账号，按照步骤选择自己喜欢的搜索样式，配置完成后，选择install，然后会出现<a href="http://7xuupy.com1.z0.glb.clouddn.com/Snip20160531_10.png" target="_blank" rel="noopener"><img src="http://7xuupy.com1.z0.glb.clouddn.com/Snip20160531_10.png" alt="Snip20160531_10"></a><br>如图所示，我不知道为什么，这个代码框无法滚动，所以我们必须将它全部复制出来</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;script type=&quot;text/javascript&quot;&gt;</span><br><span class="line">  (function(w,d,t,u,n,s,e)&#123;w[&apos;SwiftypeObject&apos;]=n;w[n]=w[n]||function()&#123;</span><br><span class="line">  (w[n].q=w[n].q||[]).push(arguments);&#125;;s=d.createElement(t);</span><br><span class="line">  e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);</span><br><span class="line">  &#125;)(window,document,&apos;script&apos;,&apos;//s.swiftypecdn.com/install/v2/st.js&apos;,&apos;_st&apos;);</span><br><span class="line">  </span><br><span class="line">  _st(&apos;install&apos;,&apos;7Qoo1zkKbfSsp5bzUjQu&apos;,&apos;2.0.0&apos;);</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure>

<p>然后复制install —-2.0.0之间的一段代码，添加到全局配置文件里：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 搜索插件 hexo-generator-sitemap</span><br><span class="line">swiftype_key: 7Qoo1zkKbfSsp5bzUjQu</span><br></pre></td></tr></table></figure>

<ul>
<li>添加本地搜索</li>
</ul>
<p>直接在全局配置文件添加参数：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">search:</span><br><span class="line">  path: search.xml</span><br><span class="line">  field: post</span><br></pre></td></tr></table></figure>

<p>search.xml这些都是默认带有的</p>
<h4 id="给站点添加友情链接功能"><a href="#给站点添加友情链接功能" class="headerlink" title="给站点添加友情链接功能"></a>给站点添加友情链接功能</h4><p>直接在全局配置文件添加参数：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">links_title: 友情链接</span><br><span class="line">links:</span><br><span class="line">	#百度: http://www.baidu.com/</span><br><span class="line">	#新浪: http://example.com/</span><br></pre></td></tr></table></figure>

<p>其实也可以新建一个文件专门放置这些需要链接的网站，这样方便管理，不必每次都对全局配置文件进行更改</p>
<blockquote>
<p>如果没有链接，那么友情链接不会显示，为了测试，可以随便写一个</p>
</blockquote>
<h4 id="给站点添加多说评论、热评、分享功能"><a href="#给站点添加多说评论、热评、分享功能" class="headerlink" title="给站点添加多说评论、热评、分享功能"></a>给站点添加多说评论、热评、分享功能</h4><p>直接在全局配置文件添加参数：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Disqus  disqus评论,  与多说类似, 国内一般使用多说</span><br><span class="line">#disqus_shortname: </span><br><span class="line">duoshuo_shortname: chaser</span><br><span class="line"></span><br><span class="line"># 多说热评文章 true 或者 false</span><br><span class="line">duoshuo_hotartical: true</span><br><span class="line"></span><br><span class="line"># 多说分享服务</span><br><span class="line">duoshuo_share: true</span><br><span class="line">duoshuo_info:</span><br><span class="line">  ua_enable: true</span><br><span class="line">  admin_enable: false</span><br><span class="line">  user_id:</span><br><span class="line">	  admin_nickname:</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>注意：</strong>这里的<code>duoshuo_shortname</code>是需要你去多说主页 – <a href="http://duoshuo.com/" target="_blank" rel="noopener">传送门</a> 注册一个账号，然后填写你的多说域名，这里填写的就是你在多说填写的域名<br>例如：我的是：<code>http://chaser.duoshuo.com/</code>，那么我填写的就是<code>chaser</code></p>
<ul>
<li>这里配置的是所有页面都支持评论，但是后面有的页面不需要，比如标签页，分类页，关于等等，那么就单独设置。</li>
</ul>
</blockquote>
<h3 id="Next主题的优化"><a href="#Next主题的优化" class="headerlink" title="Next主题的优化"></a>Next主题的优化</h3><p>这之前，先对主题配置文件进行一些配置，打开博客根目录/themes/next，这个路径，然后打开，主题配置文件_config.yml：</p>
<h4 id="配置个人头像"><a href="#配置个人头像" class="headerlink" title="配置个人头像"></a>配置个人头像</h4><p>在主题配置文件里找到avatar字段，(如果没有就添加)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Sidebar Avatar</span><br><span class="line"># in theme directory(source/images): /images/avatar.jpg</span><br><span class="line"># in site  directory(source/uploads): /uploads/avatar.jpg</span><br><span class="line">avatar: http://ww4.sinaimg.cn/small/937882b5jw1f4db4lroy9j20hs0npmy6.jpg</span><br></pre></td></tr></table></figure>

<blockquote>
<p>我采用的是地址，并没有将图片放在本地（采用新浪博客相册）</p>
</blockquote>
<h4 id="Next主题选择"><a href="#Next主题选择" class="headerlink" title="Next主题选择"></a>Next主题选择</h4><p>在主题配置文件_config.yml里，找到scheme字段</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># ---------------------------------------------------------------</span><br><span class="line"># Scheme Settings</span><br><span class="line"># ---------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"># Schemes</span><br><span class="line">#scheme: Muse</span><br><span class="line">#scheme: Mist</span><br><span class="line">scheme: Pisces</span><br></pre></td></tr></table></figure>

<ul>
<li><p>Muse - 默认 Scheme，这是 NexT 最初的版本，黑白主调，大量留白</p>
</li>
<li><p>Mist - Muse 的紧凑版本，整洁有序的单栏外观</p>
</li>
<li><p>Pisces - 双栏 Scheme，小家碧玉似的清新</p>
<p>我选择的是第三种，去掉</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#</span><br></pre></td></tr></table></figure>

<p>，然后把第一个前面加上</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#</span><br></pre></td></tr></table></figure>

<blockquote>
<p>每进行一步都可以自己去进行预览：</p>
<p>hexo s –debug</p>
</blockquote>
</li>
</ul>
<h4 id="Next主题菜单配置"><a href="#Next主题菜单配置" class="headerlink" title="Next主题菜单配置"></a>Next主题菜单配置</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># ---------------------------------------------------------------</span><br><span class="line"># Menu Settings</span><br><span class="line"># ---------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"># When running the site in a subdirectory (e.g. domain.tld/blog), remove the leading slash (/archives -&gt; archives)</span><br><span class="line">menu:</span><br><span class="line">  home: / #主页</span><br><span class="line">  categories: /categories #分类页面</span><br><span class="line">  about: /about #关于</span><br><span class="line">  archives: /archives #归档</span><br><span class="line">  tags: /tags #标签</span><br><span class="line">  commonweal: /404.html  #公益404</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Enable/Disable menu icons.</span><br><span class="line"># Icon Mapping:</span><br><span class="line">#   Map a menu item to a specific FontAwesome icon name.</span><br><span class="line">#   Key is the name of menu item and value is the name of FontAwsome icon. Key is case-senstive.</span><br><span class="line">#   When an question mask icon presenting up means that the item has no mapping icon.</span><br><span class="line">menu_icons:</span><br><span class="line">  enable: true #是否显示图标</span><br><span class="line">  #KeyMapsToMenuItemKey: NameOfTheIconFromFontAwesome</span><br><span class="line">  home: home</span><br><span class="line">  about: user</span><br><span class="line">  categories: th</span><br><span class="line">  tags: tags</span><br><span class="line">  archives: archive</span><br><span class="line">  commonweal: heartbeat</span><br></pre></td></tr></table></figure>

<blockquote>
<ol>
<li>如果需要添加你自己自定义的菜单，那么就只需要在menu下添加相关的菜单项，然后新建页面与之匹配，然后去next主题目录的<code>languages</code>目录下找到我们之前配置的主题所使用的语言，（我们用的是<code>zh-Hans</code>）对其进行国际化。</li>
<li>menu_icon的设置采用<code>key-value</code>。key对应上面的menu里面的菜单项，大小写一致，value就是对应<a href="http://www.bootcss.com/p/font-awesome/#icons-web-app" target="_blank" rel="noopener">FontAwsome icon</a>这个网站的图标的名字，去掉前缀icon</li>
</ol>
<p>关于这里的所有的图标都支持从<code>FontAwsome icon</code>这个网站获取，当然也可以自己放在资源文件夹里（一般比如个人头像(<code>avatar</code>)，网站图标(<code>favicon</code>)等)。<br>当然也支持从网址获取，推荐使用<code>七牛</code>云存储。当然也可以使用新浪博客的相册，谷歌相册，甚至QQ空间，都可以，只要能获取到图片网址，并且你不会轻易删掉。</p>
</blockquote>
<h5 id="添加关于，标签，分类，公益404页面"><a href="#添加关于，标签，分类，公益404页面" class="headerlink" title="添加关于，标签，分类，公益404页面"></a>添加关于，标签，分类，公益404页面</h5><p>菜单配置好了，但是我们还得新建一些页面与之相匹配，否则点击进去找不到。这里说一下，对于<code>标签页</code>和<code>分类页</code>，我们需要在新建一篇文章的时候指定它的标签和分类。对于刚开始建立的博客，点进去可能是空的，所以等会新建一篇文章试试，这之前，先建立相关页面。</p>
<h6 id="添加标签页"><a href="#添加标签页" class="headerlink" title="添加标签页"></a>添加标签页</h6><p>打开终端，进入博客根站点，输入：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo new page tags</span><br></pre></td></tr></table></figure>

<p>进入博客根目录/source路径，找到tags文件夹，可以看到生成了index.md文件。可以使用编辑器打开<br>在里面添加<code>tags</code>和<code>comments</code><br><a href="http://7xuupy.com1.z0.glb.clouddn.com/Snip20160601_11.png" target="_blank" rel="noopener"><img src="http://7xuupy.com1.z0.glb.clouddn.com/Snip20160601_11.png" alt="Snip20160531_11"></a></p>
<blockquote>
<ol>
<li><code>tags</code>设置页面的类型</li>
<li><code>comments</code>用来控制是否显示评论。</li>
</ol>
</blockquote>
<h6 id="添加分类页"><a href="#添加分类页" class="headerlink" title="添加分类页"></a>添加分类页</h6><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo new page categories</span><br></pre></td></tr></table></figure>

<p>进入博客根目录/source路径，找到categories文件夹，可以看到生成了index.md文件。可以使用编辑器打开<br>在里面添加<code>tags</code>和<code>comments</code><br><a href="http://7xuupy.com1.z0.glb.clouddn.com/Snip20160601_11.png" target="_blank" rel="noopener"><img src="http://7xuupy.com1.z0.glb.clouddn.com/Snip20160601_11.png" alt="Snip20160531_11"></a></p>
<blockquote>
<ol>
<li><code>tags</code>设置页面的类型</li>
<li><code>comments</code>用来控制是否显示评论。</li>
</ol>
</blockquote>
<h6 id="添加关于页"><a href="#添加关于页" class="headerlink" title="添加关于页"></a>添加关于页</h6><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo new page about</span><br></pre></td></tr></table></figure>

<p>进入博客根目录/source路径，找到categories文件夹，可以看到生成了index.md文件。可以使用编辑器打开<br>在里面添加<code>tags</code>和<code>comments</code><br><a href="http://7xuupy.com1.z0.glb.clouddn.com/Snip20160601_11.png" target="_blank" rel="noopener"><img src="http://7xuupy.com1.z0.glb.clouddn.com/Snip20160601_11.png" alt="Snip20160531_11"></a></p>
<blockquote>
<ol>
<li><code>tags</code>设置页面的类型</li>
<li><code>comments</code>用来控制是否显示评论。</li>
</ol>
</blockquote>
<p>about这个页面一般都是填写一些你的个人信息，要不要无所谓，我这里给about页面添加了一个背景音乐盒.去网易云音乐，创建一个自己的歌单，然后分享，然后找到自己分享的动态，点击链接，<a href="http://7xuupy.com1.z0.glb.clouddn.com/Snip20160601_12.png" target="_blank" rel="noopener"><img src="http://7xuupy.com1.z0.glb.clouddn.com/Snip20160601_12.png" alt="Snip20160531_12"></a><br>出现如图的页面，然后点击生成’’外链播放器’’字样。将出现的代码复制，粘贴到你的about页面<br><a href="http://7xuupy.com1.z0.glb.clouddn.com/Snip20160601_13.png" target="_blank" rel="noopener"><img src="http://7xuupy.com1.z0.glb.clouddn.com/Snip20160601_13.png" alt="Snip20160531_13"></a></p>
<p>新建一篇文章给它添加分类和标签试试吧：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo new &quot;Hexo教程&quot;</span><br></pre></td></tr></table></figure>

<p>通过mou编辑器打开：添加<code>tags</code>和<code>categories</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: title #文章標題</span><br><span class="line">date: 2016-06-01 23:47:44 #文章生成時間</span><br><span class="line">categories: &quot;Hexo教程&quot; #文章分類目錄 可以省略</span><br><span class="line">tags: #文章標籤 可以省略</span><br><span class="line">	 - 标签1</span><br><span class="line">	 - 标签2</span><br><span class="line"> description: #你對本頁的描述 可以省略</span><br><span class="line">---</span><br></pre></td></tr></table></figure>

<h6 id="添加公益404页面"><a href="#添加公益404页面" class="headerlink" title="添加公益404页面"></a>添加公益404页面</h6><p>直接在根目录的source路径下，新建一个404.html文件，就可以了<br>附：404.html</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;!DOCTYPE HTML&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">  &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html;charset=utf-8;&quot;/&gt;</span><br><span class="line">  &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge,chrome=1&quot; /&gt;</span><br><span class="line">  &lt;meta name=&quot;robots&quot; content=&quot;all&quot; /&gt;</span><br><span class="line">  &lt;meta name=&quot;robots&quot; content=&quot;index,follow&quot;/&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line"></span><br><span class="line">&lt;script type=&quot;text/javascript&quot; src=&quot;http://www.qq.com/404/search_children.js&quot;</span><br><span class="line">        charset=&quot;utf-8&quot; homePageUrl=&quot;your site url &quot;</span><br><span class="line">        homePageName=&quot;回到我的主页&quot;&gt;</span><br><span class="line">&lt;/script&gt;</span><br><span class="line"></span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>提示：<code>homePageUrl</code>记得修改成你的博客域名</p>
</blockquote>
<h3 id="Next主题侧边栏社交链接"><a href="#Next主题侧边栏社交链接" class="headerlink" title="Next主题侧边栏社交链接"></a>Next主题侧边栏社交链接</h3><p>打开主题配置文件_config.yml：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># ---------------------------------------------------------------</span><br><span class="line"># Sidebar Settings</span><br><span class="line"># ---------------------------------------------------------------</span><br><span class="line"># Social Links</span><br><span class="line">social:</span><br><span class="line">	GitHub: https://github.com/chaserr</span><br><span class="line">	新浪微博: http://weibo.com/lovaxiang</span><br><span class="line">	FaceBook: https://www.facebook.com/x.tongxing</span><br><span class="line">	GooglePlus : https://plus.google.com/u/0/117848542581702766384</span><br><span class="line">	豆瓣: https://www.douban.com/people/lovax/</span><br><span class="line"></span><br><span class="line"># Social Links Icons</span><br><span class="line">social_icons:</span><br><span class="line"> enable: true #控制是否显示图标</span><br><span class="line">  # Icon Mappings.</span><br><span class="line">  # KeyMapsToSocalItemKey: NameOfTheIconFromFontAwesome</span><br><span class="line">  GitHub: github</span><br><span class="line">  新浪微博: weibo</span><br><span class="line">  FaceBook: facebook</span><br><span class="line">  GooglePlus: google-plus</span><br><span class="line">  豆瓣: globe  #douban</span><br></pre></td></tr></table></figure>

<blockquote>
<p>这里的配置和Menu里一样，</p>
<ol>
<li><code>social</code>后面跟着的是你的社交网站的主页地址</li>
<li><code>social_icons</code>是FontAwesome网站的图标名称</li>
</ol>
<p>不过豆瓣icon好像是没有的，我在github上issue过，他们给我的解决方案就是去官网找到图标，放到本地资源、。、<br>所以亲们也不用去issue了。直接用别的代替吧，如果真想显示你的豆瓣的话。</p>
</blockquote>
<h3 id="开启打赏功能"><a href="#开启打赏功能" class="headerlink" title="开启打赏功能"></a>开启打赏功能</h3><p>很简单，打开主题配置文件_config.yml<br>添加字段：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">reward_comment: 坚持原创技术分享，您的支持将鼓励我继续创作！</span><br><span class="line">alipay: http://ww3.sinaimg.cn/small/937882b5jw1f4dalzfc5nj20p00vu0um.jpg</span><br></pre></td></tr></table></figure>

<blockquote>
<p><code>alipay:</code> 填写的是支付宝或者微信的收款二维码图片地址。</p>
</blockquote>
<h3 id="给文章添加阅读量"><a href="#给文章添加阅读量" class="headerlink" title="给文章添加阅读量"></a>给文章添加阅读量</h3><h4 id="配置LeanCloud"><a href="#配置LeanCloud" class="headerlink" title="配置LeanCloud"></a>配置LeanCloud</h4><p>打开<a href="https://leancloud.cn/login.html#/signin" target="_blank" rel="noopener">LeanCloud</a>官网，注册一个账号，完成激活<br><a href="http://7xuupy.com1.z0.glb.clouddn.com/Snip20160601_14.png" target="_blank" rel="noopener"><img src="http://7xuupy.com1.z0.glb.clouddn.com/Snip20160601_14.png" alt="Snip20160531_14"></a><br>点击创建新应用之后，进入新创建的应用<br><a href="http://7xuupy.com1.z0.glb.clouddn.com/Snip20160601_15.png" target="_blank" rel="noopener"><img src="http://7xuupy.com1.z0.glb.clouddn.com/Snip20160601_15.png" alt="Snip20160531_15"></a><br>点击创建Class，类名叫做<code>Counter</code>。</p>
<h4 id="修改主题配置文件-config-yml"><a href="#修改主题配置文件-config-yml" class="headerlink" title="修改主题配置文件_config.yml"></a>修改主题配置文件_config.yml</h4><p>打开主题配置文件，找到<code>leancloud_visitors</code>字段或者创建</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Show number of visitors to each article.</span><br><span class="line"># You can visit https://leancloud.cn get AppID and AppKey.</span><br><span class="line">leancloud_visitors:</span><br><span class="line">  enable: true</span><br><span class="line">  app_id: ytnok33cvEchgidigtb0WumC-gzGzoHsz #&lt;AppID&gt;</span><br><span class="line">  app_key: SrcG8cy1VhONurWBoEBGGHML #&lt;AppKEY&gt;</span><br></pre></td></tr></table></figure>

<blockquote>
<ol>
<li><code>app_id</code></li>
<li><code>app_key</code><br><a href="http://7xuupy.com1.z0.glb.clouddn.com/Snip20160601_18.png" target="_blank" rel="noopener"><img src="http://7xuupy.com1.z0.glb.clouddn.com/Snip20160601_18.png" alt="Snip20160531_18"></a></li>
</ol>
<p>将对应key的value复制填写即可。</p>
</blockquote>
<h4 id="添加lean-analytics-swing"><a href="#添加lean-analytics-swing" class="headerlink" title="添加lean-analytics.swing"></a>添加lean-analytics.swing</h4><p>在主题目录下的\layout_scripts路径下，新建名为：<code>lean-analytics.swing</code>的文件，<br>这里贴上<code>lean-analytics.swing</code>代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;% if theme.leancloud_visitors.enable %&#125;</span><br><span class="line"></span><br><span class="line">  &#123;# custom analytics part create by xiamo #&#125;</span><br><span class="line">  &lt;script src=&quot;https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js&quot;&gt;&lt;/script&gt;</span><br><span class="line">  &lt;script&gt;AV.initialize(&quot;&#123;&#123;theme.leancloud_visitors.app_id&#125;&#125;&quot;, &quot;&#123;&#123;theme.leancloud_visitors.app_key&#125;&#125;&quot;);&lt;/script&gt;</span><br><span class="line">  &lt;script&gt;</span><br><span class="line">    function showTime(Counter) &#123;</span><br><span class="line">      var query = new AV.Query(Counter);</span><br><span class="line">      var entries = [];</span><br><span class="line">      var $visitors = $(&quot;.leancloud_visitors&quot;);</span><br><span class="line"></span><br><span class="line">      $visitors.each(function () &#123;</span><br><span class="line">        entries.push( $(this).attr(&quot;id&quot;).trim() );</span><br><span class="line">      &#125;);</span><br><span class="line"></span><br><span class="line">      query.containedIn(&apos;url&apos;, entries);</span><br><span class="line">      query.find()</span><br><span class="line">        .done(function (results) &#123;</span><br><span class="line">          var COUNT_CONTAINER_REF = &apos;.leancloud-visitors-count&apos;;</span><br><span class="line"></span><br><span class="line">          if (results.length === 0) &#123;</span><br><span class="line">            $visitors.find(COUNT_CONTAINER_REF).text(0);</span><br><span class="line">            return;</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">          for (var i = 0; i &lt; results.length; i++) &#123;</span><br><span class="line">            var item = results[i];</span><br><span class="line">            var url = item.get(&apos;url&apos;);</span><br><span class="line">            var time = item.get(&apos;time&apos;);</span><br><span class="line">            var element = document.getElementById(url);</span><br><span class="line"></span><br><span class="line">            $(element).find(COUNT_CONTAINER_REF).text(time);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">        .fail(function (object, error) &#123;</span><br><span class="line">          console.log(&quot;Error: &quot; + error.code + &quot; &quot; + error.message);</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    function addCount(Counter) &#123;</span><br><span class="line">      var $visitors = $(&quot;.leancloud_visitors&quot;);</span><br><span class="line">      var url = $visitors.attr(&apos;id&apos;).trim();</span><br><span class="line">      var title = $visitors.attr(&apos;data-flag-title&apos;).trim();</span><br><span class="line">      var query = new AV.Query(Counter);</span><br><span class="line"></span><br><span class="line">      query.equalTo(&quot;url&quot;, url);</span><br><span class="line">      query.find(&#123;</span><br><span class="line">        success: function(results) &#123;</span><br><span class="line">          if (results.length &gt; 0) &#123;</span><br><span class="line">            var counter = results[0];</span><br><span class="line">            counter.fetchWhenSave(true);</span><br><span class="line">            counter.increment(&quot;time&quot;);</span><br><span class="line">            counter.save(null, &#123;</span><br><span class="line">              success: function(counter) &#123;</span><br><span class="line">                var $element = $(document.getElementById(url));</span><br><span class="line">                $element.find(&apos;.leancloud-visitors-count&apos;).text(counter.get(&apos;time&apos;));</span><br><span class="line">              &#125;,</span><br><span class="line">              error: function(counter, error) &#123;</span><br><span class="line">                console.log(&apos;Failed to save Visitor num, with error message: &apos; + error.message);</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">          &#125; else &#123;</span><br><span class="line">            var newcounter = new Counter();</span><br><span class="line">            /* Set ACL */</span><br><span class="line">            var acl = new AV.ACL();</span><br><span class="line">            acl.setPublicReadAccess(true);</span><br><span class="line">            acl.setPublicWriteAccess(true);</span><br><span class="line">            newcounter.setACL(acl);</span><br><span class="line">            /* End Set ACL */</span><br><span class="line">            newcounter.set(&quot;title&quot;, title);</span><br><span class="line">            newcounter.set(&quot;url&quot;, url);</span><br><span class="line">            newcounter.set(&quot;time&quot;, 1);</span><br><span class="line">            newcounter.save(null, &#123;</span><br><span class="line">              success: function(newcounter) &#123;</span><br><span class="line">                var $element = $(document.getElementById(url));</span><br><span class="line">                $element.find(&apos;.leancloud-visitors-count&apos;).text(newcounter.get(&apos;time&apos;));</span><br><span class="line">              &#125;,</span><br><span class="line">              error: function(newcounter, error) &#123;</span><br><span class="line">                console.log(&apos;Failed to create&apos;);</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        error: function(error) &#123;</span><br><span class="line">          console.log(&apos;Error:&apos; + error.code + &quot; &quot; + error.message);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    $(function() &#123;</span><br><span class="line">      var Counter = AV.Object.extend(&quot;Counter&quot;);</span><br><span class="line">      if ($(&apos;.leancloud_visitors&apos;).length == 1) &#123;</span><br><span class="line">        addCount(Counter);</span><br><span class="line">      &#125; else if ($(&apos;.post-title-link&apos;).length &gt; 1) &#123;</span><br><span class="line">        showTime(Counter);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">  &lt;/script&gt;</span><br><span class="line"></span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>网上也有人贴出来这部分代码，但是会出现阅读量出现重复情况，这里的代码是经过测试后出现的，准确无误。</p>
</blockquote>
<h4 id="修改post-swing文件"><a href="#修改post-swing文件" class="headerlink" title="修改post.swing文件"></a>修改post.swing文件</h4><p>打开主题目录\layout_macro路径,找到post.swig文件，找到<code>LeanCould PageView #</code>字样,去掉 其中一个<code>&amp;nbsp; | &amp;nbsp</code>，否则部署之后会出现双<code>||</code>。</p>
<h4 id="修改layout-swing文件"><a href="#修改layout-swing文件" class="headerlink" title="修改layout.swing文件"></a>修改layout.swing文件</h4><p>打开主题目录\layout路径，找到_layout.swing<br>搜索<code>&lt;/body&gt;</code>标签，在其上方添加代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;% if theme.leancloud_visitors.enable %&#125;</span><br><span class="line">&#123;% include &apos;_scripts/lean-analytics.swig&apos; %&#125;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure>

<h3 id="给页面添加High一下"><a href="#给页面添加High一下" class="headerlink" title="给页面添加High一下"></a>给页面添加High一下</h3><p>打开<code>博客根目录\themes\next\layout_partials\header.swig</code>，在<code>&lt;ul&gt; ... /ul&gt;</code>标签之间加入以下代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;li&gt; &lt;a title=&quot;把这个链接拖到你的Chrome收藏夹工具栏中&quot; href=&apos;javascript:(function() &#123;</span><br><span class="line">    function c() &#123;</span><br><span class="line">        var e = document.createElement(&quot;link&quot;);</span><br><span class="line">        e.setAttribute(&quot;type&quot;, &quot;text/css&quot;);</span><br><span class="line">        e.setAttribute(&quot;rel&quot;, &quot;stylesheet&quot;);</span><br><span class="line">        e.setAttribute(&quot;href&quot;, f);</span><br><span class="line">        e.setAttribute(&quot;class&quot;, l);</span><br><span class="line">        document.body.appendChild(e)</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    function h() &#123;</span><br><span class="line">        var e = document.getElementsByClassName(l);</span><br><span class="line">        for (var t = 0; t &lt; e.length; t++) &#123;</span><br><span class="line">            document.body.removeChild(e[t])</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    function p() &#123;</span><br><span class="line">        var e = document.createElement(&quot;div&quot;);</span><br><span class="line">        e.setAttribute(&quot;class&quot;, a);</span><br><span class="line">        document.body.appendChild(e);</span><br><span class="line">        setTimeout(function() &#123;</span><br><span class="line">            document.body.removeChild(e)</span><br><span class="line">        &#125;, 100)</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    function d(e) &#123;</span><br><span class="line">        return &#123;</span><br><span class="line">            height : e.offsetHeight,</span><br><span class="line">            width : e.offsetWidth</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    function v(i) &#123;</span><br><span class="line">        var s = d(i);</span><br><span class="line">        return s.height &gt; e &amp;&amp; s.height &lt; n &amp;&amp; s.width &gt; t &amp;&amp; s.width &lt; r</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    function m(e) &#123;</span><br><span class="line">        var t = e;</span><br><span class="line">        var n = 0;</span><br><span class="line">        while (!!t) &#123;</span><br><span class="line">            n += t.offsetTop;</span><br><span class="line">            t = t.offsetParent</span><br><span class="line">        &#125;</span><br><span class="line">        return n</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    function g() &#123;</span><br><span class="line">        var e = document.documentElement;</span><br><span class="line">        if (!!window.innerWidth) &#123;</span><br><span class="line">            return window.innerHeight</span><br><span class="line">        &#125; else if (e &amp;&amp; !isNaN(e.clientHeight)) &#123;</span><br><span class="line">            return e.clientHeight</span><br><span class="line">        &#125;</span><br><span class="line">        return 0</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    function y() &#123;</span><br><span class="line">        if (window.pageYOffset) &#123;</span><br><span class="line">            return window.pageYOffset</span><br><span class="line">        &#125;</span><br><span class="line">        return Math.max(document.documentElement.scrollTop, document.body.scrollTop)</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    function E(e) &#123;</span><br><span class="line">        var t = m(e);</span><br><span class="line">        return t &gt;= w &amp;&amp; t &lt;= b + w</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    function S() &#123;</span><br><span class="line">        var e = document.createElement(&quot;audio&quot;);</span><br><span class="line">        e.setAttribute(&quot;class&quot;, l);</span><br><span class="line">        e.src = i;</span><br><span class="line">        e.loop = false;</span><br><span class="line">        e.addEventListener(&quot;canplay&quot;, function() &#123;</span><br><span class="line">            setTimeout(function() &#123;</span><br><span class="line">                x(k)</span><br><span class="line">            &#125;, 500);</span><br><span class="line">            setTimeout(function() &#123;</span><br><span class="line">                N();</span><br><span class="line">                p();</span><br><span class="line">                for (var e = 0; e &lt; O.length; e++) &#123;</span><br><span class="line">                    T(O[e])</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;, 15500)</span><br><span class="line">        &#125;, true);</span><br><span class="line">        e.addEventListener(&quot;ended&quot;, function() &#123;</span><br><span class="line">            N();</span><br><span class="line">            h()</span><br><span class="line">        &#125;, true);</span><br><span class="line">        e.innerHTML = &quot; &lt;p&gt;If you are reading this, it is because your browser does not support the audio element. We recommend that you get a new browser.&lt;/p&gt; &lt;p&gt;&quot;;</span><br><span class="line">        document.body.appendChild(e);</span><br><span class="line">        e.play()</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    function x(e) &#123;</span><br><span class="line">        e.className += &quot; &quot; + s + &quot; &quot; + o</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    function T(e) &#123;</span><br><span class="line">        e.className += &quot; &quot; + s + &quot; &quot; + u[Math.floor(Math.random() * u.length)]</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    function N() &#123;</span><br><span class="line">        var e = document.getElementsByClassName(s);</span><br><span class="line">        var t = new RegExp(&quot;\\b&quot; + s + &quot;\\b&quot;);</span><br><span class="line">        for (var n = 0; n &lt; e.length; ) &#123;</span><br><span class="line">            e[n].className = e[n].className.replace(t, &quot;&quot;)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    var e = 30;</span><br><span class="line">    var t = 30;</span><br><span class="line">    var n = 350;</span><br><span class="line">    var r = 350;</span><br><span class="line">    var i = &quot;//7xuupy.com1.z0.glb.clouddn.com/tongxingSibel%20-%20Im%20Sorry.mp3&quot;;</span><br><span class="line">    var s = &quot;mw-harlem_shake_me&quot;;</span><br><span class="line">    var o = &quot;im_first&quot;;</span><br><span class="line">    var u = [&quot;im_drunk&quot;, &quot;im_baked&quot;, &quot;im_trippin&quot;, &quot;im_blown&quot;];</span><br><span class="line">    var a = &quot;mw-strobe_light&quot;;</span><br><span class="line">    var f = &quot;//s3.amazonaws.com/moovweb-marketing/playground/harlem-shake-style.css&quot;;</span><br><span class="line">    var l = &quot;mw_added_css&quot;;</span><br><span class="line">    var b = g();</span><br><span class="line">    var w = y();</span><br><span class="line">    var C = document.getElementsByTagName(&quot;*&quot;);</span><br><span class="line">    var k = null;</span><br><span class="line">    for (var L = 0; L &lt; C.length; L++) &#123;</span><br><span class="line">        var A = C[L];</span><br><span class="line">        if (v(A)) &#123;</span><br><span class="line">            if (E(A)) &#123;</span><br><span class="line">                k = A;</span><br><span class="line">                break</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    if (A === null) &#123;</span><br><span class="line">        console.warn(&quot;Could not find a node of the right size. Please try a different page.&quot;);</span><br><span class="line">        return</span><br><span class="line">    &#125;</span><br><span class="line">    c();</span><br><span class="line">    S();</span><br><span class="line">    var O = [];</span><br><span class="line">    for (var L = 0; L &lt; C.length; L++) &#123;</span><br><span class="line">        var A = C[L];</span><br><span class="line">        if (v(A)) &#123;</span><br><span class="line">            O.push(A)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">	&#125;)()    &apos;&gt;High一下&lt;/a&gt; &lt;/li&gt;</span><br></pre></td></tr></table></figure>

<blockquote>
<p><code>//7xuupy.com1.z0.glb.clouddn.com/tongxingSibel%20-%20Im%20Sorry.mp3&quot;</code>可以替换成任意你想要的音乐地址</p>
</blockquote>
<h3 id="设置网站的图标Favicon"><a href="#设置网站的图标Favicon" class="headerlink" title="设置网站的图标Favicon"></a>设置网站的图标Favicon</h3><p>favicon图标也就是我们打开一个网页，出现在最浅的图标样式，可以自定义，首先我们需要一个favicon.ico的图标，可以去<a href="http://www.bitbug.net/" target="_blank" rel="noopener">比特虫</a>网站制作，网上的做法是将其放在根目录的source文件夹里。然后在主题目录的layout_partials路径下，修改header.swig的meta标签，我实验了一下，并不能配置成功呢，所以代码就不贴了，这里介绍我的做法:<br>图表制作好后，上传到云存储空间，获取图片的网址，然后打开主题配置文件_config.yml，找到favicon字段，将图片网址粘贴在后面，即可。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">favicon: http://ww4.sinaimg.cn/square/937882b5jw1f4db4lroy9j20hs0npmy6.jpg #网站图标</span><br></pre></td></tr></table></figure>

<p>到此，Next的主题算是简单的美化了一下，你现在可以在本地预览，也可以将其部署到github上去哦。</p>
<h3 id="增加评论功能"><a href="#增加评论功能" class="headerlink" title="增加评论功能"></a>增加评论功能</h3><p>Hexo Next 集成 utterances 评论系统</p>
<h4 id="GitHub-配置与脚本获取"><a href="#GitHub-配置与脚本获取" class="headerlink" title="GitHub 配置与脚本获取"></a>GitHub 配置与脚本获取</h4><ol>
<li>创建存放 comments 的代码仓库，必须为 public，且可创建 issue。</li>
<li><a href="https://github.com/apps/utterances" target="_blank" rel="noopener">install utterances app</a> 点击这个链接安装utterances app到刚刚创建的那个仓库。</li>
<li>打开 <a href="https://utteranc.es/" target="_blank" rel="noopener">https://utteranc.es/</a> ，根据提示的步骤生成所需的js script。也可在下面代码的基础上更新自己的信息。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;script src=&quot;https://utteranc.es/client.js&quot;</span><br><span class="line">        repo=&quot;maoqyhz/comments&quot; # onwer/repo</span><br><span class="line">        issue-term=&quot;pathname&quot;   # 命名issue的格式，默认pathname</span><br><span class="line">        label=&quot;Comment&quot;         # 创建issue的tag，默认Comment</span><br><span class="line">        theme=&quot;github-light&quot;    # 评论系统theme，github-light或github-dark</span><br><span class="line">        crossorigin=&quot;anonymous&quot; # 跨域，默认</span><br><span class="line">        async&gt;</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure>

<h4 id="Hexo-Next-主题配置"><a href="#Hexo-Next-主题配置" class="headerlink" title="Hexo Next 主题配置"></a>Hexo Next 主题配置</h4><p>首先，进入主题目录，在 <code>layout/_third-party/comments/</code> 中创建 <code>utterances.swig</code>，并添加以下代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;% if theme.utterances.enable %&#125;</span><br><span class="line">&lt;script src=&quot;https://utteranc.es/client.js&quot;</span><br><span class="line">        repo=&quot;&#123;&#123; theme.utterances.repo &#125;&#125;&quot;</span><br><span class="line">        issue-term=&quot;&#123;&#123; theme.utterances.issue_term &#125;&#125;&quot;</span><br><span class="line">        label=&quot;Comment&quot;</span><br><span class="line">        theme=&quot;&#123;&#123; theme.utterances.theme &#125;&#125;&quot;</span><br><span class="line">        crossorigin=&quot;anonymous&quot;</span><br><span class="line">        async&gt;</span><br><span class="line">&lt;/script&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure>

<p>再在 <code>layout/_partials/comments.swig</code> 最后添加以下代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;% if theme.utterances.enable %&#125;</span><br><span class="line"> &lt;div class=&quot;comments&quot; id=&quot;comments&quot;&gt;</span><br><span class="line">    &#123;% include &apos;../_third-party/comments/utterances.swig&apos; %&#125;</span><br><span class="line"> &lt;/div&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure>

<p>最后，在主题配置文件 <code>theme/_config.yml</code> 中添加如下配置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># utterances </span><br><span class="line">utterances:</span><br><span class="line">  enable: true</span><br><span class="line">  repo:                  # owner/repo</span><br><span class="line">  issue_term: pathname   # pathname, url, title</span><br><span class="line">  theme: github-light    # github-light or github-dark</span><br></pre></td></tr></table></figure>

<p>重新生成网页，就能看到评论系统了。</p>
<h3 id="添加分享功能"><a href="#添加分享功能" class="headerlink" title="添加分享功能"></a>添加分享功能</h3><p>多说已经不可用</p>
<p>参考<code>https://github.com/theme-next/hexo-next-share</code></p>
<h2 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h2><h3 id="标签页和分类页无内容显示"><a href="#标签页和分类页无内容显示" class="headerlink" title="标签页和分类页无内容显示"></a>标签页和分类页无内容显示</h3><p>首先创建两个页面</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ hexo new page categories</span><br><span class="line">$ hexo new page tags</span><br></pre></td></tr></table></figure>



<p>打开 <code>categories</code> 和<code>tags</code> 文件夹下的 <code>index.md</code> ，在最下面一行加一行文字就行，注意中间有空格。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">type: categories</span><br></pre></td></tr></table></figure>



<h3 id="生成静态页面报错"><a href="#生成静态页面报错" class="headerlink" title="生成静态页面报错"></a>生成静态页面报错</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FATAL Something&apos;s wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.html</span><br><span class="line">Template render error: (unknown path) [Line 7, Column 23]</span><br><span class="line">  Error: Unable to call `the return value of (posts[&quot;first&quot;])[&quot;updated&quot;][&quot;toISOString&quot;]`</span><br></pre></td></tr></table></figure>

<p>解决方案</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">把</span><br><span class="line"></span><br><span class="line">plugins:</span><br><span class="line">- hexo-generator-feed</span><br><span class="line">改成</span><br><span class="line"></span><br><span class="line">plugins:</span><br><span class="line">  hexo-generator-feed</span><br><span class="line">就行了，把短横线去掉</span><br></pre></td></tr></table></figure>

]]></content>
      <tags>
        <tag>hexo</tag>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title>GitHub 如何向开源项目提PR</title>
    <url>/2019/07/29/GitHub-%E5%A6%82%E4%BD%95%E5%90%91%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E6%8F%90PR/</url>
    <content><![CDATA[<ul>
<li>fork 到自己的仓库</li>
<li>git clone 到本地</li>
<li>上游建立连接<br><code>git remote add upstream 开源项目地址</code></li>
<li>创建开发分支 (非必须)<br><code>git checkout -b dev</code></li>
<li>修改提交代码<br><code>git status</code> <code>git add .</code> <code>git commit -m</code> <code>git push origin branch</code></li>
<li>同步代码三部曲<br><code>git fetch upstream</code> <code>git rebase upstream/master</code> <code>git push origin master</code></li>
<li>提交pr<br>去自己github仓库对应fork的项目下new pull request</li>
</ul>]]></content>
      <tags>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title>简析 GitLab Runner</title>
    <url>/2019/07/25/%E7%AE%80%E6%9E%90-GitLab-Runner/</url>
    <content><![CDATA[<p>原计划本文是作为此系列文章的最后一篇，即整合<code>Kubernetes</code>和<code>GitLab CI</code>并构建持续集成流程。但由于后面对<code>GitLab Runner</code>作了进一步的了解，因此，在此作下记录，同时方便有需要的同学。上两篇文章的主题分别是在<code>Kubernetes</code>中安装<code>GitLab Runner</code>以及<code>Docker-in-Docker &amp; Socket-Binding</code>这两种可以实现在容器中执行容器命令的方法。本文侧重于对<code>GitLab Runner</code>相关内容作一个补充。本文内容主要来源于两个地方：一部分是来提炼于官方文档，另一部分是通过查阅源码，归纳总结出来的核心操作的逻辑。因此，如果大家对<code>GitLab Runner</code>有兴趣或者学习/工作有需要，可以仔细查阅<a href="https://docs.gitlab.com/runner/" target="_blank" rel="noopener">官方文档</a>，和追踪它的<a href="https://gitlab.com/gitlab-org/gitlab-ce/tree/master" target="_blank" rel="noopener">源码</a>。这篇文章主要阐述三个方面的内容，一是关于<code>GitLab Runner</code>的知识，其二是强调和细化一下<code>Executors</code>这个概念，最后，通过阅读源码，概要阐述<code>GitLab Runner</code>和<code>GitLab Server</code>二者的基本交互逻辑。</p>
<a id="more"></a>

<p>不是不说，有些概念官方也没有说地特别清楚（个人观点，至少对于新手而言不太友好），需要自己去实践才能彻底明白其中的原理或用法。<code>GitLab Runner</code>的源代码是用<code>Golang</code>写的，总体而言，各模块代码组织结构比较清晰，而且也不会难以读懂，强烈建议有兴趣的读者可以翻看下。下面对这三方面一一展开介绍。</p>
<h2 id="关于-GitLab-Runner"><a href="#关于-GitLab-Runner" class="headerlink" title="关于 GitLab Runner"></a>关于 GitLab Runner</h2><p>有一个最基本的概念需要清楚——<code>GitLab Runner</code>到底是做什么的？事实上，<code>GitLab Runner(Runner)</code>并不负责最终执行我们在<code>.gitlab-ci.yml</code>中定义的各个<code>stage</code>中的脚本（真奇怪，明明都被称为是<code>Runner</code>了）。意识到这一点很重要。因此，对于<code>Job</code>的构建效率与<code>Runner</code>本身的配置没有直接关联（但是<code>Runner</code>确实会影响到<code>CI</code>流程的构建效率，这在后面阐述）。</p>
<p>另外，需要提醒的是，<code>GitLab Runner</code>允许以<code>rpm</code>包、<code>debian</code>包（<code>yum</code>源、<code>apt-get</code>）安装在 <code>Linux</code>,、<code>macOS</code>或<code>FreeBSD</code>上，甚至可以通过二进制文件安装在<code>Windows</code>上，当然也可以通过拉取镜像安装在<code>Docker</code>或 <code>Kubernetes</code>中。<code>Runner</code>本身没有任何特殊之处，它也只是一个使用<code>Golang</code>编写的程序而已，因此，理论上它可以安装在任何具有<code>Golang</code>环境的机器上。</p>
<p>另外一个问题是，很多时候如果你的<code>GitLab CI</code>工作流程跑得比较慢（这很常见），或者说构建效率较低。此时，一般而言，可以从三个方面来调整解决：</p>
<ul>
<li>调整你的<code>.gitlab-ci.yml</code>文件内容（确保自己熟悉<a href="https://docs.gitlab.com/ce/ci/yaml/" target="_blank" rel="noopener"><code>.gitlab-ci.yml</code></a>各选项），实施一些优化操作。典型地，让各<code>stage</code>之间共享缓存。</li>
<li>优化你的<code>GitLab Runner</code>的配置和<code>Job</code>调度策略。这包括两个方面，其一是<code>Runner</code>的配置，比如，<code>concurrent</code>参数决定了你的项目中同时可以构建的<code>Job</code>的数量，另外还有其它的几个相关的选项。其二是<code>Runner</code>调度<code>Job</code>的策略，不同的调度策略会影响到你提交的<code>Job</code>的构建情况。典型地，若某个<code>Project</code>包含很多个<code>Job</code>，那么它很有可能会占居大量的<code>Runner</code>资源，而<code>Shared Runner</code>采用的<code>Fair Usage Queue</code>调度策略就可以缓解此问题。<code>Runner</code>的调度策略与<a href="https://docs.gitlab.com/ee/ci/runners/#shared-specific-and-group-runners" target="_blank" rel="noopener"><code>Runner</code>的类型</a>相关，其中<code>Specific/Group Runner</code>使用的是<code>FIFO</code>，注意，此<code>FIFO</code>针对的是<code>Job</code>，而不是<code>Project</code>。而<code>Shared Runner</code>使用的是<code>Fair Usage Queue</code>这种调度策略，官方文档给了<a href="https://docs.gitlab.com/ee/ci/runners/#how-shared-runners-pick-jobs" target="_blank" rel="noopener">两个例子</a>来解释。在后面，我有一张<code>PPT</code>有阐述<code>Fair Usage Queue</code>策略具体是怎样，另外有两张<code>GIF</code>分别对应官方文档的两个示例。</li>
<li>最后，当然，你也可以升级<code>Runner</code>的物理硬件资源配置，这种方法就不多阐述了。</li>
</ul>
<p>关于<code>GitLab Runner</code>的最佳实践，这是<code>GitLab</code>官方论坛的<a href="https://forum.gitlab.com/t/best-practices-for-ci-with-gitlab/5169" target="_blank" rel="noopener">讨论贴</a>。这是网上的一个关于<a href="https://www.digitalocean.com/community/tutorials/an-introduction-to-ci-cd-best-practices" target="_blank" rel="noopener"><code>GitLab Best Practices</code>的建议</a>。若有需要，大家可以参考下。</p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/raw/hexo/static/GitLab-Runner/GitLab-Runer.png" alt="GitLab-Runner"></p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/raw/hexo/static/GitLab-Runner/shared-runner-1.gif" alt="Shared Runner - Fair Usage Queue-1"></p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/raw/hexo/static/GitLab-Runner/shared-runner-2_1.gif" alt="Shared Runner - Fair Usage Queue-2"></p>
<p>最后，通过阅读官方文档，本文整理一些关于<code>Runner</code>一些<code>tips</code>：</p>
<ul>
<li><p>关于<code>Runner</code></p>
<ol>
<li>你可以为多个<code>Project</code>注册同一个<code>Specific Runner</code>，与使用<code>Shared Runner</code>注册给多个<code>Project</code>的区别是：你需要显式地在每个<code>Project</code>下 enable 这个<code>Specific Runner</code>；</li>
<li>注意<code>Specific Runner</code>不会为会<code>forked project</code>自动开启，因此，你需要显式注册绑定；</li>
<li>GitLab admin 只能注册<code>Shared Runner</code>，当然你也可以在<code>Shared Runner</code>被注册后，主动为某个<code>Project</code>取消注册此 <code>Shared Runner</code>；</li>
<li><code>Specific Runner</code>可以被 lock 到某个<code>Project</code>。这样其它项目不能使用此<code>Runner</code>；</li>
<li>注册<code>Specific Runner</code>有两种方法：<br>a.  一是直接通过<code>gitlabUrl</code>和 <code>registerToken</code>。注意此 <code>registerToken</code> 是同<code>Project</code>绑定的！<br>b.  另一种是将<code>Shared Runner</code>转换成<code>Specific Runner</code>。此操作是一次性的，且只有 admin 才能操作。</li>
<li>你可以通过使用<code>protected branches</code>或<code>protected tags</code>来关联拥有这些信息的<code>protected project</code>和 <code>protected Runner</code>。因为考虑到实际生产环境有些 Runner 可能包含私密信息；</li>
<li>实践建议：尝试给<code>Runner</code>使用<code>tag</code>，同时给<code>Project</code>打上 <code>tag</code>； 为<code>Runner</code>设置执行<code>Job</code>的超时时间。</li>
</ol>
</li>
<li><p>注册<code>Runner</code>是否与<code>Project</code>有关，例如<code>registerUrl</code> 和 <code>token</code> 跟项目是相关的？<br>注册<code>Specific Runner</code>与<code>Project</code>相关。必须使用<code>gitlabUrl</code>以及此项目下的<code>registerToken</code>才能将此 <code>Runner</code>注册到此<code>project</code>下。若没有提供正确的<code>registerToken</code>（但这个<code>registerToken</code>确实合法的，比如选择了其它 <code>Project</code>的<code>registerToken</code>），则也可以显式地在这些<code>Project</code>下手动 enable 此 <code>Runner</code>，前提是你是这些项目的<code>maintainer</code>。</p>
<p><strong>TODO</strong>: 你可以实践一个错误的<code>registerToken</code>，即它不与任何<code>Project</code>关联（<code>Kubernetes Executor</code>）。<br><strong>实践结果</strong>：<code>Runner</code>所在的<code>Pod</code>启动失败，容器就绪探针有问题。因此，验证了前述逻辑。</p>
</li>
<li><p>关于<code>Runner Token</code>的问题？<br>有两种类型的<code>Token</code>。一个是<code>Registration Token</code>，用于<code>Runner</code>注册时使用。另一个是<code>Authentication Token</code>，用于<code>Runner</code>向<code>GitLab</code>提供认证。这个<code>Token</code>可以在使用<code>Registration Token</code>注册到<code>GitLab</code>时自动获取到（由 <code>GitLab Server</code>返回）；然后，<code>Runner</code>会将它放在<code>Runner</code>的配置文件中。 或者是手动在<code>Runner</code>配置文件 的<code>[[runners]] section</code>下设置<code>token=&quot;&lt;authentication_token&gt;&quot;</code>。之后，<code>GitLab Server</code> 和 <code>Runner</code>就能正常建立连接。</p>
</li>
</ul>
<h2 id="关于-Executor"><a href="#关于-Executor" class="headerlink" title="关于 Executor"></a>关于 Executor</h2><p>既然<code>Runner</code>不是<code>Job</code>的执行体，那究竟是谁负责执行<code>Job</code>呢？事实上，这与<code>Executor</code>密切相关。总而言之，<code>Runner</code>是借助<code>Executor</code>来创建具体的执行我们<code>Job</code>的资源实体，官方文档把它称为<code>Runner</code>，有点尴尬，但是读者必须清楚二者的区别。那<a href="https://docs.gitlab.com/runner/executors/" target="_blank" rel="noopener"><code>Executor</code></a>又是什么呢？我个人的理解是，所谓的<code>Executor</code>是一个抽象的概念，它为<code>GitLab CI</code>构建过程提供资源环境。引入<code>Executor</code>这个概念，可以使得<code>Runner</code>使用不同的 <code>Executor</code>（<code>SSH</code>、<code>Shell</code>和<code>Kubernetes</code>等）来执行<code>Job</code>构建过程。典型地，在具体某个环境中，比如在<code>Kubernets</code>中，就由 <a href="https://docs.gitlab.com/runner/executors/kubernetes.html" target="_blank" rel="noopener"><code>Kuberentes Executor</code></a>来请求<code>Kubernetes API Server</code>动态创建<code>Pod</code>，动态创建出来的<code>Pod</code>才负责<code>Job</code>的执行（关于<code>Pod</code>的含义读者可以参考<code>Kubernetes</code>文档）。</p>
<p>最后，<code>Runner</code>所安装的地方并不会与最终<code>Job</code>的执行体绑定，我们姑且称这个执行体为<code>Executor</code>吧，可能不是很准确。比如，如果我们使用<code>Kubernetes Executor</code>，则我们可以将<code>Runner</code>安装在<code>Windows</code>上，但却将它远程连接到<code>Kubernetes</code>集群，并通过<code>Kubernetes Executor</code>来为<code>Job</code>的构建动态创建<code>Pod</code>，但这种方式不是最简便或最合理的，个人是将<code>Runner</code>同样安装在<code>Kubernetes</code>中，这是官方的推荐做法，一方面，因为最终的应用是部署在<code>Kubernetes</code>中，因此，这会带来便利；另外，也会省去<code>Runner</code>连接集群的一些认证等过程。当然，如果选择将<code>Runner</code>安装在<code>Windows</code>中，这是最简单朴素的方式，此时<code>Runnre</code>会直接在本地为每一个<code>Job</code>动态启动一个进程，是的，这就是<code>Shell Executor</code>。更准确而言，应该是<code>PowerShell Executor</code>。下面是个人翻译整理官方文档的一些关于各种<code>Executor</code>的基本情况：</p>
<ul>
<li><a href="https://docs.gitlab.com/runner/executors/ssh.html" target="_blank" rel="noopener"><code>SSH</code></a><ul>
<li>通过<code>ssh</code>连接到远程主机，然后在远程主机上启动一个进程来执行<code>GitLab CI</code>构建过程。连接时需指定<code>url、port、user、password/identity_file</code>等参数；</li>
<li>若想要上传<code>artificate</code>，需要将<code>Runner</code>安装在<code>ssh</code> 连接到的远程主机上。</li>
</ul>
</li>
<li><a href="https://docs.gitlab.com/runner/executors/shell.html" target="_blank" rel="noopener"><code>Shell</code></a><ul>
<li>使用安装<code>Runner</code>的同一台主机启动一个进程来执行<code>GitLab CI</code>构建过程。凡是支持安装<code>Runner</code>的机器类型，都可以用使用<code>shell</code>的方式。这意味着<code>Windows PowerShell</code>、<code>Bash</code>、<code>Sh</code>和<code>CMD</code>都是可以的。</li>
</ul>
</li>
<li><a href="https://docs.gitlab.com/runner/executors/virtualbox.html" target="_blank" rel="noopener"><code>VirtualBox/Parallel</code></a><ul>
<li>通过<code>ssh</code>远程连接到虚拟机，在虚拟机中执行<code>GitLab CI</code>构建过程，可能会创建虚拟机快照以加速下一次构建。类似地，需指定<code>user、password/identity_file</code>；</li>
<li>同<code>SSH</code>方式类似，若想要上传<code>artificate</code>，需要将<code>Runner</code>安装在<code>VirtualBox</code>的虚拟机中；</li>
<li>正式开启<code>CI</code>流程前，需提前在<code>VirtualBox</code>中创建或导入一个<code>Base Virtual Machine</code>，并在其中安装 <code>OpenSSH Server</code>以及依赖等。</li>
</ul>
</li>
<li><a href="https://docs.gitlab.com/runner/executors/docker.html" target="_blank" rel="noopener"><code>Docker</code></a><ul>
<li>将<code>Executor</code>连接到<code>Docker Daemon</code>，并在一个单独容器中跑每一次的构建过程，并使用在<code>.gitlab-ci.yml</code>文件中定义的镜像，<code>Docker Executor</code>具体是通过<code>config.toml</code>文件来配置的。</li>
</ul>
</li>
<li><a href="https://docs.gitlab.com/runner/executors/kubernetes.html" target="_blank" rel="noopener"><code>Kuberentes</code></a><ul>
<li>让<code>Runner</code>连接到连<code>Kubernetes API Server</code>，为每一个<code>Job</code>动态创建一个<code>Pod</code>来执行<code>GitLab CI</code>构建过程。</li>
<li>且此<code>Pod</code>除了包含固有的<code>Infra Container</code>外，还一定会包含<code>Build Container</code>和<code>Help Container</code>，另外，可能包含<code>Service Container</code>。简单而言，<code>Build Container</code>用于执行<code>.gitlab-ci.yml</code>文件中在<code>stage</code>标签中定义的脚本。<code>Help Container</code>则用于辅助<code>Build Container</code>的执行构建工作，具体是负责<code>git</code>和<code>certificate store</code>相关的操作。最后<code>Service Container</code>的用途则对应着<code>.gitlab-ci.yml</code>文件中定义的<code>service</code>标签，即一个辅助容器，为<code>Build Container</code>提供服务，其基本实现原理是<code>Docker Link</code>。</li>
<li>最后，每一个<code>Job</code>都会包含四个阶段（<code>Job</code>构建过程的生命周期）：<code>Prepare</code>、<code>Pre-Build</code>、<code>Build</code>和<code>Post-Build</code>。这几个阶段的具体作用，我在这里就不阐述了，比较简单，可以阅读<a href="https://docs.gitlab.com/runner/executors/kubernetes.html#workflow" target="_blank" rel="noopener">这里</a>，也可以在源码中找到。</li>
</ul>
</li>
</ul>
<p>关于<code>Executor</code>就阐述到这里，<code>Executor</code>的概念非常重要，也比较抽象。</p>
<h2 id="关于-GitLab-Server-同-GitLab-Runner-的交互"><a href="#关于-GitLab-Server-同-GitLab-Runner-的交互" class="headerlink" title="关于 GitLab Server 同 GitLab Runner 的交互"></a>关于 GitLab Server 同 GitLab Runner 的交互</h2><p>这一小节简要阐述下<code>GitLab Server</code>同<code>GitLab Runner</code>的交互过程，基本是通过阅读源码总结而来，但并未详细阅读源码，只是大概理清整个交互逻辑。因此，如果读者没有跟随源码，下面的描述中涉及到源码的部分可能会有点不模糊，不过没有关系，若读者只想了解二者交互的大概过程，只需要把下面的二者的交互图搞清楚即可。但若读者有兴趣，个人还是建议，可以翻看下源码，会更清楚一些。</p>
<p>下面从四个重要操作展开叙述，分别是：</p>
<ul>
<li><strong><code>Register Runner</code></strong>，<code>Runner</code>注册过程，即将<code>Runner</code>绑定到<code>GitLab Server</code>实例的过程；</li>
<li><strong><code>Polling Job</code></strong>，<code>Runner</code>轮询<code>Job</code>的过程，当<code>Runner</code>从<code>GitLab Server</code>获取到<code>Authetication Token</code>后，它会定期去向<code>GitLab Server</code>轮询是否有等待构建的<code>Job</code>；</li>
<li><strong><code>Handle Job</code></strong>，<code>Runner</code>一旦轮询到<code>Job</code>后，它会启动构建过程，即开始上述四个阶段：<code>Prepare、Pre-Build、Build和Post-Build</code>。（对于<code>Kubernetes Executor</code>而言）。</li>
<li><strong><code>Patch Job</code></strong>，在构建<code>Job</code>的过程中，会定期将<code>Job Trace</code>日志信息发送给<code>GitLab Server</code>；</li>
</ul>
<h3 id="Register-Runner"><a href="#Register-Runner" class="headerlink" title="Register Runner"></a>Register Runner</h3><p><strong><code>Register Runner</code></strong>。当执行客户端执行<code>register</code>命令(<code>gitlab-runner register ...</code>)并提供一些配置信息时，如<code>gitlabUrl、executors、token</code>和<code>tag</code>等，会触发对应的<code>Runner</code>注册过程。源码中对应的方法是 <code>commands/register.go#Execute</code>，然后会继续调用<code>register.askRunner</code>方法来配置<code>Runner</code>，在构造所需参数后，将调用<code>network/gitlab.RegisterRunner</code>方法来注册<code>Runner</code>。在此方法中，最终通过<code>http POST /runners</code>来完成向<code>GitLab Server</code>发送注册请求，同时处理注册请求的返回结果。其中，注册请求的重要参数包括 <code>registrationToken</code>，<code>locked</code>，<code>maximum_timeout</code>，<code>tag_list</code>等（这需要在配置时填写的）。而注册请求的响应内容包含一个<code>token</code>，正如前文所述，在此之后，当<code>Runner</code>向<code>GitLab Server</code>请求<code>Job</code>信息时，需携带此 <code>token</code>。最后，需要提醒的是，<a href="https://gitlab.example.com/api/v4/runners" target="_blank" rel="noopener">此接口</a>是公开的，换言之，你可以使用程序调用此接口。</p>
<h3 id="Polling-Job"><a href="#Polling-Job" class="headerlink" title="Polling Job"></a>Polling Job</h3><p><strong><code>Polling Job</code></strong>。当<code>Runner</code>注册成功后，其会定期（默认是<code>3</code>秒，可配置）向<code>GitLab</code>请求<code>Job</code>信息。这在源码中对应的是<code>commands/multi.go#processRunner</code>方法，然后调<code>multi.requestJob</code>法，进一步调用 <code>network.RequestJob</code>（即<code>GitLabClient.RequestJob</code>）请求<code>Job</code>。最终通过<code>http POST /jobs/request</code>接口 来完成轮询<code>Job</code>请求。此请求的重要参数包括<code>token</code>和<code>RunnerInfo</code>等 。而响应内容包括<code>jobInfo、gitInfo</code>等。当然，若没有没有等待构建的<code>Job</code>信息，则返回<code>204 StatusNoContent</code>。最后，此接口似乎没有公开。</p>
<p>关于<code>Polling Job</code>的具体源码体现。在<code>commands/multi.go#Run</code>方法中，异步开启一个<code>goroutine</code>，执行 <code>multi.feedRunners(runners)</code>方法，此方法会判断是否在可用的<code>runners</code>，若存在，则遍历所有可用的 <code>runner</code>，并周期性地（默认，每隔<code>CheckInterval=3s</code>）往<code>runners</code> 通道中压入<code>runner</code>。需要注意的是，若有多个<code>runners</code>，则实际的周期是<code>CheckInterval / len(runners)</code>。接着会调用方法链： <code>multi.startWorkers -&gt; multi.processRunners</code>，在此方法中通过<code>select case</code>结构从<code>runners</code>取前面压入的<code>runner</code>实例，一旦取出成功，则调用<code>multi.processRunner</code>方法，随后的步骤如前所述。</p>
<p>需要注意的是，在正式调用<code>multi.requestJob</code>方法前，会先通过<code>common.GetExecutor</code>获取<code>executor</code>，同时还要为<code>runner</code>申请足够资源 <code>(multi.acquireRunnerResources)</code>。</p>
<p>另外，最终构建<code>Job</code>是通过方法链完成的：<code>common/build.go#build.Run(mr.config, trace) -&gt; build.run(context, executor) -&gt; build.executeScript(runContext, executor)</code>。关于构建的四个阶段，对应的源码内容也比较清楚，在<code>build.executeScript</code>方法中存在如下代码调用：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">prepare -&gt; build.executeStage(ctx, BuildStagePrepare, executor)</span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">pre-build -&gt; build.attemptExecuteStage(ctx, </span><br><span class="line">BuildStageGetSources|BuildStageRestoreCache|BuildStageDownloadArtifacts, executor, </span><br><span class="line">b.GetGetSourcesAttempts()</span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">build -&gt; build.executeStage(ctx, BuildStageUserScript, </span><br><span class="line">executor) 和 build.executeStage(timeoutContext, </span><br><span class="line">BuildStageAfterScript, executor)</span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">post-build -&gt; build.executeStage(ctx, BuildStageArchiveCache, </span><br><span class="line">executor) 和 b.executeUploadArtifacts(ctx, err, executor</span><br></pre></td></tr></table></figure>

<h3 id="Handle-Job"><a href="#Handle-Job" class="headerlink" title="Handle Job"></a>Handle Job</h3><p><strong><code>Handle Job</code></strong>。当成功获取<code>Job</code>息后，<code>Runner</code>就开始处理<code>Job</code>的构建过程。这在源码中对应的是 <code>commands/multi.go#requestJob</code>方法，然后调用<code>network.ProcessJob</code>方法。在这之前会构造 <code>jobCredentials{ID, Token}</code>，接着通过<code>trace.newJobTrace</code>创建<code>Job Trace</code>即<code>Job</code>处理日志，在构造函数中指定了<code>Job Trace</code>更新的周期，默认是<code>UpdateInterval=3s</code>，然后调用<code>trace.start</code>方法开启 Job Trace 输出。</p>
<h3 id="Patch-Job"><a href="#Patch-Job" class="headerlink" title="Patch Job"></a>Patch Job</h3><p><strong><code>Patch Job</code></strong>。在<code>Job</code>被正式构建时，是通过调用<code>trace.start</code>方法来调用<code>trace.watch</code>以周期性地<code>patch Job trace</code>。在源码中是通过<code>trace.incrementalUpdate -&gt; trace.sendPatch -&gt; network.PatchTrace</code>方法链来完成调用的，最终通过<code>http PATCH /jobs/{JobId}/trace</code>来完成<code>patch Job trace</code>请求。其中重要参数即为<code>job trace content</code>，且为增量输出，在请求的<code>headers</code>中需要设置<code>Job token</code>。若请求发送成功，则返回 <code>StatusAccepted 202</code>响应码。同时，每隔<code>forceSendInterval</code>（默认<code>30s</code>） 的时间还要更新<code>Job</code>执行状态信息（<code>pending、running、failed</code>和<code>success</code>），在源码中是通过方法链<code>trace.touchJob -&gt; network.UpdateJob</code>来完成，最后通过<code>http  PUT /jobs/{JobId}</code>完成请求的发送，其中重要参数包括<code>runnerInfo、JobToken、JobState</code> 等。但需要注意的是，若<code>Job</code>执行失败，则会附带上失败原因<code>FailureReason</code>，若<code>Job Status</code>更新成功，则返回<code>UpdateSucceeded 200</code>响应码。</p>
<p>下面是一张完整的<code>GitLab Server</code>同<code>GitLab Runner</code>的交互图。其中，最左边的表示客户端执行的<code>Runner</code>的命令（注册，启动和取消注册）。中间用红色标示的表示各个详细的阶段。右边中绿色标注的表示<code>Runner</code>同<code>GitLab Server</code>的<code>Http</code>通信细节，这个是最重要的。右边的黑色和蓝色标示的表示<code>Runner</code>自身内部执行的一些操作。</p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/raw/hexo/static/GitLab-Runner/Runner%26GitLabServer_meitu_1.jpg" alt="Runner-GitLab-communication"></p>
<p>简单小结，本文主要阐述了三个方面的内容：一是阐述<code>Runner</code>相关的知识，特别要清楚<code>Runner</code>的本质是什么，以及提高<code>GitLab CI</code>构建效率的三个方面的知识，最后补充了<code>Runner</code>相关的细节知识点；二是阐述<code>Executor</code>相关的知识，包括<code>Executor</code>的本质，与<code>Runner</code>的关系，并且简要阐述了各种<code>Executor</code>，需要重点关注<code>Kubernetes Executor</code>。最后，阐述<code>GitLab Server</code>同<code>GitLab Runner</code>基本交互逻辑，主要是包括四个阶段（没包括最后的取消注册），这几个阶段都挺重要，读者可以借助二者的交互图来理解，重点关注二者之间的<code>Http</code>交互的各阶段。这有助于理解<code>Runner</code>的执行原理。</p>
<p>参考文献</p>
<p>[1].<a href="https://docs.gitlab.com/runner/" target="_blank" rel="noopener">https://docs.gitlab.com/runner/</a><br>[2].<a href="https://forum.gitlab.com/t/best-practices-for-ci-with-gitlab/5169" target="_blank" rel="noopener">https://forum.gitlab.com/t/best-practices-for-ci-with-gitlab/5169</a><br>[3].<a href="https://docs.gitlab.com/runner/executors/" target="_blank" rel="noopener">https://docs.gitlab.com/runner/executors/</a><br>[4].<a href="https://docs.gitlab.com/runner/executors/kubernetes.html" target="_blank" rel="noopener">https://docs.gitlab.com/runner/executors/kubernetes.html</a><br>[5].<a href="https://docs.gitlab.com/ee/api/" target="_blank" rel="noopener">https://docs.gitlab.com/ee/api/</a><br>[6].<a href="https://gitlab.com/gitlab-org/gitlab-ce/tree/master" target="_blank" rel="noopener">https://gitlab.com/gitlab-org/gitlab-ce/tree/master</a></p>
]]></content>
      <categories>
        <category>持续集成</category>
      </categories>
      <tags>
        <tag>gitlab-ci</tag>
      </tags>
  </entry>
  <entry>
    <title>浅析 docker-in-docker 和 socket-binding</title>
    <url>/2019/07/07/%E6%B5%85%E6%9E%90-docker-in-docker-%E5%92%8C-socket-binding/</url>
    <content><![CDATA[<p>上一篇文章详细阐述在<code>k8s</code>中安装<code>gitlab runner</code>的整个流程，并且也阐明了其中涉及的原理。原计划这一篇博文紧接着叙述基于<code>k8s</code>并集成<code>gitlab-ci</code>的持续集成部署方案的第二阶段——研究集成<code>gitlab-ci</code>和<code>k8s</code>来实现一个以<code>build-&gt;test-&gt;deploy</code>为核心的持续集成部署流程。第一阶段只是搭建好了环境，显然第二阶段要更重要。但考虑到个人在第二阶段实验过程涉及到至关重要的一个问题，因此，打算单独开一篇博文总结一些看过的资料，并基于个人的理解与认识将此问题解释清楚。是的，这个问题是：若我们想在<code>docker</code>中运行<code>docker</code>应该如何实现呢？简单而言，在一个<code>docker</code>容器内能够安装<code>docker daemon</code>，以使得我们能够执行<code>docker build/push</code>等命令。这个问题在<code>ci/cd</code>中很典型，无论是采用<code>Jenkins</code>还是<code>gitlab-ci</code>同<code>docker</code>或<code>k8s</code>结合。比如，对于<code>gitlab-ci</code>而言，它的每一个<code>stage</code>都跑在一个容器中的，而若想在某个<code>stage</code>中执行<code>docker</code>命令（典型的，在服务构建阶段会涉及到<code>docker build</code>），默认是不支持的。我们将此种需求概略地称为在容器中运行容器。在本博文中主要讨论实现此需求的两种实现方式，但事实上，也可能不仅仅这两种方式。</p>
<a id="more"></a>

<p>本文不会过多阐述<a href="https://docs.docker.com/" target="_blank" rel="noopener"><code>docker</code></a>基本原理，但这两种实现方式确实会涉及到<code>docker</code>的一些知识。因此，你需要具备<code>docker</code>基本原理的基础。若要在一个容器中安装另外一个容器，从技术上而言，这是可以实现的。似乎在<code>Docker 0.6</code>版就添加了这个新特性，且从使用上而言，也较为简单，我们暂且称之<code>docker-in-docker(dind)</code>。但它涉及到一些安全问题，也可能会引起一些奇怪的问题。具体你可以参考<a href="http://jpetazzo.github.io/2015/09/03/do-not-use-docker-in-docker-for-ci/" target="_blank" rel="noopener">这里</a>。因此，自然而然就诞生了其它更为合理的方式——<code>socket-binding</code>，它实际上并非严格意义上的<code>docker-in-docker</code>，但它可以实现类似在容器中执行容器相关命令的效果。并且它还具备其它的优势，典型的，可以让子容器，孙子容器等等共享镜像缓存，这在某些情况下是非常合适的。下面详细介绍这两种实现方式，都遵循从实践到理论的阐述思路。</p>
<h2 id="docker-in-docker"><a href="#docker-in-docker" class="headerlink" title="docker-in-docker"></a>docker-in-docker</h2><p><code>docker-in-docker</code>这种模式从最初作为新特性被引入<code>docker</code>，到当前的版本，功能确实日趋完善。但在这里仍旧只涉及其核心部分的实践及原理。</p>
<h3 id="docker-in-docker-初步实践"><a href="#docker-in-docker-初步实践" class="headerlink" title="docker-in-docker 初步实践"></a>docker-in-docker 初步实践</h3><p>在<code>0.6</code>版的<code>Docker</code>在执行<code>docker run</code>命令时，增加了一项新特性——<code>privileged</code>选项参数，可以说就是此参数真正实现了在容器中运行容器的功能。如图1，当你执行如下命令：</p>
<p><code>docker run --privileged -it jpetazzo/dind</code></p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/raw/hexo/static/dind%26socket-binding/practice-privileged-1.png" alt="run-jpetazzo/dind-with-privileged"></p>
<p>它会从<a href="https://hub.docker.com/r/jpetazzo/dind/" target="_blank" rel="noopener"><code>docker hub</code></a>下载一个特殊的<code>docker image</code>，此镜像包含了<code>docker client</code>和<code>docker daemon</code>，并且指明以特权模式来执行它，然后它启动一个本地<code>docker daemon</code>，并进入容器交互式<code>shell</code>。在此特殊容器中，你可以继续执行<code>docker run</code>启动容器：</p>
<p><code>docker run -it ubuntu bash</code></p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/raw/hexo/static/dind%26socket-binding/practice-previliged.png" alt="run-in-dind"></p>
<p>仔细观察你的容器<code>ID</code>，你的<code>hostname</code>发生了变化，说明你已经从外层容器进入到了内层容器了！值得注意的是，此时，内层容器与外层容器依然是隔离的。我们可以简单验证一下。</p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/raw/hexo/static/dind%26socket-binding/practice-privileged-3.png" alt="dind-islotation"></p>
<h3 id="docker-in-docker-in-docker"><a href="#docker-in-docker-in-docker" class="headerlink" title="docker-in-docker-in-docker?"></a>docker-in-docker-in-docker?</h3><p>有读者可能会思考，既然我可以在容器中启动容器，即<code>docker-in-docker</code>，那么我是否可以做到<code>docker-in-docker-in-docker</code>呢？是的，这完全可以实现，甚至，理论上你可以无限递归下去，只要你在启动下一层容器时，开启特权选项即可。你可以实践下图的操作内容，观察容器<code>ID</code>，说明你确实做到了容器递归嵌套容器。而且你会发现每次执行<code>docker run</code>命令时，它都会去下载<code>jpetazzo/dind</code>这个镜像，这说明了各个层级的容器不会共享<code>image</code>，这也间接证明了各层级的容器确实处于隔离状态。</p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/raw/hexo/static/dind%26socket-binding/docker-in-docker-in-docker.png" alt="docker-in-docker-docker"></p>
<h3 id="关于-privileged-特权模式"><a href="#关于-privileged-特权模式" class="headerlink" title="关于 privileged 特权模式"></a>关于 privileged 特权模式</h3><p>关于<code>privileged</code>特权模式。我们知道<code>linux</code>进程包括<code>priviledged process</code>，即<code>root</code>用户（或者说<code>pid=0</code>的用户）创建的进程，和<code>unpriviledged process</code>，即普通用户创建的进程。<code>--privileged</code>选项实际上就是创建<code>priviledged container</code>进程。考虑到默认情况下<code>docker</code>容器运行模式为<code>unprivileged</code>，这使得在一个<code>docker</code>容器中跑另外一个<code>docker daemon</code>不被允许，因为容器不能访问宿主机的任何<code>device</code>。但一个具备<code>privileged</code>特权的容器则允许访问所有<code>device</code><a href="https://www.kernel.org/doc/Documentation/cgroup-v1/devices.txt" target="_blank" rel="noopener"><code>(cgroup device)</code></a>，即可以访问<code>/dev</code>下所有的目录。换言之，当容器被配置成<code>privileged</code>模式时，容器对宿主机的所有<code>device</code>具有完全控制权，同时通过修改<code>AppArmor</code>及<code>SELinux</code>相关的配置，使得容器几乎相当于运行在宿主机上的进程一样，具有完全访问宿主机的权限。</p>
<p>虽然，在<code>Docker 0.6</code>版，纯粹只添加了<code>--privileged</code>选项。但当前的版本(<code>18.09.6</code>)其实限制容器对宿主机设备的访问权限的粒度已经控制得比较精确了。换言之，如果只想让容器访问部分设备，可以使用<code>--device</code>选项，这使得默认情况下，容器对这些设备具有<code>read</code>、<code>write</code>、和<code>mknod</code>权限，但可使用<code>:rwm</code>作出限制。</p>
<p>除了使用<code>privileged</code>选项，也可使用<code>--cap-add</code>和<code>--cap-drop</code>选项以更细粒度的控制容器对宿主机访问的某些方面的权限。更多可参考<code>docker</code><a href="https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux-capabilities" target="_blank" rel="noopener">官方文档</a>。</p>
<h3 id="jpetazzo-dind-基本原理"><a href="#jpetazzo-dind-基本原理" class="headerlink" title="jpetazzo-dind 基本原理"></a>jpetazzo-dind 基本原理</h3><p>现在，我们来讨论一下<code>jpetazzo/dind</code>这个镜像的特殊之处。主要参考的是<a href="https://blog.docker.com/2013/09/docker-can-now-run-within-docker/" target="_blank" rel="noopener">这篇文章</a>。事实上，这个镜像也没有什么太大不同，也是由<code>Dockerfile</code>构建，下面是它的<code>Dockerfile</code>内容：</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">FROM</span> ubuntu:<span class="number">14.04</span></span><br><span class="line"><span class="keyword">MAINTAINER</span> jerome.petazzoni@docker.com</span><br><span class="line"></span><br><span class="line"><span class="comment"># Let's start with some basic stuff.</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get update -qq &amp;&amp; apt-get install -qqy \</span></span><br><span class="line"><span class="bash">    apt-transport-https \</span></span><br><span class="line"><span class="bash">    ca-certificates \</span></span><br><span class="line"><span class="bash">    curl \</span></span><br><span class="line"><span class="bash">    lxc \</span></span><br><span class="line"><span class="bash">    iptables</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># Install Docker from Docker Inc. repositories.</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> curl -sSL https://get.docker.com/ | sh</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Install the magic wrapper.</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> ./wrapdocker /usr/<span class="built_in">local</span>/bin/wrapdocker</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> chmod +x /usr/<span class="built_in">local</span>/bin/wrapdocker</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define additional metadata for our image.</span></span><br><span class="line"><span class="keyword">VOLUME</span><span class="bash"> /var/lib/docker</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"wrapdocker"</span>]</span></span><br></pre></td></tr></table></figure>

<p><code>Dockerfile</code>所包含的内容并不复杂，主要做了如下四几件事情：</p>
<ul>
<li>安装一些<code>docker daemon</code>依赖软件包，包括<code>lxc</code>和<code>iptables</code>。另外，当<code>docker daemon</code>同<code>docker index/registry</code>通信时，需要校验其<code>SSL</code>认证，因此需安装<code>ca-certificates</code>和<code>apt-transport-https</code>等。</li>
<li>挂载<code>/var/lib/docker volume</code>。因为容器文件系统是基于<code>AUFS</code>的挂载点(<code>mountpoint</code>)，而构成<code>AUFS</code>的分层文件系统应为正常的文件系统。 换言之，<code>/var/lib/docker</code>这个用于存储它创建的容器的目录不能是<code>AUFS</code>文件系统。因此，将此目录以<code>volume</code>的形式挂载到宿主机。这使得后面在容器中创建的内层容器的数据真正存储宿主机的<code>/var/lib/docker/volumns</code>目录下。</li>
<li>通过脚本快速安装一个最新的<a href="https://github.com/docker/docker-install" target="_blank" rel="noopener"><code>docker</code></a>二进制镜像文件。</li>
<li>执行一个<a href="https://github.com/jpetazzo/dind/blob/master/wrapdocker" target="_blank" rel="noopener"><code>helper</code></a>脚本。脚本主要操作包括如下三个方面：<ul>
<li>确保<code>cgroup</code>伪文件系统已经被正确挂载，若没有挂载，则依据宿主机中<code>cgroup</code>层级文件系统的形式对它进行挂载，因为<code>docker(lxc-start)</code>需要它。</li>
<li>关闭宿主机上多余的文件描述符。否则可能会造成文件描述符资源泄露。虽然这不是严格必需，但目前我们关闭它可以避免一些奇怪的行为（副作用）。</li>
<li>检测你是否在命令行中通过<code>-e PORT=...</code>指定了一个<code>PORT</code>环境变量。如果你确实指定了，<code>docker daemon</code>将会在前台启动，并在指定<code>TCP</code>端口监听<code>API</code>请求。反之，它会在后台启动<code>docker daemon</code>进程，并且为你提供一个交互式的<code>shell</code>。</li>
</ul>
</li>
</ul>
<h3 id="docker-as-a-service"><a href="#docker-as-a-service" class="headerlink" title="docker-as-a-service"></a>docker-as-a-service</h3><p>最后，需要补充的一点是，若你想使用<code>docker-in-docker</code>来作为一个服务（上述已提到<code>helper</code>脚本中最后一个操作，即判定<code>docker deamon</code>是监听指定端口，还是提供一个临时<code>shell</code>），即计划提供一个<code>Docker-as-a-Service</code>，注意不是<code>Containers-as-a-Service</code>，这两者在概念上是有区别的。因为我们提供的服务是一个<code>docker</code>实例。我们可以通过如下命令，通过让容器运行于后台模式，并对外暴露一个端口来实现：</p>
<p><code>docker run --privileged -d -p 1234 -e PORT=1234 jpetazzo/dind</code></p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/raw/hexo/static/dind%26socket-binding/dokcer-as-as-service.png" alt="docker-as-a-service"></p>
<p>如上的命令可以获取到容器的<code>ip</code>和<code>port</code>，如此便可为第三方提供<code>docker</code>实例的服务。简单而言，它们可直接连接到<code>docker</code>实例(<code>docker daemon</code>)执行与容器相关的操作。我们简单运行一个只安装了<code>docker clinet</code>的容器，然后设置其<code>DOCKER_HOST</code>为此提供<code>docker daemon</code>的容器的地址，然后简单实验一下是否成功连接，并使用作为服务的<code>docker daemon</code>。当然，你也可以参考<a href="https://hub.docker.com/_/docker" target="_blank" rel="noopener">这里</a>，使用<code>docker link</code>来做实验完成类似的效果。同样，考虑到此<code>docker</code>实例服务是以<code>priviliged</code>模式运行的，因此，它可能会因为获取了特权而造成不可预料的风险。</p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/raw/hexo/static/dind%26socket-binding/docker-as-a-servce-1.png" alt="dind-host"></p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/raw/hexo/static/dind%26socket-binding/docker-as-a-service-2.png" alt="dind-docker"></p>
<h2 id="socket-binding"><a href="#socket-binding" class="headerlink" title="socket-binding"></a>socket-binding</h2><p><code>docker-in-docker</code>的方式可以实现在容器中启动另一个容器，但它确实存在安全风险，而且，也存在潜在的棘手问题，具体可以参考这篇<a href="http://jpetazzo.github.io/2015/09/03/do-not-use-docker-in-docker-for-ci/" target="_blank" rel="noopener">博文</a>。值得一提的是，使用<code>dind</code>的方式，无法让各内层容器之间或容器与主机之间共享缓存，这在基于<code>k8s</code>集成<code>gitlab</code>实现持续集成部署方案的用例中是一个比较严重的问题。因此，笔者考虑使用<code>socket-binding</code>的方式（<code>socket-binding</code>称呼源自<code>gitlab</code><a href="https://docs.gitlab.com/runner/executors/kubernetes.html#exposing-varrundockersock" target="_blank" rel="noopener">官方文档</a>，也可称之为<a href="https://docs.docker.com/storage/bind-mounts/" target="_blank" rel="noopener"><code>bind-mount</code></a>）。</p>
<h3 id="socket-binding-实践"><a href="#socket-binding-实践" class="headerlink" title="socket-binding 实践"></a>socket-binding 实践</h3><p>事实上，很多情况下，我们并不真正需要在一个容器中运行另外一个容器（或许存在特例）。我们需要的可能只是想在<code>docker</code>容器中能够继续执行<code>docker</code>相关操作（如<code>docker build/pull/push</code>等），至少在笔者的使用案例中是这样的。因此，使用<code>dind</code>的方式是否显得小题大做了？事实上若要达到我们的目的（在容器中执行<code>docker</code>相关命令操作）是很简单的——在启动容器时使用<code>-v</code>选项以绑定挂载的方式(<code>binding mount</code>)将宿主机的<code>docker socket</code>挂载到容器，即执行如下命令：</p>
<p><code>docker run -it -v /var/run/docker.sock:/var/run/docker.sock some-docker-image /bin/bash</code></p>
<p>且此<code>docker run</code>命令中的使用的<code>some-docker-image</code>镜像则不必为<code>jpetazzo/dind</code>，它没有任何特殊之处。当然，此镜像必须包含<code>docker client</code>，而可以不用包含<code>docker engine</code>。因为，当我们以<code>socket-binding</code>的形式来<code>run</code>一个容器时，它实际上是将宿主机的<code>/var/run/docker.sock</code>挂载到了容器中<code>/var/run/docker.sock</code>，这使得在容器中执行<code>docker build/push/pull</code>命令真正使用的是宿主机的<code>docker daemon</code>，换言之，我们使用容器中的<code>docker client</code>和容器外的宿主机的<code>docker daemon</code>进行通信。这不同于<code>dind</code>，它并非真正实现了在容器中运行容器的功能。当使用<code>socket-binding</code>的方式时，所创建的容器和执行<code>docker</code>命令的当前容器处于同一层级（不是父子关系，而是兄弟关系），都是直接隶属于宿主机下的一层。因此，你可以推理得到，正因为所有的”内层”容器实际上都使用的是宿主机的<code>docker daemon</code>，这使得宿主机和所有有的容器可以共享镜像缓存！最后，同<code>docker-in-docker-in-docker...</code>类似，<code>socket-binding</code>的方式理论上也可以无限递归。我们简单通过如下的操作过程简单实践：</p>
<p>先使用下面的<code>Dockerfile</code>构建我们的实验镜像，注意，我们在容器中只安装了<code>docker client</code>。</p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/raw/hexo/static/dind%26socket-binding/socket-binding-1.png" alt="sc-dockerfile"></p>
<p>然后，构建一个名为<code>dind-sc</code>的镜像。</p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/raw/hexo/static/dind%26socket-binding/socket-binding-2.png" alt="sc-image-build"></p>
<p>使用<code>run</code>命令启动容器，并进入到容器中，执行<code>docker version</code>命令，可以同时输出了<code>docker client</code>和<code>docker engine</code>的信息！另外，执行<code>docker image</code>命令，发现输出一堆<code>image</code>，是的，这是宿主机上的镜像。</p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/raw/hexo/static/dind%26socket-binding/socket-binding-3.png" alt="sc-docker-run"></p>
<p>我们再一次在当前容器中基于此<code>Dockerfile</code>构建（有没有发现这次构建非常快，是的，使用了上一次的镜像缓存），然后运行此容器……，重复上述的操作。可以发现，所启动的容器的地位其实是一样的，它们都在同一个层级。</p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/raw/hexo/static/dind%26socket-binding/socket-binding-4.png" alt="sc-dind-build"></p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/raw/hexo/static/dind%26socket-binding/socket-binding-5.png" alt="sc-docker-2"></p>
<p>最后，实验验证宿主机同各容器共享镜像<code>cache</code>。可以看到，我们在宿主机中构建的镜像可以在容器中看到，而在容器中拉到的<code>nginx</code>镜像，也能在宿主机中看到。</p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/raw/hexo/static/dind%26socket-binding/socket-binding-6.png" alt="sc-docker-cache"></p>
<h3 id="关于-docker-volume"><a href="#关于-docker-volume" class="headerlink" title="关于 docker volume"></a>关于 docker volume</h3><p>基于<code>socket-binding</code>来实现在容器中执行容器相关操作的命令的原理其实就是<code>docker volume</code>。<code>docker</code>为了能够保存（持久化）数据以及共享容器间的数据，引入了<code>volume</code>机制。简单而言，<code>volume</code>就是目录或者文件，它可以绕过默认的由多个只读层及一个读写层叠加而成的联合文件系统(<code>union file system</code>)，而以正常的文件或者目录的形式存在于宿主机上。<code>volume</code>机制隔离了容器自身与数据，这是为了保证数据对于容器的生命周期来说是持久化的，换言之，即使你删除了停止的容器数据也还在（除非显式加上<code>-v</code>选项）。</p>
<p><code>volume</code>可以通过两种方式来创建：其一是在<code>Dockerfile</code>中指定<code>VOLUME /some/dir</code>；其二是执行<code>docker run -v /some/dir</code>命令来指定。这两种方式都是让<code>Docker</code>在主机上创建一个目录，注意默认情况下是在<code>/var/lib/docker</code>下的。并将其挂载到我们指定的路径(<code>/some/dir</code>)，当此路径在容器中不存在时，默认会自动创建它。值得注意的是，我们也可以显式指定将宿主机的某个目录或文件挂载到容器的指定位置（在上述实践环节正是这样操作的，这种方式也被称为是<code>bind-mount</code>）。最后强调一点，当删除使用<code>volume</code>的容器时，<code>volume</code>本身不受影响。</p>
<p>更多关于<code>volume</code>的操作请查看<a href="https://docs.docker.com/storage/volumes/" target="_blank" rel="noopener">官方文档</a>。</p>
<p>简单小结，本文阐述了两种实现在容器中运行容器的方法——<code>docker-in-docker</code>和<code>socket-binding</code>。对于<code>docker-in-docker</code>这种方式，虽然它存在不少问题，但它确实实现了在容器中运行容器。围绕<code>docker-in-docker</code>，先简单演示了其基本用法，然后进一步推广出<code>docker-in-docker-in-docker...</code>模式，这在理论上都是可行的。紧接从<code>privileged</code>选项切入阐述<code>dind</code>的相关原理，重点解释了<code>jpetazzo/dind</code>此特殊镜像的构建过程，最后描述了生产环境中<code>dind</code>的实践方式，即以<code>docker-as-a-service</code>的模式以将<code>docker</code>实例通过端口暴露给外部使用。另一种巧妙实现在容器中执行容器命令的方法是<code>socket-binding</code>。可以说，<code>dind</code>能够实现的，它基本都能实现，而且，它解决了各内层容器同宿主机共享镜像缓存的问题。且<code>socket-binding</code>的用法也较为简单，其原理简单而言，就是采用<code>bind-mount</code>通过<code>-v</code>选项将宿主机的<code>docker daemon</code>挂载到容器中，使得只需在容器中安装<code>docker client</code>（事实上，也可不安装<code>docker client</code>，而直接将宿主机的<code>/usr/bin/docker</code>挂载到容器中，同时安装<code>docker</code>执行所需的依赖文件即可）即可执行<code>docker pull/push/build</code>命令。</p>
<p>参考文献</p>
<p><code>docker-in-docker</code><br>[1].<a href="https://hub.docker.com/_/docker" target="_blank" rel="noopener">https://hub.docker.com/_/docker</a><br>[2].<a href="https://github.com/jpetazzo/dind/" target="_blank" rel="noopener">https://github.com/jpetazzo/dind/</a><br>[3].<a href="https://blog.docker.com/2013/09/docker-can-now-run-within-docker/" target="_blank" rel="noopener">https://blog.docker.com/2013/09/docker-can-now-run-within-docker/</a><br>[4].<a href="https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux-capabilities" target="_blank" rel="noopener">https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux-capabilities</a></p>
<p><code>socket-binding</code><br>[1].<a href="https://docs.docker.com/storage/volumes/" target="_blank" rel="noopener">https://docs.docker.com/storage/volumes/</a><br>[2].<a href="http://dockone.io/article/128" target="_blank" rel="noopener">http://dockone.io/article/128</a></p>
]]></content>
      <categories>
        <category>持续集成</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s 中安装 gitlab runner</title>
    <url>/2019/07/06/k8s-%E4%B8%AD%E5%AE%89%E8%A3%85-gitlab-runner/</url>
    <content><![CDATA[<p>最近工作的内容属于<code>devops</code>领域方向，研究的课题是基于<code>k8s</code>并集成<code>gitlab-ci</code>的持续集成部署方案。个人以前只使用过<code>Jenkins</code>来做持续集成部署(<code>ci/cd</code>)，而且，当时应该是部署在云主机上的。<code>gitlab</code>本身一个企业级代码托管平台，在<code>8.0</code>版本加入了<code>ci</code>，并且默认为每个项目开启。持续集成基本解放了软件项目的开发测试到最终的部署上线的繁琐流程，简单而言，它保证了每一次往版本库提交的代码都符合预期。我们知道<code>docker</code>解决了应用打包和发布这一运维技术难题，简单而言，<code>docker</code>所提供的极为方便的打包机制直接打包了应用运行所需要的整个操作系统，从而保证了本地环境和云端环境的高度一致。但毕竟在整个云计算领域中，<code>docker</code>只是整个容器生态的一个承载点，换言之，与开发者更为密切相关的事情是定义容器组织和管理规范的容器编排技术，这属于一个更高的层次，是一个平台级的技术。<code>kuberentes</code>正是这样一个开源平台，简而言之，<code>kubernetes</code>项目解决的问题是容器的编排、调度以及集群管理，当然，它也提供了一些高级的运维功能，如路由网关、水平扩展、监控、备份以及灾难恢复等。这也使得<code>kubernetes</code>从一诞生就备受关注。因此，将<code>gitlab-ci</code>与<code>k8s</code>进行整合是<code>ci/cd</code>实践中值得期待的方案。本系列博客会阐述个人基于<code>k8s</code>并集成<code>gitlab-ci</code>的持续集成部署方案的实现过程。实践环节包括两个部分，其一是在<code>k8s</code>中安装<code>gitlab runner</code>，其二是研究集成<code>gitlab-ci</code>和<code>k8s</code>来实现一个以<code>build-&gt;test-&gt;deploy</code>为核心的持续集成部署流程。本文的内容为第一个部分。</p>
<a id="more"></a>

<p>本文不会过多阐述<a href="https://docs.docker.com/" target="_blank" rel="noopener"><code>docker</code></a>相关原理，也不会过多涉及到<a href="https://kubernetes.io/docs/home/" target="_blank" rel="noopener"><code>kubernetes</code></a>相关原理。只会在阐述整个基于<a href="https://docs.gitlab.com/ee/ci/introduction/" target="_blank" rel="noopener"><code>gitlab-ci</code></a>和<code>kubernetes</code>的持续集成部署方案的过程中，涉及到的概念原理。本文从如下几个方面来完整的阐述在<code>k8s</code>中安装<a href="https://docs.gitlab.com/ee/ci/runners/README.html#shared-specific-and-group-runners" target="_blank" rel="noopener"><code>gitlab runner</code></a>的流程：其一，简述<code>gitlab-ci</code>的核心概念及基本原理；其二，简述<code>gitlab runner</code>相关知识 ；其三，详细阐述<code>gitlab runner</code>在<code>k8s</code>中的安装流程；最后，对<code>gitlab runner</code>相关的配置文件中重要的配置进行介绍，以更深入地理解<code>gitlab runner</code>集成到<code>k8s</code>的原理。依据官方文档是使用<a href="https://helm.sh/docs/" target="_blank" rel="noopener"><code>helm</code></a>作为软件安装工具，以在<code>k8s</code>中安装<code>gitlab runner</code>，但本文不会过多涉及<code>helm</code>的相关知识和原理。事实上，若读者不具备相关的知识基础，也没有太大影响。若读者已经对<code>gitlab, gitlab runner</code>已经较为熟悉，可以直接跳到第3小节。</p>
<h2 id="gitlab-ci-核心概念和基本原理"><a href="#gitlab-ci-核心概念和基本原理" class="headerlink" title="gitlab-ci 核心概念和基本原理"></a>gitlab-ci 核心概念和基本原理</h2><p>所谓持续集成持续部署(<code>ci/cd</code>, <code>Continuous Integration, Continuous Delivery, and Continuous Deployment</code>)，通俗而言，即在软件开发过程中，每当涉及版本库代码变更或更迭时，通过自动化执行一些由开发人员定义的脚本，以最小化引入错误的风险。自动化执行脚本说明（几乎）不需要人为干预。具体而言，持续集成表示当开发人员提交代码到版本库时（不一定是<code>master</code>分支），都会触发一系列的关于测试、构建等步骤的脚本自动化执行，以验证版本库中当前的代码所产生的效果是符合预期的。另外，持续交付(<code>Continuous Delivery</code>)和持续部署(<code>Continuous Deployment</code>)的区别在于是否需要人为干预，以部署项目到生产环境，而后者不需要人为干预。</p>
<p><code>gitlab-ci/cd</code>集成了上述功能。其基本原理是版本库每一次<code>push</code>或者<code>merge reqeust</code>操作都会触发一次<code>gitlab-ci</code>流程，即执行开发人员预先在<code>.gitlab-ci.yml</code>定义的一系列<code>stage</code>，典型的，包括<code>build</code>、<code>test</code>和<code>deploy</code>这几个核心阶段。<code>gitlab-ci</code>确实较为强大，提供了丰富的功能，以实现项目开发的快速更迭。比如，它可以在各<code>stage</code>中共享缓存，以提高各<code>stage</code>的构建效率。和<code>gitlab-ci/cd</code>相关的几个核心概念如下：</p>
<ul>
<li><code>pipeline</code>，表示一次构建任务，可包含多个阶段，如依赖安装、运行测试、项目编译、服务部署。</li>
<li><code>stage</code>，表示某个具体阶段，它们会依次串行执行，前一个成功执行后下一个才会执行，相反，若前一个执行失败，下一个则默认不会执行。</li>
<li><code>job</code>，表示<code>stage</code>上所执行的具体工作，一个<code>stage</code>可包含若干个并行执行的<code>job</code>，只有所有的<code>job</code>都执行成功，整个<code>stage</code>才被标记为执行成功，否则标记为执行失败。</li>
</ul>
<p>图1来自<code>gitlab</code>官网，阐述了<code>gitlab-ci</code>的一个典型工作流程。使用<code>gitlab</code>作为代码托管工具，你不需要额外的第三方<code>ci/cd</code>软件，并且，它提供整个流程的可视化界面。</p>
<p><img src="https://raw.githubusercontent.com/qqzeng/qqzeng.github.io/hexo/static/install-runner-in-k8s/gitlab_workflow_example_11_9.png" alt="gitlab workflow example"></p>
<p>图1 <code>gitlab workflow example</code></p>
<p>下面的<code>.gitlab-ci.yml</code>模板文件同样来自<a href="https://gitlab.com/gitlab-examples/spring-gitlab-cf-deploy-demo" target="_blank" rel="noopener"><code>gitlab</code>官网</a>，它是依赖<code>spring boot</code>的<code>java</code>应用服务的一个<code>.gitlab-ci.yml</code>示例。没有任何复杂的内容，整个<code>pipeline</code>中包含<code>test</code>和<code>build</code>两个<code>stage</code>。在全局<code>before_script</code>所定义的脚本会在所有<code>stage</code>执行之前被执行，<code>artifacts</code>表示此<code>stage</code>会生成一个<code>artifact</code>（比如一个<code>war</code>包或者可执行文件），最后<code>only</code>表示只会在对应的分支下执行。因此，当你将此<code>.gitlab-ci.yml</code>文件放到你的项目的根目录时，则表示此项目的<code>gitlab-ci</code>的功能已经开启，当你往版本库中<code>push</code>代码时，你会看到它会起作用了——自动执行你在<code>.gitlab-ci.yml</code>中定义的脚本（前提是你已经安装好了<code>gitlab</code>和<code>gitlab runner</code>，且将<code>runner</code>注册到了<code>gitlab</code>仓库中对应的项目，这会在后面提及）。你可以在<a href="https://gitlab.com/gitlab-examples" target="_blank" rel="noopener">这里</a>找到更多的<code>.gitlab-ci.yml</code>示例。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">image: java:8</span><br><span class="line"></span><br><span class="line">stages:</span><br><span class="line">  - build</span><br><span class="line">  - deploy</span><br><span class="line">  </span><br><span class="line">before_script:</span><br><span class="line">  - chmod +x mvnw</span><br><span class="line">  </span><br><span class="line">build:</span><br><span class="line">  stage: build</span><br><span class="line">  script: ./mvnw package</span><br><span class="line">  artifacts:</span><br><span class="line">    paths:</span><br><span class="line">      - target/demo-0.0.1-SNAPSHOT.jar</span><br><span class="line"></span><br><span class="line">production:</span><br><span class="line">  stage: deploy</span><br><span class="line">  script:</span><br><span class="line">  - curl --location "https://cli.run.pivotal.io/stable?release=linux64-binary&amp;source=github" | tar zx</span><br><span class="line">  - ./cf login -u $CF_USERNAME -p $CF_PASSWORD -a api.run.pivotal.io</span><br><span class="line">  - ./cf push</span><br><span class="line">  only:</span><br><span class="line">  - master</span><br></pre></td></tr></table></figure>

<h2 id="gitlab-runner-相关知识"><a href="#gitlab-runner-相关知识" class="headerlink" title="gitlab runner 相关知识"></a>gitlab runner 相关知识</h2><p>当你读完上节内容中一个示例后，你会想你在<code>.gitlab-ci.yml</code>中定义的脚本到底是在哪里执行的，换言之，是什么提供了你执行这些<code>stage</code>的资源。是的，这就是<code>gitlab runner</code>所做的。它会同<code>gitlab-ci</code>协同工作，<code>gitlab runner</code>用于运行<code>stage</code>中定义的<code>job</code>（<code>job</code>是<code>runner</code>执行的最小单位）。在阐述<code>runner</code>在<code>k8s</code>中的安装流程之前，让我们先来了解下<code>gitlab runner</code>的基本知识。</p>
<p>当你<a href="https://docs.gitlab.com/runner/#install-gitlab-runner" target="_blank" rel="noopener">安装<code>gitlab runner</code></a>并<a href="https://docs.gitlab.com/runner/register/" target="_blank" rel="noopener">将它注册到某个项目</a>后（当然你可以使用<code>shared runner</code>，在这种情况下，此<code>runner</code>就不会隶属于某个项目，而是被一组或所有的项目所共享使用），你可以使用它来执行你在<code>.gitlab-ci.yml</code>中定义的<code>job</code>，只要<code>runner</code>能够访问<code>gitlab server</code>所在的网络，则<code>gitlab</code>和<code>runner</code>就能通过<code>api</code>进行网络通信，准确而言，是<code>runner</code>会定期轮询<code>gitlab server</code>是否有等待被执行的<code>pipeline</code>。从本质上而言，<code>runner</code>只是一个使用<code>go</code>语言编写的进程，当利用它来执行<code>.gitlab-ci.yml</code>中定义的<code>pipeline</code>时，它会<code>clone</code>对应的项目，然后执行你预定义在<code>job</code>中的脚本。</p>
<p>前面提到，当多个项目共享同一个<code>runner</code>时，则称此<code>runner</code>为<code>shared runner</code>，且理想状况下，<code>runner</code>不应该同<code>gitlab server</code>安装在同一台机器上，这会影响<code>gitlab</code>的正常工作。且<code>gitlab admin</code>只能注册<code>shared runner</code>。具体而言，<code>runner</code>主要包括如下三种：</p>
<ul>
<li><code>shared runner</code>，它主要服务于多个项目中具有类似需求的<code>job</code>，显然，使用<code>shared runner</code>可以不需要为每一个项目配置单独的<code>runner</code>，且通常来说，<code>shared runner</code>与项目是多对多的关系，类似于资源池。<code>shared runner</code>采用<a href="https://docs.gitlab.com/ee/ci/runners/README.html#how-shared-runners-pick-jobs" target="_blank" rel="noopener"><code>fair useage queue</code></a>来调度<code>job</code>，这可以防止某个项目由于定义了过多的<code>job</code>而独占整个可用的<code>shared runner</code>集合。</li>
<li><code>specific runner</code>，它主要服务于具有特殊需求的项目，通常会结合<code>tag</code>来将<code>specific runner</code>与项目进行绑定，<code>specific runner</code>采用<code>FIFO</code>的方式调度<code>job</code>。值得注意的是，<code>specific runner</code>也可服务于多个项目，只是你需要显式的为每个项目<code>enable</code>它们。</li>
<li><code>group runner</code>，定义在<code>group runner</code>集合中的<code>runner</code>会服务于一组项目，与<code>shared runner</code>不同的是，它也采用的是<code>FIFO</code>的方式来调度<code>job</code>，这意味着一个定义了较多<code>job</code>的项目可能会长时间独占所有<code>runner</code>。</li>
</ul>
<p>最后，通过一个示例来简要阐述<code>shared runner</code>是如何调度<code>job</code>的，即<code>fair useage queue</code>的原理，这些内容基本来自于<a href="https://docs.gitlab.com/ee/ci/runners/README.html#how-shared-runners-pick-jobs" target="_blank" rel="noopener">官方文档</a>。示例如下：若我们为<code>project 1</code>定义了3个<code>job</code>，为<code>project 2</code>定义了2个<code>job</code>，为<code>project 3</code>定义了1个<code>job</code>，则一个典型的调度流程如下：首选会调度<code>p1-j1(job 1 of project 1)</code>，因为此时它是所有不存在正运行的<code>job</code>的项目中编号最小的<code>job</code>，这句话很重要。然后调度<code>p2-j4</code>，因为此时<code>porject 1</code>有一个正运行的作业<code>job 1</code>。再调度<code>p3-j6</code>，原因是类似的。其次，调度<code>p1-j2</code>，因为它是存在正在运行<code>job</code>的项目中，包含最少运行的<code>job</code>数（每个项目都有1个）的项目的尚未运行的<code>job</code>的编号。接下来的调度依次是<code>p2-j5</code>、<code>p1-j3</code>。需要注意的是，上面描述的调度顺序的前提是每个被调度的<code>job</code>都一直处于运行状态。因为，若当我们调度<code>p1-j1</code>时，它立刻完成了，则下一个调度的<code>job</code>则仍然从<code>project 1</code>中挑选，即为<code>p1-j2</code>。因此，总结一下，当调度<code>job</code>时，首先看哪个<code>project</code>存在最少的处于运行状态的<code>job</code>数量，然后在此<code>project</code>中选择尚未运行的<code>job</code>集合中编号最小的<code>job</code>。</p>
<p>此小节阐述了<code>gitlab runner</code>的基本原理，以及不同类型的<code>runner</code>的适用情形，同时通过一个示例来阐述<code>shared runner</code>是如何调度<code>job</code>的。更多详细内容可参考<a href="https://docs.gitlab.com/ee/ci/runners/README.html" target="_blank" rel="noopener">官方文档</a>。</p>
<h2 id="k8s-中安装gitlab-runner-的详细流程"><a href="#k8s-中安装gitlab-runner-的详细流程" class="headerlink" title="k8s 中安装gitlab runner 的详细流程"></a>k8s 中安装<code>gitlab runner</code> 的详细流程</h2><p>本小节侧重实践，详细阐述在<code>k8s</code>中安装<code>gitlab runner</code>的整个过程。其中，<code>gitlab</code>的版本是<code>GitLab Community Edition 9.4.2</code>，<code>minikube</code>的版本是<code>v1.2.0</code>，<code>Kubernetes</code>的版本是<code>v1.15.0</code>，最后<code>Docker</code>的版本是<code>18.09.6</code>。具体而言，主要包括两个方面的内容：一是<code>minikube</code>安装的注意事项，其次是在<code>k8s</code>中部署<code>gitlab runner</code>的详细流程。基本都是参考官方文档。</p>
<h3 id="minikube-安装注意事项"><a href="#minikube-安装注意事项" class="headerlink" title="minikube 安装注意事项"></a>minikube 安装注意事项</h3><p>需要说明的是，在这之前你应该有一个<code>kubernetes</code>集群，笔者的实验环境是<code>VMware® Workstation 15 Pro</code>安装<code>ubuntu18.04 desktop</code>系统，然后搭建了<code>minikube</code>（单节点）的<code>k8s</code>环境，<code>vm driver</code>采用的是<code>kvm2</code>。</p>
<blockquote>
<p>笔者之前尝试过<code>virtualbox hypervisor</code>，并以<code>virtualbox</code>和<code>kvm2</code>作为<code>vm driver</code>，但都没有成功。简单说，<code>virtualbox hypervisor</code>不支持对硬件的虚拟化。相关的<code>issue</code>可以看<a href="https://github.com/kubernetes/minikube/issues/4348" target="_blank" rel="noopener">这里</a>和<a href="https://github.com/kubernetes/minikube/issues/2991" target="_blank" rel="noopener">这里</a>，<code>virtualbox</code>官方一个相关说明，在<a href="https://www.virtualbox.org/ticket/4032" target="_blank" rel="noopener">这里</a>。如果有读者在<code>virtualbox hypervisor</code>下成功安装<code>kvm2</code>或<code>virtual</code>作为<code>vm driver</code>，还请留言。</p>
</blockquote>
<p>关于<code>minikube</code>的安装，直接参考<a href="https://kubernetes.io/docs/tasks/tools/install-minikube/" target="_blank" rel="noopener">官方文档</a>即可。但需要注意GFW，若不能上外网，可以尝试通过拉取国内镜像源来安装，参考<a href="https://yq.aliyun.com/articles/221687" target="_blank" rel="noopener">这里</a>。另外一个在安装前需要关注的操作是：<code>egrep --color &#39;vmx|svm&#39; /proc/cpuinfo</code>，必须确保此命令的输出不为空，否则，表明你的系统不支持虚拟化。安装完之后，可以执行一个<code>hello world</code>，参考<a href="https://github.com/kubernetes/minikube" target="_blank" rel="noopener">这里</a>，以确认<code>minkube</code>已经成功安装。</p>
<h3 id="k8s-中安装gitlab-runner"><a href="#k8s-中安装gitlab-runner" class="headerlink" title="k8s 中安装gitlab runner"></a>k8s 中安装<code>gitlab runner</code></h3><p>前述提到<code>gitlab runner</code>只是一个使用<code>go</code>编写的程序。因此，理论上在任何安装了<code>go</code>的环境都能安装<code>gitlab runner</code>，不仅仅局限于<code>k8s</code>的环境，详解可参考<a href="https://docs.gitlab.com/runner/install/" target="_blank" rel="noopener">这里</a>。但若将<code>runner</code>安装在<code>k8s</code>中，其原理与其它方式还是略有区别，这个在后面阐述。另外，在前一小节中提到，<code>runner</code>会周期性的轮询<code>gitlab server</code>以确认当前是否有需要执行的<code>pipeline</code>，换言之，<code>runner</code>是可以安装在你本地环境的（不需要一个外网能够访问的ip），但<code>gitlab server</code>若安装在本地环境（主机或<code>docker</code>），你要确保它能够被<code>runner</code>访问到。</p>
<p>官方提供的在<code>k8s</code>安装<code>runner</code>的<a href="https://docs.gitlab.com/runner/install/kubernetes.html" target="_blank" rel="noopener">最新教程</a>采用了<a href="https://helm.sh/docs/" target="_blank" rel="noopener"><code>helm</code></a>，因此，在安装<code>runner</code>前需要提前在<code>k8s</code>集群中安装<code>helm</code>。简单而言，<code>helm</code>是一个在<code>k8s</code>环境下的软件包管理工具，类似于<code>ubuntu</code>下的<code>apt-get</code>或<code>centos</code>下的<code>yum</code>。<code>helm</code>会为我们管理一个软件包所包含的一系列配置文件，通过使用<code>helm</code>，应用发布者可以很方便地打包(<code>pakcage</code>)应用、管理应用依赖关系和应用版本，并将其发布应用到软件仓库。另外，<code>helm</code>还提供了<code>k8s</code>上的软件部署和卸载、应用回滚等高阶功能。<code>helm</code>是一个典型的<code>cs</code>架构，为了让<code>helm</code>帮助我们管理<code>k8s</code>中的软件包，它会将<code>tiller server</code>安装在<code>k8s</code>集群中，然后使用<code>helm client</code>与之通信来完成指定功能。在<code>helm</code>安装过程中，需要注意的就是<code>helm</code>的权限(<code>RBAC</code>)的配置，在笔者的实验中，为了方便测试，给予了<code>tiller</code>这个<code>ServiceAccount</code>的<code>role</code>为<code>cluster-admin</code>。图2为<code>helm</code>的相关安装配置。更多关于<code>helm</code>的中文资料可以参考<a href="https://zhaohuabing.com/2018/04/16/using-helm-to-deploy-to-kubernetes/" target="_blank" rel="noopener">这里</a>和<a href="https://whmzsu.github.io/helm-doc-zh-cn/quickstart/install-zh_cn.html" target="_blank" rel="noopener">这里</a>。</p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/raw/hexo/static/install-runner-in-k8s/tiller.jpg" alt="helm"></p>
<p>图2 <code>k8s</code>中安装<code>helm</code>的相关配置</p>
<p>事实上，所谓的在<code>k8s</code>中安装<code>gitlab runner</code>，也就是将<code>gitlab runner</code>这个<code>helm chart</code>包安装在<code>k8s</code>中，<code>runner</code>具体是使用<code>kubernetes executor</code>执行<code>job</code>，<code>executor</code>会连接到<code>k8s</code>集群中的<code>kubernetes API</code>，并为每个<code>job</code>创建一个<code>pod</code>。<code>pod</code>是<code>k8s</code>中应用编排的最小单元（不是<code>container</code>），相当于一个逻辑/虚拟机主机，它包含了一组共享资源的<code>contaienr</code>，这些<code>container</code>共享相同的<code>network namespace</code>，可通过<code>localhost</code>通信，另外，这些<code>container</code>可声明共享同一个<code>volume</code>。通常而言，为<code>gitlab-ci</code>的每个<code>job</code>动态创建的<code>pod</code>至少包含两个<code>container</code>（也有三个的情况），分别是<code>build container</code>和<code>service container</code>，其中<code>build container</code>即用于构建<code>job</code>，而当在<code>.gitlab-ci.yml</code>中定义了<a href="https://docs.gitlab.com/ce/ci/yaml/README.html#services" target="_blank" rel="noopener"><code>service</code>标签</a>时，就会此<code>service container</code>来运行对应的<code>service</code>，以连接到<code>build container</code>，并协助它完成指定功能。这同<code>docker</code>中的<a href="https://docs.docker.com/engine/userguide/networking/default_network/dockerlinks/" target="_blank" rel="noopener"><code>link container</code></a>原理类似。最后，当使用<code>docker/docker+machine/kubernetes</code>的<code>executors</code>时，<code>gitlab runner</code>会使用基于<a href="https://docs.gitlab.com/runner/configuration/advanced-configuration.html#helper-image" target="_blank" rel="noopener"><code>helper image</code></a>的<code>help container</code>，它的使用是处理<code>git</code>、<code>artifacts</code>以及<code>cache</code>相关操作。它包含了<code>gitlab-runner-helper</code>二进制包，提供了<code>git</code>、<code>git-lfs</code>、<code>SSL certificates store</code>等命令。但当使用<code>kubernetes executor</code>时，<code>runner</code>会临时从<code>gitlab/gitlab-runner-helper</code>下载镜像而并非从本地的归档文件中加载此二进制文件。</p>
<p>现在可以执行正式的安装操作了。安装之前，通常我们需要配置<code>runner</code>，这通过在<a href="https://gitlab.com/charts/gitlab-runner/blob/master/values.yaml" target="_blank" rel="noopener"><code>values.yaml</code></a>中自定义特定选项来实现，以覆盖默认选项值。配置过程也较为简单，唯一必须配置的选项是<code>gitlabUrl</code>和<code>runnerRegistrationToken</code>，前者即为<code>gitlab server</code>的<code>url</code>，它可以是一个完整域名（如<code>https://example.gitlab.com</code>），也可以是一个<code>ip</code>地址（记得不要漏掉端口号），而后者则为你的<code>gitlab</code>的<code>token</code>，以表明你具备向<code>gitlab</code>添加<code>runner</code>的权限。这两个值可以从<code>gitlab-project-settings-pipelines</code>下获取到（注意因为笔者的<code>gitlab</code>帐户只是普通帐户，意味着只能注册<code>specific runner</code>，它与<code>admin</code>的稍有不同）。图3显示了这两个选项参数。</p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/raw/hexo/static/install-runner-in-k8s/gitlab-url-token.jpg" alt="gitlaburl and token"></p>
<p>图3 <code>runner</code>所需的<code>gitlabUrl</code>和<code>token</code>参数</p>
<p>确认了这两个最核心的配置选项后，如果你不需要覆盖其它的默认选项值，就可以开始<a href="https://docs.gitlab.com/runner/install/kubernetes.html#installing-gitlab-runner-using-the-helm-chart" target="_blank" rel="noopener">安装</a>了，非常简单。仅有两个步骤：</p>
<p>其一，将<code>gitlab</code>这个<code>repository</code>添加到<code>helm repository list</code>中。执行下面的命令即可：<br><code>helm repo add gitlab https://charts.gitlab.io</code><br>其二，使用<code>helm</code>来安装<code>gitlab runner chart</code>，如下：<br><code>helm install --namespace &lt;NAMESPACE&gt; --name gitlab-runner -f &lt;CONFIG_VALUES_FILE&gt; gitlab/gitlab-runner</code><br>其中<code>&lt;NAMESPACE&gt;</code>指定了你需要将<code>runner</code>安装在哪个<code>namespace</code>，因为，你很可能需要预先创建此<code>namespace</code>，这通过<code>kubectl create namespace &lt;NAMESPACE&gt;</code>命令来实现。而后一个参数则为你定义的<code>values.yml</code>配置文件的路径。</p>
<p>附带介绍下，另外两个重要的操作——<code>gitlab runner</code>的升级以及卸载操作。升级操作同安装操作非常类似，<code>&lt;RELEASE-NAME&gt;</code>即为<code>gitlab runner</code>，<code>release</code>是<code>helm</code>的概念，表示安装在<code>k8s</code>中的一个软件：<br><code>helm upgrade --namespace &lt;NAMESPACE&gt; -f &lt;CONFIG_VALUES_FILE&gt; &lt;RELEASE-NAME&gt; gitlab/gitlab-runner</code></p>
<p>最后的卸载操作可通过如下命令实现：<br><code>helm delete --namespace &lt;NAMESPACE&gt; &lt;RELEASE-NAME&gt;</code><br>值得注意的是，即使执行了此卸载操作，<code>helm</code>仍然保留已删除<code>release</code>的记录，这允许你回滚已删除的资源并重新激活它们。若要彻底删除，可以加上<code>--purge</code>选项。</p>
<p>至此，最简版本的<code>gitlab runner</code>已经安装完毕。当执行<code>helm install</code>命令后，它会打印出此次安装所涉及的对象资源，如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NAME:   gitlab-runner</span><br><span class="line">LAST DEPLOYED: Fri Jul  5 11:06:30 2019</span><br><span class="line">NAMESPACE: kube-gitlab-test</span><br><span class="line">STATUS: DEPLOYED</span><br><span class="line"></span><br><span class="line">RESOURCES:</span><br><span class="line">==&gt; v1/ConfigMap</span><br><span class="line">NAME                         DATA  AGE</span><br><span class="line">gitlab-runner-gitlab-runner  5     0s</span><br><span class="line"></span><br><span class="line">==&gt; v1/Pod(related)</span><br><span class="line">NAME                                          READY  STATUS    RESTARTS  AGE</span><br><span class="line">gitlab-runner-gitlab-runner-6f996b5464-8wwnz  0/1    Init:0/1  0         0s</span><br><span class="line"></span><br><span class="line">==&gt; v1/Secret</span><br><span class="line">NAME                         TYPE    DATA  AGE</span><br><span class="line">gitlab-runner-gitlab-runner  Opaque  2     0s</span><br><span class="line"></span><br><span class="line">==&gt; v1/ServiceAccount</span><br><span class="line">NAME                         SECRETS  AGE</span><br><span class="line">gitlab-runner-gitlab-runner  1        0s</span><br><span class="line"></span><br><span class="line">==&gt; v1beta1/Deployment</span><br><span class="line">NAME                         READY  UP-TO-DATE  AVAILABLE  AGE</span><br><span class="line">gitlab-runner-gitlab-runner  0/1    1           0          0s</span><br><span class="line"></span><br><span class="line">==&gt; v1beta1/Role</span><br><span class="line">NAME                         AGE</span><br><span class="line">gitlab-runner-gitlab-runner  0s</span><br><span class="line"></span><br><span class="line">==&gt; v1beta1/RoleBinding</span><br><span class="line">NAME                         AGE</span><br><span class="line">gitlab-runner-gitlab-runner  0s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">NOTES:</span><br><span class="line"></span><br><span class="line">Your GitLab Runner should now be registered against the GitLab instance reachable at: &quot;http://*******/&quot;</span><br></pre></td></tr></table></figure>

<p>你也可以执行如图4中的命令，以确认是否安装成功，甚至使用<code>-o yaml</code>选项来查看各对象配置的详细内容。</p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/raw/hexo/static/install-runner-in-k8s/gitlab-runner.jpg" alt="gitlab runner install result"></p>
<p>图4 <code>k8s</code>中安装的<code>gitlab ruuner</code>详情</p>
<p>安装成功后，如图5所示，我们可以到<code>gitlab</code>管理上查看已经有一个<code>runner</code>实例可供特定的项目使用了，记得在这之前先在<code>gitlab</code>上创建一个示例项目，不然，你可能找不到此页面的位置。</p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/raw/hexo/static/install-runner-in-k8s/gitlab-runner-list.jpg" alt="gitlab runner list"></p>
<p>图5 <code>gitlab</code> 特定项目所关联的 <code>runner</code> 列表</p>
<p>在本小节的最后，我们来看一下<code>values.yml</code>文件中定义的核心配置选项。其它的配置在下一小节阐述。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">## The GitLab Server URL (with protocol) that want to register the runner against</span></span><br><span class="line"><span class="comment">## ref: https://docs.gitlab.com/runner/commands/README.html#gitlab-runner-register</span></span><br><span class="line"><span class="comment">## gitlab server 的地址</span></span><br><span class="line"><span class="attr">gitlabUrl:</span> <span class="attr">https://gitlab.example.com/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## The registration token for adding new Runners to the GitLab server. This must</span></span><br><span class="line"><span class="comment">## be retrieved from your GitLab instance.</span></span><br><span class="line"><span class="comment">## ref: https://docs.gitlab.com/ee/ci/runners/</span></span><br><span class="line"><span class="comment">## 向 gitlab server 添加 runner 的令牌</span></span><br><span class="line"><span class="attr">runnerRegistrationToken:</span> <span class="string">""</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Set the certsSecretName in order to pass custom certificates for GitLab Runner to use</span></span><br><span class="line"><span class="comment">## Provide resource name for a Kubernetes Secret Object in the same namespace,</span></span><br><span class="line"><span class="comment">## this is used to populate the /etc/gitlab-runner/certs directory</span></span><br><span class="line"><span class="comment">## ref: https://docs.gitlab.com/runner/configuration/tls-self-signed.html#supported-options-for-self-signed-certificates</span></span><br><span class="line"><span class="comment">## 当需要向 gitlab runner 提供自定义证书时，可在此附上证书对应的secret名称</span></span><br><span class="line"><span class="comment">##（secret 需提前安装在k8s）</span></span><br><span class="line"><span class="comment">#certsSecretName:</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Configure the maximum number of concurrent jobs</span></span><br><span class="line"><span class="comment">## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-global-section</span></span><br><span class="line"><span class="comment">## 使用所有注册的 runner 能并行执行的 job 数量的上限，0 表示不限制</span></span><br><span class="line"><span class="attr">concurrent:</span> <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Defines in seconds how often to check GitLab for a new builds</span></span><br><span class="line"><span class="comment">## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-global-section</span></span><br><span class="line"><span class="comment">## runner 轮询 gitlab server 来查询是否有待执行的 pipeline 的间隔时间/s</span></span><br><span class="line"><span class="attr">checkInterval:</span> <span class="number">30</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## For RBAC support:</span></span><br><span class="line"><span class="comment">## runner 的 RBAs 权限配置（RBAC是kubernetes 1.6版本默认使用的权限机制）。</span></span><br><span class="line"><span class="comment">## 若你想 helm 为你创建对应角色、权限及角色绑定，则设置为 true，否则若你已额外创建，则设置为false</span></span><br><span class="line"><span class="attr">rbac:</span></span><br><span class="line"><span class="attr">  create:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## Run the gitlab-bastion container with the ability to deploy/manage containers of jobs</span></span><br><span class="line">  <span class="comment">## cluster-wide or only within namespace</span></span><br><span class="line">  <span class="comment">## false 表示创建的角色是隶属于某个 namespace,反之属于 cluster 范围内，后者权限更大</span></span><br><span class="line"><span class="attr">  clusterWideAccess:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## If RBAC is disabled in this Helm chart, use the following Kubernetes Service Account name.</span></span><br><span class="line">  <span class="comment">## 若你额外创建了 RBAC 相关配置，则在这里指定 ServiceAccount 的名称</span></span><br><span class="line">  <span class="comment">## default 是每个 namespace 中自带的一个帐户，但其拥有的角色可能不具备执行某些操作的权限</span></span><br><span class="line">  <span class="comment"># serviceAccountName: default</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Configuration for the Pods that the runner launches for each new job</span></span><br><span class="line"><span class="comment">## 配置 runner 为每一个 job 动态创建的 pod</span></span><br><span class="line"><span class="attr">runners:</span></span><br><span class="line">  <span class="comment">## Default container image to use for builds when none is specified</span></span><br><span class="line">  <span class="comment">## 基础容器所使用的镜像</span></span><br><span class="line"><span class="attr">  image:</span> <span class="attr">ubuntu:18.04</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## Run all containers with the privileged flag enabled</span></span><br><span class="line">  <span class="comment">## This will allow the docker:stable-dind image to run if you need to run Docker</span></span><br><span class="line">  <span class="comment">## commands. Please read the docs before turning this on:</span></span><br><span class="line">  <span class="comment">## ref: https://docs.gitlab.com/runner/executors/kubernetes.html#using-docker-dind</span></span><br><span class="line">  <span class="comment">## 这个选项对于 ci/cd 应用场景至关重要。简单而言，true 表示启用 pod 中容器的特权，</span></span><br><span class="line">  <span class="comment">## 此时，容器几乎具有容器外运行在宿主机的进程完全相同的权限，可以访问所有的设备，存在一定风险</span></span><br><span class="line">  <span class="comment">## 但是开启此选项是实现 docker-in-docker 的前提，后面会详细阐述 dind</span></span><br><span class="line"><span class="attr">  privileged:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## Namespace to run Kubernetes jobs in (defaults to 'default')</span></span><br><span class="line">  <span class="comment">## 配置 runner 为每个 job 创建的 pod 所运行的 namespace</span></span><br><span class="line">  <span class="comment"># namespace:</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## Build Container specific configuration</span></span><br><span class="line">  <span class="comment">## build 容器，用作 stage 中的基础容器</span></span><br><span class="line"><span class="attr">  builds:</span></span><br><span class="line">    <span class="comment"># cpuLimit: 200m</span></span><br><span class="line">    <span class="comment"># memoryLimit: 256Mi</span></span><br><span class="line"><span class="attr">    cpuRequests:</span> <span class="number">100</span><span class="string">m</span> <span class="comment"># 基础 cpu 占用量，表示 0.1 的cpu，m 表示 Milli 毫</span></span><br><span class="line"><span class="attr">    memoryRequests:</span> <span class="number">128</span><span class="string">Mi</span> <span class="comment"># 基础内存占用量，表示 128M 的内存</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## Service Container specific configuration</span></span><br><span class="line">  <span class="comment">## service 容器，通过 link build 容器，以协助 build 容器完成特定功能</span></span><br><span class="line"><span class="attr">  services:</span></span><br><span class="line">    <span class="comment"># cpuLimit: 200m</span></span><br><span class="line">    <span class="comment"># memoryLimit: 256Mi</span></span><br><span class="line"><span class="attr">    cpuRequests:</span> <span class="number">100</span><span class="string">m</span></span><br><span class="line"><span class="attr">    memoryRequests:</span> <span class="number">128</span><span class="string">Mi</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## Helper Container specific configuration</span></span><br><span class="line">  <span class="comment">## helper 容器，用于执行 git, git-lfs, SSL certificates store 等命令</span></span><br><span class="line"><span class="attr">  helpers:</span></span><br><span class="line">    <span class="comment"># cpuLimit: 200m</span></span><br><span class="line">    <span class="comment"># memoryLimit: 256Mi</span></span><br><span class="line"><span class="attr">    cpuRequests:</span> <span class="number">100</span><span class="string">m</span></span><br><span class="line"><span class="attr">    memoryRequests:</span> <span class="number">128</span><span class="string">Mi</span></span><br></pre></td></tr></table></figure>

<p>至此，关于在<code>k8s</code>中安装<code>gitlab runner</code>的完整流程已经阐述完毕。事实上，后面的版本中使用<code>helm</code>来安装<code>gitlab runner</code>是非常便捷的。但同时，它也向我们隐藏了相关的配置细节，为了更好的理解<code>runner</code>在<code>k8s</code>中的运行原理，有必要详细了解相关的配置文件。最后，值得注意的是，<code>runner</code>使用<code>kubernetes executor</code>的原理也是值得关注的。</p>
<h2 id="gitlab-runner-配置详解"><a href="#gitlab-runner-配置详解" class="headerlink" title="gitlab runner 配置详解"></a>gitlab runner 配置详解</h2><p>为了进一步理解<code>gitlab ruuner</code>的相关原理，本小节会详细解读有关其<a href><code>value.yml</code></a>配置选项，在正式的生产环境中，我们可能需要自定义其中的大部分的配置选项的值。其中，核心配置选项已在上一节中详细阐述。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">## GitLab Runner Image</span></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"><span class="comment">## ref: https://hub.docker.com/r/gitlab/gitlab-runner/tags/</span></span><br><span class="line"><span class="comment">## gitlab runner 的默认镜像</span></span><br><span class="line"><span class="comment"># image: gitlab/gitlab-runner:alpine-v11.6.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images</span></span><br><span class="line"><span class="comment">## gitlab runner 镜像的拉取策略，Never/IfNotPresent/Always</span></span><br><span class="line"><span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## ref: https://docs.gitlab.com/runner/commands/README.html#gitlab-runner-register</span></span><br><span class="line"><span class="comment">## gitlab server 的地址</span></span><br><span class="line"><span class="comment"># gitlabUrl: http://gitlab.your-domain.com/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## ref: https://docs.gitlab.com/ce/ci/runners/README.html</span></span><br><span class="line"><span class="comment">## 向 gitlab server 添加 runner 的令牌</span></span><br><span class="line"><span class="comment"># runnerRegistrationToken: ""</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## The Runner Token for adding new Runners to the GitLab Server. This must</span></span><br><span class="line"><span class="comment">## be retrieved from your GitLab Instance. It is token of already registered runner.</span></span><br><span class="line"><span class="comment">## ref: (we don't yet have docs for that, but we want to use existing token)</span></span><br><span class="line"><span class="comment">## 已注册的 runner 的token。不是特别清楚此选项的意义，感觉同上一个选项类似</span></span><br><span class="line"><span class="comment"># runnerToken: ""</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## ref: https://docs.gitlab.com/runner/commands/README.html#gitlab-runner-unregister</span></span><br><span class="line"><span class="comment">## 当 runner 被重新创建时，会导致 gitlab server 引用一个不存在的 runner，因此，开启此选项表示在</span></span><br><span class="line"><span class="comment">## runner 关闭时会自动从 gitlab server 取消注册</span></span><br><span class="line"><span class="attr">unregisterRunners:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## ref: https://docs.gitlab.com/runner/configuration/tls-self-signed.html#supported-options-for-self-signed-certificates</span></span><br><span class="line"><span class="comment">## 当需要向 gitlab runner 提供自定义证书时，可在此附上证书对应的secret名称</span></span><br><span class="line"><span class="comment">##（secret 需提前安装在k8s）</span></span><br><span class="line"><span class="comment"># certsSecretName:</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-global-section</span></span><br><span class="line"><span class="comment">## 使用所有注册的 runner 能并行执行的 job 数量的上限，0 表示不限制</span></span><br><span class="line"><span class="attr">concurrent:</span> <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-global-section</span></span><br><span class="line"><span class="comment">## runner 轮询 gitlab server 来查询是否有待执行的 pipeline 的间隔时间/s</span></span><br><span class="line"><span class="attr">checkInterval:</span> <span class="number">30</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-global-section</span></span><br><span class="line"><span class="comment">## gitlab runner 的日志级别</span></span><br><span class="line"><span class="comment"># logLevel:</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## runner 的 RBAs 权限配置（RBAC是kubernetes 1.6版本默认使用的权限机制）。</span></span><br><span class="line"><span class="comment">## 若你想 helm 为你创建对应角色、权限及角色绑定，则设置为 true，否则若你已额外创建，则设置为false</span></span><br><span class="line"><span class="attr">rbac:</span></span><br><span class="line"><span class="attr">  create:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## false 表示创建的角色是隶属于某个 namespace,反之属于 cluster 范围内，后者权限更大</span></span><br><span class="line"><span class="attr">  clusterWideAccess:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## 若你额外创建了 RBAC 相关配置，则在这里指定 ServiceAccount 的名称</span></span><br><span class="line">  <span class="comment">## default 是每个 namespace 中自带的一个帐户，但其拥有的角色可能不具备执行某些操作的权限</span></span><br><span class="line">  <span class="comment"># serviceAccountName: default</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## ref: https://docs.gitlab.com/runner/monitoring/#configuration-of-the-metrics-http-server</span></span><br><span class="line"><span class="comment">## 是否开启 metric 数据记录器，使用的是 Prometheus metrics exporter</span></span><br><span class="line"><span class="attr">metrics:</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 配置 runner 为每一个 job 动态创建的 pod 相关选项</span></span><br><span class="line"><span class="attr">runners:</span></span><br><span class="line">  <span class="comment">## 基础容器(build container)默认使用的镜像</span></span><br><span class="line"><span class="attr">  image:</span> <span class="attr">ubuntu:18.04</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/</span></span><br><span class="line">  <span class="comment">## 当从私有 registry 拉取镜像时，需要预先在 k8s 中创建对应的 secret，并在这里填写对应的 secret</span></span><br><span class="line">  <span class="comment"># imagePullSecrets: []</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## 镜像拉取策略，Never/IfNotPresent/Always</span></span><br><span class="line">  <span class="comment"># imagePullPolicy: ""</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## Defines number of concurrent requests for new job from GitLab</span></span><br><span class="line">  <span class="comment">## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-runners-section</span></span><br><span class="line">  <span class="comment">## gitlab-ci 能够并发请求的 job 数量</span></span><br><span class="line">  <span class="comment"># requestConcurrency: 1</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## 此 runner 是否与特定项目绑定</span></span><br><span class="line">  <span class="comment"># locked: true</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## ref: https://docs.gitlab.com/ce/ci/runners/#using-tags</span></span><br><span class="line">  <span class="comment">## runner 所运行的 pod 所关联的 tag</span></span><br><span class="line">  <span class="comment"># tags: ""</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## ref: https://docs.gitlab.com/runner/executors/kubernetes.html#using-docker-dind</span></span><br><span class="line">  <span class="comment">## 这个选项对于 ci/cd 应用场景至关重要。简单而言，true 表示启用 pod 中容器的特权，</span></span><br><span class="line">  <span class="comment">## 此时，容器几乎具有容器外运行在宿主机的进程完全相同的权限，可以访问所有的设备，存在一定风险</span></span><br><span class="line">  <span class="comment">## 但是开启此选项是实现 docker-in-docker 的前提，后面会详细阐述 dind</span></span><br><span class="line"><span class="attr">  privileged:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># gitlab runner 为 runner-token and runner-registration-token 创建的 secret 的名称</span></span><br><span class="line">  <span class="comment"># secret: gitlab-runner</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## 配置 runner 为每个 job 创建的 pod 所运行的 namespace</span></span><br><span class="line">  <span class="comment"># namespace:</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## ref: https://gitlab.com/gitlab-org/gitlab-runner/blob/master/docs/configuration/autoscale.md#distributed-runners-caching</span></span><br><span class="line">  <span class="comment">## 分布式 runner 缓存相关的配置，这里暂且忽略</span></span><br><span class="line"><span class="attr">  cache:</span> <span class="string">&#123;&#125;</span></span><br><span class="line">    <span class="comment">## General settings</span></span><br><span class="line">    <span class="comment"># cacheType: s3</span></span><br><span class="line">    <span class="comment"># cachePath: "gitlab_runner"</span></span><br><span class="line">    <span class="comment"># cacheShared: true</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">## S3 settings</span></span><br><span class="line">    <span class="comment"># s3ServerAddress: s3.amazonaws.com</span></span><br><span class="line">    <span class="comment"># s3BucketName:</span></span><br><span class="line">    <span class="comment"># s3BucketLocation:</span></span><br><span class="line">    <span class="comment"># s3CacheInsecure: false</span></span><br><span class="line">    <span class="comment"># secretName: s3access</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">## GCS settings</span></span><br><span class="line">    <span class="comment"># gcsBucketName:</span></span><br><span class="line">    <span class="comment">## Use this line for access using access-id and private-key</span></span><br><span class="line">    <span class="comment"># secretName: gcsaccess</span></span><br><span class="line">    <span class="comment">## Use this line for access using google-application-credentials file</span></span><br><span class="line">    <span class="comment"># secretName: google-application-credentials</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## build 容器，用作 stage 中的基础容器</span></span><br><span class="line"><span class="attr">  builds:</span></span><br><span class="line">    <span class="comment"># cpuLimit: 200m</span></span><br><span class="line">    <span class="comment"># memoryLimit: 256Mi</span></span><br><span class="line"><span class="attr">    cpuRequests:</span> <span class="number">100</span><span class="string">m</span> <span class="comment"># 基础 cpu 占用量，表示 0.1 的cpu，m 表示 Milli 毫</span></span><br><span class="line"><span class="attr">    memoryRequests:</span> <span class="number">128</span><span class="string">Mi</span> <span class="comment"># 基础内存占用量，表示 128M 的内存</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## service 容器，通过 link build 容器，以协助 build 容器完成特定功能</span></span><br><span class="line"><span class="attr">  services:</span></span><br><span class="line">    <span class="comment"># cpuLimit: 200m</span></span><br><span class="line">    <span class="comment"># memoryLimit: 256Mi</span></span><br><span class="line"><span class="attr">    cpuRequests:</span> <span class="number">100</span><span class="string">m</span></span><br><span class="line"><span class="attr">    memoryRequests:</span> <span class="number">128</span><span class="string">Mi</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## helper 容器，用于执行 git, git-lfs, SSL certificates store 等命令</span></span><br><span class="line"><span class="attr">  helpers:</span></span><br><span class="line">    <span class="comment"># cpuLimit: 200m</span></span><br><span class="line">    <span class="comment"># memoryLimit: 256Mi</span></span><br><span class="line"><span class="attr">    cpuRequests:</span> <span class="number">100</span><span class="string">m</span></span><br><span class="line"><span class="attr">    memoryRequests:</span> <span class="number">128</span><span class="string">Mi</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## runner 动态创建的 pod 所关联的 ServiceAccount 的名称，它可能需要被赋予特定角色</span></span><br><span class="line">  <span class="comment"># serviceAccountName:</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## If Gitlab is not reachable through $CI_SERVER_URL</span></span><br><span class="line">  <span class="comment">##</span></span><br><span class="line">  <span class="comment"># cloneUrl:</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/</span></span><br><span class="line">  <span class="comment">## 限制 gitlab-ci 的 pod 只能被调度在指定 node 上</span></span><br><span class="line">  <span class="comment"># nodeSelector: &#123;&#125;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## 指定 gitlab-ci 的 pod 所包含的 labels</span></span><br><span class="line">  <span class="comment"># podLabels: &#123;&#125;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## 指定 gitlab-ci 的 pod 所包含的 annotations</span></span><br><span class="line">  <span class="comment"># podAnnotations: &#123;&#125;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## ref: https://docs.gitlab.com/runner/commands/#gitlab-runner-register</span></span><br><span class="line">  <span class="comment">## 为 gitlab-ci runner 注入指定的环境变量，注意不是 runner 动态创建的 pod 的环境变量</span></span><br><span class="line">  <span class="comment"># env:</span></span><br><span class="line">  <span class="comment">#   NAME: VALUE</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## ref: http://kubernetes.io/docs/user-guide/compute-resources/</span></span><br><span class="line"><span class="comment">## 为 runner 配置资源限制</span></span><br><span class="line"><span class="attr">resources:</span> <span class="string">&#123;&#125;</span></span><br><span class="line">  <span class="comment"># limits:</span></span><br><span class="line">  <span class="comment">#   memory: 256Mi</span></span><br><span class="line">  <span class="comment">#   cpu: 200m</span></span><br><span class="line">  <span class="comment"># requests:</span></span><br><span class="line">  <span class="comment">#   memory: 128Mi</span></span><br><span class="line">  <span class="comment">#   cpu: 100m</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity</span></span><br><span class="line"><span class="comment">## 配置 runner 所在 pod 的亲和性，同 label的作用类似，都用于指定 pod的调度策略，</span></span><br><span class="line"><span class="comment">## 但其功能更加强大，它可以设置简单的逻辑组合，不单单是 label 所局限的简单的相等匹配</span></span><br><span class="line"><span class="attr">affinity:</span> <span class="string">&#123;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Ref: https://kubernetes.io/docs/user-guide/node-selection/</span></span><br><span class="line"><span class="comment">## gitlab runner 的节点选择器，即指定只能运行在哪些节点上</span></span><br><span class="line"><span class="attr">nodeSelector:</span> <span class="string">&#123;&#125;</span></span><br><span class="line">  <span class="comment"># node-role.kubernetes.io/worker: "true"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## List of node taints to tolerate (requires Kubernetes &gt;= 1.6)</span></span><br><span class="line"><span class="comment">## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/</span></span><br><span class="line"><span class="comment">## tolerations 与 taints 相关。一个被标记为 Taints 的节点，除非 pod 也被标识为可以容忍污点节点，</span></span><br><span class="line"><span class="comment">## 否则该 Taints 节点不会被调度 pod。</span></span><br><span class="line"><span class="comment">## 典型的，在 kubernetes 集群，Master 节点通过被标记为 taints 以保留给 Kubernetes 系统组件使用</span></span><br><span class="line"><span class="comment">## 但若仍然希望某个 pod 调度到 taint 节点上，则必须在 Spec 中做出Toleration定义，才能调度到该节点</span></span><br><span class="line"><span class="attr">tolerations:</span> <span class="string">[]</span></span><br><span class="line">  <span class="comment"># Example: Regular worker nodes may have a taint, thus you need to tolerate the taint</span></span><br><span class="line">  <span class="comment"># when you assign the gitlab runner manager with nodeSelector or affinity to the nodes.</span></span><br><span class="line">  <span class="comment"># - key: "node-role.kubernetes.io/worker"</span></span><br><span class="line">  <span class="comment">#   operator: "Exists"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## ref: https://docs.gitlab.com/runner/configuration/advanced-configuration.html</span></span><br><span class="line"><span class="comment">## 环境变量，在执行 register 命令时使用，以进一步控制注册的过程和 config.toml 配置文件</span></span><br><span class="line"><span class="comment"># envVars:</span></span><br><span class="line"><span class="comment">#   - name: RUNNER_EXECUTOR</span></span><br><span class="line"><span class="comment">#     value: kubernetes</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 主机名与ip的映射，它们可以被注入到 runner 所在 pod 的 host 文件</span></span><br><span class="line"><span class="attr">hostAliases:</span> <span class="string">[]</span></span><br><span class="line">  <span class="comment"># Example:</span></span><br><span class="line">  <span class="comment"># - ip: "127.0.0.1"</span></span><br><span class="line">  <span class="comment">#   hostnames:</span></span><br><span class="line">  <span class="comment">#   - "foo.local"</span></span><br><span class="line">  <span class="comment">#   - "bar.local"</span></span><br><span class="line">  <span class="comment"># - ip: "10.1.2.3"</span></span><br><span class="line">  <span class="comment">#   hostnames:</span></span><br><span class="line">  <span class="comment">#   - "foo.remote"</span></span><br><span class="line">  <span class="comment">#   - "bar.remote"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 附加在 runner 所在 pod 上的 annotations</span></span><br><span class="line"><span class="attr">podAnnotations:</span> <span class="string">&#123;&#125;</span></span><br><span class="line">  <span class="comment"># Example:</span></span><br><span class="line">  <span class="comment"># iam.amazonaws.com/role: &lt;my_role_arn&gt;</span></span><br></pre></td></tr></table></figure>

<p>最后强调下关于<code>namespace</code>和<code>ServerAccount</code>的权限的问题。事实上<code>gitlab runner</code>会存在于某一个<code>namespace</code>，同时它会关联一个<code>ServiceAccount</code>，此<code>sa</code>决定了其为每个<code>job</code>动态创建的<code>pod</code>操作的权限问题。典型的，若其<code>sa</code>只具备某个<code>namespace</code>下的所有权限，则它不能在集群范围内其它<code>namespace</code>中创建<code>pod</code>。且动态创建的<code>pod</code>所在的<code>namespace</code>可以与<code>runner</code>所在<code>namespace</code>不同。最后，由<code>runner</code>动态创建出来的<code>pod</code>，也会关联一个<code>sa</code>，此<code>sa</code>所绑定的<code>role</code>决定了在对应的<code>job</code>中能够执行的脚本操作，比如，在<code>job</code>中又创建一个<code>pod</code>（我们后面的<code>ci/cd</code>方案中就属于此种情况），那么，此<code>pod</code>所处的<code>namespace</code>也可以和<code>job</code>对应的<code>pod</code>所处的<code>namespace</code>不同，这取决于<code>job</code>所关联的<code>sa</code>的权限。读者若有兴趣，完全可以自己尝试一下这些配置会带来什么影响。</p>
<p>至此，关于<code>runner</code>的相关的配置已经讲解完毕。大部分还是容易理解的，读者可以通过实验来验证它们的功能。在生产环境中，可能需要覆盖大多默认配置选项。</p>
<p>简单小结，本文详细分析了在<code>k8s</code>中安装<code>gitlab runner</code>的完整流程。在阐述具体的安装操作前，先是阐述了<code>gitlab-ci/cd</code>的核心概念和基本原理，这有助于了解<code>gitlab-ci</code>到底是如何工作。其次，阐述了<code>gitlab runner</code>的相关知识，<code>gitlab runner</code>才是定义在<code>.gitlab-ci.yml</code>的脚本的执行器，但它并不特殊，只是一个使用<code>go</code>写的应用程序而已。然后，重点阐述了<code>k8s</code>中安装<code>gitlab runner</code>的详细步骤，附带阐述了<code>kubernetes executor</code>的原理和<code>helm</code>的基本作用。同时，详细解释了<code>gitlab runner chart</code>包的<code>values.yml</code>配置文件的核心配置选项。最后，为了更深入了解<code>gitlab runner</code>的运行原理，简述了<code>values.yml</code>中几乎所有的配置选项。</p>
<p>需要提醒读者的是，整篇文件比较长。涉及到的内容也较多，提供的参考资料也挺多。但只要耐心跟随整个流程，在<code>k8s</code>中安装<code>gitlab runner</code>是完全没有问题的。</p>
<p>参考文献</p>
<p><code>minikube</code><br>[1].<a href="https://kubernetes.io/docs/tasks/tools/install-minikube/" target="_blank" rel="noopener">https://kubernetes.io/docs/tasks/tools/install-minikube/</a><br>[2].<a href="https://github.com/kubernetes/minikube" target="_blank" rel="noopener">https://github.com/kubernetes/minikube</a><br>[3].<a href="https://github.com/kubernetes/minikube/issues/2991" target="_blank" rel="noopener">https://github.com/kubernetes/minikube/issues/2991</a></p>
<p><code>gitlab-ci/cd</code><br>[1].<a href="https://docs.gitlab.com/ee/ci/" target="_blank" rel="noopener">https://docs.gitlab.com/ee/ci/</a><br>[2].<a href="https://docs.gitlab.com/ee/ci/introduction/index.html#how-gitlab-cicd-works" target="_blank" rel="noopener">https://docs.gitlab.com/ee/ci/introduction/index.html#how-gitlab-cicd-works</a><br>[3].<a href="https://docs.gitlab.com/ee/ci/yaml/README.html" target="_blank" rel="noopener">https://docs.gitlab.com/ee/ci/yaml/README.html</a><br>[4].<a href="https://gitlab.com/gitlab-examples" target="_blank" rel="noopener">https://gitlab.com/gitlab-examples</a></p>
<p><code>gitlab runner</code><br>[1].<a href="https://docs.gitlab.com/ee/ci/runners/README.html" target="_blank" rel="noopener">https://docs.gitlab.com/ee/ci/runners/README.html</a><br>[2].<a href="https://docs.gitlab.com/runner/" target="_blank" rel="noopener">https://docs.gitlab.com/runner/</a><br>[3].<a href="https://docs.gitlab.com/ce/ci/docker/using_docker_images.html#what-is-a-service" target="_blank" rel="noopener">https://docs.gitlab.com/ce/ci/docker/using_docker_images.html#what-is-a-service</a></p>
<p><code>helm</code><br>[1].<a href="https://helm.sh/docs/" target="_blank" rel="noopener">https://helm.sh/docs/</a><br>[2].<a href="https://zhaohuabing.com/2018/04/16/using-helm-to-deploy-to-kubernetes/" target="_blank" rel="noopener">https://zhaohuabing.com/2018/04/16/using-helm-to-deploy-to-kubernetes/</a><br>[3].<a href="https://www.qikqiak.com/post/first-use-helm-on-kubernetes/" target="_blank" rel="noopener">https://www.qikqiak.com/post/first-use-helm-on-kubernetes/</a></p>
<p><code>kubernetes executor</code><br>[1].<a href="https://docs.gitlab.com/runner/executors/kubernetes.html" target="_blank" rel="noopener">https://docs.gitlab.com/runner/executors/kubernetes.html</a></p>
<p><code>install runner in k8s</code><br>[1].<a href="https://docs.gitlab.com/runner/install/kubernetes.html" target="_blank" rel="noopener">https://docs.gitlab.com/runner/install/kubernetes.html</a><br>[2].<a href="https://docs.gitlab.com/runner/configuration/advanced-configuration.html" target="_blank" rel="noopener">https://docs.gitlab.com/runner/configuration/advanced-configuration.html</a></p>
]]></content>
      <categories>
        <category>持续集成</category>
      </categories>
      <tags>
        <tag>k8s</tag>
        <tag>gitlab-ci</tag>
      </tags>
  </entry>
  <entry>
    <title>Shell学习笔记</title>
    <url>/2019/06/23/Shell%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="Shell命令"><a href="#Shell命令" class="headerlink" title="Shell命令"></a>Shell命令</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br></pre></td></tr></table></figure><h3 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">变量名:不需要使用$符号，<span class="string">"="</span>不能有空格</span></span><br><span class="line">my_name="BinZhiZhu"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">输出:需要$符号</span></span><br><span class="line">echo $my_name</span><br></pre></td></tr></table></figure><h3 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#单引号</span></span><br><span class="line"></span><br><span class="line">str=<span class="string">'I try to learn shell '</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$str</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#双引号:可以有变量,可以有转义字符</span></span><br><span class="line"></span><br><span class="line">str=<span class="string">"My name is \"<span class="variable">$my_name</span>\",Nice to meet u"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$str</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#拼接</span></span><br><span class="line"></span><br><span class="line">str1=<span class="string">"What's ur name,bro? My name is "</span><span class="variable">$my_name</span><span class="string">"!"</span></span><br><span class="line"></span><br><span class="line">str2=<span class="string">"What's ur name,bro? My name is "</span>&#123;<span class="variable">$my_name</span>&#125;<span class="string">"!"</span></span><br><span class="line"></span><br><span class="line">str3=<span class="string">"What's ur name,bro? My name is &#123;<span class="variable">$my_name</span>&#125;!"</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$str1</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$str2</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$str3</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#获取长度:$&#123;# + 变量&#125;</span></span><br><span class="line"></span><br><span class="line">str=<span class="string">'qwer'</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;#str&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#提取子字符串:</span></span><br><span class="line"></span><br><span class="line">str=<span class="string">"my name is <span class="variable">$my_name</span> "</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#提取名字：BinZhiZhu</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;str:11&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#提取指定索引范围:name</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;str:3:5&#125;</span></span><br></pre></td></tr></table></figure><a id="more"></a>





<h3 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#括号括起来 元素之间用空格相隔</span></span><br><span class="line">array=(a b c d)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#可以直接赋值</span></span><br><span class="line">array1[0]=1</span><br><span class="line">array1[1]=2</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"所有元素为：<span class="variable">$&#123;array[*]&#125;</span>"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"第一个元素为：<span class="variable">$&#123;array[0]&#125;</span>"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"第二个元素为：<span class="variable">$&#123;array[1]&#125;</span>"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"第三个元素为：<span class="variable">$&#123;array[2]&#125;</span>"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"第四个元素为：<span class="variable">$&#123;array[3]&#125;</span>"</span></span><br></pre></td></tr></table></figure>

<h3 id="流程控制"><a href="#流程控制" class="headerlink" title="流程控制"></a>流程控制</h3><h3 id="if的使用"><a href="#if的使用" class="headerlink" title="if的使用"></a>if的使用</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">运算符 : -gt:大于; -lt:小于; -eq:等于</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="keyword">if</span>使用</span></span><br><span class="line"></span><br><span class="line">a=6</span><br><span class="line">b=4</span><br><span class="line"></span><br><span class="line">if [ $a -gt $b ]</span><br><span class="line">then</span><br><span class="line">     echo "a大于b咯"</span><br><span class="line">elif [ $a -eq $b ]</span><br><span class="line">then</span><br><span class="line">     echo "a等于b咯"</span><br><span class="line">elif [ $a -lt $b ]</span><br><span class="line">then</span><br><span class="line">     echo "a小于b咯"</span><br><span class="line">else</span><br><span class="line">     echo "没有找到该条件判断"</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">test</span>命令</span></span><br><span class="line"></span><br><span class="line">let num1=2*3</span><br><span class="line">let num2=3+3</span><br><span class="line"></span><br><span class="line">if test $num1 -eq $num2</span><br><span class="line">then</span><br><span class="line">    echo '两个数字相等!'</span><br><span class="line">else</span><br><span class="line">    echo '两个数字不相等!'</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">等价于</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">let num3=2*3</span><br><span class="line">let num4=3+2</span><br><span class="line"></span><br><span class="line">if [ $num3 -eq $num4 ]</span><br><span class="line">then</span><br><span class="line">    echo '两个数字相等!'</span><br><span class="line">else</span><br><span class="line">    echo '两个数字不相等!'</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>

<h4 id="for循环"><a href="#for循环" class="headerlink" title="for循环"></a>for循环</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">arr=(1 2 3 4)</span><br><span class="line">for loop in $&#123;arr[*]&#125;</span><br><span class="line">do</span><br><span class="line">    echo "The Number is: $loop"</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">写成一行</span></span><br><span class="line">for loop in $&#123;arr[*]&#125;;do echo "Number is: $loop";done;</span><br></pre></td></tr></table></figure>

<h4 id="while循环"><a href="#while循环" class="headerlink" title="while循环"></a>while循环</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">当num小于等于5条件为<span class="literal">true</span></span></span><br><span class="line">num=1</span><br><span class="line"></span><br><span class="line"><span class="meta">while(($</span><span class="bash">num &lt;= 5 ))</span></span><br><span class="line">do</span><br><span class="line">   echo "num is:$num"</span><br><span class="line">   let num++</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">读取键盘信息</span></span><br><span class="line"></span><br><span class="line">echo '按下 &lt;CTRL-D&gt; 退出'</span><br><span class="line">echo -n '输入你最喜欢的网站名: '</span><br><span class="line">while read FILM</span><br><span class="line">do</span><br><span class="line">    echo "是的！$FILM 是一个好网站"</span><br><span class="line">    break</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h4 id="until循环"><a href="#until循环" class="headerlink" title="until循环"></a>until循环</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">until 循环执行一系列命令直至条件为 <span class="literal">true</span> 时停止，与<span class="keyword">while</span>相反</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">输入1-10数字咯</span></span><br><span class="line">a=0</span><br><span class="line">b=10</span><br><span class="line"></span><br><span class="line">until [ $a -eq $b ]</span><br><span class="line">do</span><br><span class="line">    echo " value is : $a"</span><br><span class="line">    let a++</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h4 id="case循环"><a href="#case循环" class="headerlink" title="case循环"></a>case循环</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="keyword">esac</span>的意思与<span class="keyword">case</span>相反 也就是结束执行</span></span><br><span class="line">echo "case 循环"</span><br><span class="line"></span><br><span class="line">echo '输入 1 到 4 之间的数字:'</span><br><span class="line">echo '你输入的数字为:'</span><br><span class="line">read aNum</span><br><span class="line">case $aNum in</span><br><span class="line">    1)  echo '你选择了 1'</span><br><span class="line">    ;;</span><br><span class="line">    2)  echo '你选择了 2'</span><br><span class="line">    ;;</span><br><span class="line">    3)  echo '你选择了 3'</span><br><span class="line">    ;;</span><br><span class="line">    4)  echo '你选择了 4'</span><br><span class="line">    ;;</span><br><span class="line">    *)  echo '你没有输入 1 到 4 之间的数字'</span><br><span class="line">    ;;</span><br><span class="line">esac</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#输入 1 到 5 之间的数字才可结束循环</span></span></span><br><span class="line">while :</span><br><span class="line">do</span><br><span class="line">    echo -n "输入 1 到 5 之间的数字:"</span><br><span class="line">    read aNum</span><br><span class="line">    case $aNum in</span><br><span class="line">        1|2|3|4|5) echo "你输入的数字为 $aNum!"</span><br><span class="line">        ;;</span><br><span class="line">        *) echo "你输入的数字不是 1 到 5 之间的! 游戏结束"</span><br><span class="line">            break</span><br><span class="line">        ;;</span><br><span class="line">    esac</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h4 id="简单的删除文件"><a href="#简单的删除文件" class="headerlink" title="简单的删除文件"></a>简单的删除文件</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">filePath=&quot;del.php&quot;</span><br><span class="line"></span><br><span class="line">echo &apos;确认删除del.php文件吗？(y/n)&apos;</span><br><span class="line">read check</span><br><span class="line">case $check in</span><br><span class="line">     &apos;y&apos;)</span><br><span class="line">         rm $filePath;;</span><br><span class="line">     &apos;n&apos;)</span><br><span class="line">         echo &apos;取消删除&apos;;;</span><br><span class="line">      *)</span><br><span class="line">         echo &apos;请输入y/n&apos;;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>


]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title>nsq diskqueue 源码简析</title>
    <url>/2019/05/19/nsq-diskqueue-%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/</url>
    <content><![CDATA[<p><code>diskQueue</code>是<code>nsq</code>分布式实时消息队列的消息持久化存储组件。考虑到<code>nsq</code>为了限制消息积压所占的内存，同时也为了保证节点宕机消息尽可能丢失，因此，当内存消息队列<code>memoryMsgChan</code>的长度达到配置的阈值时，会将消息写入到持久化存储消息队列中。是的，<code>diskQueue</code>提供两个关键特性，一是持久化存储，二是队列接口。而在<code>nsq</code>系统中<code>diskQueue</code>的用法和<code>memoryMsgChan</code>（<code>buffered go channel</code>）基本上是相同的，因此，对于生产者或者消费者而言，消息的存储方式对于它们而言是透明的，它们只需要调用相应的接口投递或获取消息即可。这确实是数据存储的最佳实践。在此前的6篇文章已经将<code>nsq</code>相关模块的源码阐述完毕。本文的主题是<code>diskQueue</code>——持久化消息队列存储组件。重点阐述其实现原理，同时分析其为上层应用程序提供的接口。</p>
<a id="more"></a>

<p>据官方介绍，<code>diskQueue</code>是从<code>nsq</code>项目中抽取而来，将它单独作为一个项目<a href="https://github.com/nsqio/go-diskqueue" target="_blank" rel="noopener"><code>go-diskqueue</code></a>。它本身比较简单，只有一个源文件<code>diskqueue.go</code>。本文阐述的内容更完整的源码注释可在<a href="https://github.com/qqzeng/nsqio/tree/master/go-diskqueue" target="_blank" rel="noopener">这里</a>找到，注释源码版本为<code>v1.1.0</code>，仅供参考。</p>
<p>本文阐述的内容可分两个部分：其一，分析<code>diskQueue</code>的工作原理，这包括如何从文件中读取一条消息以及如何写入一条消息到文件系统中（考虑到写入或读取文件时，可能涉及到文件的切换，因为它需要保证单个文件的大小 不能过大，因此采用滚动写入的方式。另外在读取或写入文件时，也要考虑文件损坏的情况）。同时分析<code>diskQueue</code>提供给应用程序的接口，典型地，包括将消息写入到<code>diskQueue</code>中，从<code>diskQueue</code>读取一条消息，以及删除或清空<code>diskQueue</code>存储的消息。但本文的行文方式为：从<code>diskQueue</code>实例结构开始，围绕<code>diskQueue.ioLoop</code>主循环展开，阐述上述介绍的各个流程。</p>
<h2 id="diskQueue-实例结构"><a href="#diskQueue-实例结构" class="headerlink" title="diskQueue 实例结构"></a>diskQueue 实例结构</h2><p><code>diskQueue</code>结构所包含字段可以分为四个部分：</p>
<ul>
<li>第一部分为<code>diskQueue</code>当前读写的文件的状态，如读取或写入索引<code>readPos/writePos</code>，读取或写入文件编号<code>readFileNum/writeFileNum</code>，以及<code>depth</code>表示当前可供读取或消费的消息的数量；</li>
<li>第二部分为<code>diskQueue</code>的元数据信息，如单个文件最大大小<code>maxBytesPerFile</code>，每写多少条消息需要执行刷盘操作<code>syncEvery</code>等待；</li>
<li>第三部分是读写文件句柄<code>readFile/wirteFile</code>，以及文件读取流<code>reader</code>或写入缓冲<code>writeBuf</code>；</li>
<li>最后一部分为用于传递信号的内部管道，如<code>writeChan</code>，应用程序可通过此管道向<code>diskQueue</code>间接压入消息，<code>emptyChan</code>应用程序通过此管道间接发出清空<code>diskQueue</code>的信号等。</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// diskQueue 实现了一个基于后端持久化的 FIFO 队列</span></span><br><span class="line"><span class="keyword">type</span> diskQueue <span class="keyword">struct</span> &#123;</span><br><span class="line">	<span class="comment">// run-time state (also persisted to disk)</span></span><br><span class="line">	<span class="comment">// 运行时状态，需要被持久化</span></span><br><span class="line">	readPos      <span class="keyword">int64</span>					<span class="comment">// 当前的文件读取索引</span></span><br><span class="line">	writePos     <span class="keyword">int64</span>					<span class="comment">// 当前的文件写入索引</span></span><br><span class="line">	readFileNum  <span class="keyword">int64</span>					<span class="comment">// 当前读取的文件号</span></span><br><span class="line">	writeFileNum <span class="keyword">int64</span>					<span class="comment">// 当前写入的文件号</span></span><br><span class="line">	depth        <span class="keyword">int64</span>					<span class="comment">// diskQueue 中等待被读取的消息数</span></span><br><span class="line"></span><br><span class="line">	sync.RWMutex</span><br><span class="line"></span><br><span class="line">	<span class="comment">// instantiation time metadata</span></span><br><span class="line">	<span class="comment">// 初始化时元数据</span></span><br><span class="line">	name            <span class="keyword">string</span>				<span class="comment">// diskQueue 名称</span></span><br><span class="line">	dataPath        <span class="keyword">string</span>				<span class="comment">// 数据持久化路径</span></span><br><span class="line">	maxBytesPerFile <span class="keyword">int64</span> 				<span class="comment">// 目前，此此属性一旦被初始化，则不可变更</span></span><br><span class="line">	minMsgSize      <span class="keyword">int32</span>				<span class="comment">// 最小消息的大小</span></span><br><span class="line">	maxMsgSize      <span class="keyword">int32</span>				<span class="comment">// 最大消息的大小</span></span><br><span class="line">	syncEvery       <span class="keyword">int64</span>         		<span class="comment">// 累积的消息数量，才进行一次同步刷新到磁盘操作</span></span><br><span class="line">	syncTimeout     time.Duration 		<span class="comment">// 两次同步之间的间隔</span></span><br><span class="line">	exitFlag        <span class="keyword">int32</span>				<span class="comment">// 退出标志</span></span><br><span class="line">	needSync        <span class="keyword">bool</span>				<span class="comment">// 是否需要同步刷新</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// keeps track of the position where we have read</span></span><br><span class="line">	<span class="comment">// (but not yet sent over readChan)</span></span><br><span class="line">	<span class="comment">// 之所以存在 nextReadPos &amp; nextReadFileNum 和 readPos &amp; readFileNum</span></span><br><span class="line">    <span class="comment">// 是因为虽然消费者已经发起了数据读取请求，但 diskQueue 还未将此消息发送给消费者，</span></span><br><span class="line">	<span class="comment">// 当发送完成后，会将 readPos 更新到 nextReadPos，readFileNum 也类似</span></span><br><span class="line">	nextReadPos     <span class="keyword">int64</span>				<span class="comment">// 下一个应该被读取的索引位置</span></span><br><span class="line">	nextReadFileNum <span class="keyword">int64</span>				<span class="comment">// 下一个应该被读取的文件号</span></span><br><span class="line"></span><br><span class="line">	readFile  *os.File					<span class="comment">// 当前读取文件句柄</span></span><br><span class="line">	writeFile *os.File					<span class="comment">// 当前写入文件句柄</span></span><br><span class="line">	reader    *bufio.Reader				<span class="comment">// 当前文件读取流</span></span><br><span class="line">	writeBuf  bytes.Buffer				<span class="comment">// 当前文件写入流</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// exposed via ReadChan()</span></span><br><span class="line">	<span class="comment">// 应用程序可通过此通道从 diskQueue 中读取消息，</span></span><br><span class="line">    <span class="comment">// 因为 readChan 是 unbuffered的，所以，读取操作是同步的</span></span><br><span class="line">	<span class="comment">// 另外当一个文件中的数据被读取完时，文件会被删除，同时切换到下一个被读取的文件</span></span><br><span class="line">	readChan <span class="keyword">chan</span> []<span class="keyword">byte</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// internal channels</span></span><br><span class="line">    <span class="comment">// 应用程序通过此通道往 diskQueue压入消息，写入操作也是同步的</span></span><br><span class="line">	writeChan         <span class="keyword">chan</span> []<span class="keyword">byte</span> </span><br><span class="line">	writeResponseChan <span class="keyword">chan</span> error		<span class="comment">// 可通过此通道向应用程序返回消息写入结果</span></span><br><span class="line">	emptyChan         <span class="keyword">chan</span> <span class="keyword">int</span>			<span class="comment">// 应用程序可通过此通道发送清空 diskQueue 的消息</span></span><br><span class="line">	emptyResponseChan <span class="keyword">chan</span> error		<span class="comment">// 可通过此通道向应用程序返回清空 diskQueue 的结果</span></span><br><span class="line">	exitChan          <span class="keyword">chan</span> <span class="keyword">int</span>			<span class="comment">// 退出信号</span></span><br><span class="line">	exitSyncChan      <span class="keyword">chan</span> <span class="keyword">int</span>			<span class="comment">// 保证 ioLoop 已退出的信号</span></span><br><span class="line"></span><br><span class="line">	logf AppLogFunc</span><br><span class="line">&#125; <span class="comment">// diskQueue.go</span></span><br></pre></td></tr></table></figure>

<h2 id="diskQueue-构造方法"><a href="#diskQueue-构造方法" class="headerlink" title="diskQueue 构造方法"></a>diskQueue 构造方法</h2><p>首先考虑<code>diskQueue</code>在<code>nsq</code>系统中什么情况下会被实例化？答案是在实例化<code>topic</code>或<code>channel</code>时候。<code>diskQueue</code>的实例过程比较简单，首先根据传入的参数构造<code>diskQueue</code>实例，然后从配置文件中加载<code>diskQueue</code>的重要的属性状态，这包括<code>readPos &amp; writePos</code>,<code>readFileNum &amp; writerFileNum</code>和<code>depth</code>，并初始化<code>nextReadFileNum</code>和<code>nextReadPos</code>两个重要的属性。最后异步开启消息处理的主循环<code>ioLoop</code>方法。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// New 方法初始化一个 diskQueue 实例，并从持久化存储中加载元数据信息，然后开始启动</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">(name <span class="keyword">string</span>, dataPath <span class="keyword">string</span>, maxBytesPerFile <span class="keyword">int64</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">	minMsgSize <span class="keyword">int32</span>, maxMsgSize <span class="keyword">int32</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">	syncEvery <span class="keyword">int64</span>, syncTimeout time.Duration, logf AppLogFunc)</span> <span class="title">Interface</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 实例化 diskQueue</span></span><br><span class="line">	d := diskQueue&#123;</span><br><span class="line">		name:              name,</span><br><span class="line">		dataPath:          dataPath,</span><br><span class="line">		maxBytesPerFile:   maxBytesPerFile,</span><br><span class="line">		minMsgSize:        minMsgSize,</span><br><span class="line">		maxMsgSize:        maxMsgSize,</span><br><span class="line">		readChan:          <span class="built_in">make</span>(<span class="keyword">chan</span> []<span class="keyword">byte</span>),</span><br><span class="line">		writeChan:         <span class="built_in">make</span>(<span class="keyword">chan</span> []<span class="keyword">byte</span>),</span><br><span class="line">		writeResponseChan: <span class="built_in">make</span>(<span class="keyword">chan</span> error),</span><br><span class="line">		emptyChan:         <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>),</span><br><span class="line">		emptyResponseChan: <span class="built_in">make</span>(<span class="keyword">chan</span> error),</span><br><span class="line">		exitChan:          <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>),</span><br><span class="line">		exitSyncChan:      <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>),</span><br><span class="line">		syncEvery:         syncEvery,</span><br><span class="line">		syncTimeout:       syncTimeout,</span><br><span class="line">		logf:              logf,</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 从持久化存储中初始化 diskQueue 的一些属性状态： readPos, writerPos, depth 等</span></span><br><span class="line">	err := d.retrieveMetaData()</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// 3. 在一个单独的 goroutien 中执行主循环</span></span><br><span class="line">	<span class="keyword">go</span> d.ioLoop()</span><br><span class="line">	<span class="keyword">return</span> &amp;d</span><br><span class="line">&#125; <span class="comment">// diskQueue.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 从持久化存储中初始化 diskQueue 的一些属性状态</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *diskQueue)</span> <span class="title">retrieveMetaData</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> f *os.File</span><br><span class="line">	<span class="keyword">var</span> err error</span><br><span class="line">	<span class="comment">// 1. 获取元数据文件名 *.diskqueue.meta.dat，并打开文件，准备读取文件</span></span><br><span class="line">	fileName := d.metaDataFileName()</span><br><span class="line">	f, err = os.OpenFile(fileName, os.O_RDONLY, <span class="number">0600</span>)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">defer</span> f.Close()</span><br><span class="line">	<span class="comment">// 2. 从文件中内容初始化特定状态属性信息 readPos, writerPos, depth</span></span><br><span class="line">	<span class="keyword">var</span> depth <span class="keyword">int64</span></span><br><span class="line">	_, err = fmt.Fscanf(f, <span class="string">"%d\n%d,%d\n%d,%d\n"</span>,</span><br><span class="line">		&amp;depth,</span><br><span class="line">		&amp;d.readFileNum, &amp;d.readPos,</span><br><span class="line">		&amp;d.writeFileNum, &amp;d.writePos)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 3. 初始化 nextReadFileNum 和 nextReadPos</span></span><br><span class="line">	atomic.StoreInt64(&amp;d.depth, depth)</span><br><span class="line">	d.nextReadFileNum = d.readFileNum</span><br><span class="line">	d.nextReadPos = d.readPos</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="diskQueue-消息处理主循环"><a href="#diskQueue-消息处理主循环" class="headerlink" title="diskQueue 消息处理主循环"></a>diskQueue 消息处理主循环</h2><p><code>diskQueue</code>消息处理主循环<code>ioLoop</code>在其被实例化后就会开始执行。<code>diskQueue</code>包含的逻辑主要包括四个方面：从文件中读取一条消息，并压入到<code>readChan</code>管道中；将应用程序传入的消息，写入到文件；每隔一段时间，将写入缓冲的数据执行刷盘动作；最后是当应用程序调用清空<code>diskQueue</code>的接口时，执行删除并关闭<code>diskQueue</code>的动作。同时，笔者在阐述这些流程的实现细节的同时，将应用程序如何同<code>diskQueue</code>交互放在一起串联分析。下面的代码是<code>ioLoop</code>的大致框架，为了使框架更清晰省略了细节：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// diskQueue 消息处理主循环</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *diskQueue)</span> <span class="title">ioLoop</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="comment">// 1. 只有写入缓冲中的消息达到一定数量，才执行同步刷新到磁盘的操作</span></span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		<span class="comment">// 2. 刷新磁盘操作，重置计数信息，即将 writeFile 流刷新到磁盘，同时持久化元数据</span></span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">        <span class="comment">// 3. 从文件中读取消息的逻辑</span></span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="comment">// 4. 当读取到数据时，将它压入到 r/readChan 通道，</span></span><br><span class="line">            <span class="comment">// 同时判断是否需要更新到下一个文件读取，同时设置 needSync</span></span><br><span class="line">		<span class="keyword">case</span> r &lt;- dataRead:</span><br><span class="line">			<span class="comment">// ...</span></span><br><span class="line">		<span class="comment">// 5. 收到清空持久化存储 disQueue 的消息</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-d.emptyChan: <span class="comment">// (当应用程序调用 diskQueue.Empty 方法时触发)</span></span><br><span class="line">			<span class="comment">// ...</span></span><br><span class="line">		<span class="comment">// 6. 收到写入消息到磁盘的消息 (当应用程序调用 diskQueue.Put 方法时触发)</span></span><br><span class="line">		<span class="keyword">case</span> dataWrite := &lt;-d.writeChan:</span><br><span class="line">			<span class="comment">// ...</span></span><br><span class="line">		<span class="comment">// 7. 定时执行刷盘操作，在存在数据等待刷盘时，才需要执行刷盘动作</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-syncTicker.C:</span><br><span class="line">			<span class="comment">// ...</span></span><br><span class="line">		<span class="comment">// 8. 退出信号</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-d.exitChan:</span><br><span class="line">			<span class="keyword">goto</span> exit</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">exit:</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125; <span class="comment">// diskQueue.go</span></span><br></pre></td></tr></table></figure>

<h3 id="diskQueue-读取消息"><a href="#diskQueue-读取消息" class="headerlink" title="diskQueue 读取消息"></a>diskQueue 读取消息</h3><p>从<code>diskQueue</code>读取一条消息涉及到的<code>ioLoop</code>方法中的步骤3和4，其中步骤2的核心逻辑为：若当前持久化中还有未被读取或消费的消息，则尝试从特定的文件(<code>readFileNum</code>)、特定偏移位置(<code>readPos</code>)读取一条消息。这个过程并不复杂，值得注意的一点是：程序中还使用了另外一组与读取相关的状态(<code>nextReadFileNum</code>和<code>nextReadPos</code>)。当消息未从文件中读取时，<code>readPos == nextReadPos &amp;&amp; readFileNum == nextReadFileNum</code> ，当消息已从文件中读出但未发送给应用程序时，<code>readPos + totalBytes == nextReadPos &amp;&amp; readFileNum == nextReadFileNum</code>（若涉及到文件切换，则<code>nextReadFileNum++ &amp;&amp; nextReadPos == 0</code>），当消息已经发送给应用程序时，<code>readPos == nextReadPos &amp;&amp; readFileNum == nextReadFileNum</code>。换言之，之所以存在<code>nextReadFileNum</code>和<code>nextReadPos</code>是因为虽然消费者已经发起了数据读取请求，但 <code>diskQueue</code>还未将此消息发送给消费者，当发送完成后，会将它们相应更新。好，文件读取过程已经阐述完毕。当消息从文件中读取出来后，是通过<code>diskQueue.readChan</code>发送给上层应用程序的，上层应用程序通过调用<code>diskQueue.ReadChan</code>获取到此管道实例，并一直等待从此管道接收消息。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取 diskQueu 的读取通道，即 readChan，通过此通道从 diskQueue 中读取/消费消息</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *diskQueue)</span> <span class="title">ReadChan</span><span class="params">()</span> <span class="title">chan</span> []<span class="title">byte</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> d.readChan</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *diskQueue)</span> <span class="title">ioLoop</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> dataRead []<span class="keyword">byte</span></span><br><span class="line">	<span class="keyword">var</span> err error</span><br><span class="line">	<span class="keyword">var</span> count <span class="keyword">int64</span></span><br><span class="line">	<span class="keyword">var</span> r <span class="keyword">chan</span> []<span class="keyword">byte</span></span><br><span class="line">	syncTicker := time.NewTicker(d.syncTimeout)</span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="comment">// dont sync all the time :)</span></span><br><span class="line">		<span class="comment">// 1. 只有写入缓冲中的消息达到一定数量，才执行同步刷新到磁盘的操作</span></span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		<span class="comment">// 2. 刷新磁盘操作，重置计数信息，即将 writeFile 流刷新到磁盘，同时持久化元数据</span></span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		<span class="comment">// 3. 若当前还有数据（消息）可供消费</span></span><br><span class="line">        <span class="comment">// （即当前读取的文件编号 readFileNum &lt; 目前已经写入的文件编号 writeFileNum</span></span><br><span class="line">		<span class="comment">// 或者 当前的读取索引 readPos &lt; 当前的写的索引 writePos）</span></span><br><span class="line">		<span class="comment">// 因为初始化读每一个文件时都需要重置 readPos = 0</span></span><br><span class="line">		<span class="keyword">if</span> (d.readFileNum &lt; d.writeFileNum) || (d.readPos &lt; d.writePos) &#123;</span><br><span class="line">			<span class="comment">// 保证当前处于可读取的状态，即 readPos + totalByte == nextReadPos，</span></span><br><span class="line">			<span class="comment">// 若二者相等，则需要通过 d.readOne 方法先更新 nextReadPos</span></span><br><span class="line">			<span class="keyword">if</span> d.nextReadPos == d.readPos &#123;</span><br><span class="line">				dataRead, err = d.readOne()</span><br><span class="line">				<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">					d.logf(ERROR, <span class="string">"DISKQUEUE(%s) reading at %d of %s - %s"</span>,</span><br><span class="line">						d.name, d.readPos, d.fileName(d.readFileNum), err)</span><br><span class="line">					d.handleReadError()</span><br><span class="line">					<span class="keyword">continue</span></span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">// 取出读取通道 readChan</span></span><br><span class="line">			r = d.readChan</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 当 r == nil时，代表此时消息已经全部读取完毕，</span></span><br><span class="line">            <span class="comment">// 因此使用 select 不能将数据（消息）压入其中</span></span><br><span class="line">			r = <span class="literal">nil</span> </span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="comment">// 4. 当读取到数据时，将它压入到 r/readChan 通道，</span></span><br><span class="line">            <span class="comment">// 同时判断是否需要更新到下一个文件读取，同时设置 needSync</span></span><br><span class="line">		<span class="keyword">case</span> r &lt;- dataRead:</span><br><span class="line">			count++ <span class="comment">// 更新当前等待刷盘的消息数量</span></span><br><span class="line">			<span class="comment">// 判断是否可以将磁盘中读取的上一个文件删除掉（已经读取完毕），同时需要设置 needSync</span></span><br><span class="line">			<span class="comment">// 值得注意的是，moveForward 方法中将 readPos 更新为了 nextReadPos，</span></span><br><span class="line">            <span class="comment">// 且 readFileNum 也被更新为 nextReadFileNum</span></span><br><span class="line">			<span class="comment">// 因为此时消息已经发送给了消费者了。</span></span><br><span class="line">			d.moveForward()</span><br><span class="line">		<span class="comment">// 5. 收到清空持久化存储 disQueue 的消息</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-d.emptyChan: <span class="comment">// (当应用程序调用 diskQueue.Empty 方法时触发)</span></span><br><span class="line">			<span class="comment">// ...</span></span><br><span class="line">		<span class="comment">// 6. 收到写入消息到磁盘的消息 (当应用程序调用 diskQueue.Put 方法时触发)</span></span><br><span class="line">		<span class="keyword">case</span> dataWrite := &lt;-d.writeChan:</span><br><span class="line">			<span class="comment">// ...</span></span><br><span class="line">		<span class="comment">// 7. 定时执行刷盘操作，在存在数据等待刷盘时，才需要执行刷盘动作</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-syncTicker.C:</span><br><span class="line">			<span class="comment">// ...</span></span><br><span class="line">		<span class="comment">// 8. 退出信号</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-d.exitChan:</span><br><span class="line">			<span class="keyword">goto</span> exit</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">exit:</span><br><span class="line">	syncTicker.Stop()</span><br><span class="line">	d.exitSyncChan &lt;- <span class="number">1</span></span><br><span class="line">&#125; <span class="comment">// diskQueue.go</span></span><br></pre></td></tr></table></figure>

<p>当消息被压入到<code>readChan</code>管道后，随即更新等待刷盘的消息数量，然后调用<code>diskQueue.moveForward</code>方法判断是否可以将磁盘中读取的上一个文件删除掉（已经读取完毕），同时考虑是否需要设置<code>needSync</code>（因为即将读取一个新的文件），最后复原<code>readFileNum</code>和<code>readPos</code>并更新等待被读取的消息数量<code>depth</code>。相关源码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 检查当前读取的文件和上一次读取的文件是否为同一个，即读取是否涉及到文件的更换，</span></span><br><span class="line"><span class="comment">// 若是，则说明可以将磁盘中上一个文件删除掉，因为上一个文件包含的消息已经读取完毕，</span></span><br><span class="line"><span class="comment">// 同时需要设置 needSync</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *diskQueue)</span> <span class="title">moveForward</span><span class="params">()</span></span> &#123;</span><br><span class="line">	oldReadFileNum := d.readFileNum</span><br><span class="line">	d.readFileNum = d.nextReadFileNum</span><br><span class="line">	d.readPos = d.nextReadPos</span><br><span class="line">	depth := atomic.AddInt64(&amp;d.depth, <span class="number">-1</span>)</span><br><span class="line">	<span class="keyword">if</span> oldReadFileNum != d.nextReadFileNum &#123;</span><br><span class="line">		<span class="comment">// 每当准备读取一个新的文件时，需要设置 needSync</span></span><br><span class="line">		d.needSync = <span class="literal">true</span></span><br><span class="line">		fn := d.fileName(oldReadFileNum)</span><br><span class="line">		err := os.Remove(fn) <span class="comment">// 将老的文件删除</span></span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 检测文件末尾是否已经损坏</span></span><br><span class="line">	d.checkTailCorruption(depth)</span><br><span class="line">&#125; <span class="comment">// diskQueue.go</span></span><br></pre></td></tr></table></figure>

<p>注意到在<code>moveForward</code>方法的最后，还检查了文件末尾是否损坏。它先通过元数据信息（4个变量）判断是否已经读到了最后一个文件的末尾，若未到，则返回。否则，通过<code>depth</code>与0的大小关系来判断文件损坏的类型或原因。详细可以查看源码中的注释，解释得较为清楚。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 检测文件末尾是否已经损坏</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *diskQueue)</span> <span class="title">checkTailCorruption</span><span class="params">(depth <span class="keyword">int64</span>)</span></span> &#123;</span><br><span class="line">	<span class="comment">// 若当前还有消息可供读取，则说明未读取到文件末尾，暂时不用检查</span></span><br><span class="line">	<span class="keyword">if</span> d.readFileNum &lt; d.writeFileNum || d.readPos &lt; d.writePos &#123;</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// we've reached the end of the diskqueue</span></span><br><span class="line">	<span class="comment">// if depth isn't 0 something went wrong</span></span><br><span class="line">	<span class="comment">// 若代码能够执行，则正常情况下，说明已经读取到 diskQueue 的尾部，</span></span><br><span class="line">	<span class="comment">// 即读取到了最后一个文件的尾部了，因此，此时的 depth(累积等待读取或消费的消息数量)</span></span><br><span class="line">	<span class="comment">// 应该为0,因此若其不为0,则表明文件尾部已经损坏，报错。</span></span><br><span class="line">	<span class="comment">// 一方面，若其小于 0,则表明初始化加载的元数据已经损坏（depth从元数据文件中读取而来）</span></span><br><span class="line">	<span class="comment">// 原因是：实际上文件还有可供读取的消息，但depth指示没有了，因此 depth 计数错误。</span></span><br><span class="line">	<span class="comment">// 否则，说明是消息实体数据存在丢失的情况</span></span><br><span class="line">	<span class="comment">// 原因是：实际上还有消息可供读取 depth &gt; 0,但是文件中已经没有消息了，因此文件被损坏。</span></span><br><span class="line">	<span class="comment">// 同时，强制重置 depth，并且设置 needSync</span></span><br><span class="line">	<span class="keyword">if</span> depth != <span class="number">0</span> &#123;</span><br><span class="line">		<span class="keyword">if</span> depth &lt; <span class="number">0</span> &#123;</span><br><span class="line">			d.logf(ERROR,</span><br><span class="line">				<span class="string">"DISKQUEUE(%s) negative depth at tail (%d), metadata corruption,"</span> \</span><br><span class="line">                   resetting <span class="number">0.</span>..<span class="string">", d.name, depth)</span></span><br><span class="line"><span class="string">		&#125; else if depth &gt; 0 &#123;</span></span><br><span class="line"><span class="string">			d.logf(ERROR,</span></span><br><span class="line"><span class="string">				"</span>DISKQUEUE(%s) positive depth at tail (%d), data loss, resetting <span class="number">0.</span>..<span class="string">",</span></span><br><span class="line"><span class="string">				d.name, depth)</span></span><br><span class="line"><span class="string">		&#125;</span></span><br><span class="line"><span class="string">		// force set depth 0</span></span><br><span class="line"><span class="string">		atomic.StoreInt64(&amp;d.depth, 0)</span></span><br><span class="line"><span class="string">		d.needSync = true</span></span><br><span class="line"><span class="string">	&#125;</span></span><br><span class="line"><span class="string">	// 另外，若 depth == 0。</span></span><br><span class="line"><span class="string">	// 但文件读取记录信息不合法 d.readFileNum != d.writeFileNum || d.readPos != d.writePos</span></span><br><span class="line"><span class="string">	// 则跳过接下来需要被读或写的所有文件，类似于重置持久化存储的状态，格式化操作</span></span><br><span class="line"><span class="string">	// 同时设置 needSync</span></span><br><span class="line"><span class="string">	if d.readFileNum != d.writeFileNum || d.readPos != d.writePos &#123;</span></span><br><span class="line"><span class="string">		if d.readFileNum &gt; d.writeFileNum &#123;</span></span><br><span class="line"><span class="string">			d.logf(ERROR,</span></span><br><span class="line"><span class="string">				"</span>DISKQUEUE(%s) readFileNum &gt; writeFileNum (%d &gt; %d), <span class="string">" \</span></span><br><span class="line"><span class="string">                   "</span>corruption, skipping to next writeFileNum and resetting <span class="number">0.</span>..<span class="string">",</span></span><br><span class="line"><span class="string">				d.name, d.readFileNum, d.writeFileNum)</span></span><br><span class="line"><span class="string">		&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">		if d.readPos &gt; d.writePos &#123;</span></span><br><span class="line"><span class="string">			d.logf(ERROR,</span></span><br><span class="line"><span class="string">				"</span>DISKQUEUE(%s) readPos &gt; writePos (%d &gt; %d), corruption, <span class="string">"  \</span></span><br><span class="line"><span class="string">                   "</span>skipping to next writeFileNum and resetting <span class="number">0.</span>..<span class="string">",</span></span><br><span class="line"><span class="string">				d.name, d.readPos, d.writePos)</span></span><br><span class="line"><span class="string">		&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">		d.skipToNextRWFile()</span></span><br><span class="line"><span class="string">		d.needSync = true</span></span><br><span class="line"><span class="string">	&#125;</span></span><br><span class="line"><span class="string">&#125; // diskQueue.go</span></span><br></pre></td></tr></table></figure>

<p>当程序发现在<code>depth == 0</code>的情况下，即此时所有的消息已经被读取完毕，但若某个异常的情况下，可能会有：<code>readFileNum != writeFileNum || readPos != writePos</code>，则<code>diskQueue</code>会显式地删除掉接下来需要被读或写的所有文件，类似于重置持久化存储的状态或格式化操作。同时，<code>skipToNextRWFile</code>也可用作清空 <code>diskQueue</code>当前未读取的所有文件。具体代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 将 readFileNum 到 writeFileNum 之间的文件全部删除</span></span><br><span class="line"><span class="comment">// 将 readFileNum 设置为 writeFileNum</span></span><br><span class="line"><span class="comment">// 即将前面不正确的文件全部删除掉，重新开始读取</span></span><br><span class="line"><span class="comment">// 另外，其也可用作清空 diskQueue 当前未读取的所有文件的操作，重置 depth</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *diskQueue)</span> <span class="title">skipToNextRWFile</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> err error</span><br><span class="line">	<span class="keyword">if</span> d.readFile != <span class="literal">nil</span> &#123;</span><br><span class="line">		d.readFile.Close()</span><br><span class="line">		d.readFile = <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> d.writeFile != <span class="literal">nil</span> &#123;</span><br><span class="line">		d.writeFile.Close()</span><br><span class="line">		d.writeFile = <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">for</span> i := d.readFileNum; i &lt;= d.writeFileNum; i++ &#123;</span><br><span class="line">		fn := d.fileName(i)</span><br><span class="line">		innerErr := os.Remove(fn)</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">	&#125;</span><br><span class="line">	d.writeFileNum++</span><br><span class="line">	d.writePos = <span class="number">0</span></span><br><span class="line">	d.readFileNum = d.writeFileNum</span><br><span class="line">	d.readPos = <span class="number">0</span></span><br><span class="line">	d.nextReadFileNum = d.writeFileNum</span><br><span class="line">	d.nextReadPos = <span class="number">0</span></span><br><span class="line">	atomic.StoreInt64(&amp;d.depth, <span class="number">0</span>)</span><br><span class="line">	<span class="keyword">return</span> err</span><br><span class="line">&#125; <span class="comment">// diskQueue.go</span></span><br></pre></td></tr></table></figure>

<p>至此，从<code>diskQueue</code>的文件系统中读取消息，并发送到上层应用程序的相关逻辑已经阐述完毕。除了需要清楚其读取核心逻辑外，还需要关注其对文件损坏的检测与处理。</p>
<h3 id="diskQueue-写入消息"><a href="#diskQueue-写入消息" class="headerlink" title="diskQueue 写入消息"></a>diskQueue 写入消息</h3><p>当<code>topic</code>或<code>channel</code>所维护的内存消息队列<code>memoryMsgChan</code>满了时，会通过调用<code>backend.Put</code>方法将消息写入到<code>diskQueue</code>。消息写入持久化存储的逻辑比从文件系统中读取一条消息的逻辑要简单。其关键步骤为先定位写入索引，同样是先写临时文件缓冲再执行数据刷新操作，最后需要更新<code>writePos</code>，当发现要切换写入文件时，还要更新<code>writeFileNum</code>。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *diskQueue)</span> <span class="title">ioLoop</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="comment">// 1-5.</span></span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">		<span class="comment">// 6. 收到写入消息到磁盘的消息 (当应用程序调用 diskQueue.Put 方法时触发)</span></span><br><span class="line">		<span class="keyword">case</span> dataWrite := &lt;-d.writeChan:</span><br><span class="line">			<span class="comment">// 删除目前还未读取的文件，同时删除元数据文件</span></span><br><span class="line">			d.emptyResponseChan &lt;- d.deleteAllFiles()</span><br><span class="line">			count = <span class="number">0</span> <span class="comment">// 重置当前等待刷盘的消息数量</span></span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">&#125; <span class="comment">// diskQueue.go</span></span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 将一个字节数组内容写入到持久化存储，同时更新读写位置信息，以及判断是否需要滚动文件</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *diskQueue)</span> <span class="title">writeOne</span><span class="params">(data []<span class="keyword">byte</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> err error</span><br><span class="line">	<span class="comment">// 1. 若当前写入文件句柄为空，则需要先实例化</span></span><br><span class="line">	<span class="keyword">if</span> d.writeFile == <span class="literal">nil</span> &#123;</span><br><span class="line">		curFileName := d.fileName(d.writeFileNum)</span><br><span class="line">		d.writeFile, err = os.OpenFile(curFileName, os.O_RDWR|os.O_CREATE, <span class="number">0600</span>)</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		d.logf(INFO, <span class="string">"DISKQUEUE(%s): writeOne() opened %s"</span>, d.name, curFileName)</span><br><span class="line">		<span class="comment">// 2. 同时，若当前的写入索引大于0,则重新定位写入索引</span></span><br><span class="line">		<span class="keyword">if</span> d.writePos &gt; <span class="number">0</span> &#123;</span><br><span class="line">			_, err = d.writeFile.Seek(d.writePos, <span class="number">0</span>)</span><br><span class="line">			<span class="comment">// ...</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 3. 获取写入数据长度，并检查长度合法性。然后将数据写入到写入缓冲，</span></span><br><span class="line">    <span class="comment">// 最后将写入缓冲的数据一次性刷新到文件</span></span><br><span class="line">	dataLen := <span class="keyword">int32</span>(<span class="built_in">len</span>(data))</span><br><span class="line">	<span class="keyword">if</span> dataLen &lt; d.minMsgSize || dataLen &gt; d.maxMsgSize &#123;</span><br><span class="line">		<span class="keyword">return</span> fmt.Errorf(<span class="string">"invalid message write size (%d) maxMsgSize=%d"</span>, </span><br><span class="line">                          dataLen, d.maxMsgSize)</span><br><span class="line">	&#125;</span><br><span class="line">	d.writeBuf.Reset()</span><br><span class="line">	err = binary.Write(&amp;d.writeBuf, binary.BigEndian, dataLen)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	_, err = d.writeBuf.Write(data)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// only write to the file once</span></span><br><span class="line">	_, err = d.writeFile.Write(d.writeBuf.Bytes())</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// 更新写入索引 writePos 及 depth，且若 writePos 大于 maxBytesPerFile，</span></span><br><span class="line">    <span class="comment">// 则说明当前已经写入到文件的末尾。</span></span><br><span class="line">	<span class="comment">// 因此需要更新 writeFileNum，重置 writePos，</span></span><br><span class="line">    <span class="comment">// 即更换到一个新的文件执行写入操作（为了避免一直写入单个文件）</span></span><br><span class="line">	<span class="comment">// 且每一次更换到下一个文件，都需要将写入文件同步到磁盘</span></span><br><span class="line">	totalBytes := <span class="keyword">int64</span>(<span class="number">4</span> + dataLen)</span><br><span class="line">	d.writePos += totalBytes</span><br><span class="line">	atomic.AddInt64(&amp;d.depth, <span class="number">1</span>)</span><br><span class="line">	<span class="keyword">if</span> d.writePos &gt; d.maxBytesPerFile &#123;</span><br><span class="line">		d.writeFileNum++</span><br><span class="line">		d.writePos = <span class="number">0</span></span><br><span class="line">		<span class="comment">// sync every time we start writing to a new file</span></span><br><span class="line">		err = d.sync()</span><br><span class="line">		<span class="comment">// ..</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> err</span><br><span class="line">&#125; <span class="comment">// diskQueue.go</span></span><br></pre></td></tr></table></figure>

<h3 id="diskQueue-清空消息"><a href="#diskQueue-清空消息" class="headerlink" title="diskQueue 清空消息"></a>diskQueue 清空消息</h3><p>当应用程序调用<code>diskQueue.Empty</code>接口时，会将持久化存储<code>diskQueue</code>中的所有消息清空，并重置了所有状态属性信息，类似于一个格式化操作。还记得上面在阐述读取消息的流程中涉及到的<code>diskQueue.skipToNextRWFile</code>方法吗，它的一个作用就是删除<code>diskQueue</code>当前未读取的所有文件。除此之外，清空消息操作还删除了元数据文件。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 清空 diskQueue 中未读取的文件</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *diskQueue)</span> <span class="title">Empty</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	d.RLock()</span><br><span class="line">	<span class="keyword">defer</span> d.RUnlock()</span><br><span class="line">	<span class="keyword">if</span> d.exitFlag == <span class="number">1</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> errors.New(<span class="string">"exiting"</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	d.logf(INFO, <span class="string">"DISKQUEUE(%s): emptying"</span>, d.name)</span><br><span class="line">	d.emptyChan &lt;- <span class="number">1</span></span><br><span class="line">	<span class="keyword">return</span> &lt;-d.emptyResponseChan</span><br><span class="line">&#125; <span class="comment">// diskQueue.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// diskQueue 消息处理主循环</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *diskQueue)</span> <span class="title">ioLoop</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="comment">// 1-3.</span></span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="comment">// 4.</span></span><br><span class="line">        <span class="comment">// ...    </span></span><br><span class="line">		<span class="comment">// 5. 收到清空持久化存储 disQueue 的消息</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-d.emptyChan: <span class="comment">// (当应用程序调用 diskQueue.Empty 方法时触发)</span></span><br><span class="line">			<span class="comment">// 删除目前还未读取的文件，同时删除元数据文件</span></span><br><span class="line">			d.emptyResponseChan &lt;- d.deleteAllFiles()</span><br><span class="line">			count = <span class="number">0</span> <span class="comment">// 重置当前等待刷盘的消息数量</span></span><br><span class="line">		<span class="comment">// 6-8</span></span><br><span class="line">        <span class="comment">// ...    </span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">&#125; <span class="comment">// diskQueue.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 调用 skipToNextRWFile 方法清空 readFileNum -&gt; writeFileNum 之间的文件，</span></span><br><span class="line"><span class="comment">// 并且设置 depth 为 0。 同时删除元数据文件</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *diskQueue)</span> <span class="title">deleteAllFiles</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	err := d.skipToNextRWFile()</span><br><span class="line">	innerErr := os.Remove(d.metaDataFileName())</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">return</span> err</span><br><span class="line">&#125; <span class="comment">// diskQueue.go</span></span><br></pre></td></tr></table></figure>

<h3 id="diskQueue-刷盘操作"><a href="#diskQueue-刷盘操作" class="headerlink" title="diskQueue 刷盘操作"></a>diskQueue 刷盘操作</h3><p>同大多的存储系统类似，<code>diskQueue</code>采用批量刷新缓冲区的操作来提高消息写入文件系统的性能。其中，<code>diskQueue</code>规定触发刷盘动作的有个条件，其中任一条件成立即可。一是当缓冲区中的消息的数量达到阈值(<code>syncEvery</code>)时，二是每隔指定时间(<code>syncTimeout</code>)。需要注意的一点为在执行刷盘动作，也会重新持久化<code>diskQueue</code>的元数据信息。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *diskQueue)</span> <span class="title">ioLoop</span><span class="params">()</span></span> &#123;</span><br><span class="line">	syncTicker := time.NewTicker(d.syncTimeout)</span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="comment">// dont sync all the time :)</span></span><br><span class="line">		<span class="comment">// 1. 只有写入缓冲中的消息达到一定数量，才执行同步刷新到磁盘的操作</span></span><br><span class="line">		<span class="keyword">if</span> count == d.syncEvery &#123;</span><br><span class="line">			d.needSync = <span class="literal">true</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 2. 刷新磁盘操作，重置计数信息，即将 writeFile 流刷新到磁盘，同时持久化元数据</span></span><br><span class="line">		<span class="keyword">if</span> d.needSync &#123;</span><br><span class="line">			err = d.sync()</span><br><span class="line">			<span class="comment">// ...</span></span><br><span class="line">			count = <span class="number">0</span> <span class="comment">// 重置当前等待刷盘的消息数量</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 3.</span></span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="comment">// 4-6</span></span><br><span class="line">        <span class="comment">// ...    </span></span><br><span class="line">		<span class="comment">// 7. 定时执行刷盘操作，在存在数据等待刷盘时，才需要执行刷盘动作</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-syncTicker.C:</span><br><span class="line">			<span class="keyword">if</span> count == <span class="number">0</span> &#123;</span><br><span class="line">				<span class="comment">// avoid sync when there's no activity</span></span><br><span class="line">				<span class="keyword">continue</span></span><br><span class="line">			&#125;</span><br><span class="line">			d.needSync = <span class="literal">true</span></span><br><span class="line">		<span class="comment">// 8.</span></span><br><span class="line">        <span class="comment">// ...    </span></span><br><span class="line">	&#125;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">&#125; <span class="comment">// diskQueue.go</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">// 同步刷新 writeFile 文件流（即将操作系统缓冲区中的数据写入到磁盘），同时持久化元数据信息</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *diskQueue)</span> <span class="title">sync</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> d.writeFile != <span class="literal">nil</span> &#123;</span><br><span class="line">		err := d.writeFile.Sync()</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">	&#125;</span><br><span class="line">	err := d.persistMetaData()</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// 重置了刷新开关</span></span><br><span class="line">	d.needSync = <span class="literal">false</span></span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>简单小结，本文详细分析了持久化消息队列存储组件——<code>diskQueue</code>，它被用作<code>nsq</code>的消息持久化存储。围绕<code>diskQueue</code>展开，通过阐述其提供给上层应用程序的功能接口来分析其工作原理，重点梳理了从<code>diskQueue</code>中读取和写消息的逻辑，同一般的队列实现类似，采用一组索引标记读写的位置，只不过<code>diskQueue</code>采用了两组读取索引。另外，在读取消息的过程检测文件是否被损坏，同时在写入过程中，通过不断切换文件来限制写入单个文件的数据量。<code>diskQueue</code>同样提供了清空存储的所有消息（删除所有文件，并重置<code>diskQueue</code>状态信息）的操作（类似于文件系统的格式化操作），最后不要忘记缓冲区的批量刷新刷盘动作助于提高文件系统的写入性能。更完整的源码注释可参考<a href="https://github.com/qqzeng/nsqio/tree/master/go-diskqueue" target="_blank" rel="noopener">这里</a>。</p>
<p>参考文献</p>
<p>[1].<a href="https://github.com/nsqio/go-diskqueue" target="_blank" rel="noopener">https://github.com/nsqio/go-diskqueue</a></p>
]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title>物联网的设备防伪认证</title>
    <url>/2019/05/18/2019-05-18-%E7%89%A9%E8%81%94%E7%BD%91%E7%9A%84%E8%AE%BE%E5%A4%87%E9%98%B2%E4%BC%AA%E8%AE%A4%E8%AF%81/</url>
    <content><![CDATA[<h1 id="什么是防伪认证"><a href="#什么是防伪认证" class="headerlink" title="什么是防伪认证"></a>什么是防伪认证</h1><p>&emsp;&emsp;毫无疑问，是为了校验物联网产品的合法性，只有通过了合法性认证的物联网产品才能和物联网云建立连接。   </p>
<h1 id="为什么需要防伪认证"><a href="#为什么需要防伪认证" class="headerlink" title="为什么需要防伪认证"></a>为什么需要防伪认证</h1><p>&emsp;&emsp;物联网安全是物联网的重中之重，必须得到重视，而防伪认证时物联网安全的<strong>第一道门槛</strong>。  </p>
<h1 id="防伪模式有哪些"><a href="#防伪模式有哪些" class="headerlink" title="防伪模式有哪些"></a>防伪模式有哪些</h1><ol>
<li><strong>密钥认证模式</strong></li>
<li><strong>签名认证模式</strong></li>
</ol>
<a id="more"></a>

<h1 id="如何实现防伪认证"><a href="#如何实现防伪认证" class="headerlink" title="如何实现防伪认证"></a>如何实现防伪认证</h1><h2 id="密钥认证模式"><a href="#密钥认证模式" class="headerlink" title="密钥认证模式"></a>密钥认证模式</h2><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><p>&emsp;&emsp;物联网平台给每一个设备或者每一型号设备分配固定的<strong>产品ID</strong>和<strong>产品密钥</strong>，将SN码，MAC地址，产品ID和产品密钥四个参数写入flash，当设备注册时，携带以上四个参数请求物联网云，物联网云认证数据正确性之后，再响应<code>auth_token</code>和分配连接地址，每一次数据上传都需要携带<code>auth_token</code>。  </p>
<h3 id="流程图"><a href="#流程图" class="headerlink" title="流程图"></a>流程图</h3><p><img src="http://assets.processon.com/chart_image/5cdfbd4ee4b00446dc694dac.png" alt="物联网设备密钥防伪认证" title="物联网设备密钥防伪认证"></p>
<h2 id="签名认证模式"><a href="#签名认证模式" class="headerlink" title="签名认证模式"></a>签名认证模式</h2><h3 id="说明-1"><a href="#说明-1" class="headerlink" title="说明"></a>说明</h3><p>&emsp;&emsp;物联网平台给每一个设备的SN码和MAC地址进行私钥签名（如<strong>ECDSA_sign</strong>），将SN码，MAC地址和签名三个参数写入<code>flash</code>，当设备注册时，携带以上三个参数请求物联网云，然后物联网云进行公钥校验（如<strong>ECDSA_verify</strong>），再响应<code>auth_token</code>和分配连接地址，每一次数据上传都需要携带<code>auth_token</code>。  </p>
<h3 id="流程图-1"><a href="#流程图-1" class="headerlink" title="流程图"></a>流程图</h3><p><img src="http://assets.processon.com/chart_image/5cde7588e4b006c6eaa177c5.png" alt="物联网设备签名防伪认证" title="物联网设备签名防伪认证"></p>
<h2 id="两种模式比较"><a href="#两种模式比较" class="headerlink" title="两种模式比较"></a>两种模式比较</h2><table>
<thead>
<tr>
<th>模式</th>
<th>性能</th>
<th>安全</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>密钥认证模式</td>
<td>低</td>
<td>中</td>
<td>1. 需要查询数据或者缓存，增加服务端负载； 2. 需要提前将数据产生并持久化，要防止出现重复数据，生产烧写flash时进行下发数据；</td>
</tr>
<tr>
<td>签名认证模式</td>
<td>高</td>
<td>高</td>
<td>1. 要求硬件高性能的加密方式保存签名；2. 动态数字签名消耗的性能也不低，固定签名的数据需要持久化，也需要生产烧写flash时进行下发数据；</td>
</tr>
</tbody></table>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://www.cnblogs.com/fishou/p/4175509.html" target="_blank" rel="noopener">智能硬件设备防伪设计</a><br><a href="https://help.aliyun.com/document_detail/42649.html?spm=a2c4g.11186623.6.641.5b495483ULe3ox" target="_blank" rel="noopener">阿里云文档</a><br><a href="https://smartdev.jd.com/docCenterDoc/view/2/102/134000001/134000001#topMaoDot" target="_blank" rel="noopener">京东小京鱼文档</a>  </p>
]]></content>
      <categories>
        <category>万物互联</category>
      </categories>
  </entry>
  <entry>
    <title>nsq 消息发送订阅源码简析</title>
    <url>/2019/05/15/nsq-%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%AE%A2%E9%98%85%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/</url>
    <content><![CDATA[<p>上一篇文章阐述了<code>channel</code>模块的源码。以<code>channel</code>为核心分析<code>channel</code>结构组件、<code>channel</code>实例的创建、删除以及查找这四方面的源码逻辑，另外也简要分析了<code>Message</code>结构的字段，以及两个与消息发送相关的优先级队列<code>in-flight queue</code>和<code>deferred queue</code>。同时也将对应方法与其它方法进行串联分析，以在整体上把握程序逻辑。本文的主题是<code>nsq</code>消息队列系统中消息的发送和订阅相关源码的逻辑。本文的核心是阐述，当生产者将消息投递到某个<code>nsqd</code>实例上对应的<code>topic</code>时，消息是如何在<code>nsqd</code>内部各组件（包括<code>nsqd</code>、<code>topic</code>和<code>chanel</code>）之间流动的，并且分析<code>nsq</code>是如何处理延时消息的投递。另外，结合网络传输模块的源码，分析两个典型的过程：生产者发布消息的逻辑，以及消费者是订阅并获取消息的逻辑。此篇文章内容较前两篇复杂，它是<code>nsq</code>实时消息队列的核心部分，对理解<code>nsq</code>的关键工作原理至关重要。</p>
<a id="more"></a>

<p>本文阐述的内容更详细的源码注释可在<a href="https://github.com/qqzeng/nsqio/tree/master/nsq" target="_blank" rel="noopener">这里</a>找到，注释源码版本为<code>v1.1.0</code>，仅供参考。本文所涉及到源码文件主要为<code>/nsq/nsqd/</code>和<code>/nsq/internal/</code>下的若干子目录。具体而言，围绕<code>nsqd.go</code>、<code>topic.go</code>、<code>channel.go</code>展开，同时也会涉及到<code>protocol_v2.go</code>和<code>http.go</code>。</p>
<p>本文侧重于分析消息在<code>nsq</code>系统内部各组件之间是如何流动的，典型地，如消息是何时通过何种方式从<code>topic</code>实例流向<code>channel</code>实例的，另外，如何实现消息的延时投递逻辑，消息投递超时处理逻辑等。另外，也分析生产者是发布消息的到指定的<code>topic</code>的逻辑，以及消费者是订阅<code>channel</code>的逻辑，并且如何从订阅的<code>channel</code>收到消息。最后阐述客户端（生产者和消费者）使用的几个典型的命令请求。</p>
<h2 id="topic-消息处理逻辑"><a href="#topic-消息处理逻辑" class="headerlink" title="topic 消息处理逻辑"></a>topic 消息处理逻辑</h2><p>我们依据正常的消息发布的流程来阐述，以<code>topic</code>作为切入点，分析<code>topic</code>如何将从生产者收到的消息传递给与其关联的<code>channel</code>实例。当生产者发布一条消息到指定的<code>topic</code>时，请求在<code>protocolV2(protocol_v2.go)</code>实例接收，然后交由<code>protocolV2.PUB</code>方法处理，其接着调用<code>topic.PutMessage</code>方法向<code>topic</code>实例添加一条消息，由此消息就正式进入了<code>nsq</code>系统内部了。<code>PutMessage</code>方法通过调用<code>put</code>方法将接收的消息写入到消息队列，若内存消息队列(<code>memoryMsgChan</code>)未满，则 push 到内存消息队列，否则 push 到持久化存储消息队列(<code>backend</code>)。然后在<code>topic</code>的消息处理主循环中，从<code>memoryMsgChan</code>或<code>backendChan</code>管道中接收到新的消息，其随即遍历自己维护的所有<code>channel</code>实例，将此消息副本发送给每一个<code>channel</code>实例，即调用<code>chanel.PutMessage</code>将消息压入到<code>channel</code>维护的消息队列中（同样包括<code>memoryMsgChan</code>和<code>backend</code>两个），或者若此消息需要被延迟，则调用<code>channel.PutMessageDeferred</code>方法将消息压入到消息延时的优先级队列(<code>deferred queue</code>)。</p>
<p>好，<code>topic</code>处理消息的核心逻辑已经阐述完毕。我们贴出这个过程中消息流动所涉及到的方法调用链：<code>protocolV2.PUB-&gt;topic.PutMessage-&gt;topic.put-&gt;topic.messagPump-&gt;</code>，从这里开始分叉，对于正常的消息：<code>channel.PutMessage-&gt;channel.put</code>，最后写入<code>channel.memoryMsgChan</code>或<code>channel.backend</code>；对于被延时的消息：<code>channel.PutMessageDeferred-&gt;channel.StartDeferredTimeout-&gt;chanel.addToDeferredPQ-&gt;deferredPQ.push</code>。</p>
<p>核心流程如上所述，补充几点，<code>topic.messagePump</code>方法在<code>topic</code>启动（有可能是从配置文件中加载启动<code>LoadMetadata</code>或新创建时启动<code>GetTopic</code>）时开始工作，换言之，开始处理生产者给它发送的消息。另外，<code>messagePump</code>循环中也可能收到<code>topic</code>所维护的<code>channel</code>集合更新的消息（添加或移除），此时需要重新初始化两个消息队列管道(<code>memoryMsgChan &amp; backendChan</code>)。最后，当收到<code>paused</code>的消息时，会重置这两个消息队列管道，因为一旦<code>topic.Paused</code>属性被设置，则表示此<code>topic</code>不应该再处理消息。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// [ topic.go 文件中，由 topic 实例的消息处理逻辑 ]</span></span><br><span class="line"><span class="comment">// 此方法由 httpServer.PUB 或 protocolV2.PUB 方法中调用，即生产者通过 http/tcp 投递消息到 topic</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *Topic)</span> <span class="title">PutMessage</span><span class="params">(m *Message)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	t.RLock()</span><br><span class="line">	<span class="keyword">defer</span> t.RUnlock()</span><br><span class="line">	<span class="comment">// 1. 消息写入操作只在 exitFlag 为0时才进行</span></span><br><span class="line">	<span class="keyword">if</span> atomic.LoadInt32(&amp;t.exitFlag) == <span class="number">1</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> errors.New(<span class="string">"exiting"</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 写入消息内存队列 memoryMsgChan 或者 持久化存储 backend</span></span><br><span class="line">	err := t.put(m)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 3. 更新当前 topic 所对应的消息数量以及消息总大小</span></span><br><span class="line">	atomic.AddUint64(&amp;t.messageCount, <span class="number">1</span>)</span><br><span class="line">	atomic.AddUint64(&amp;t.messageBytes, <span class="keyword">uint64</span>(<span class="built_in">len</span>(m.Body)))</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/topic.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 将指定消息进行持久化</span></span><br><span class="line"><span class="comment">// 通常情况下，在 memoryMsChan 未达到其设置的最大的消息的数量时</span></span><br><span class="line"><span class="comment">// （即内存中的消息队列中保存的消息的数量未达到上限时，由 MemQueueSize 指定）</span></span><br><span class="line"><span class="comment">// 会先将消息 push 到内在消息队列 memoryChan 中，否则会被 push 到后端持久化队列 backend 中。</span></span><br><span class="line"><span class="comment">// 这是通过 go buffered channel 语法来实现。</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *Topic)</span> <span class="title">put</span><span class="params">(m *Message)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">select</span> &#123;</span><br><span class="line">	<span class="keyword">case</span> t.memoryMsgChan &lt;- m:</span><br><span class="line">	<span class="keyword">default</span>: <span class="comment">// 内存消息队列已满时，会将消息存放到持久化存储</span></span><br><span class="line">		<span class="comment">// 从缓冲池中获取缓冲</span></span><br><span class="line">		b := bufferPoolGet()</span><br><span class="line">		<span class="comment">// 将消息写入持久化消息队列</span></span><br><span class="line">		err := writeMessageToBackend(b, m, t.backend)</span><br><span class="line">		bufferPoolPut(b) <span class="comment">// 回收从缓冲池中获取的缓冲</span></span><br><span class="line">		t.ctx.nsqd.SetHealth(err)</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			t.ctx.nsqd.logf(LOG_ERROR,</span><br><span class="line">				<span class="string">"TOPIC(%s) ERROR: failed to write message to backend - %s"</span>,</span><br><span class="line">				t.name, err)</span><br><span class="line">			<span class="keyword">return</span> err</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;  <span class="comment">// /nsq/nsqd/topic.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// messagePump 监听 message 的更新的一些状态，以及时将消息持久化，</span></span><br><span class="line"><span class="comment">// 同时写入到此 topic 对应的channel</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *Topic)</span> <span class="title">messagePump</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> msg *Message</span><br><span class="line">	<span class="keyword">var</span> buf []<span class="keyword">byte</span></span><br><span class="line">	<span class="keyword">var</span> err error</span><br><span class="line">	<span class="keyword">var</span> chans []*Channel</span><br><span class="line">	<span class="keyword">var</span> memoryMsgChan <span class="keyword">chan</span> *Message</span><br><span class="line">	<span class="keyword">var</span> backendChan <span class="keyword">chan</span> []<span class="keyword">byte</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// 1. 等待开启 topic 消息处理循环，即等待调用 topic.Start，</span></span><br><span class="line">    <span class="comment">// 在 nsqd.GetTopic 和 nsqd.LoadMetadata 方法中调用</span></span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> &lt;-t.channelUpdateChan:</span><br><span class="line">			<span class="keyword">continue</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-t.pauseChan:</span><br><span class="line">			<span class="keyword">continue</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-t.exitChan:</span><br><span class="line">			<span class="keyword">goto</span> exit</span><br><span class="line">		<span class="comment">// 在 nsqd.Main 中最后一个阶段会开启消息处理循环 topic.Start</span></span><br><span class="line">            <span class="comment">// （处理由客户端（producers）向 topci 投递的消息）</span></span><br><span class="line">		<span class="comment">// 在此之前的那些信号全部忽略</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-t.startChan:</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">break</span></span><br><span class="line">	&#125;</span><br><span class="line">	t.RLock()</span><br><span class="line">	<span class="comment">// 2. 根据 topic.channelMap 初始化两个通道 memoryMsgChan，backendChan</span></span><br><span class="line">	<span class="comment">// 并且保证 topic.channelMap 存在 channel，且 topic 未被 paused</span></span><br><span class="line">	<span class="keyword">for</span> _, c := <span class="keyword">range</span> t.channelMap &#123;</span><br><span class="line">		chans = <span class="built_in">append</span>(chans, c)</span><br><span class="line">	&#125;</span><br><span class="line">	t.RUnlock()</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(chans) &gt; <span class="number">0</span> &amp;&amp; !t.IsPaused() &#123;</span><br><span class="line">		memoryMsgChan = t.memoryMsgChan</span><br><span class="line">		backendChan = t.backend.ReadChan()</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 3. topic 处理消息的主循环</span></span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="comment">// 3.1 从内存消息队列 memoryMsgChan 或 持久化存储 backend 中收到消息</span></span><br><span class="line">		<span class="comment">// 则将消息解码，然后会将消息 push 到此 topic 关联的所有 channel</span></span><br><span class="line">		<span class="keyword">case</span> msg = &lt;-memoryMsgChan:</span><br><span class="line">		<span class="keyword">case</span> buf = &lt;-backendChan:</span><br><span class="line">			msg, err = decodeMessage(buf)</span><br><span class="line">			<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">				t.ctx.nsqd.logf(LOG_ERROR, <span class="string">"failed to decode message - %s"</span>, err)</span><br><span class="line">				<span class="keyword">continue</span></span><br><span class="line">			&#125;</span><br><span class="line">		<span class="comment">// 3.2 当从 channelUpdateChan 读取到消息时，</span></span><br><span class="line">            <span class="comment">// 表明有 channel 更新，比如创建了新的 channel，</span></span><br><span class="line">		<span class="comment">// 因此需要重新初始化 memoryMsgChan及 backendChan</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-t.channelUpdateChan:</span><br><span class="line">			chans = chans[:<span class="number">0</span>]</span><br><span class="line">			t.RLock()</span><br><span class="line">			<span class="keyword">for</span> _, c := <span class="keyword">range</span> t.channelMap &#123;</span><br><span class="line">				chans = <span class="built_in">append</span>(chans, c)</span><br><span class="line">			&#125;</span><br><span class="line">			t.RUnlock()</span><br><span class="line">			<span class="keyword">if</span> <span class="built_in">len</span>(chans) == <span class="number">0</span> || t.IsPaused() &#123;</span><br><span class="line">				memoryMsgChan = <span class="literal">nil</span></span><br><span class="line">				backendChan = <span class="literal">nil</span></span><br><span class="line">			&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">				memoryMsgChan = t.memoryMsgChan</span><br><span class="line">				backendChan = t.backend.ReadChan()</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">continue</span></span><br><span class="line">		<span class="comment">// 3.3 当收到 pause 消息时，则将 memoryMsgChan及backendChan置为 nil，注意不能 close，</span></span><br><span class="line">		<span class="comment">// 二者的区别是 nil的chan不能接收消息了，但不会报错。</span></span><br><span class="line">            <span class="comment">// 而若从一个已经 close 的 chan 中尝试取消息，则会 panic。</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-t.pauseChan:</span><br><span class="line">			<span class="comment">// 当 topic 被 paused 时，其不会将消息投递到 channel 的消息队列</span></span><br><span class="line">			<span class="keyword">if</span> <span class="built_in">len</span>(chans) == <span class="number">0</span> || t.IsPaused() &#123;</span><br><span class="line">				memoryMsgChan = <span class="literal">nil</span></span><br><span class="line">				backendChan = <span class="literal">nil</span></span><br><span class="line">			&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">				memoryMsgChan = t.memoryMsgChan</span><br><span class="line">				backendChan = t.backend.ReadChan()</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">continue</span></span><br><span class="line">		<span class="comment">// 3.4 当调用 topic.exit 时会收到信号，以终止 topic 的消息处理循环</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-t.exitChan:</span><br><span class="line">			<span class="keyword">goto</span> exit</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 4. 当从 memoryMsgChan 或 backendChan 中 pull 到一个 msg 后，会执行这里：</span></span><br><span class="line">		<span class="comment">// 遍历 channelMap 中的每一个 channel，将此 msg 拷贝到 channel 中的后备队列。</span></span><br><span class="line">		<span class="comment">// 注意，因为每个 channel 需要一个独立 msg，因此需要在拷贝时需要创建 msg 的副本</span></span><br><span class="line">		<span class="comment">// 同时，针对 msg 是否需要被延时投递来选择将 msg 放到</span></span><br><span class="line">        <span class="comment">// 延时队列 deferredMessages中还是 in-flight queue 中</span></span><br><span class="line">		<span class="keyword">for</span> i, channel := <span class="keyword">range</span> chans &#123;</span><br><span class="line">			chanMsg := msg</span><br><span class="line">			<span class="keyword">if</span> i &gt; <span class="number">0</span> &#123; <span class="comment">// 若此 topic 只有一个 channel，则不需要显式地拷贝了</span></span><br><span class="line">				chanMsg = NewMessage(msg.ID, msg.Body)</span><br><span class="line">				chanMsg.Timestamp = msg.Timestamp</span><br><span class="line">				chanMsg.deferred = msg.deferred</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">// 将 msg push 到 channel 所维护的延时消息队列 deferred queue</span></span><br><span class="line">			<span class="comment">// 等待消息的延时时间走完后，会把消息进一步放入到 in-flight queue 中</span></span><br><span class="line">			<span class="keyword">if</span> chanMsg.deferred != <span class="number">0</span> &#123;</span><br><span class="line">				channel.PutMessageDeferred(chanMsg, chanMsg.deferred)</span><br><span class="line">				<span class="keyword">continue</span></span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">// 将 msg push 到普通消息队列 in-flight queue</span></span><br><span class="line">			err := channel.PutMessage(chanMsg)</span><br><span class="line">			<span class="comment">// ...</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">exit:</span><br><span class="line">	t.ctx.nsqd.logf(LOG_INFO, <span class="string">"TOPIC(%s): closing ... messagePump"</span>, t.name)</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/topic.go</span></span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// [ channel.go 文件中，topic 发送消息到 in-flight queue 相关逻辑 ]</span></span><br><span class="line"><span class="comment">// 此方法会由 topic.messagePump 方法中调用。</span></span><br><span class="line"><span class="comment">// 即当 topic 收到生产者投递的消息时，将此消息放到与其关联的 channels 的延迟队列 deferred queue</span></span><br><span class="line"><span class="comment">// 或者 普通的消息队列中(包括 内存消息队列 memoryMsgChan 或 后端持久化 backend)（即此方法）</span></span><br><span class="line"><span class="comment">// channel 调用 put 方法将消息放到消息队列中，同时更新消息计数</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Channel)</span> <span class="title">PutMessage</span><span class="params">(m *Message)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	c.RLock()</span><br><span class="line">	<span class="keyword">defer</span> c.RUnlock()</span><br><span class="line">	<span class="keyword">if</span> c.Exiting() &#123;</span><br><span class="line">		<span class="keyword">return</span> errors.New(<span class="string">"exiting"</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	err := c.put(m)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	atomic.AddUint64(&amp;c.messageCount, <span class="number">1</span>)</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/channel.go</span></span><br><span class="line"><span class="comment">// 同 topic.put 方法类似，其在 put message 时，</span></span><br><span class="line"><span class="comment">// 依据实际情况将消息 push 到内在队列 memoryMsgChan 或者后端持久化 backend</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Channel)</span> <span class="title">put</span><span class="params">(m *Message)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">select</span> &#123;</span><br><span class="line">	<span class="keyword">case</span> c.memoryMsgChan &lt;- m:</span><br><span class="line">	<span class="keyword">default</span>:</span><br><span class="line">		b := bufferPoolGet()</span><br><span class="line">		err := writeMessageToBackend(b, m, c.backend)</span><br><span class="line">		bufferPoolPut(b)</span><br><span class="line">		c.ctx.nsqd.SetHealth(err)</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/channel.go</span></span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// [ channel.go 文件中，topic 发送消息到 deferred queue 相关逻辑 ]</span></span><br><span class="line"><span class="comment">// 将 message 添加到 deferred queue 中</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Channel)</span> <span class="title">PutMessageDeferred</span><span class="params">(msg *Message, timeout time.Duration)</span></span> &#123;</span><br><span class="line">	atomic.AddUint64(&amp;c.messageCount, <span class="number">1</span>)</span><br><span class="line">	c.StartDeferredTimeout(msg, timeout)</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/channel.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 message 加入到 deferred queue 中，等待被 queueScanWorker 处理</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Channel)</span> <span class="title">StartDeferredTimeout</span><span class="params">(msg *Message, timeout time.Duration)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 计算超时超时戳，作为 Priority</span></span><br><span class="line">	absTs := time.Now().Add(timeout).UnixNano()</span><br><span class="line">	<span class="comment">// 2. 构造 item</span></span><br><span class="line">	item := &amp;pqueue.Item&#123;Value: msg, Priority: absTs&#125;</span><br><span class="line">	<span class="comment">// 3. item 添加到 deferred 字典</span></span><br><span class="line">	err := c.pushDeferredMessage(item)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 4. 将 item 放入到 deferred message 优先级队列</span></span><br><span class="line">	c.addToDeferredPQ(item)</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/channel.go</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Channel)</span> <span class="title">addToDeferredPQ</span><span class="params">(item *pqueue.Item)</span></span> &#123;</span><br><span class="line">	c.deferredMutex.Lock()</span><br><span class="line">	heap.Push(&amp;c.deferredPQ, item)</span><br><span class="line">	c.deferredMutex.Unlock()</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/channel.go</span></span><br></pre></td></tr></table></figure>

<p>至此，关于<code>topic</code>如何处理消息，如何将消息传递给<code>channel</code>已经讲述完毕，接下来，分析对于那些超时的消息应该如何处理，<code>deferred queue</code>中存储的延时投递的消息如何发送给客户端。这涉及到<code>nsqd.go</code>文件中<code>nsqd</code>实例的消息处理主循环，它循环扫描所有的<code>channel</code>关联的两个消息队列中的消息，并做针对性处理。</p>
<h2 id="nsqd-消息处理循环"><a href="#nsqd-消息处理循环" class="headerlink" title="nsqd 消息处理循环"></a>nsqd 消息处理循环</h2><p>在<code>nsqd</code>源码分析的文章中，没有涉及到<code>nsqd</code>消息处理循环相关的逻辑，考虑到在介绍之前必须要先了解<code>topic</code>及<code>channel</code>的相关功能。因此，把<code>nsqd</code>关于消息处理的部分单独开篇文章介绍。在<code>nsqd.Main</code>启动方法中，异步开启三个处理循环：<code>nsqd.queueScanLoop</code>、<code>nsqd.lookupLoop</code>和<code>nsqd.statsLoop</code>，分别作为消息处理循环，同<code>nsqlookupd</code>通信交互循环，以及数据统计循环。在<code>nsqd.queueScanLoop</code>方法中：</p>
<p>它首先根据配置文件参数初始化了一些重要属性：<code>workTicker</code>根据<code>QueueScanInterval</code>初始化，表示每隔<code>QueueScanInterval</code>的时间（默认<code>100ms</code>），<code>nsqd</code>随机挑选<code>QueueScanSelectionCount</code>数量的<code>channel</code>执行<code>dirty channel</code>的计数统计；另外<code>refreshTicker</code>根据<code>QueueScanRefreshInterval</code>初始化，每过<code>QueueScanRefreshInterval</code>时间（默认<code>5s</code>）就调整<code>queueScanWorker pool</code>的大小。之后，</p>
<p><code>queueScanLoop</code>的任务是处理发送中的消息队列(<code>in-flight queue</code>)，以及被延迟发送的消息队列(<code>deferred queue</code>)两个优先级消息队列中的消息。具体而言，它循环执行两个定时任务：</p>
<ul>
<li><p>其一，由<code>workTicker</code>计时器触发，每过<code>QueueScanInterval</code>（默认为<code>100ms</code>）的时间，就从本地的消息缓存队列中（<code>nsqd</code>维护的所有<code>topic</code>所关联的<code>channel</code>集合），随机选择<code>QueueScanSelectionCount</code>（默认<code>20</code>）个<code>channel</code>。检查这些<code>channel</code>集合中被标记为<code>dirty</code>属性的<code>channel</code>的数量，所谓的<code>dirty channel</code>即表示此<code>channel</code>实例中存在消息需要处理，这包含两个方面的处理逻辑：</p>
<ul>
<li>对于<code>in-flight queue</code>而言，检查消息是否已经处理超时（消费者处理超时），若存在超时的消息，则将消息从<code>in-flight queue</code>中移除，并重新将它压入到此<code>channel</code>的消息队列中(<code>memoryMsgChan</code>或<code>backend</code>)，等待后面重新被发送（即之后还会被重新压入到<code>in-flight queue</code>中），此为消息发送超时的处理逻辑。</li>
<li>对于<code>deferred queue</code>而言，检查消息的延迟时间是否已经走完，换言之，检查被延迟的消息现在是否应该发送给消费者了。若某个被延时的消息的延时时间已经达到，则将它从<code>deferred queue</code>中移除，并重新压入到此<code>channel</code>的消息队列中(<code>memoryMsgChan</code>或<code>backend</code>)，等待后面正式被发送（即之后还会被重新压入到<code>in-flight queue</code>中），此为消息延迟发送超时的处理逻辑。</li>
</ul>
<p>若处理的结果显示，<code>dirty channel</code>的数量超过<code>QueueScanDirtyPercent</code>（默认<code>25%</code>）的比例，则再次随机选择<code>QueueScanSelectionCount</code>（默认<code>20</code>）个<code>channel</code>，并让<code>queueScanWorker</code>对它们进行处理。</p>
</li>
<li><p>另一个定时任何由<code>refreshTicker</code>计时器触发，每过<code>QueueScanRefreshInterval</code>（默认<code>5s</code>）的时间，就调整<code>queueScanWorker pool</code>的大小。具体的调整措施为：</p>
<ul>
<li>若现有的<code>queueScanWorker</code>的数量低于理想值（<code>nsqd</code>包含的<code>channel</code>集合的总数的<code>1/4</code>，程序硬编码），则显式地增加<code>queueScanWorker</code>的数量，即异步执行<code>queueScanWorker</code>方法。</li>
<li>否则，若现有的<code>queueScanWorker</code>数量高于理想值，则通过<code>exitCh</code>显式地结束执行<code>queueScanWorker</code>方法。</li>
</ul>
<p>所谓的<code>queueScanWorker</code>实际上只是一个循环消息处理的方法，一旦它从<code>workCh</code>管道接收到消息，则会开始处理<code>in-fligth queue</code>和<code>deferred queue</code>中的消息，最后将处理结果，即队列中是否存在<code>dirty channel</code>通过<code>responseCh</code>通知给<code>queeuScanLoop</code>主循环。</p>
</li>
</ul>
<p>上述逻辑即为<code>nsqd</code>对两个消息队列(<code>in-flight queue</code>和<code>deferred queue</code>)的核心处理逻辑。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// queueScanLoop 方法在一个单独的 go routine 中运行。</span></span><br><span class="line"><span class="comment">// 用于处理正在发送的 in-flight 消息以及被延迟处理的 deferred 消息</span></span><br><span class="line"><span class="comment">// 它管理了一个 queueScanWork pool，其默认数量为5。queueScanWorker 可以并发地处理 channel。</span></span><br><span class="line"><span class="comment">// 它借鉴了Redis随机化超时的策略，即它每 QueueScanInterval 时间（默认100ms）就从本地的缓存队列中</span></span><br><span class="line"><span class="comment">// 随机选择 QueueScanSelectionCount 个（默认20个） channels。</span></span><br><span class="line"><span class="comment">// 其中 缓存队列每间隔  QueueScanRefreshInterval 还会被刷新。</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *NSQD)</span> <span class="title">queueScanLoop</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 获取随机选择的 channel 的数量，以及队列扫描的时间间隔，及队列刷新时间间隔</span></span><br><span class="line">	workCh := <span class="built_in">make</span>(<span class="keyword">chan</span> *Channel, n.getOpts().QueueScanSelectionCount)</span><br><span class="line">	responseCh := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">bool</span>, n.getOpts().QueueScanSelectionCount)</span><br><span class="line">	closeCh := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br><span class="line"></span><br><span class="line">	workTicker := time.NewTicker(n.getOpts().QueueScanInterval)</span><br><span class="line">	refreshTicker := time.NewTicker(n.getOpts().QueueScanRefreshInterval)</span><br><span class="line">	<span class="comment">// 2. 获取 nsqd 所包含的 channel 集合，一个 topic 包含多个 channel，</span></span><br><span class="line">    <span class="comment">// 而一个 nsqd 实例可包含多个 topic 实例</span></span><br><span class="line">	channels := n.channels()</span><br><span class="line">	n.resizePool(<span class="built_in">len</span>(channels), workCh, responseCh, closeCh)</span><br><span class="line">	<span class="comment">// 3. 这个循环中的逻辑就是依据配置参数，</span></span><br><span class="line">    <span class="comment">// 反复处理 nsqd 所维护的 topic 集合所关联的 channel 中的消息</span></span><br><span class="line">	<span class="comment">// 即循环处理将 channel 从 topic 接收到的消息，发送给订阅了对应的 channel 的客户端</span></span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="comment">// 3.1 每过 QueueScanInterval 时间（默认100ms），</span></span><br><span class="line">            <span class="comment">// 则开始随机挑选 QueueScanSelectionCount 个 channel。转到 loop: 开始执行</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-workTicker.C:</span><br><span class="line">			<span class="keyword">if</span> <span class="built_in">len</span>(channels) == <span class="number">0</span> &#123; <span class="comment">// 此 nsqd 没有包含任何 channel　实例当然就不用处理了</span></span><br><span class="line">				<span class="keyword">continue</span></span><br><span class="line">			&#125;</span><br><span class="line">		<span class="comment">// 3.2 每过 QueueScanRefreshInterval 时间（默认5s），</span></span><br><span class="line">            <span class="comment">// 则调整 pool 的大小，即调整开启的 queueScanWorker 的数量为 pool 的大小</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-refreshTicker.C:</span><br><span class="line">			channels = n.channels()</span><br><span class="line">			n.resizePool(<span class="built_in">len</span>(channels), workCh, responseCh, closeCh)</span><br><span class="line">			<span class="keyword">continue</span></span><br><span class="line">		<span class="comment">// 3.3 nsqd 已退出</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-n.exitChan:</span><br><span class="line">			<span class="keyword">goto</span> exit</span><br><span class="line">		&#125;</span><br><span class="line">		num := n.getOpts().QueueScanSelectionCount</span><br><span class="line">		<span class="keyword">if</span> num &gt; <span class="built_in">len</span>(channels) &#123;</span><br><span class="line">			num = <span class="built_in">len</span>(channels)</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 3.4 利用 util.UniqRands，随机选取 num（QueueScanSelectionCount 默认20个）channel</span></span><br><span class="line">		<span class="comment">// 将它们 push 到 workCh 管道，queueScanWorker 中会收到此消息，</span></span><br><span class="line">        <span class="comment">// 然后立即处理 in-flight queue 和 deferred queue 中的消息。</span></span><br><span class="line">		<span class="comment">// 注意，因为这里是随机抽取 channel 因此，有可能被选中的 channel 中并没有消息</span></span><br><span class="line">	loop:</span><br><span class="line">		<span class="keyword">for</span> _, i := <span class="keyword">range</span> util.UniqRands(num, <span class="built_in">len</span>(channels)) &#123;</span><br><span class="line">			workCh &lt;- channels[i]</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 3.5 统计 dirty 的 channel 的数量， responseCh 管道在上面的 nsqd.resizePool 方法中</span></span><br><span class="line">        <span class="comment">// 传递给了 len(channels) * 0.25 个 queueScanWorker。</span></span><br><span class="line">		<span class="comment">// 它们会在循环中反复查看两个消息优先级队列中是否有消息等待被处理： </span></span><br><span class="line">        <span class="comment">// 即查看 inFlightPQ 和 deferredPQ。</span></span><br><span class="line">		numDirty := <span class="number">0</span></span><br><span class="line">		<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; num; i++ &#123;</span><br><span class="line">			<span class="keyword">if</span> &lt;-responseCh &#123;</span><br><span class="line">				numDirty++</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 3.6 若其 dirtyNum 的比例超过配置的 QueueScanDirtyPercent（默认为25%）</span></span><br><span class="line">		<span class="keyword">if</span> <span class="keyword">float64</span>(numDirty)/<span class="keyword">float64</span>(num) &gt; n.getOpts().QueueScanDirtyPercent &#123;</span><br><span class="line">			<span class="keyword">goto</span> loop</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">exit:</span><br><span class="line">	n.logf(LOG_INFO, <span class="string">"QUEUESCAN: closing"</span>)</span><br><span class="line">	<span class="built_in">close</span>(closeCh)</span><br><span class="line">	workTicker.Stop()</span><br><span class="line">	refreshTicker.Stop()</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/nsqd.go</span></span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 调整 queueScanWorker 的数量</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *NSQD)</span> <span class="title">resizePool</span><span class="params">(num <span class="keyword">int</span>, workCh <span class="keyword">chan</span> *Channel, responseCh <span class="keyword">chan</span> <span class="keyword">bool</span>, closeCh <span class="keyword">chan</span> <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 根据 channel 的数量来设置合适的 pool size，默认为 1/4 的 channel 数量</span></span><br><span class="line">	idealPoolSize := <span class="keyword">int</span>(<span class="keyword">float64</span>(num) * <span class="number">0.25</span>)</span><br><span class="line">	<span class="keyword">if</span> idealPoolSize &lt; <span class="number">1</span> &#123;</span><br><span class="line">		idealPoolSize = <span class="number">1</span></span><br><span class="line">	&#125; <span class="keyword">else</span> <span class="keyword">if</span> idealPoolSize &gt; n.getOpts().QueueScanWorkerPoolMax &#123;</span><br><span class="line">		idealPoolSize = n.getOpts().QueueScanWorkerPoolMax</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 开启一个循环，直到理想的 pool size 同实际的 pool size 相同才退出。</span></span><br><span class="line">	<span class="comment">// 否则，若理想值更大，则需扩展已有的 queueScanWorker 的数量，</span></span><br><span class="line">		<span class="comment">// 即在一个单独的 goroutine 中调用一次 nsqd.queueScanWorker 方法（开启了一个循环）。</span></span><br><span class="line">	<span class="comment">// 反之， 需要减少已有的 queueScanWorker 的数量，</span></span><br><span class="line">    <span class="comment">// 即往 closeCh 中 push 一条消息，强制 queueScanWorker goroutine 退出</span></span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="keyword">if</span> idealPoolSize == n.poolSize &#123;</span><br><span class="line">			<span class="keyword">break</span></span><br><span class="line">		&#125; <span class="keyword">else</span> <span class="keyword">if</span> idealPoolSize &lt; n.poolSize &#123;</span><br><span class="line">			<span class="comment">// contract</span></span><br><span class="line">			closeCh &lt;- <span class="number">1</span></span><br><span class="line">			n.poolSize--</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			<span class="comment">// expand</span></span><br><span class="line">			n.waitGroup.Wrap(<span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">				n.queueScanWorker(workCh, responseCh, closeCh)</span><br><span class="line">			&#125;)</span><br><span class="line">			n.poolSize++</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;  <span class="comment">// /nsq/nsqd/nsqd.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 在 queueScanLoop 中处理 channel 的具体就是由 queueScanWorker 来负责。</span></span><br><span class="line"><span class="comment">// 调用方法 queueScanWorker 即表示新增一个  queueScanWorker goroutine 来处理 channel。</span></span><br><span class="line"><span class="comment">// 一旦开始工作 (从 workCh 中收到了信号， 即 dirty 的 channel 的数量达到阈值)，</span></span><br><span class="line"><span class="comment">// 则循环处理 in-flight queue 和 deferred queue 中的消息，</span></span><br><span class="line"><span class="comment">// 并将处理结果（即是否是 dirty channel）通过 reponseCh 反馈给 queueScanWorker。</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *NSQD)</span> <span class="title">queueScanWorker</span><span class="params">(workCh <span class="keyword">chan</span> *Channel, responseCh <span class="keyword">chan</span> <span class="keyword">bool</span>, closeCh <span class="keyword">chan</span> <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="comment">// 开始处理两个消息队列中的消息</span></span><br><span class="line">		<span class="keyword">case</span> c := &lt;-workCh:</span><br><span class="line">			now := time.Now().UnixNano()</span><br><span class="line">			dirty := <span class="literal">false</span></span><br><span class="line">			<span class="comment">// 若返回true，则表明　in-flight 优先队列中有存在处理超时的消息，</span></span><br><span class="line">			<span class="comment">// 因此将消息再次写入到　内存队列 memoryMsgChan　或 后端持久化　backend</span></span><br><span class="line">			<span class="comment">// 等待消息被重新投递给消费者（重新被加入到 in-flight queue）</span></span><br><span class="line">			<span class="keyword">if</span> c.processInFlightQueue(now) &#123;</span><br><span class="line">				dirty = <span class="literal">true</span></span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">// 若返回 true，则表明　deferred 优先队列中存在延时时间已到的消息，</span></span><br><span class="line">            <span class="comment">// 因此需要将此消息从 deferred queue 中移除，</span></span><br><span class="line">			<span class="comment">// 并将消息重新写入到　内存队列 memoryMsgChan　或后端持久化　backend</span></span><br><span class="line">            <span class="comment">// 等待消息被正式投递给消费者 （正式被加入到 in-flight queue）</span></span><br><span class="line">			<span class="keyword">if</span> c.processDeferredQueue(now) &#123;</span><br><span class="line">				dirty = <span class="literal">true</span></span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">// 报告 queueScanLoop 主循环，发现一个 dirty channel</span></span><br><span class="line">			responseCh &lt;- dirty</span><br><span class="line">		<span class="comment">// 退出处理循环，缩减 queueScanWorker 数量时，被调用</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-closeCh:</span><br><span class="line">			<span class="keyword">return</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/nsqd.go</span></span><br></pre></td></tr></table></figure>

<p>为了更好的理解消息的流动，小结一下，生产者投递消息到指定<code>topic</code>后，消息进入了<code>topic</code>维护的消息队列(<code>memoryMsgChan</code>和<code>backend</code>)，而在启动<code>nsqd</code>时，会异步开启一个消息处理循环即<code>queueScanLoop</code>，它包含两个计时任务，其中一个是，定时调整已经正在运行的<code>queueScanWorker</code>数量，其中<code>queueScanWorker</code>的任务为查看两个优先级队列中是否存在需要被处理的消息，若存在，则标记对应的<code>channel</code>为<code>dirty channel</code>。另一个计时任务是，定时抽取一定数量的<code>channel</code>，查看其中为<code>dirty channel</code>的比例（由<code>queueScanWorker</code>完成），若达到一定比例，则继续执行抽取<code>channel</code>的动作，如此反复。</p>
<p>好，到目前为止，<code>nsq</code>内部的消息处理逻辑已经阐述完毕。这对于理解整个<code>nsq</code>实时消息队列的关键原理至关重要。下面阐述几个典型的命令请求的核心实现逻辑。</p>
<h2 id="生产者消息发布消息"><a href="#生产者消息发布消息" class="headerlink" title="生产者消息发布消息"></a>生产者消息发布消息</h2><p>考虑到<code>nsq</code>为生产者提供了<code>http/tcp</code>两种方式来发布消息。因此，笔者以<code>tcp</code>的命令请求处理器为示例来阐述其核心处理逻辑（<code>http</code>的方式也类似）。当生产者通过<code>go-nsq</code>库以<code>tcp</code>的方式发送消息发布请求命令给指定<code>topic</code>时，请求首先从<code>protocolV2.IOLoop</code>中被读取，然后其调用<code>protocolV2.Exec</code>方法根据命令请求的类型调用相应的处理方法，此为<code>PUB</code>命令，因此调用<code>protocolV2.PUB</code>方法处理。处理过程比较简单，首先解析请求，取出<code>topic</code>名称，然后执行权限检查，检查通过后，便依据<code>topic</code>名称获取此<code>topic</code>实例，然后，构建一条消息，并调用<code>topic.PutMessage</code>方法发布消息，最后，调用<code>cleint.PublishedMessage</code>方法更新一些信息，并返回<code>ok</code>。整个流程比较简单，因为关键的处理逻辑在前文介绍过了，读者需要把它们串联起来。代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 客户端在指定的 topic 上发布消息</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *protocolV2)</span> <span class="title">PUB</span><span class="params">(client *clientV2, params [][]<span class="keyword">byte</span>)</span> <span class="params">([]<span class="keyword">byte</span>, error)</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> err error</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(params) &lt; <span class="number">2</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(<span class="literal">nil</span>, <span class="string">"E_INVALID"</span></span><br><span class="line">                             , <span class="string">"PUB insufficient number of parameters"</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 1. 读取 topic 名称</span></span><br><span class="line">	topicName := <span class="keyword">string</span>(params[<span class="number">1</span>])</span><br><span class="line">	<span class="keyword">if</span> !protocol.IsValidTopicName(topicName) &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(<span class="literal">nil</span>, <span class="string">"E_BAD_TOPIC"</span>,</span><br><span class="line">			fmt.Sprintf(<span class="string">"PUB topic name %q is not valid"</span>, topicName))</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 读取消息体长度 bodyLen，并在长度上进行校验</span></span><br><span class="line">	bodyLen, err := readLen(client.Reader, client.lenSlice)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(err, </span><br><span class="line">                            <span class="string">"E_BAD_MESSAGE"</span>, <span class="string">"PUB failed to read message body size"</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> bodyLen &lt;= <span class="number">0</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(<span class="literal">nil</span>, <span class="string">"E_BAD_MESSAGE"</span>,</span><br><span class="line">			fmt.Sprintf(<span class="string">"PUB invalid message body size %d"</span>, bodyLen))</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> <span class="keyword">int64</span>(bodyLen) &gt; p.ctx.nsqd.getOpts().MaxMsgSize &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(<span class="literal">nil</span>, <span class="string">"E_BAD_MESSAGE"</span>,</span><br><span class="line">			fmt.Sprintf(<span class="string">"PUB message too big %d &gt; %d"</span>, bodyLen, p.ctx.nsqd.getOpts().MaxMsgSize))</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 3. 读取指定字节长度的消息内容到 messageBody</span></span><br><span class="line">	messageBody := <span class="built_in">make</span>([]<span class="keyword">byte</span>, bodyLen)</span><br><span class="line">	_, err = io.ReadFull(client.Reader, messageBody)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// 4. 检查客户端是否具备 PUB 此 topic 命令的权限</span></span><br><span class="line">	<span class="keyword">if</span> err := p.CheckAuth(client, <span class="string">"PUB"</span>, topicName, <span class="string">""</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 5. 获取 topic 实例</span></span><br><span class="line">	topic := p.ctx.nsqd.GetTopic(topicName)</span><br><span class="line">	<span class="comment">// 6. 构造一条 message，并将此 message 投递到此 topic 的消息队列中</span></span><br><span class="line">	msg := NewMessage(topic.GenerateID(), messageBody)</span><br><span class="line">	err = topic.PutMessage(msg)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// 7. 开始发布此消息，即将对应的 client 修改为此 topic 保存的消息的计数。</span></span><br><span class="line">	client.PublishedMessage(topicName, <span class="number">1</span>)</span><br><span class="line">	<span class="comment">// 回复 Ok</span></span><br><span class="line">	<span class="keyword">return</span> okBytes, <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/protocol_v2.go</span></span><br></pre></td></tr></table></figure>

<p>生产者除了可以发送<code>PUB</code>命令外，类似地，还有命令请求<code>MPUB</code>来一次性发布多条消息，<code>DPUB</code>用于发布延时投递的消息等等，逻辑都比较简单，不多阐述。下面介绍消费者处理消息的相关流程。</p>
<h2 id="消费者处理消息"><a href="#消费者处理消息" class="headerlink" title="消费者处理消息"></a>消费者处理消息</h2><p>消费者处理消息的流程包括，消费者发送<code>SUB</code>命令请求以订阅<code>channel</code>，消费者发送<code>RDY</code>命令请求以通知服务端自的消息处理能力，消费者发送<code>FIN</code>消息表示消息已经处理完成，最后还有个消费者发送<code>REQ</code>消息请求服务端重新将消息入队。下面依次分析这些命令请求的核心实现。</p>
<h3 id="消费者订阅消息"><a href="#消费者订阅消息" class="headerlink" title="消费者订阅消息"></a>消费者订阅消息</h3><p>当消费者通过<code>tcp</code>发送订阅消息的请求时，请求同样是首先从<code>protocolV2.IOLoop</code>方法中被接收，然后交由<code>Exec</code>方法处理。最后进入到<code>SUB</code>方法的流程，它首先执行必要的请求校验工作，其中容易被忽略的一点是，只有当<code>client</code>处于<code>stateInit</code>状态才能订阅某个<code>topic</code>的<code>channel</code>，换言之，当一个<code>client</code>订阅了某个<code>channel</code>后，它的状态会被更新为<code>stateSubscribed</code>，因此不能再订阅其它<code>channel</code>了。总而言之，<strong>一个 <code>client</code>同一时间只能订阅一个<code>channel</code></strong>。之后，获取并校验订阅的<code>topic</code>名称、<code>channel</code>名称，然后，客户端是否有订阅的权限，权限检查通过后，通过<code>topic</code>和<code>channel</code>名称获取对应的实例，并将此<code>client</code>实例添加到其订阅的<code>channel</code>的客户端集合中。最后，也是最关键的步骤是，它将订阅的<code>channel</code>实例传递给了<code>client</code>，同时将<code>channel</code>发送到了<code>client.SubEventChan</code>管道中，因此在<code>protocolV2.messagePump</code>方法中就能够根据，此客户端可以利用<code>channel.memoryMsgChan</code>和<code>channel.backend</code>来获取<code>channel</code>实例从<code>topic</code>实例接收到的消息，具体过程可以参考<a href="https://qqzeng.top/2019/05/13/nsq-nsqd-%E6%9C%8D%E5%8A%A1%E5%90%AF%E5%8A%A8%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/#%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E5%A4%84%E7%90%86" target="_blank" rel="noopener">这里</a>。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 客户端在指定的 topic 上订阅消息</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *protocolV2)</span> <span class="title">SUB</span><span class="params">(client *clientV2, params [][]<span class="keyword">byte</span>)</span> <span class="params">([]<span class="keyword">byte</span>, error)</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 做一些校验工作，只有当 client 处于 stateInit 状态才能订阅某个 topic 的 channel</span></span><br><span class="line">	<span class="comment">// 换言之，当一个 client 订阅了某个 channel 之后，</span></span><br><span class="line">    <span class="comment">// 它的状态会被更新为 stateSubscribed，因此不能再订阅 channel 了。</span></span><br><span class="line">	<span class="comment">// 总而言之，一个 client 只能订阅一个 channel</span></span><br><span class="line">	<span class="keyword">if</span> atomic.LoadInt32(&amp;client.State) != stateInit &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(<span class="literal">nil</span>, <span class="string">"E_INVALID"</span>, <span class="string">"cannot SUB in current state"</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> client.HeartbeatInterval &lt;= <span class="number">0</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(<span class="literal">nil</span>, <span class="string">"E_INVALID"</span>, <span class="string">"cannot SUB with heartbeats disabled"</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(params) &lt; <span class="number">3</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(<span class="literal">nil</span>, <span class="string">"E_INVALID"</span>, <span class="string">"SUB insufficient number of parameters"</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 获取订阅的 topic 名称、channel 名称，并对它们进行校验</span></span><br><span class="line">	topicName := <span class="keyword">string</span>(params[<span class="number">1</span>])</span><br><span class="line">	<span class="keyword">if</span> !protocol.IsValidTopicName(topicName) &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(<span class="literal">nil</span>, <span class="string">"E_BAD_TOPIC"</span>,</span><br><span class="line">			fmt.Sprintf(<span class="string">"SUB topic name %q is not valid"</span>, topicName))</span><br><span class="line">	&#125;</span><br><span class="line">	channelName := <span class="keyword">string</span>(params[<span class="number">2</span>])</span><br><span class="line">	<span class="keyword">if</span> !protocol.IsValidChannelName(channelName) &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(<span class="literal">nil</span>, <span class="string">"E_BAD_CHANNEL"</span>,</span><br><span class="line">			fmt.Sprintf(<span class="string">"SUB channel name %q is not valid"</span>, channelName))</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 3. 同时检查此客户端是否有订阅的权限</span></span><br><span class="line">	<span class="keyword">if</span> err := p.CheckAuth(client, <span class="string">"SUB"</span>, topicName, channelName); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 此循环是为了避免 client 订阅到正在退出的 ephemeral 属性的 channel 或 topic</span></span><br><span class="line">	<span class="keyword">var</span> channel *Channel</span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="comment">// 4. 获取 topic 及 channel 实例</span></span><br><span class="line">		topic := p.ctx.nsqd.GetTopic(topicName)</span><br><span class="line">		channel = topic.GetChannel(channelName)</span><br><span class="line">		<span class="comment">// 5. 调用 channel的 AddClient 方法添加指定客户端</span></span><br><span class="line">		<span class="keyword">if</span> err := channel.AddClient(client.ID, client); err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(<span class="literal">nil</span>, <span class="string">"E_TOO_MANY_CHANNEL_CONSUMERS"</span>,</span><br><span class="line">				fmt.Sprintf(<span class="string">"channel consumers for %s:%s exceeds limit of %d"</span>,</span><br><span class="line">					topicName, channelName, p.ctx.nsqd.getOpts().MaxChannelConsumers))</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 6. 若此 channel 或 topic 为ephemeral，并且channel或topic正在退出，则移除此client</span></span><br><span class="line">		<span class="keyword">if</span> (channel.ephemeral &amp;&amp; channel.Exiting()) || (topic.ephemeral &amp;&amp; topic.Exiting()) &#123;</span><br><span class="line">			channel.RemoveClient(client.ID)</span><br><span class="line">			time.Sleep(<span class="number">1</span> * time.Millisecond)</span><br><span class="line">			<span class="keyword">continue</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">break</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 6. 修改客户端的状态为 stateSubscribed</span></span><br><span class="line">	atomic.StoreInt32(&amp;client.State, stateSubscribed)</span><br><span class="line">	<span class="comment">// 7. 这一步比较关键，将订阅的 channel 实例传递给了 client，</span></span><br><span class="line">    <span class="comment">// 同时将 channel 发送到了 client.SubEventChan 通道中。</span></span><br><span class="line">	<span class="comment">// 后面的 SubEventChan 就会使得当前的 client 在一个 goroutine 中订阅这个 channel 的消息</span></span><br><span class="line">	client.Channel = channel</span><br><span class="line">	<span class="comment">// update message pump</span></span><br><span class="line">	<span class="comment">// 8. 通知后台订阅协程来订阅消息,包括内存管道和磁盘</span></span><br><span class="line">	client.SubEventChan &lt;- channel</span><br><span class="line">	<span class="comment">// 9. 返回 ok</span></span><br><span class="line">	<span class="keyword">return</span> okBytes, <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/protocol_v2.go</span></span><br></pre></td></tr></table></figure>

<h3 id="消费者发送-RDY-命令"><a href="#消费者发送-RDY-命令" class="headerlink" title="消费者发送 RDY 命令"></a>消费者发送 RDY 命令</h3><p>在消费者未发送<code>RDY</code>命令给服务端之前，服务端不会推送消息给客户端，因为此时服务端认为消费者还未准备好接收消息（由方法<code>client.IsReadyForMessages</code>实现）。另外，此<code>RDY</code>命令的含义，简而言之，当<code>RDY 100</code>即表示客户端具备一次性接收并处理100个消息的能力，因此服务端此时更可推送100条消息给消费者（如果有的话），每推送一条消息，就要修改<code>client.ReadyCount</code>的值。而<code>RDY</code>命令请求的处理非常简单，即通过<code>client.SetReadyCount</code>方法直接设置<code>client.ReadyCount</code>的值。注意在这之前的两个状态检查动作。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 消费者发送 RDY 命令请求表示服务端可以开始推送指定数目的消息了</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *protocolV2)</span> <span class="title">RDY</span><span class="params">(client *clientV2, params [][]<span class="keyword">byte</span>)</span> <span class="params">([]<span class="keyword">byte</span>, error)</span></span> &#123;</span><br><span class="line">	state := atomic.LoadInt32(&amp;client.State)</span><br><span class="line">	<span class="keyword">if</span> state == stateClosing &#123;</span><br><span class="line">		<span class="comment">// just ignore ready changes on a closing channel</span></span><br><span class="line">		p.ctx.nsqd.logf(LOG_INFO,</span><br><span class="line">			<span class="string">"PROTOCOL(V2): [%s] ignoring RDY after CLS in state ClientStateV2Closing"</span>,</span><br><span class="line">			client)</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> state != stateSubscribed &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(<span class="literal">nil</span>, <span class="string">"E_INVALID"</span>, </span><br><span class="line">                                               <span class="string">"cannot RDY in current state"</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	count := <span class="keyword">int64</span>(<span class="number">1</span>)</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(params) &gt; <span class="number">1</span> &#123;</span><br><span class="line">		b10, err := protocol.ByteToBase10(params[<span class="number">1</span>])</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(err, <span class="string">"E_INVALID"</span>,</span><br><span class="line">				fmt.Sprintf(<span class="string">"RDY could not parse count %s"</span>, params[<span class="number">1</span>]))</span><br><span class="line">		&#125;</span><br><span class="line">		count = <span class="keyword">int64</span>(b10)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> count &lt; <span class="number">0</span> || count &gt; p.ctx.nsqd.getOpts().MaxRdyCount &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(<span class="literal">nil</span>, <span class="string">"E_INVALID"</span>,</span><br><span class="line">			fmt.Sprintf(<span class="string">"RDY count %d out of range 0-%d"</span>, count,</span><br><span class="line">                        p.ctx.nsqd.getOpts().MaxRdyCount))</span><br><span class="line">	&#125;</span><br><span class="line">	client.SetReadyCount(count)</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/protocol_v2.go</span></span><br></pre></td></tr></table></figure>

<h3 id="消费者发送-FIN-命令"><a href="#消费者发送-FIN-命令" class="headerlink" title="消费者发送 FIN 命令"></a>消费者发送 FIN 命令</h3><p>当消费者将<code>channel</code>发送的消息消费完毕后，会显式向<code>nsq</code>发送<code>FIN</code>命令（类似于<code>ACK</code>）。当服务端收到此命令后，就可将消息从消息队列中删除。<code>FIN</code>方法首先调用<code>client.Channel.FinishMessage</code>方法将消息从<code>channel</code>的两个集合<code>in-flight queue</code>队列及<code>inFlightMessages</code> 字典中移除。然后调用<code>client.FinishedMessage</code>更新<code>client</code>的维护的消息消费的统计信息。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 消费者 client 收到消息后，会向 nsqd　响应　FIN+msgID　通知服务器成功投递消息，可以清空消息了'</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *protocolV2)</span> <span class="title">FIN</span><span class="params">(client *clientV2, params [][]<span class="keyword">byte</span>)</span> <span class="params">([]<span class="keyword">byte</span>, error)</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 正式处理　FIN　请求前，对 client 及 请求参数属性信息进行校验</span></span><br><span class="line">	state := atomic.LoadInt32(&amp;client.State)</span><br><span class="line">	<span class="keyword">if</span> state != stateSubscribed &amp;&amp; state != stateClosing &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(<span class="literal">nil</span>, <span class="string">"E_INVALID"</span>, <span class="string">"cannot FIN in current state"</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(params) &lt; <span class="number">2</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(<span class="literal">nil</span>, <span class="string">"E_INVALID"</span>, <span class="string">"FIN insufficient number of params"</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 获取 msgID</span></span><br><span class="line">	id, err := getMessageID(params[<span class="number">1</span>])</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// 3. client 调用 channel.FinishMessage 方法，</span></span><br><span class="line">    <span class="comment">// 即将消息从 channel 的 in-flight queue 及 inFlightMessages 字典中移除</span></span><br><span class="line">	err = client.Channel.FinishMessage(client.ID, *id)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// 4. 更新 client 维护的消息消费的统计信息</span></span><br><span class="line">	client.FinishedMessage()</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/protocol_v2.go</span></span><br></pre></td></tr></table></figure>

<h3 id="消费者发送-REQ-命令"><a href="#消费者发送-REQ-命令" class="headerlink" title="消费者发送 REQ 命令"></a>消费者发送 REQ 命令</h3><p>消费者可以通过向服务端发送<code>REQ</code>命令以将消息重新入队，即让服务端一定时间后（也可能是立刻）将消息重新发送给<code>channel</code>关联的客户端。此方法的核心是<code>client.Channel.RequeueMessage</code>，它会先将消息从<code>in-flight queue</code>优先级队列中移除，然后根据客户端是否需要延时<code>timeout</code>发送，分别将消息压入<code>channel</code>的消息队列(<code>memoryMsgChan</code>或<code>backend</code>)，或者构建一个延时消息，并将其压入到<code>deferred queue</code>。代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// nsqd 为此 client 将 message 重新入队，并指定是否需要延时发送</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *protocolV2)</span> <span class="title">REQ</span><span class="params">(client *clientV2, params [][]<span class="keyword">byte</span>)</span> <span class="params">([]<span class="keyword">byte</span>, error)</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 先检验 client 的状态以及参数信息</span></span><br><span class="line">	state := atomic.LoadInt32(&amp;client.State)</span><br><span class="line">	<span class="keyword">if</span> state != stateSubscribed &amp;&amp; state != stateClosing &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(<span class="literal">nil</span>, <span class="string">"E_INVALID"</span>, <span class="string">"cannot REQ in current state"</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(params) &lt; <span class="number">3</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(<span class="literal">nil</span>, <span class="string">"E_INVALID"</span>, <span class="string">"REQ insufficient number of params"</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	id, err := getMessageID(params[<span class="number">1</span>])</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(<span class="literal">nil</span>, <span class="string">"E_INVALID"</span>, err.Error())</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 从请求中取出重入队的消息被延迟的时间，</span></span><br><span class="line">    <span class="comment">// 并转化单位，同时限制其不能超过最大的延迟时间 maxReqTimeout</span></span><br><span class="line">	timeoutMs, err := protocol.ByteToBase10(params[<span class="number">2</span>])</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	timeoutDuration := time.Duration(timeoutMs) * time.Millisecond</span><br><span class="line">	maxReqTimeout := p.ctx.nsqd.getOpts().MaxReqTimeout</span><br><span class="line">	clampedTimeout := timeoutDuration</span><br><span class="line">	<span class="keyword">if</span> timeoutDuration &lt; <span class="number">0</span> &#123;</span><br><span class="line">		clampedTimeout = <span class="number">0</span></span><br><span class="line">	&#125; <span class="keyword">else</span> <span class="keyword">if</span> timeoutDuration &gt; maxReqTimeout &#123;</span><br><span class="line">		clampedTimeout = maxReqTimeout</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// 3. 调用 channel.RequeueMessage 将消息重新入队。首先会将其从 in-flight queue 中删除，</span></span><br><span class="line">	<span class="comment">// 然后依据其 timeout 而定，若其为0,则直接将其添加到消息队列中，</span></span><br><span class="line">	<span class="comment">// 否则，若其 timeout 不为0,则构建一个 deferred message，</span></span><br><span class="line">    <span class="comment">// 并设置好延迟时间为 timeout，并将其添加到 deferred queue 中</span></span><br><span class="line">	err = client.Channel.RequeueMessage(client.ID, *id, timeoutDuration)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// 4. 更新 client 保存的关于消息的统计计数</span></span><br><span class="line">	client.RequeuedMessage()</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/protocol_v2.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 将消息重新入队。这与 timeout 参数密切相关。</span></span><br><span class="line"><span class="comment">// 当 timeout == 0 时，直接将此消息重入队。</span></span><br><span class="line"><span class="comment">// 否则，异步等待此消息超时，然后 再将此消息重入队，即是相当于消息被延迟了</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Channel)</span> <span class="title">RequeueMessage</span><span class="params">(clientID <span class="keyword">int64</span>, id MessageID, timeout time.Duration)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 先将消息从 inFlightMessages 移除</span></span><br><span class="line">	msg, err := c.popInFlightMessage(clientID, id)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 同时将消息从 in-flight queue 中移除，并更新 chanel 维护的消息重入队数量 requeueCount</span></span><br><span class="line">	c.removeFromInFlightPQ(msg)</span><br><span class="line">	atomic.AddUint64(&amp;c.requeueCount, <span class="number">1</span>)</span><br><span class="line">	<span class="comment">// 3. 若 timeout 为0,则将消息重新入队。即调用 channel.put 方法，</span></span><br><span class="line">    <span class="comment">// 将消息添加到 memoryMsgChan 或 backend</span></span><br><span class="line">	<span class="keyword">if</span> timeout == <span class="number">0</span> &#123;</span><br><span class="line">		c.exitMutex.RLock()</span><br><span class="line">		<span class="keyword">if</span> c.Exiting() &#123;</span><br><span class="line">			c.exitMutex.RUnlock()</span><br><span class="line">			<span class="keyword">return</span> errors.New(<span class="string">"exiting"</span>)</span><br><span class="line">		&#125;</span><br><span class="line">		err := c.put(msg)</span><br><span class="line">		c.exitMutex.RUnlock()</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 否则，创建一个延迟消息，并设置延迟时间</span></span><br><span class="line">	<span class="keyword">return</span> c.StartDeferredTimeout(msg, timeout)</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/channel.go</span></span><br></pre></td></tr></table></figure>

<p>至此，关于客户端的消息处理相关的命令请求已经阐述完毕，其实还有一些，比如<code>TOUCH</code>命令请求，即重置消息的超时时间。但这些处理过程都比较简单，只是对前面两小节的逻辑进行封装调用。</p>
<p>简单小结，本文的重点在两个方面：<code>topic</code>消息处理逻辑，即消息是如何从<code>topic</code>实例流向<code>channel</code>实例的，实际上就是将从<code>topic.memoryMsgChan</code>或<code>topic.backend</code>收到的消息的副本依次压入到其关联的<code>channel</code>的<code>in-flight queue</code>（对于正常的消息）或者<code>deferred queue</code>（对于延时消息）。另一个方面，<code>nsqd</code>消息处理处理逻辑，<code>nsqd</code>负责<code>in-flight queue</code>中的消息超时的处理工作，以及<code>deferred queue</code>中的消息延时时间已到的处理工作。另外，也阐述了一些有关客户端的命令请求的核心处理逻辑，包括生产者发布消息的流程，消费者订阅消息，以及发送<code>RDY/FIN/REQ</code>命令请求的实现逻辑。</p>
<p>至此，整个<code>nsq</code>实时消息队列的源码基本已经分析完毕，总共包括<a href="https://qqzeng.top/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" target="_blank" rel="noopener">6篇文章</a>。这里简单总结：</p>
<ol>
<li><a href="https://qqzeng.top/2019/05/11/nsq-%E7%AE%80%E4%BB%8B%E5%92%8C%E7%89%B9%E6%80%A7%E7%90%86%E8%A7%A3/" target="_blank" rel="noopener">nsq 简介和特性理解</a>简要介绍<code>nsq</code>的各个组件及系统的核心工作流程，并重点阐述几个值得关注的特性；</li>
<li><a href="https://qqzeng.top/2019/05/12/nsq-nsqlookupd-%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/" target="_blank" rel="noopener">nsq nsqlookupd 源码简析</a>是以<code>nsqlookupd</code>命令为切入点，详细阐述<code>nsqlookupd</code>启动过程，其重点在于分析<code>nsqlookupd</code>的<code>tcp</code>请求处理器的相关逻辑，并梳理了<code>topic</code>查询和创建这两个典型的流程；</li>
<li><a href="https://qqzeng.top/2019/05/13/nsq-nsqd-%E6%9C%8D%E5%8A%A1%E5%90%AF%E5%8A%A8%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/" target="_blank" rel="noopener">nsq nsqd 服务启动源码简析</a>同样是以<code>nsqd</code>命令为切入点，行文逻辑同上一篇类似，即阐述<code>nsqd</code>服务启动的一系列流程，并详述<code>nsqd</code>与<code>nsqlookupd</code>交互的主循环逻辑，以及<code>nsqd</code>为客户端建立的<code>tcp</code>请求处理器；</li>
<li><a href="https://qqzeng.top/2019/05/14/nsq-topic-%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/" target="_blank" rel="noopener">nsq topic 源码简析</a>内容相对简单，以<code>topic</code>为核心，阐述<code>topic</code>实例结构组成以及<code>topic</code>实例的创建、删除、关闭和查询流程；</li>
<li><a href="https://qqzeng.top/2019/05/14/nsq-channel-%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/" target="_blank" rel="noopener">nsq channel 源码简析</a>文章的行文同上一篇文章类似，以<code>channel</code>为核心，阐述<code>channel</code>实例结构组成以及<code>channel</code>实例的创建、删除、关闭和查询流程，并附带分析了<code>Message</code>实例结构；</li>
<li><a href="https://qqzeng.top/2019/05/15/nsq-%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%AE%A2%E9%98%85%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/" target="_blank" rel="noopener">nsq 消息发送订阅源码简析</a>，是这一系列文章中最重要的一篇，它对于理解<code>nsq</code>分布式实时消息消息队列的关键工作原理至关重要。它重点阐述<code>topic</code>实例如何将消息发送给它所关联的<code>channel</code>集合，以及<code>nsqd</code>实例如何处理消息处理超时和被延迟的消息处理。另外，简要分析了客户端执行的几条命令请求，如生产者发布消息流程和消费者订阅消息流程。</li>
</ol>
<p>完整的源码注释可以参考<a href="https://github.com/qqzeng/nsqio/tree/master/nsq" target="_blank" rel="noopener">这里</a>。考虑到个人能力有限，因此无论文章内容或源码注释存在错误，欢迎留言指正！</p>
<p>参考文献</p>
<p>[1]. <a href="https://github.com/nsqio/nsq" target="_blank" rel="noopener">https://github.com/nsqio/nsq</a><br>[2]. <a href="https://nsq.io/overview/quick_start.html" target="_blank" rel="noopener">https://nsq.io/overview/quick_start.html</a></p>
]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title>nsq channel 源码简析</title>
    <url>/2019/05/14/nsq-channel-%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/</url>
    <content><![CDATA[<p>上一篇文章阐述了<code>topic</code>模块的源码。即以<code>topic</code>为核心分析<code>topic</code>结构组件、<code>topic</code>实例的创建、删除以及查找这四方面的源码逻辑。同时也将这些方法放到一个完整的请求调用链中串联分析，以在整体上把握程序逻辑。本文的主题是<code>channel</code>（注意不要与<code>go channel</code>混淆）。<code>channel</code>可以视为发送消息的队列，它更贴近于消费者端，一旦<code>topic</code>实例从生产者那里收到一条消息，它会将这条消息复制并发送到每一个与它关联的<code>channel</code>，然后由<code>channel</code>将此消息随机发送到一个订阅了此<code>channel</code>的客户端。<code>channel</code>实例存储消息涉及到两个消息队列：内存消息队列和持久化消息队列。另外，<code>channel</code>还维护两个和消息发送相关的优先级队列：正在发送的消息队列和被推迟发送的消息队列。同样，本文只论述<code>channel</code>本身的相关逻辑，不涉及<code>channel</code>收发消息的逻辑。</p>
<a id="more"></a>

<p>本文分析<code>nsq channel</code>模块的源码，更详细<code>nsq</code>源码注释可在<a href="https://github.com/qqzeng/nsqio/tree/master/nsq" target="_blank" rel="noopener">这里</a>找到，注释源码版本为<code>v1.1.0</code>，仅供参考。本文所涉及到源码主要为<code>/nsq/nsqd/</code>和<code>/nsq/internal/</code>下的若干子目录。</p>
<p>同上一篇分析<code>topic</code>的源码类似，本文侧重于分析<code>channel</code>模块本身相关源码，而关于<code>channel</code>如何接收<code>topic</code>发送的消息、又如何对消息进行存储管理，最后又如何将消息推送给客户端，这部分会另外写一篇文章专门阐述。本文从五个方面来阐述<code>channel</code>：其一，简要介绍<code>channel</code>结构字段的组成；其二，由于<code>channel</code>同<code>message</code>密切相关，因此，也会分析<code>message</code>相关的字段，以及<code>chanel</code>维护的两个和消息发送相关的优先级队列。其三，阐述创建<code>channel</code>相关逻辑；其四，分析删除<code>channel</code>的过程；最后阐述<code>chanel</code>的查询过程。显然，本文分析<code>channel</code>的模式大体上同上一篇文章分析<code>topic</code>的模式相同，因此笔者会尽量精简介绍。</p>
<h2 id="channel-实例结构"><a href="#channel-实例结构" class="headerlink" title="channel 实例结构"></a>channel 实例结构</h2><p>相比<code>topic</code>结构，<code>channel</code>结构所包含的字段稍复杂些，重要的有：<code>topicName</code>代表<code>channel</code>实例所隶属的<code>topic</code>实例的名称；两个消息队列实例：<code>backend</code>表示<code>channel</code>使用的消息持久化队列接口，<code>memoryMsgChan</code>则表示内存消息队列；<code>clients</code>表示订阅此<code>channel</code>的客户端实例集合；<code>ephemeral</code>字段表示<code>channel</code>是否是临时的，临时的<code>channel</code>（<code>#ephemeral</code>开头）同样不会被持久化(<code>PersistMetadata</code>)，且当<code>channel</code> 关联的所有客户端都被移除后，此<code>channel</code>也会被删除（同临时的<code>topic</code>含义类似）。最后还有两个和消息发送相关的优先级队列：<code>deferredPQ</code>代表被延迟发送的消息集合，它是一个最小堆优先级队列，其中优先级比较字段为消息发送时间(<code>Item.Priority</code>)。<code>inFlightPQ</code>代表正在发送的消息集合，同样是最小堆优先级队列，优先级比较字段也为消息发送时间(<code>Message.pri</code>)。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Channel <span class="keyword">struct</span> &#123;</span><br><span class="line">	<span class="comment">// 64bit atomic vars need to be first for proper alignment on 32bit platforms</span></span><br><span class="line">	requeueCount <span class="keyword">uint64</span>				<span class="comment">// 需要重新排队的消息数</span></span><br><span class="line">	messageCount <span class="keyword">uint64</span>				<span class="comment">// 接收到的消息的总数</span></span><br><span class="line">	timeoutCount <span class="keyword">uint64</span>				<span class="comment">// 正在发送的消息的数量</span></span><br><span class="line"></span><br><span class="line">	sync.RWMutex					<span class="comment">// guards</span></span><br><span class="line"></span><br><span class="line">	topicName <span class="keyword">string</span>				<span class="comment">// 其所对应的 topic 名称</span></span><br><span class="line">	name      <span class="keyword">string</span>				<span class="comment">// channel 名称</span></span><br><span class="line">	ctx       *context				<span class="comment">// nsqd 实例</span></span><br><span class="line">	backend BackendQueue			<span class="comment">// 后端消息持久化的队列</span></span><br><span class="line">	<span class="comment">// 内存消息通道。 其关联的 topic 会向此 channel 发送消息，</span></span><br><span class="line">    <span class="comment">// 且所有订阅的 client 会开启一个 go routine 订阅此 channel</span></span><br><span class="line">	memoryMsgChan <span class="keyword">chan</span> *Message</span><br><span class="line">	exitFlag      <span class="keyword">int32</span>				<span class="comment">// 退出标识（同 topic 的 exitFlag 作用类似）</span></span><br><span class="line">	exitMutex     sync.RWMutex</span><br><span class="line">	<span class="comment">// state tracking</span></span><br><span class="line">	clients        <span class="keyword">map</span>[<span class="keyword">int64</span>]Consumer<span class="comment">// 与此 channel关联的client集合，即订阅的Consumer 集合</span></span><br><span class="line">	paused         <span class="keyword">int32</span> <span class="comment">// 若paused属性被设置，则那些订阅了此channel的客户端不会被推送消息</span></span><br><span class="line">	ephemeral      <span class="keyword">bool</span>				<span class="comment">// 标记此 channel 是否是临时的</span></span><br><span class="line">	deleteCallback <span class="function"><span class="keyword">func</span><span class="params">(*Channel)</span>	// 删除回调函数（同 <span class="title">topic</span> 的 <span class="title">deleteCallback</span> 作用类似）</span></span><br><span class="line"><span class="function">	<span class="title">deleter</span>        <span class="title">sync</span>.<span class="title">Once</span></span></span><br><span class="line"><span class="function">	// <span class="title">Stats</span> <span class="title">tracking</span></span></span><br><span class="line"><span class="function">	<span class="title">e2eProcessingLatencyStream</span> *<span class="title">quantile</span>.<span class="title">Quantile</span></span></span><br><span class="line"><span class="function">	// 延迟投递消息集合，消息体会放入 <span class="title">deferredPQ</span>，并且由后台的<span class="title">queueScanLoop</span>协程来扫描消息</span></span><br><span class="line"><span class="function">	// 将过期的消息照常使用 <span class="title">c</span>.<span class="title">put</span><span class="params">(msg)</span> 发送出去。</span></span><br><span class="line"><span class="function">	<span class="title">deferredMessages</span> <span class="title">map</span>[<span class="title">MessageID</span>]*<span class="title">pqueue</span>.<span class="title">Item</span></span></span><br><span class="line"><span class="function">	<span class="title">deferredPQ</span>       <span class="title">pqueue</span>.<span class="title">PriorityQueue</span>		// 被延迟投递消息集合对应的 <span class="title">PriorityQueue</span></span></span><br><span class="line"><span class="function">	<span class="title">deferredMutex</span>    <span class="title">sync</span>.<span class="title">Mutex</span>					// <span class="title">guards</span> <span class="title">deferredMessages</span></span></span><br><span class="line"><span class="function">	// 正在发送中的消息记录集合，直到收到客户端的 <span class="title">FIN</span> 才删除，否则一旦超过 <span class="title">timeout</span>，则重传消息。</span></span><br><span class="line"><span class="function">	// （因此<span class="title">client</span>需要对消息做去重处理 <span class="title">de</span>-<span class="title">duplicate</span>）</span></span><br><span class="line"><span class="function">	<span class="title">inFlightMessages</span> <span class="title">map</span>[<span class="title">MessageID</span>]*<span class="title">Message</span></span></span><br><span class="line"><span class="function">	<span class="title">inFlightPQ</span>       <span class="title">inFlightPqueue</span>				// 正在发送中的消息记录集合 对应的 <span class="title">inFlightPqueue</span></span></span><br><span class="line"><span class="function">	<span class="title">inFlightMutex</span>    <span class="title">sync</span>.<span class="title">Mutex</span>					// <span class="title">guards</span> <span class="title">inFlightMessages</span></span></span><br><span class="line"><span class="function">&#125; // /<span class="title">nsq</span>/<span class="title">nsqd</span>/<span class="title">channel</span>.<span class="title">go</span></span></span><br></pre></td></tr></table></figure>

<h2 id="Message-实例结构"><a href="#Message-实例结构" class="headerlink" title="Message 实例结构"></a>Message 实例结构</h2><p><code>Message</code>代表生产者生产或消费者消费的一条消息。它是<code>nsq</code>消息队列系统中最基本的元素。<code>Message</code>结构包含的重要字段有：<code>Attempts</code>表示消息已经重复发送的次数（一旦消息投递次数过多，客户端可针对性地做处理）；<code>deliveryTS</code>表示<code>channel</code>向<code>client</code>发送消息时刻的时间戳；<code>clientID</code>表示消息被投递的目的客户端标识；<code>pri</code>表示消息优先级（即为消息被处理的<code>deadline</code>）；<code>deferred</code>为消息被延迟的时间（若消息确实被延迟了）。另外，网络传输的消息包格式构成为：<code>Timestamp</code>(<code>8byte</code>) + <code>Attempts</code>(<code>2byte</code>) + <code>MessageID</code>(<code>16byte</code>) + <code>MessageBody</code>(<code>N-byte</code>)。具体可参考相关源码，<code>Message</code>相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 代表逻辑消息实体结构</span></span><br><span class="line"><span class="keyword">type</span> Message <span class="keyword">struct</span> &#123;</span><br><span class="line">	ID        MessageID				<span class="comment">// 消息 ID</span></span><br><span class="line">	Body      []<span class="keyword">byte</span>				<span class="comment">// 消息体</span></span><br><span class="line">	Timestamp <span class="keyword">int64</span>					<span class="comment">// 当前时间戳</span></span><br><span class="line">	Attempts  <span class="keyword">uint16</span>				<span class="comment">// 消息重复投递次数</span></span><br><span class="line">	<span class="comment">// for in-flight handling</span></span><br><span class="line">	deliveryTS time.Time			<span class="comment">// 投递消息的时间戳</span></span><br><span class="line">	clientID   <span class="keyword">int64</span>				<span class="comment">// 接收此消息的 client ID</span></span><br><span class="line">	pri        <span class="keyword">int64</span>				<span class="comment">// 消息的优先级（即消息被处理的 deadline 时间戳）</span></span><br><span class="line">	index      <span class="keyword">int</span>					<span class="comment">// 当前消息在 priority queue 中的索引</span></span><br><span class="line">	deferred   time.Duration		<span class="comment">// 若消息被延迟，则为延迟时间</span></span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/message.go</span></span><br></pre></td></tr></table></figure>

<p>另外简要贴出两个消息发送优先级队列<code>inFlightPQ</code>和<code>deferredPQ</code>核心组成代码：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> inFlightPqueue []*Message</span><br><span class="line"><span class="comment">// 使用一个 heap 堆来存储所有的 message，</span></span><br><span class="line"><span class="comment">// 根据 Message.pri（即消息处理时间的 deadline 时间戳） 来组织成一个小顶堆</span></span><br><span class="line"><span class="comment">// 非线程安全，需要 caller 来保证线程安全</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newInFlightPqueue</span><span class="params">(capacity <span class="keyword">int</span>)</span> <span class="title">inFlightPqueue</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">make</span>(inFlightPqueue, <span class="number">0</span>, capacity)</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/in_flight_pqueue.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 若堆顶元素的 pri 大于此时的 timestamp，则返回　nil, 及二者的差值</span></span><br><span class="line"><span class="comment">// 此种情况表示还未到处理超时时间，即 nsqd 还不需要将它重新加入发送队列。</span></span><br><span class="line"><span class="comment">// 否则返回堆顶元素, 0，表示堆顶元素已经被客户端处理超时了，需要重新加入发送队列</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(pq *inFlightPqueue)</span> <span class="title">PeekAndShift</span><span class="params">(max <span class="keyword">int64</span>)</span> <span class="params">(*Message, <span class="keyword">int64</span>)</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(*pq) == <span class="number">0</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, <span class="number">0</span></span><br><span class="line">	&#125;</span><br><span class="line">	x := (*pq)[<span class="number">0</span>]</span><br><span class="line">	<span class="keyword">if</span> x.pri &gt; max &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, x.pri - max</span><br><span class="line">	&#125;</span><br><span class="line">	pq.Pop()</span><br><span class="line">	<span class="keyword">return</span> x, <span class="number">0</span></span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/in_flight_pqueue.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 最小堆优先级队列，其操作接口同 in_flight_queue （nsqd/in_flight_queue.go）类似</span></span><br><span class="line"><span class="comment">// 不同的是它借用了标准库 container/heap/heap.go</span></span><br><span class="line"><span class="keyword">type</span> PriorityQueue []*Item</span><br><span class="line"><span class="keyword">type</span> Item <span class="keyword">struct</span> &#123;</span><br><span class="line">	Value    <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">	Priority <span class="keyword">int64</span></span><br><span class="line">	Index    <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">(capacity <span class="keyword">int</span>)</span> <span class="title">PriorityQueue</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">make</span>(PriorityQueue, <span class="number">0</span>, capacity)</span><br><span class="line">&#125; <span class="comment">// /nsq/internal/pqueue/pqueue.go</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(pq *PriorityQueue)</span> <span class="title">PeekAndShift</span><span class="params">(max <span class="keyword">int64</span>)</span> <span class="params">(*Item, <span class="keyword">int64</span>)</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> pq.Len() == <span class="number">0</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, <span class="number">0</span></span><br><span class="line">	&#125;</span><br><span class="line">	item := (*pq)[<span class="number">0</span>]</span><br><span class="line">	<span class="keyword">if</span> item.Priority &gt; max &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, item.Priority - max</span><br><span class="line">	&#125;</span><br><span class="line">	heap.Remove(pq, <span class="number">0</span>) <span class="comment">// Remove 方法中重新调整了堆的结构</span></span><br><span class="line">	<span class="keyword">return</span> item, <span class="number">0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="创建-topic-实例"><a href="#创建-topic-实例" class="headerlink" title="创建 topic 实例"></a>创建 topic 实例</h2><p><code>channel</code>的构造方法同<code>topic</code>的构造方法所涉及的逻辑非常相似，只不过<code>channel</code>还初始化了前面阐述的两个用于存储发送消息的优先级队列<code>inFlightPQ</code>和<code>deferredPQ</code>。因此就不再阐述，读者若需参考，可以看<a href="https://qqzeng.top/2019/05/14/nsq-topic-%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/#%E5%88%9B%E5%BB%BA-topic-%E5%AE%9E%E4%BE%8B" target="_blank" rel="noopener">这里</a>。注意，它同样会通过<code>nsqd.Notify</code>通知<code>nsqlookupd</code>有新的<code>channel</code>创建，因此需要重新调用<code>PersistMetadata</code>以持久化元数据。（方法调用链为：<code>NewChannel-&gt;nsqd.Notify-&gt;nsqd.lookupLoop-&gt;nsqd.PersistMetadata</code>）相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// channel 构造函数</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewChannel</span><span class="params">(topicName <span class="keyword">string</span>, channelName <span class="keyword">string</span>, ctx *context,</span></span></span><br><span class="line"><span class="function"><span class="params">	deleteCallback <span class="keyword">func</span>(*Channel)</span>) *<span class="title">Channel</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 初始化 channel 部分参数</span></span><br><span class="line">	c := &amp;Channel&#123;</span><br><span class="line">		topicName:      topicName,</span><br><span class="line">		name:           channelName,</span><br><span class="line">		memoryMsgChan:  <span class="built_in">make</span>(<span class="keyword">chan</span> *Message, ctx.nsqd.getOpts().MemQueueSize),</span><br><span class="line">		clients:        <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">int64</span>]Consumer),</span><br><span class="line">		deleteCallback: deleteCallback,</span><br><span class="line">		ctx:            ctx,</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(ctx.nsqd.getOpts().E2EProcessingLatencyPercentiles) &gt; <span class="number">0</span> &#123;</span><br><span class="line">		c.e2eProcessingLatencyStream = quantile.New(</span><br><span class="line">			ctx.nsqd.getOpts().E2EProcessingLatencyWindowTime,</span><br><span class="line">			ctx.nsqd.getOpts().E2EProcessingLatencyPercentiles,</span><br><span class="line">		)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 初始化 channel 维护的两个消息队列</span></span><br><span class="line">	c.initPQ()</span><br><span class="line">	<span class="comment">// 3. 同　topic　类似，那些 ephemeral 类型的 channel 不会关联到一个 BackendQueue，</span></span><br><span class="line">    <span class="comment">// 而只是被赋予了一个 dummy BackendQueue</span></span><br><span class="line">	<span class="keyword">if</span> strings.HasSuffix(channelName, <span class="string">"#ephemeral"</span>) &#123;</span><br><span class="line">		c.ephemeral = <span class="literal">true</span></span><br><span class="line">		c.backend = newDummyBackendQueue()</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		dqLogf := <span class="function"><span class="keyword">func</span><span class="params">(level diskqueue.LogLevel, f <span class="keyword">string</span>, args ...<span class="keyword">interface</span>&#123;&#125;)</span></span> &#123;</span><br><span class="line">			opts := ctx.nsqd.getOpts()</span><br><span class="line">			lg.Logf(opts.Logger, opts.LogLevel, lg.LogLevel(level), f, args...)</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// backend names, for uniqueness, automatically include the topic...</span></span><br><span class="line">		<span class="comment">// 4. 实例化一个后端持久化存储，同样是通过 go-diskqueue  来创建的，</span></span><br><span class="line">        <span class="comment">// 其初始化参数同 topic 中实例化 backendQueue 参数类似</span></span><br><span class="line">		backendName := getBackendName(topicName, channelName)</span><br><span class="line">		c.backend = diskqueue.New(</span><br><span class="line">			backendName,</span><br><span class="line">			ctx.nsqd.getOpts().DataPath,</span><br><span class="line">			ctx.nsqd.getOpts().MaxBytesPerFile,</span><br><span class="line">			<span class="keyword">int32</span>(minValidMsgLength),</span><br><span class="line">			<span class="keyword">int32</span>(ctx.nsqd.getOpts().MaxMsgSize)+minValidMsgLength,</span><br><span class="line">			ctx.nsqd.getOpts().SyncEvery,</span><br><span class="line">			ctx.nsqd.getOpts().SyncTimeout,</span><br><span class="line">			dqLogf,</span><br><span class="line">		)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 5. 通知 lookupd 添加注册信息</span></span><br><span class="line">	c.ctx.nsqd.Notify(c)</span><br><span class="line">	<span class="keyword">return</span> c</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/channel.go</span></span><br></pre></td></tr></table></figure>

<p>类似地，前文提过<code>channel</code>不会被预先创建，一般是因为某个消费者在订阅<code>channel</code>时才被创建的。同样，我们追踪方法调用，发现只有<code>topic.getOrCreateChannel</code>方法调用了<code>NewChannel</code>构造方法，而它又只会被<code>topic.GetChannel</code>方法调用。因此，程序中只存在三条调用链：其一，<code>nsqd.Start-&gt;nsqd.LoadMetadata-&gt;topic.GetChannel-&gt;topic.getOrCreateChannel-&gt;NewChannel</code>；其二，<code>httpServer.doCreateChannel-&gt;topic.GetChannel</code>；以及<code>protocolV2.SUB-&gt;topic.GetChannel</code>。</p>
<h2 id="删除或关闭-channel-实例"><a href="#删除或关闭-channel-实例" class="headerlink" title="删除或关闭 channel 实例"></a>删除或关闭 channel 实例</h2><p>删除(<code>Delete</code>)或者关闭(<code>Close</code>)<code>channel</code>实例的方法逻辑同<code>topic</code>也非常类似。相似部分不多阐述，读者若需要参考，可以看<a href="https://qqzeng.top/2019/05/14/nsq-topic-%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/#%E5%88%A0%E9%99%A4%E6%88%96%E5%85%B3%E9%97%AD-topic-%E5%AE%9E%E4%BE%8B" target="_blank" rel="noopener">这里</a>。这里重点阐述两个不同点：其一，无论是关闭还是删除<code>channel</code>都会显式地将订阅了此<code>channel</code>的客户端强制关闭（当然是关闭客户端在服务端的实体）；其二，关闭和删除<code>channel</code>都会显式刷新<code>channel</code>，即将<code>channel</code>所维护的三个消息队列：内存消息队列<code>memoryMsgChan</code>、正在发送的优先级消息队列<code>inFlightPQ</code>以及被推迟发送的优先级消息队列<code>deferredPQ</code>，将它们的消息显式写入到持久化存储消息队列。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 删除此 channel，清空所有消息，然后关闭</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Channel)</span> <span class="title">Delete</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> c.exit(<span class="literal">true</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 只是将三个消息队列中的消息刷盘，然后关闭</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Channel)</span> <span class="title">Close</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> c.exit(<span class="literal">false</span>)</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/channel.go</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Channel)</span> <span class="title">exit</span><span class="params">(deleted <span class="keyword">bool</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	c.exitMutex.Lock()</span><br><span class="line">	<span class="keyword">defer</span> c.exitMutex.Unlock()</span><br><span class="line">	<span class="comment">// 1. 保证还未被设置 exitFlag，即还在运行中，同时设置 exitFlag</span></span><br><span class="line">	<span class="keyword">if</span> !atomic.CompareAndSwapInt32(&amp;c.exitFlag, <span class="number">0</span>, <span class="number">1</span>) &#123;</span><br><span class="line">		<span class="keyword">return</span> errors.New(<span class="string">"exiting"</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 若需要删除数据，则通知 nsqlookupd，有 channel 被删除</span></span><br><span class="line">	<span class="keyword">if</span> deleted &#123;</span><br><span class="line">		c.ctx.nsqd.logf(LOG_INFO, <span class="string">"CHANNEL(%s): deleting"</span>, c.name)</span><br><span class="line">		c.ctx.nsqd.Notify(c)</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		c.ctx.nsqd.logf(LOG_INFO, <span class="string">"CHANNEL(%s): closing"</span>, c.name)</span><br><span class="line">	&#125;</span><br><span class="line">	c.RLock()</span><br><span class="line">	<span class="comment">// 3. 强制关闭所有订阅了此 channel 的客户端</span></span><br><span class="line">	<span class="keyword">for</span> _, client := <span class="keyword">range</span> c.clients &#123;</span><br><span class="line">		client.Close()</span><br><span class="line">	&#125;</span><br><span class="line">	c.RUnlock()</span><br><span class="line">	<span class="comment">// 4. 清空此 channel 所维护的内存消息队列和持久化存储消息队列中的消息</span></span><br><span class="line">	<span class="keyword">if</span> deleted &#123;</span><br><span class="line">		<span class="comment">// empty the queue (deletes the backend files, too)</span></span><br><span class="line">		c.Empty()</span><br><span class="line">		<span class="comment">// 5. 删除持久化存储消息队列中的消息</span></span><br><span class="line">		<span class="keyword">return</span> c.backend.Delete()</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 6. 强制将内存消息队列、以及两个发送消息优先级队列中的消息写到持久化存储中</span></span><br><span class="line">	c.flush()</span><br><span class="line">	<span class="comment">// 7. 关闭持久化存储消息队列</span></span><br><span class="line">	<span class="keyword">return</span> c.backend.Close()</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/channel.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 清空 channel 的消息</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Channel)</span> <span class="title">Empty</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	c.Lock()</span><br><span class="line">	<span class="keyword">defer</span> c.Unlock()</span><br><span class="line">	<span class="comment">// 1. 重新初始化（清空） in-flight queue 及 deferred queue</span></span><br><span class="line">	c.initPQ()</span><br><span class="line">	<span class="comment">// 2. 清空由 channel 为客户端维护的一些信息，比如 当前正在发送的消息的数量 InFlightCount</span></span><br><span class="line">	<span class="comment">// 同时更新了 ReadyStateChan</span></span><br><span class="line">	<span class="keyword">for</span> _, client := <span class="keyword">range</span> c.clients &#123;</span><br><span class="line">		client.Empty()</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 3. 将 memoryMsgChan 中的消息清空</span></span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> &lt;-c.memoryMsgChan:</span><br><span class="line">		<span class="keyword">default</span>:</span><br><span class="line">			<span class="keyword">goto</span> finish</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 4. 最后将后端持久化存储中的消息清空</span></span><br><span class="line">finish:</span><br><span class="line">	<span class="keyword">return</span> c.backend.Empty()</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/channel.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 将未消费的消息都写到持久化存储中，</span></span><br><span class="line"><span class="comment">// 主要包括三个消息集合：memoryMsgChan、inFlightMessages和deferredMessages</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Channel)</span> <span class="title">flush</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> msgBuf bytes.Buffer</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// 1. 将内存消息队列中的积压的消息刷盘</span></span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> msg := &lt;-c.memoryMsgChan:</span><br><span class="line">			err := writeMessageToBackend(&amp;msgBuf, msg, c.backend)</span><br><span class="line">			<span class="comment">// ...</span></span><br><span class="line">		<span class="keyword">default</span>:</span><br><span class="line">			<span class="keyword">goto</span> finish</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 将还未发送出去的消息 inFlightMessages 也写到持久化存储</span></span><br><span class="line">finish:</span><br><span class="line">	c.inFlightMutex.Lock()</span><br><span class="line">	<span class="keyword">for</span> _, msg := <span class="keyword">range</span> c.inFlightMessages &#123;</span><br><span class="line">		err := writeMessageToBackend(&amp;msgBuf, msg, c.backend)</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">	&#125;</span><br><span class="line">	c.inFlightMutex.Unlock()</span><br><span class="line">	<span class="comment">// 3. 将被推迟发送的消息集合中的 deferredMessages 消息也到持久化存储</span></span><br><span class="line">	c.deferredMutex.Lock()</span><br><span class="line">	<span class="keyword">for</span> _, item := <span class="keyword">range</span> c.deferredMessages &#123;</span><br><span class="line">		msg := item.Value.(*Message)</span><br><span class="line">		err := writeMessageToBackend(&amp;msgBuf, msg, c.backend)</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">	&#125;</span><br><span class="line">	c.deferredMutex.Unlock()</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/channel.go</span></span><br></pre></td></tr></table></figure>

<h2 id="查询-channel-实例"><a href="#查询-channel-实例" class="headerlink" title="查询 channel 实例"></a>查询 channel 实例</h2><p>同样是即依据名称查询（获取）<code>channel</code>实例，它被定义为<code>topic</code>实例的方法。查询逻辑的关键是，若此<code>channl</code>不在<code>topic</code>的<code>channel</code>集合中，则需要创建一个新的<code>channel</code>实例。并为其注册<code>channel</code>实例的删除回调函数。接下来，还要更新<code>topic.memoryMsgChan</code>和<code>topoc.backendChan</code>结构（因为<code>channel</code>集合更新了）。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 根据 channel 名称返回 channel 实例，且有可能是新建的。线程安全方法。</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *Topic)</span> <span class="title">GetChannel</span><span class="params">(channelName <span class="keyword">string</span>)</span> *<span class="title">Channel</span></span> &#123;</span><br><span class="line">	t.Lock()</span><br><span class="line">	channel, isNew := t.getOrCreateChannel(channelName)</span><br><span class="line">	t.Unlock()</span><br><span class="line">	<span class="keyword">if</span> isNew &#123;</span><br><span class="line">		<span class="comment">// update messagePump state</span></span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="comment">// 若此 channel 为新创建的，则 push 消息到 channelUpdateChan中，</span></span><br><span class="line">            <span class="comment">// 使 memoryMsgChan 及 backend 刷新状态</span></span><br><span class="line">		<span class="keyword">case</span> t.channelUpdateChan &lt;- <span class="number">1</span>:</span><br><span class="line">		<span class="keyword">case</span> &lt;-t.exitChan:</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> channel</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/topic.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 根据 channel 名称获取指定的 channel，若不存在，则创建一个新的 channel 实例。非线程安全</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *Topic)</span> <span class="title">getOrCreateChannel</span><span class="params">(channelName <span class="keyword">string</span>)</span> <span class="params">(*Channel, <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">	channel, ok := t.channelMap[channelName]</span><br><span class="line">	<span class="keyword">if</span> !ok &#123;</span><br><span class="line">		<span class="comment">// 注册 channel 被删除时的回调函数</span></span><br><span class="line">		deleteCallback := <span class="function"><span class="keyword">func</span><span class="params">(c *Channel)</span></span> &#123;</span><br><span class="line">			t.DeleteExistingChannel(c.name)</span><br><span class="line">		&#125;</span><br><span class="line">		channel = NewChannel(t.name, channelName, t.ctx, deleteCallback)</span><br><span class="line">		t.channelMap[channelName] = channel</span><br><span class="line">		t.ctx.nsqd.logf(LOG_INFO, <span class="string">"TOPIC(%s): new channel(%s)"</span>, t.name, channel.name)</span><br><span class="line">		<span class="keyword">return</span> channel, <span class="literal">true</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> channel, <span class="literal">false</span></span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/topic.go</span></span><br></pre></td></tr></table></figure>

<p>简单小结，本文内容同上一篇文章分析<code>topic</code>源码非常相似，因此阐述得比较简单，只是贴了注释的源码，并重点阐述二者不同。文章围绕<code>channel</code>展开，首先简要介绍<code>channel</code>结构字段的组成；然后，分析<code>message</code>相关的字段，以及<code>chanel</code>维护的两个和消息发送相关的优先级队列：<code>inFlightPQ</code>，存放正在发送的消息的优先级队列，以及<code>deferredPQ</code>，存放被推迟发送的消息的优先级队列。接下来，分析了<code>channel</code>实例化的逻辑以及<code>channel</code>删除逻辑；最后阐述<code>channel</code>的查询过程，查询过程需要注意的是通知<code>topic</code>的消息处理主循环<code>messagePump</code>更新两个消息队列实例。</p>
<p>参考文献</p>
<p>[1]. <a href="https://github.com/nsqio/nsq" target="_blank" rel="noopener">https://github.com/nsqio/nsq</a><br>[2]. <a href="https://nsq.io/overview/quick_start.html" target="_blank" rel="noopener">https://nsq.io/overview/quick_start.html</a></p>
]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title>nsq topic 源码简析</title>
    <url>/2019/05/14/nsq-topic-%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/</url>
    <content><![CDATA[<p>上一篇文章阐述了<code>nsqd</code>模块的源码。准确而言是<code>nsqd</code>服务启动过程的部分源码。内容非常多，总共分为五个部分来分析，其中略讲的内容包括利用<code>svc</code>启动进程的流程、<code>nsqd</code>实例创建及初始化过程。重点阐述的内容包括<code>nsqd</code>异步开启<code>nsqlookupd</code>查询过程，以及<code>nsqd</code>与<code>nsqlookupd</code>通信的主循环逻辑。另外，还有<code>nsqd</code>建立的<code>tcp</code>连接处理器的相关内容，这点比较复杂，涉及两个过程：<code>IOLoop</code>主循环读取连接的请求内容，以及<code>messagePump</code>处理消息发送的核心逻辑。最后略讲<code>http</code>连接处理器的创建过程。本文的主题是<code>topic</code>，相对简单。<code>topic</code>可以看作是生产者投递消息的一个逻辑键，一个<code>nsqd</code>实例可以维护多个<code>topic</code>实例，每当生产者将消息投递到某个的<code>nsqd</code>上特定的<code>topic</code>时，它随即将消息拷贝后发送到与其关联的<code>channel</code>实例集合。与<code>channel</code>实例类似，<code>topic</code>实例存储消息也涉及到两个消息队列：内存消息队列和持久化消息队列，因此对于消息的存储维护，<code>topic</code>实例和<code>channel</code>实例分开管理。同样，为了方便读者理解，本文只论述到<code>topic</code>本身的相关逻辑，换言之，不涉及到<code>topic</code>收发消息的逻辑。</p>
<a id="more"></a>

<p>本文分析<code>nsq topic</code>模块的相关逻辑，更详细<code>nsq</code>源码注释可在<a href="https://github.com/qqzeng/nsqio/tree/master/nsq" target="_blank" rel="noopener">这里</a>找到，注释源码版本为<code>v1.1.0</code>，仅供参考。本文所涉及到源码主要为<code>/nsq/nsqd/</code>和<code>/nsq/internal/</code>下的若干子目录。</p>
<p>本文侧重于分析<code>topic</code>模块本身相关源码，而关于<code>topic</code>如何从生产者收到消息、如何对消息进行存储处理，最后又如何将消息转发给<code>channel</code>实例，这部分会另外写一篇文章专门阐述，这也是<code>nsq</code>系统非常核心的处理流程。本文从四个方面来阐述<code>topic</code>：其一，简要介绍<code>topic</code>结构相关字段；其二，阐述创建<code>topic</code>相关逻辑；其三，分析删除<code>topic</code>的过程；最后阐述<code>topic</code>的查询过程。</p>
<h2 id="topic-实例结构"><a href="#topic-实例结构" class="headerlink" title="topic 实例结构"></a>topic 实例结构</h2><p><code>topic</code>结构所包含的字段比较简单，其中重要的包括：<code>channelMap</code>表示<code>topic</code>实例所关联的<code>channel</code>实例集合；<code>backend</code>表示<code>topic</code>所使用的消息持久化队列接口；<code>memoryMsgChan</code>则表示内存消息队列；还有一个<code>channelUpdateChan</code>通道表示当消息被更新时（添加或删除），通知<code>topic</code>的消息处理主循环中执行相应的逻辑，即更新两个消息队列。<code>ephemeral</code>字段表示<code>topic</code>是否是临时的，所谓临时的<code>topic</code>（<code>#ephemeral</code>开头）不会被持久化(<code>PersistMetadata</code>)，且当<code>topic</code> 包含的所有<code>channel</code>都被删除后，此<code>topic</code>也会被删除。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Topic <span class="keyword">struct</span> &#123;</span><br><span class="line">	<span class="comment">// 64bit atomic vars need to be first for proper alignment on 32bit platforms</span></span><br><span class="line">	messageCount <span class="keyword">uint64</span>			<span class="comment">// 此 topic 所包含的消息的总数（内存+磁盘）</span></span><br><span class="line">	messageBytes <span class="keyword">uint64</span>			<span class="comment">// 此 topic 所包含的消息的总大小（内存+磁盘）</span></span><br><span class="line">	sync.RWMutex				<span class="comment">// guards channelMap</span></span><br><span class="line">	name              <span class="keyword">string</span>					<span class="comment">// topic 名称</span></span><br><span class="line">	channelMap        <span class="keyword">map</span>[<span class="keyword">string</span>]*Channel		<span class="comment">// topic 所包含的 channel 集合</span></span><br><span class="line">	backend           BackendQueue				<span class="comment">// 代表持久化存储的通道</span></span><br><span class="line">	memoryMsgChan     <span class="keyword">chan</span> *Message				<span class="comment">// 代表消息在内存中的通道</span></span><br><span class="line">	startChan         <span class="keyword">chan</span> <span class="keyword">int</span>					<span class="comment">// 消息处理循环开关</span></span><br><span class="line">	exitChan          <span class="keyword">chan</span> <span class="keyword">int</span>					<span class="comment">// topic 消息处理循环退出开关</span></span><br><span class="line">	channelUpdateChan <span class="keyword">chan</span> <span class="keyword">int</span>					<span class="comment">// 消息更新的开关</span></span><br><span class="line">	waitGroup         util.WaitGroupWrapper		<span class="comment">// waitGroup 的一个 wrapper</span></span><br><span class="line">	<span class="comment">// 其会在删除一个topic时被设置，且若被设置，则 putMessage(s)操作会返回错误，拒绝写入消息</span></span><br><span class="line">	exitFlag          <span class="keyword">int32</span></span><br><span class="line">	idFactory         *guidFactory				<span class="comment">// 用于生成客户端实例的ID</span></span><br><span class="line">	<span class="comment">// 临时的 topic（#ephemeral开头），此种类型的 topic 不会进行持久化，</span></span><br><span class="line">	<span class="comment">// 当此 topic 所包含的所有的 channel 都被删除后，被标记为ephemeral的topic也会被删除</span></span><br><span class="line">	ephemeral      <span class="keyword">bool</span></span><br><span class="line">	<span class="comment">// topic 被删除前的回调函数，且对 ephemeral 类型的 topic有效，并且它只在 DeleteExistingChannel 方法中被调用</span></span><br><span class="line">	deleteCallback <span class="function"><span class="keyword">func</span><span class="params">(*Topic)</span></span></span><br><span class="line"><span class="function">	<span class="title">deleter</span>        <span class="title">sync</span>.<span class="title">Once</span></span></span><br><span class="line"><span class="function">	// 标记此 <span class="title">topic</span> 是否有被 <span class="title">paused</span>，若被 <span class="title">paused</span>，则其不会将消息写入到其关联的 <span class="title">channel</span> 的消息队列</span></span><br><span class="line"><span class="function">	<span class="title">paused</span>    <span class="title">int32</span></span></span><br><span class="line"><span class="function">	<span class="title">pauseChan</span> <span class="title">chan</span> <span class="title">int</span></span></span><br><span class="line"><span class="function">	<span class="title">ctx</span> *<span class="title">context</span>					// <span class="title">nsqd</span> 实例的 <span class="title">wrapper</span></span></span><br><span class="line"><span class="function">&#125; // /<span class="title">nsq</span>/<span class="title">nsqd</span>/<span class="title">topic</span>.<span class="title">go</span></span></span><br></pre></td></tr></table></figure>

<h2 id="创建-topic-实例"><a href="#创建-topic-实例" class="headerlink" title="创建 topic 实例"></a>创建 topic 实例</h2><p>先简单了解<code>topic</code>的构造方法，其大概涉及到这么几个步骤：先初始化实例结构，然后若此<code>topic</code>为<code>ephemeral</code>的，则设置标记，并且为此<code>topic</code>关联一个<code>DummyBackendQueue</code>作为其持久化存储，事实上，<code>DummyBackendQueue</code>表示不执行任何有效动作，显然这是考虑到临时的<code>topic</code>不用被持久化。对于正常的<code>topic</code>，则为其创建一个<a href="https://github.com/nsqio/go-diskqueue" target="_blank" rel="noopener"><code>diskqueue</code></a>实例作为后端存储消息队列，通过<code>nsqd</code>配置参数进行初始化（<code>diskqueue</code>在后面单独开一篇文章解析）。最后异步开启<code>topic</code>的消息处理主循环<code>messagePump</code>，并通知<code>nsqlookupd</code>有新的<code>topic</code>实例产生。它会在<code>nsqd.Notify</code>方法中被接收，然后将此<code>topic</code>实例压入到<code>nsqd.notifyChan</code>管道，相应地，此<code>topic</code>实例在<code>nsqd.lookupLoop</code>方法中被取出，然后构建并发送<code>REGISTER</code>命令请求给<code>nsqd</code>所维护的所有<code>nsqlookupd</code>实例。最后，通过调用<code>PersistMetadata</code>方法将此<code>topic</code>元信息持久化。（方法调用链为：<code>NewTopic-&gt;nsqd.Notify-&gt;nsqd.lookupLoop-&gt;nsqd.PersistMetadata</code>）相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// topic 的构造函数</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewTopic</span><span class="params">(topicName <span class="keyword">string</span>, ctx *context, deleteCallback <span class="keyword">func</span>(*Topic)</span>) *<span class="title">Topic</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 构造 topic 实例</span></span><br><span class="line">	t := &amp;Topic&#123;</span><br><span class="line">		name:              topicName,</span><br><span class="line">		channelMap:        <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]*Channel),</span><br><span class="line">		memoryMsgChan:     <span class="built_in">make</span>(<span class="keyword">chan</span> *Message, ctx.nsqd.getOpts().MemQueueSize),</span><br><span class="line">		startChan:         <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>, <span class="number">1</span>),</span><br><span class="line">		exitChan:          <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>),</span><br><span class="line">		channelUpdateChan: <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>),</span><br><span class="line">		ctx:               ctx,</span><br><span class="line">		paused:            <span class="number">0</span>,</span><br><span class="line">		pauseChan:         <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>),</span><br><span class="line">		deleteCallback:    deleteCallback,</span><br><span class="line">		idFactory:         NewGUIDFactory(ctx.nsqd.getOpts().ID),</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 标记那些带有 ephemeral 的 topic，并为它们构建一个 Dummy BackendQueue，</span></span><br><span class="line">	<span class="comment">// 因为这些 topic 所包含的的消息不会被持久化，因此不需要持久化队列 BackendQueue。</span></span><br><span class="line">	<span class="keyword">if</span> strings.HasSuffix(topicName, <span class="string">"#ephemeral"</span>) &#123;</span><br><span class="line">		t.ephemeral = <span class="literal">true</span></span><br><span class="line">		t.backend = newDummyBackendQueue()</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		dqLogf := <span class="function"><span class="keyword">func</span><span class="params">(level diskqueue.LogLevel, f <span class="keyword">string</span>, args ...<span class="keyword">interface</span>&#123;&#125;)</span></span> &#123;</span><br><span class="line">			opts := ctx.nsqd.getOpts()</span><br><span class="line">			lg.Logf(opts.Logger, opts.LogLevel, lg.LogLevel(level), f, args...)</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 3. 通过 diskqueue (https://github.com/nsqio/go-diskqueue) 构建持久化队列实例</span></span><br><span class="line">		t.backend = diskqueue.New(</span><br><span class="line">			topicName,						<span class="comment">// topic 名称</span></span><br><span class="line">			ctx.nsqd.getOpts().DataPath,	<span class="comment">// 数据存储路径</span></span><br><span class="line">			ctx.nsqd.getOpts().MaxBytesPerFile,		<span class="comment">// 存储文件的最大字节数</span></span><br><span class="line">			<span class="keyword">int32</span>(minValidMsgLength),				<span class="comment">// 最小的有效消息的长度</span></span><br><span class="line">			<span class="keyword">int32</span>(ctx.nsqd.getOpts().MaxMsgSize)+minValidMsgLength, <span class="comment">// 最大的有效消息的长度</span></span><br><span class="line">			<span class="comment">// 单次同步刷新消息的数量，即当消息数量达到 SyncEvery 的数量时，</span></span><br><span class="line">			<span class="comment">// 需要执行刷新动作（否则会留在操作系统缓冲区）</span></span><br><span class="line">			ctx.nsqd.getOpts().SyncEvery,</span><br><span class="line">			ctx.nsqd.getOpts().SyncTimeout,	<span class="comment">// 两次同步刷新的时间间隔，即两次同步操作的最大间隔</span></span><br><span class="line">			dqLogf,							<span class="comment">// 日志</span></span><br><span class="line">		)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 4. 执行 messagePump 方法，即 开启消息监听 go routine</span></span><br><span class="line">	t.waitGroup.Wrap(t.messagePump)</span><br><span class="line">	<span class="comment">// 5. 通知 nsqlookupd 有新的 topic 产生</span></span><br><span class="line">	t.ctx.nsqd.Notify(t)</span><br><span class="line">	<span class="keyword">return</span> t</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/topic.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 通知 nsqd 将 metadata 信息持久化到磁盘，若 nsqd 当前未处于启动过程</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *NSQD)</span> <span class="title">Notify</span><span class="params">(v <span class="keyword">interface</span>&#123;&#125;)</span></span> &#123;</span><br><span class="line">    <span class="comment">// 考虑到若在 nsqd 刚启动处于加载元数据，则此时数据并不完整，因此不会在此时执行持久化操作</span></span><br><span class="line">	persist := atomic.LoadInt32(&amp;n.isLoading) == <span class="number">0</span></span><br><span class="line">	n.waitGroup.Wrap(<span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> &lt;-n.exitChan:</span><br><span class="line">		<span class="keyword">case</span> n.notifyChan &lt;- v:</span><br><span class="line">			<span class="keyword">if</span> !persist &#123;</span><br><span class="line">				<span class="keyword">return</span></span><br><span class="line">			&#125;</span><br><span class="line">			n.Lock()</span><br><span class="line">			<span class="comment">// 重新持久化 topic 及 channel 的元信息</span></span><br><span class="line">			err := n.PersistMetadata()</span><br><span class="line">			<span class="comment">// ...</span></span><br><span class="line">			n.Unlock()</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>最后，简单分析下，程序中哪些地方会调用此构造方法。前文提到<code>topic</code>不会被提前创建，一定是因为某个生产者在注册<code>topic</code>时临时被创建的。其实通过追踪方法调用，发现只有<code>nsqd.GetTopic</code>方法调用了<code>NewTopic</code>构造方法。因此，程序中存在以下几条调用链：其一，<code>nsqd.Start-&gt;nsqd.PersistMetadata-&gt;nsqd.GetTopic-&gt;NewTopic</code>；其二，<code>httpServer.getTopicFromQuery-&gt;nsqd.GetTopic-&gt;NewTopic</code>；以及<code>protocolV2.PUB/SUB-&gt;nsqd.GetTopic</code>这三条调用路径。相信读者已经非常清楚了。</p>
<h2 id="删除或关闭-topic-实例"><a href="#删除或关闭-topic-实例" class="headerlink" title="删除或关闭 topic 实例"></a>删除或关闭 topic 实例</h2><p><code>topic</code>删除的方法(<code>topic.Delete</code>)与其被关闭的方法(<code>topic.Close</code>)相似，都调用了<code>topic.exit</code>方法，区别有三点：一是前者还显式调用了<code>nsqd.Notify</code>以通知<code>nsqlookupd</code>有<code>topic</code>实例被删除，同时重新持久化元数据。二是前者还需要递归删除<code>topic</code>关联的<code>channel</code>集合，且显式调用了<code>channel.Delete</code>方法（此方法同<code>topic.Delete</code>方法相似）。最后一点区别为前者还显式清空了<code>memoryMsgChan</code>和<code>backend</code>两个消息队列中的消息。因此，若只是关闭或退出<code>topic</code>，则纯粹退出<code>messagePump</code>消息处理循环，并将<code>memoryMsgChan</code>中的消息刷盘，最后关闭持久化存储消息队列。（方法调用链为：<code>topic.Delete-&gt;topic.exit-&gt;nsqd.Notify-&gt;nsqd.PersistMetadata-&gt;chanel.Delete-&gt;topic.Empty-&gt;topic.backend.Empty-&gt;topic.backend.Delete</code>，以及<code>topic.Close-&gt;topic.exit-&gt;topic.flush-&gt;topic.backend.Close</code>）相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Delete 方法和 Close 方法都调用的是 exit 方法。</span></span><br><span class="line"><span class="comment">// 区别在于 Delete 还需要显式得通知 lookupd，让它删除此 topic 的注册信息</span></span><br><span class="line"><span class="comment">// 而　Close　方法是在　topic　关闭时调用，因此需要持久化所有未被处理/消费的消息，然后再关闭所有的 channel，退出</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *Topic)</span> <span class="title">Delete</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> t.exit(<span class="literal">true</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *Topic)</span> <span class="title">Close</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> t.exit(<span class="literal">false</span>)</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/topic.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 使当前 topic 对象　exit，同时若指定删除其所关联的 channels 及 closes，则清空它们</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *Topic)</span> <span class="title">exit</span><span class="params">(deleted <span class="keyword">bool</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 保证目前还处于运行的状态</span></span><br><span class="line">	<span class="keyword">if</span> !atomic.CompareAndSwapInt32(&amp;t.exitFlag, <span class="number">0</span>, <span class="number">1</span>) &#123;</span><br><span class="line">		<span class="keyword">return</span> errors.New(<span class="string">"exiting"</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 当被　Delete　调用时，则需要先通知 lookupd 删除其对应的注册信息</span></span><br><span class="line">	<span class="keyword">if</span> deleted &#123;</span><br><span class="line">		t.ctx.nsqd.logf(LOG_INFO, <span class="string">"TOPIC(%s): deleting"</span>, t.name)</span><br><span class="line">		t.ctx.nsqd.Notify(t) <span class="comment">// 通知 nsqlookupd 有 topic 更新，并重新持久化元数据</span></span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		t.ctx.nsqd.logf(LOG_INFO, <span class="string">"TOPIC(%s): closing"</span>, t.name)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 3. 关闭 exitChan，保证所有的循环全部会退出，比如消息处理循环 messagePump 会退出</span></span><br><span class="line">	<span class="built_in">close</span>(t.exitChan)</span><br><span class="line">	<span class="comment">// 4. 同步等待消息处理循环 messagePump 方法的退出，</span></span><br><span class="line">    <span class="comment">// 才继续执行下面的操作（只有消息处理循环退出后，才能删除对应的 channel集合）</span></span><br><span class="line">	t.waitGroup.Wait()</span><br><span class="line">	<span class="comment">// 4. 若是被 Delete 方法调用，则需要清空 topic 所包含的 channel（同 topic 的操作类似）</span></span><br><span class="line">	<span class="keyword">if</span> deleted &#123;</span><br><span class="line">		t.Lock()</span><br><span class="line">		<span class="keyword">for</span> _, channel := <span class="keyword">range</span> t.channelMap &#123;</span><br><span class="line">			<span class="built_in">delete</span>(t.channelMap, channel.name)</span><br><span class="line">			channel.Delete()</span><br><span class="line">		&#125;</span><br><span class="line">		t.Unlock()</span><br><span class="line">		t.Empty() <span class="comment">// 清空 memoryMsgChan 和 backend 中的消息</span></span><br><span class="line">		<span class="keyword">return</span> t.backend.Delete()</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 5. 否则若是被 Close 方法调用，则只需要关闭所有的 channel，</span></span><br><span class="line">    <span class="comment">// 不会将所有的 channel 从 topic 的 channelMap 中删除</span></span><br><span class="line">	<span class="keyword">for</span> _, channel := <span class="keyword">range</span> t.channelMap &#123;</span><br><span class="line">		err := channel.Close()</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 6. 将内存中的消息，即 t.memoryMsgChan 中的消息刷新到持久化存储</span></span><br><span class="line">	t.flush()</span><br><span class="line">	<span class="keyword">return</span> t.backend.Close()</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/topic.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 清空内存消息队列和持久化存储消息队列中的消息</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *Topic)</span> <span class="title">Empty</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> &lt;-t.memoryMsgChan:</span><br><span class="line">		<span class="keyword">default</span>:</span><br><span class="line">			<span class="keyword">goto</span> finish</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">finish:</span><br><span class="line">	<span class="keyword">return</span> t.backend.Empty()</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/topic.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 刷新内存消息队列即 t.memoryMsgChan 中的消息到持久化存储 backend</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *Topic)</span> <span class="title">flush</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> msgBuf bytes.Buffer</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> msg := &lt;-t.memoryMsgChan:</span><br><span class="line">			err := writeMessageToBackend(&amp;msgBuf, msg, t.backend)</span><br><span class="line">			<span class="comment">// ...</span></span><br><span class="line">		<span class="keyword">default</span>:</span><br><span class="line">			<span class="keyword">goto</span> finish</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">finish:</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/topic.go</span></span><br></pre></td></tr></table></figure>

<p>最后同样简单分析程序中哪些地方会调用<code>Delete</code>方法。其一，<code>httpServer.doDeleteTopic-&gt;nsqd.DeleteExistingTopic-&gt;topic.Delete</code>；其二，<code>nsqd.GetTopic-&gt;nsqd.DeleteExistingTopic-&gt;topic.Delete</code>。而对于<code>topic.Close</code>方法，则比较直接：<code>nsqd.Exit-&gt;topic.Close</code>。</p>
<h2 id="查询-topic-实例"><a href="#查询-topic-实例" class="headerlink" title="查询 topic 实例"></a>查询 topic 实例</h2><p>即依据名称查询（获取）<code>topic</code>实例，包含了两个方法，都被定义为<code>nsqd</code>实例的方法。我们重点阐述<code>nsqd.GetTopic</code>方法。查询逻辑的关键是，若此<code>topic</code>不存在<code>nsqd</code>的<code>topic</code>集合中，则需要创建一个新的实例。同时，为其注册<code>topic</code>实例的删除回调函数。接下来，若此<code>nsqd</code>并非处于启动过程（还记得<code>nsqd.LoadMetadata</code>会调用<code>nsqd.GetTopic</code>方法吗），则还要进一步填充此<code>topic</code>所关联的<code>channel</code>，即<code>nsqd</code>实例向<code>nsqlookupd</code>实例查询指定<code>topic</code>所关联的<code>channel</code>集合，然后更新<code>topic.channelMap</code>，同时也要更新<code>topic.memoryMsgChan</code>和<code>topoc.backendChan</code>结构（因为<code>channel</code>集合更新了）。最后，启动此<code>topic</code>，即开启<code>topic</code>处理消息的主循环<code>topic.messagePump</code>。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// GetTopic 是一个线程安全的方法，其根据 topic 名称返回指向一个 topic 对象的指针，</span></span><br><span class="line"><span class="comment">// 此 topic 对象有可能是新创建的</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *NSQD)</span> <span class="title">GetTopic</span><span class="params">(topicName <span class="keyword">string</span>)</span> *<span class="title">Topic</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 通常，此 topic 已经被创建，因此（使用读锁）先从 nsqd 的 topicMap 中查询指定指定的 topic</span></span><br><span class="line">	n.RLock()</span><br><span class="line">	t, ok := n.topicMap[topicName]</span><br><span class="line">	n.RUnlock()</span><br><span class="line">	<span class="keyword">if</span> ok &#123;</span><br><span class="line">		<span class="keyword">return</span> t</span><br><span class="line">	&#125;</span><br><span class="line">	n.Lock()</span><br><span class="line">	<span class="comment">// 2. 因为上面查询指定的 topic 是否存在时，使用的是读锁，</span></span><br><span class="line">	<span class="comment">// 因此有线程可能同时进入到这里，执行了创建同一个 topic 的操作，因此这里还需要判断一次。</span></span><br><span class="line">	t, ok = n.topicMap[topicName]</span><br><span class="line">	<span class="keyword">if</span> ok &#123;</span><br><span class="line">		n.Unlock()</span><br><span class="line">		<span class="keyword">return</span> t</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 3. 创建删除指定 topic 的回调函数，即在删除指定的 topic 之前，需要做的一些清理工作，</span></span><br><span class="line">	<span class="comment">// 比如关闭 与此 topic 所关联的channel，同时判断删除此 topic 所包含的所有 channel</span></span><br><span class="line">	deleteCallback := <span class="function"><span class="keyword">func</span><span class="params">(t *Topic)</span></span> &#123;</span><br><span class="line">		n.DeleteExistingTopic(t.name)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 4. 通过 nsqd、topicName 和删除回调函数创建一个新的　topic，并将此 topic　添加到 nsqd 的 topicMap中</span></span><br><span class="line">	<span class="comment">// 创建 topic 过程中会初始化 diskqueue, 同时开启消息协程</span></span><br><span class="line">	t = NewTopic(topicName, &amp;context&#123;n&#125;, deleteCallback)</span><br><span class="line">	n.topicMap[topicName] = t</span><br><span class="line">	n.Unlock()</span><br><span class="line">	n.logf(LOG_INFO, <span class="string">"TOPIC(%s): created"</span>, t.name)</span><br><span class="line">	<span class="comment">// 此时内存中的两个消息队列 memoryMsgChan 和 backend 还未开始正常工作</span></span><br><span class="line">	<span class="keyword">if</span> atomic.LoadInt32(&amp;n.isLoading) == <span class="number">1</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> t</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 对于新建的 topic还要查询channel集合的原因，只能是 nsqd 实例重启，丢失了topic和channel信息</span></span><br><span class="line">    <span class="comment">// TODO</span></span><br><span class="line">	lookupdHTTPAddrs := n.lookupdHTTPAddrs()</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(lookupdHTTPAddrs) &gt; <span class="number">0</span> &#123;</span><br><span class="line">		<span class="comment">// 5.1 从指定的 nsqlookupd 及 topic 所获取的 channel 的集合</span></span><br><span class="line">		<span class="comment">// nsqlookupd 存储所有之前此 topic 创建的 channel 信息，因此需要加载消息</span></span><br><span class="line">		channelNames, err := n.ci.GetLookupdTopicChannels(t.name, lookupdHTTPAddrs)</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		<span class="comment">// 5.2 对那些非 ephemeral 的 channel，</span></span><br><span class="line">        <span class="comment">// 创建对应的实例（因为没有使用返回值，因此纯粹是更新了内在中的memoryMsgChan和backend结构）</span></span><br><span class="line">		<span class="keyword">for</span> _, channelName := <span class="keyword">range</span> channelNames &#123;</span><br><span class="line">			<span class="comment">// 对于临时的 channel，则不需要创建，使用的时候再创建</span></span><br><span class="line">			<span class="keyword">if</span> strings.HasSuffix(channelName, <span class="string">"#ephemeral"</span>) &#123;</span><br><span class="line">				<span class="keyword">continue</span> <span class="comment">// do not create ephemeral channel with no consumer client</span></span><br><span class="line">			&#125; <span class="comment">// 5.3 根据 channel name 获取 channel 实例，且有可能是新建的</span></span><br><span class="line">			<span class="comment">// 若是新建了一个 channel，则通知 topic 的后台消息协程去处理 channel 的更新事件</span></span><br><span class="line">			<span class="comment">// 之所以在查询到指定 channel 的情况下，新建 channel，是为了保证消息尽可能不被丢失，</span></span><br><span class="line">			<span class="comment">// 比如在 nsq 重启时，需要在重启的时刻创建那些 channel，避免生产者生产的消息</span></span><br><span class="line">			<span class="comment">// 不能被放到 channel 中，因为在这种情况下，</span></span><br><span class="line">            <span class="comment">// 只能等待消费者来指定的 channel 中获取消息才会创建。</span></span><br><span class="line">			t.GetChannel(channelName)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125; <span class="keyword">else</span> <span class="keyword">if</span> <span class="built_in">len</span>(n.getOpts().NSQLookupdTCPAddresses) &gt; <span class="number">0</span> &#123;</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 6. 启动了消息处理的循环，往 startChan 通道中 push 了一条消息，</span></span><br><span class="line">	<span class="comment">// 此时会内存消息队列 memoryMsgChan，以及持久化的消息队列 backendChan 就开始工作。</span></span><br><span class="line">	<span class="comment">// 即能处理内存中消息更新的的事件了。</span></span><br><span class="line">	t.Start()</span><br><span class="line">	<span class="keyword">return</span> t</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/nsqd.go</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *Topic)</span> <span class="title">Start</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">select</span> &#123;</span><br><span class="line">	<span class="keyword">case</span> t.startChan &lt;- <span class="number">1</span>:</span><br><span class="line">	<span class="keyword">default</span>:</span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/topic.go</span></span><br></pre></td></tr></table></figure>

<p>关于<code>ClusterInfo.GetLookupdTopicChannels</code>方法没有展开分析了，比较简单，纯粹就构建查询请求，并获得响应内容，最后对<code>channel</code>集合执行合并操作。另外，程序中关于<code>nsqd.GetTopic</code>的逻辑，在前面已阐述过。</p>
<p>简单小结，本文内容相比上一篇文章较少，逻辑性也相对较弱，因此较容易理解消化。文章围绕<code>topic</code>展开，从四个方面对<code>topic</code>进行介绍，其中<code>topic</code>实例所包含的字段比较简单。而<code>topic</code>实例化方法也很直接，关键在于从一条主线来把握方法，即结合系统调用逻辑，理解涉及到的整个调用方法链。删除或关闭<code>topic</code>的核心是对两个消息队列的操作。最后查询<code>topic</code>实例的方法<code>GetTopic</code>方法比较关键。</p>
<p>参考文献</p>
<p>[1]. <a href="https://github.com/nsqio/nsq" target="_blank" rel="noopener">https://github.com/nsqio/nsq</a><br>[2]. <a href="https://nsq.io/overview/quick_start.html" target="_blank" rel="noopener">https://nsq.io/overview/quick_start.html</a></p>
]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title>nsq nsqd 服务启动源码简析</title>
    <url>/2019/05/13/nsq-nsqd-%E6%9C%8D%E5%8A%A1%E5%90%AF%E5%8A%A8%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/</url>
    <content><![CDATA[<p>上一篇文章阐述了<code>nsqlookupd</code>模块的源码，主要分析<code>nsqlookupd</code>服务进程启动、实例构建及初始化、<code>tcp &amp; http</code>请求处理器的构建和注册以及由<code>nsqlookupd</code>提供的<code>topic</code>注册及查询功能这几个流程的相关源码。<code>nsqlookupd</code>耦合的模块较少，程序逻辑也较简单。但由于其和<code>topic</code>及<code>channel</code>等密切相关，因此<code>nsqd</code>更为复杂。<code>nsqd</code>充当<code>nsq</code>消息队列核心角色，它负责接收、排队以及转发（投递）消息，因此这需要同<code>nsq</code>各个组件交互，包括生产者、消费者、<code>nsqlookupd</code>以及<code>nsqadmin</code>。<code>nsq</code>提供<code>http/https</code>的方式与生产者通信，主要包括<code>topic</code>和<code>channel</code>创建和查询，配置更新，以及消息发布等功能。另外<code>nsq</code>提供了<code>tcp</code>的方式与消费者及生产者通信，为消费者提供消息订阅功能，而为生产者提供消息发布的功能。最后，考虑到<code>nsqd</code>无状态的特性，<code>nsqd</code>可以通过横向扩展来增强请求处理能力，也可以通过增加一个或多个备份来提高数据可靠性。</p>
<a id="more"></a>

<p>再次强调，个人认为查看或分析源码最好从某个业务逻辑流程切入，必要时忽略某些旁支或细节，做到从宏观上把握整个流程。本文分析<code>nsqd</code>服务启动的关键流程，更详细<code>nsq</code>源码注释可在<a href="https://github.com/qqzeng/nsqio/tree/master/nsq" target="_blank" rel="noopener">这里</a>找到，注释源码版本为<code>v1.1.0</code>，仅供参考。本文所涉及到源码主要为<code>/nsq/apps/nsqd/</code>、<code>/nsq/nsqd/</code>和<code>/nsq/internal/</code>下的若干子目录。</p>
<p>考虑到<code>nsqd</code>本身比较复杂，难以在一篇文章中介绍全部内容，因此选择将其进行拆分。本文侧重于分析<code>nsqd</code>服务启动相关源码，而在启动过程中涉及到的与<code>topic</code>和<code>channel</code>耦合部分会另外写一篇文章专门阐述。本文从五个方面来阐述<code>nsqd</code>：其一，以<code>nsqd</code>命令为切入点，介绍服务启动流程（这部分同<code>nsqlookupd</code>非常类似，因此会简述）；其二，同样追溯<code>nsqd</code>启动流程，进一步分析介绍初始化过程中<code>NSQ</code>的创建及初始化逻辑；其三，阐述<code>nsqd</code>异步开启<code>nsqlookupd</code>查询过程；其四，阐述<code>nsqd</code>同<code>nsqlookupd</code>交互的主循环的逻辑（对应源码的<code>NSQD.lookupLoop</code>方法）；最后，分析初始化过程所涵盖的<code>nsqd</code>建立<code>tcp</code>和<code>http</code>请求处理器相关逻辑。注意，<code>nsqd</code>的核心流程——开启消息队列扫描（对应源码的<code>NSQD.queueScanLoop</code>方法），这部分与<code>topic</code>及<code>channel</code>密切相关，因此放到后面单独阐述。</p>
<p>当我们在命令行执行<code>nsqd</code>命令时（同时可指定参数），相当于运行了<code>nsq/apps/nsqd</code>程序的<code>main</code>方法。此方法启动了一个进程（服务），并且通过创建<code>NSQD</code>并调用其<code>Main</code>方法执行启动逻辑。</p>
<h2 id="利用-svc-启动进程"><a href="#利用-svc-启动进程" class="headerlink" title="利用 svc 启动进程"></a>利用 svc 启动进程</h2><p>同<a href="https://qqzeng.top/2019/05/12/nsq-nsqlookupd-%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/#%E5%88%A9%E7%94%A8-svc-%E5%90%AF%E5%8A%A8%E8%BF%9B%E7%A8%8B" target="_blank" rel="noopener"><code>nsqlookupd</code>进程启动</a>类似，<code>nsqd</code>进程的启动，同样是简单包装 <a href="https://github.com/judwhite/go-svc/svc" target="_blank" rel="noopener"><code>svc</code></a>的<code>Run</code>方法以启动一个进程（守护进程或服务），然后在 <code>svc.Run</code> 方法中依次调用 <code>Init</code> 和 <code>Start</code> 方法，并阻塞直到接收到 <code>SIGINT</code>或<code>SIGTERM</code>，最后调用 <code>stop</code>方法后退出进程。更多可以查看 <code>golang</code> 标准包的<code>signal.Notify</code>以及<code>svc</code>包是如何协助启动一个进程。启动过程中，首先加载、设置并解析配置参数实例<code>opts</code>，然后由此配置实例化<code>NSQD</code>。接下来调用<code>nsqd</code>的<code>LoadMetaData</code>方法加载元数据信息，所谓的元数据信息即包括了<code>nsqd</code>所维护的<code>topic</code>及<code>channel</code>信息（重点是其名称及<code>paused</code>状态）。加载完成后，立即就重新将元信息存盘（个人暂时也没完全想明白原因 <code>#TODO</code>）。最后异步调用<code>nsqd.Main</code>方法完成启动过程的核心逻辑，同时在退出时先调用了<code>nsqd.Exit</code>方法。下面对这些过程一一展开叙述。启动过程代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> program <span class="keyword">struct</span> &#123;  </span><br><span class="line">	once sync.Once</span><br><span class="line">	nsqd *nsqd.NSQD</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// nsqd 服务程序执行入口，关于 svc 参考 apps/nsqlookupd/main.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	prg := &amp;program&#123;&#125;</span><br><span class="line">	<span class="keyword">if</span> err := svc.Run(prg, syscall.SIGINT, syscall.SIGTERM); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		logFatal(<span class="string">"%s"</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="comment">// /nsq/apps/nsqd/main.go</span></span><br><span class="line"><span class="comment">// 在 Start 方法调用之前执行，在此无实际用途</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *program)</span> <span class="title">Init</span><span class="params">(env svc.Environment)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> env.IsWindowsService() &#123;</span><br><span class="line">		dir := filepath.Dir(os.Args[<span class="number">0</span>])</span><br><span class="line">		<span class="keyword">return</span> os.Chdir(dir)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 启动方法</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *program)</span> <span class="title">Start</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 通过程序默认的参数构建 options 实例</span></span><br><span class="line">	opts := nsqd.NewOptions()</span><br><span class="line">	<span class="comment">// 2. 将 opts 结合命令行参数集进行进一步初始化</span></span><br><span class="line">	flagSet := nsqdFlagSet(opts)</span><br><span class="line">	flagSet.Parse(os.Args[<span class="number">1</span>:])</span><br><span class="line">	rand.Seed(time.Now().UTC().UnixNano())</span><br><span class="line">	<span class="comment">// 3. 若 version 参数存在，则打印版本号，然后退出</span></span><br><span class="line">	<span class="keyword">if</span> flagSet.Lookup(<span class="string">"version"</span>).Value.(flag.Getter).Get().(<span class="keyword">bool</span>) &#123;</span><br><span class="line">		fmt.Println(version.String(<span class="string">"nsqd"</span>))</span><br><span class="line">		os.Exit(<span class="number">0</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 4. 若用户指定了自定义配置文件，则加载配置文件，读取配置文件，校验配置文件合法性</span></span><br><span class="line">	<span class="comment">// 读取解析配置文件采用的是第三方库 https://github.com/BurntSushi/toml</span></span><br><span class="line">	<span class="keyword">var</span> cfg config</span><br><span class="line">	configFile := flagSet.Lookup(<span class="string">"config"</span>).Value.String()</span><br><span class="line">	<span class="keyword">if</span> configFile != <span class="string">""</span> &#123;</span><br><span class="line">		_, err := toml.DecodeFile(configFile, &amp;cfg)</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">	&#125;</span><br><span class="line">	cfg.Validate()</span><br><span class="line">	options.Resolve(opts, flagSet, cfg)</span><br><span class="line">	<span class="comment">// 5. 通过给定参数 opts 构建 nsqd 实例</span></span><br><span class="line">	nsqd, err := nsqd.New(opts)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		logFatal(<span class="string">"failed to instantiate nsqd - %s"</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">	p.nsqd = nsqd</span><br><span class="line">	<span class="comment">// 6. 加载 metadata　文件，</span></span><br><span class="line">    <span class="comment">// 若文件存在，则恢复 topic 和 channel的信息（如pause状态），并调用 topic.Start方法</span></span><br><span class="line">	err = p.nsqd.LoadMetadata()</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		logFatal(<span class="string">"failed to load metadata - %s"</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 7. 重新持久化 metadata 到文件，原因？　TODO</span></span><br><span class="line">	<span class="comment">// 即持久化 topic 及 channel的元信息（即不包括其数据）到文件中</span></span><br><span class="line">	err = p.nsqd.PersistMetadata()</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		logFatal(<span class="string">"failed to persist metadata - %s"</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 8. 在单独的 go routine 中启动 nsqd.Main 方法</span></span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		err := p.nsqd.Main()</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			p.Stop()</span><br><span class="line">			os.Exit(<span class="number">1</span>)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;()</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /nsq/apps/nsqd/main.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *program)</span> <span class="title">Stop</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	p.once.Do(<span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		p.nsqd.Exit()</span><br><span class="line">	&#125;)</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /nsq/apps/nsqd/main.go</span></span><br></pre></td></tr></table></figure>

<p>下面分析<code>main</code>方法中的关键方法。元数据加载和持久化方法（<code>nsqd.LoadMetadata</code>和<code>nsqd.persistMetadata</code>），这里的元数据不包括具体的数据，比如<code>message</code>。在加载元数据过程中即读取<code>nsqd.dat</code>文件，如果文件内容为空，则表明是首次启动，直接返回。否则，读取文件内容并反序列化，针对读取的<code>topic</code>的列表中的每一个<code>topic</code>，会获取与其关联的<code>channel</code>列表，并设置它们的<code>paused</code>属性。关于<code>paused</code>属性，对于<code>topic</code>而言，若<code>paused</code>属性被设置，则它不会将由生产者发布的消息写入到关联的<code>channel</code>的消息队列。而对<code>channel</code>而言，若其<code>paused</code>属性被设置，则那些订阅了此<code>channel</code>的客户端不会被推送消息（这两点在后面的源码中可以验证）。其中根据<code>topic</code>或<code>channel</code>的名称获取对应的实例的方法为<code>nsqd.GetTopic</code>和<code>topic.GetChannel</code>方法，这两个方法会在阐述<code>topic</code>和<code>channel</code>的时详细分析。但注意一点是，若获取一个不存在的<code>topic/channel</code>，则会创建一个对应实例（还记得第一篇文章所述，<code>topic</code>及<code>channel</code>实例不会被提前创建，而是在生产者发布消息或显式创建一个<code>topic</code>时才被创建，而<code>channel</code>则是在生产者显式地订阅一个<code>channel</code>时才被创建）。最后调用<code>topic.Start</code>方法向<code>topic.startChan</code>通道中压入一条消息，消息会在<code>topic.messagePump</code>方法中被取出，以表明<code>topic</code>可以开始进入消息队列处理的主循环。元数据的持久化则恰是一个逆过程，即获取<code>nsqd</code>实例内存中的<code>topic</code>集合，并递归地将其对应的<code>channel</code>集合保存到文件，且持久化也是通过先写临时文件，再原子性地重命名。值得注意的是整个<code>nsq</code>中（包括<code>nsqd</code>和<code>nsqlookupd</code>）涉及到数据持久化的过程只有<code>nsqd</code>的元数据的持久化以及<code>nsqd</code>对消息的持久化（通过<code>diskQueue</code>完成），而<code>nsqlookupd</code>则不涉及持久化操作。元数据加载和持久化相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// metadata 结构， Topic 结构的数组</span></span><br><span class="line"><span class="keyword">type</span> meta <span class="keyword">struct</span> &#123;</span><br><span class="line">	Topics []<span class="keyword">struct</span> &#123;</span><br><span class="line">		Name     <span class="keyword">string</span> <span class="string">`json:"name"`</span></span><br><span class="line">		Paused   <span class="keyword">bool</span>   <span class="string">`json:"paused"`</span></span><br><span class="line">		Channels []<span class="keyword">struct</span> &#123;</span><br><span class="line">			Name   <span class="keyword">string</span> <span class="string">`json:"name"`</span></span><br><span class="line">			Paused <span class="keyword">bool</span>   <span class="string">`json:"paused"`</span></span><br><span class="line">		&#125; <span class="string">`json:"channels"`</span></span><br><span class="line">	&#125; <span class="string">`json:"topics"`</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 加载 metadata </span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *NSQD)</span> <span class="title">LoadMetadata</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	atomic.StoreInt32(&amp;n.isLoading, <span class="number">1</span>)</span><br><span class="line">	<span class="keyword">defer</span> atomic.StoreInt32(&amp;n.isLoading, <span class="number">0</span>)</span><br><span class="line">	<span class="comment">// 1. 构建 metadata 文件全路径， nsqd.dat，并读取文件内容</span></span><br><span class="line">	fn := newMetadataFile(n.getOpts())</span><br><span class="line">	data, err := readOrEmpty(fn)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// 2. 若文件内容为空，则表明是第一次启动， metadata 加载过程结束</span></span><br><span class="line">	<span class="keyword">if</span> data == <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span> <span class="comment">// fresh start</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">var</span> m meta</span><br><span class="line">	err = json.Unmarshal(data, &amp;m)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// 3. 若文件内容不为空，则遍历所有 topic，针对每一个 topic 及 channel先前保持的情况进行还原．</span></span><br><span class="line">    <span class="comment">// 比如是否有被 pause，最后启动 topic</span></span><br><span class="line">	<span class="keyword">for</span> _, t := <span class="keyword">range</span> m.Topics &#123;</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		<span class="comment">// 根据 topic name 获取对应的 topic 实例，若对应的 topic 实例不存在，则会创建它。</span></span><br><span class="line">		<span class="comment">// （因此在刚启动时，会创建所有之前保存的到文件中的 topic 实例，后面的 channel 也是类似的）</span></span><br><span class="line">		topic := n.GetTopic(t.Name)</span><br><span class="line">		<span class="keyword">if</span> t.Paused &#123;</span><br><span class="line">			topic.Pause()</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">for</span> _, c := <span class="keyword">range</span> t.Channels &#123;</span><br><span class="line">			<span class="keyword">if</span> !protocol.IsValidChannelName(c.Name) &#123;</span><br><span class="line">				n.logf(LOG_WARN, <span class="string">"skipping creation of invalid channel %s"</span>, c.Name)</span><br><span class="line">				<span class="keyword">continue</span></span><br><span class="line">			&#125;</span><br><span class="line">			channel := topic.GetChannel(c.Name)</span><br><span class="line">			<span class="keyword">if</span> c.Paused &#123;</span><br><span class="line">				channel.Pause()</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 启动对应的 topic，开启了消息处理循环</span></span><br><span class="line">		topic.Start()</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/nsqd.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建 metadata 文件，遍历 nsqd 节点所有的 topic，</span></span><br><span class="line"><span class="comment">// 针对每一个非 ephemeral 属性的 topic，保存其 name、paused 属性</span></span><br><span class="line"><span class="comment">//（换言之不涉及到 topic 及 channel 的数据部分）</span></span><br><span class="line"><span class="comment">// 另外，保存 topic 所关联的非 ephemeral 的 channel 的 name、paused 属性</span></span><br><span class="line"><span class="comment">// 最后同步写入文件，注意在写文件，先是写到临时文件中，然后调用　OS.rename操作，以保证写入文件的原子性</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *NSQD)</span> <span class="title">PersistMetadata</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="comment">// persist metadata about what topics/channels we have, across restarts</span></span><br><span class="line">	fileName := newMetadataFile(n.getOpts())</span><br><span class="line">	n.logf(LOG_INFO, <span class="string">"NSQ: persisting topic/channel metadata to %s"</span>, fileName)</span><br><span class="line">	js := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125;)</span><br><span class="line">	topics := []<span class="keyword">interface</span>&#123;&#125;&#123;&#125;</span><br><span class="line">	<span class="keyword">for</span> _, topic := <span class="keyword">range</span> n.topicMap &#123;</span><br><span class="line">		<span class="keyword">if</span> topic.ephemeral &#123; <span class="comment">// 临时的 topic 不被持久化</span></span><br><span class="line">			<span class="keyword">continue</span></span><br><span class="line">		&#125;</span><br><span class="line">		topicData := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125;)</span><br><span class="line">		topicData[<span class="string">"name"</span>] = topic.name</span><br><span class="line">		topicData[<span class="string">"paused"</span>] = topic.IsPaused()</span><br><span class="line">		channels := []<span class="keyword">interface</span>&#123;&#125;&#123;&#125;</span><br><span class="line">		topic.Lock()</span><br><span class="line">		<span class="keyword">for</span> _, channel := <span class="keyword">range</span> topic.channelMap &#123;</span><br><span class="line">			channel.Lock()</span><br><span class="line">			<span class="keyword">if</span> channel.ephemeral &#123; <span class="comment">// 临时的 channel 不被持久化</span></span><br><span class="line">				channel.Unlock()</span><br><span class="line">				<span class="keyword">continue</span></span><br><span class="line">			&#125;</span><br><span class="line">			channelData := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125;)</span><br><span class="line">			channelData[<span class="string">"name"</span>] = channel.name</span><br><span class="line">			channelData[<span class="string">"paused"</span>] = channel.IsPaused()</span><br><span class="line">			channels = <span class="built_in">append</span>(channels, channelData)</span><br><span class="line">			channel.Unlock()</span><br><span class="line">		&#125;</span><br><span class="line">		topic.Unlock()</span><br><span class="line">		topicData[<span class="string">"channels"</span>] = channels</span><br><span class="line">		topics = <span class="built_in">append</span>(topics, topicData)</span><br><span class="line">	&#125;</span><br><span class="line">	js[<span class="string">"version"</span>] = version.Binary</span><br><span class="line">	js[<span class="string">"topics"</span>] = topics</span><br><span class="line">	data, err := json.Marshal(&amp;js)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	tmpFileName := fmt.Sprintf(<span class="string">"%s.%d.tmp"</span>, fileName, rand.Int())</span><br><span class="line">	err = writeSyncFile(tmpFileName, data)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	err = os.Rename(tmpFileName, fileName)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// technically should fsync DataPath here</span></span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/nsqd.go</span></span><br></pre></td></tr></table></figure>

<p>至此，<code>nsqd</code>的进程启动过程进行了大概地梳理。其包含两个重点一个是其利用<code>svc</code>来启动一个进程，另一个为<code>nsqd</code>加载及持久化元数据相关的逻辑，其中的<code>paused</code>属性与<code>topic/channel</code>密切相关。</p>
<h2 id="nsqd-创建及初始化"><a href="#nsqd-创建及初始化" class="headerlink" title="nsqd 创建及初始化"></a>nsqd 创建及初始化</h2><p>在阐述<code>nsqd</code>实例创建和启动过程前，先了解下其组成结构。其中最重要的几个字段为<code>topicMap</code>存储<code>nsqd</code>所维护的<code>topic</code>集合，<code>lookupPeers</code>为<code>nsqd</code>与<code>nsqlookupd</code>之间网络连接的抽象实体，<code>cliens</code>为订阅了此<code>nsqd</code>所维护的<code>topic</code>的客户端实体，还有<code>notifyChan</code>通道的作用是当<code>channel</code>或<code>topic</code>更新时（新增或删除），通知<code>nsqlookupd</code>服务更新对应的注册信息。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> NSQD <span class="keyword">struct</span> &#123;</span><br><span class="line">	<span class="comment">// 64bit atomic vars need to be first for proper alignment on 32bit platforms</span></span><br><span class="line">	clientIDSequence <span class="keyword">int64</span>							<span class="comment">// nsqd 借助它为订阅的 client 生成 ID</span></span><br><span class="line">	sync.RWMutex</span><br><span class="line">	opts atomic.Value								<span class="comment">// 配置参数实例</span></span><br><span class="line">	dl        *dirlock.DirLock</span><br><span class="line">	isLoading <span class="keyword">int32</span>									<span class="comment">// nsqd 当前是否处于启动加载过程</span></span><br><span class="line">	errValue  atomic.Value</span><br><span class="line">	startTime time.Time</span><br><span class="line">	topicMap <span class="keyword">map</span>[<span class="keyword">string</span>]*Topic						<span class="comment">// nsqd 所包含的 topic 集合</span></span><br><span class="line">	clientLock sync.RWMutex							<span class="comment">// guards clients</span></span><br><span class="line">	<span class="comment">// 向 nsqd 订阅的 client 的集合，即订阅了此 nsqd 所维护的 topic 的客户端</span></span><br><span class="line">    clients    <span class="keyword">map</span>[<span class="keyword">int64</span>]Client						</span><br><span class="line">	lookupPeers atomic.Value						<span class="comment">// nsqd与nsqlookupd之间网络连接抽象实体</span></span><br><span class="line">	tcpListener   net.Listener						<span class="comment">// tcp 连接 listener</span></span><br><span class="line">	httpListener  net.Listener						<span class="comment">// http 连接 listener</span></span><br><span class="line">	httpsListener net.Listener						<span class="comment">// https 连接 listener</span></span><br><span class="line">	tlsConfig     *tls.Config</span><br><span class="line">	<span class="comment">// queueScanWorker 的数量，每个 queueScanWorker代表一个单独的goroutine，用于处理消息队列</span></span><br><span class="line">    poolSize <span class="keyword">int</span></span><br><span class="line">    <span class="comment">// 当 channel 或 topic 更新时（新增或删除），用于通知 nsqlookupd 服务更新对应的注册信息</span></span><br><span class="line">	notifyChan           <span class="keyword">chan</span> <span class="keyword">interface</span>&#123;&#125;			</span><br><span class="line">	optsNotificationChan <span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;	<span class="comment">// 当 nsqd 的配置发生变更时，可以通过此 channel 通知</span></span><br><span class="line">	exitChan             <span class="keyword">chan</span> <span class="keyword">int</span>					<span class="comment">// nsqd 退出开关</span></span><br><span class="line">	waitGroup            util.WaitGroupWrapper		<span class="comment">// waitGroup 的一个 wrapper 结构</span></span><br><span class="line"></span><br><span class="line">	ci *clusterinfo.ClusterInfo</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/nsqd.go</span></span><br></pre></td></tr></table></figure>

<p><code>nsqd</code>实例化过程，比较简单，没有特别关键逻辑，主要是初始化一些属性，创建<code>tcp/http/https</code>的连接监听。简要贴下代码：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">(opts *Options)</span> <span class="params">(*NSQD, error)</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> err error</span><br><span class="line">	dataPath := opts.DataPath</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	n := &amp;NSQD&#123;</span><br><span class="line">		startTime:            time.Now(),</span><br><span class="line">		topicMap:             <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]*Topic),</span><br><span class="line">		clients:              <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">int64</span>]Client),</span><br><span class="line">		exitChan:             <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>),</span><br><span class="line">		notifyChan:           <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">interface</span>&#123;&#125;),</span><br><span class="line">		optsNotificationChan: <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;, <span class="number">1</span>),</span><br><span class="line">		dl:                   dirlock.New(dataPath),</span><br><span class="line">	&#125;</span><br><span class="line">	httpcli := http_api.NewClient(<span class="literal">nil</span>, opts.HTTPClientConnectTimeout, opts.HTTPClientRequestTimeout)</span><br><span class="line">	n.ci = clusterinfo.New(n.logf, httpcli)</span><br><span class="line">	n.lookupPeers.Store([]*lookupPeer&#123;&#125;)</span><br><span class="line">	n.swapOpts(opts)</span><br><span class="line">	n.errValue.Store(errStore&#123;&#125;)</span><br><span class="line">	err = n.dl.Lock()</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">if</span> opts.TLSClientAuthPolicy != <span class="string">""</span> &amp;&amp; opts.TLSRequired == TLSNotRequired &#123;</span><br><span class="line">		opts.TLSRequired = TLSRequired</span><br><span class="line">	&#125;</span><br><span class="line">	tlsConfig, err := buildTLSConfig(opts)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	n.tlsConfig = tlsConfig</span><br><span class="line">	<span class="keyword">for</span> _, v := <span class="keyword">range</span> opts.E2EProcessingLatencyPercentiles &#123;</span><br><span class="line">		<span class="keyword">if</span> v &lt;= <span class="number">0</span> || v &gt; <span class="number">1</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(<span class="string">"invalid E2E processing latency percentile: %v"</span>, v)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	n.tcpListener, err = net.Listen(<span class="string">"tcp"</span>, opts.TCPAddress)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	n.httpListener, err = net.Listen(<span class="string">"tcp"</span>, opts.HTTPAddress)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">if</span> n.tlsConfig != <span class="literal">nil</span> &amp;&amp; opts.HTTPSAddress != <span class="string">""</span> &#123;</span><br><span class="line">		n.httpsListener, err = tls.Listen(<span class="string">"tcp"</span>, opts.HTTPSAddress, n.tlsConfig)</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> n, <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/nsqd.go</span></span><br></pre></td></tr></table></figure>

<p>重点在<code>nsqd.Main</code>方法中所涉及到的逻辑。它首先构建一个<code>Context</code>实例（纯粹<code>nsqd</code>实例的<code>wrapper</code>），然后注册一个方法退出的<code>hook</code>函数。接下来，构建并注册用于处理<code>tcp</code>和<code>http</code>请求的<code>handler</code>，其中<code>tpc handler</code>比较简单，而<code>http handler</code>同样复用<a href="https://github.com/julienschmidt/httprouter" target="_blank" rel="noopener"><code>httprouter</code></a>作为请求路由器。而最关键的部分在于开启了三个<code>goroutine</code>用于处理<code>nsqd</code>内部逻辑，其中<code>NSQD.queueScanLoop</code>开启了<code>nsqd</code>的消息队列扫描处理逻辑，而<code>NSQD.lookupLoop</code>则开启了<code>nsqlookupd</code>查询过程，以及同<code>nsqlookupd</code>交互的主循环中的逻辑，最后的<code>NSQD.statsdLoop</code>则开启了一些数据统计工作（这部分不会做多介绍）。在<code>nsqd.Main</code>方法的最后，阻塞等待退出的信号<code>exitChan</code>。上述逻辑的相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// NSQD 进程启动入口程序</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *NSQD)</span> <span class="title">Main</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 构建 Context 实例， NSQD wrapper</span></span><br><span class="line">	ctx := &amp;context&#123;n&#125;</span><br><span class="line">	<span class="comment">// 2. 同 NSQLookupd 类似，构建一个退出 hook 函数，且在退出时仅执行一次</span></span><br><span class="line">	exitCh := <span class="built_in">make</span>(<span class="keyword">chan</span> error)</span><br><span class="line">	<span class="keyword">var</span> once sync.Once</span><br><span class="line">	exitFunc := <span class="function"><span class="keyword">func</span><span class="params">(err error)</span></span> &#123;</span><br><span class="line">		once.Do(<span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">			<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">				n.logf(LOG_FATAL, <span class="string">"%s"</span>, err)</span><br><span class="line">			&#125;</span><br><span class="line">			exitCh &lt;- err</span><br><span class="line">		&#125;)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 3. 构建用于处理 tcp连接的tcp handler，同样注册退出前需要执行的函数（打印连接关闭错误信息）</span></span><br><span class="line">	tcpServer := &amp;tcpServer&#123;ctx: ctx&#125;</span><br><span class="line">	n.waitGroup.Wrap(<span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		exitFunc(protocol.TCPServer(n.tcpListener, tcpServer, n.logf))</span><br><span class="line">	&#125;)</span><br><span class="line">	<span class="comment">// 4. 构建用于处理 http 连接的 http handler，注册错误打印函数</span></span><br><span class="line">	httpServer := newHTTPServer(ctx, <span class="literal">false</span>, n.getOpts().TLSRequired == TLSRequired)</span><br><span class="line">	n.waitGroup.Wrap(<span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		exitFunc(http_api.Serve(n.httpListener, httpServer, <span class="string">"HTTP"</span>, n.logf))</span><br><span class="line">	&#125;)</span><br><span class="line">	<span class="comment">// 5. 若配置了 https 通信，则仍然构建 http 连接的 https handler（但同时开启 tls），</span></span><br><span class="line">    <span class="comment">// 同样注册错误打印函数</span></span><br><span class="line">	<span class="keyword">if</span> n.tlsConfig != <span class="literal">nil</span> &amp;&amp; n.getOpts().HTTPSAddress != <span class="string">""</span> &#123;</span><br><span class="line">		httpsServer := newHTTPServer(ctx, <span class="literal">true</span>, <span class="literal">true</span>)</span><br><span class="line">		n.waitGroup.Wrap(<span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">			exitFunc(http_api.Serve(n.httpsListener, httpsServer, <span class="string">"HTTPS"</span>, n.logf))</span><br><span class="line">		&#125;)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 6. 等待直到 queueScanLoop循环，lookupLoop 循环以及 statsdLoop，主程序才能退出</span></span><br><span class="line">	<span class="comment">// 即开启了 队列scan扫描 goroutine 以及  lookup 的查找 goroutine</span></span><br><span class="line">	n.waitGroup.Wrap(n.queueScanLoop)</span><br><span class="line">	n.waitGroup.Wrap(n.lookupLoop)</span><br><span class="line">	<span class="keyword">if</span> n.getOpts().StatsdAddress != <span class="string">""</span> &#123;</span><br><span class="line">		<span class="comment">// 还有 状态统计处理 go routine</span></span><br><span class="line">		n.waitGroup.Wrap(n.statsdLoop)</span><br><span class="line">	&#125;</span><br><span class="line">	err := &lt;-exitCh</span><br><span class="line">	<span class="keyword">return</span> err</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/nsqd.go</span></span><br></pre></td></tr></table></figure>

<h2 id="nsqd-开启-nsqlookupd-查询过程"><a href="#nsqd-开启-nsqlookupd-查询过程" class="headerlink" title="nsqd 开启 nsqlookupd 查询过程"></a>nsqd 开启 nsqlookupd 查询过程</h2><p>这一小节介绍<code>NSQD.lookupLoop</code>方法，它代表<code>nsqd</code>开启<code>nsqlookupd</code>查询过程（这在<a href="https://qqzeng.top/2019/05/12/nsq-nsqlookupd-%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/" target="_blank" rel="noopener">一篇文章</a>有介绍）。在<code>nsqd</code>刚创建时，通过读取配置文件中所配置的<code>nsqlookupd</code>实例地址(<code>nsqlookupd_tcp_addresses</code>)集合（一个<code>nsqd</code>可连接到多个<code>nsqlookupd</code>实例），建立对应的网络连接的抽象实体(<code>lookupPeer</code>实例)，设置自己的状态为<code>stateDisconnected</code>，同时传入连接建立成功后的一个回调函数(<code>connectCallback</code>)。接下来，则调用<code>lookupPeer.Command</code>方法向指定<code>nsqlookupd</code>发起连接建立过程。此时，连接建立成功后，立即向对方发送一个<code>MagicV1</code>的消息以声明自己的通信协议版本（官方称这有用于协议升级），并忽略响应。并判断若此前的连接状态为<code>stateDisconnected</code>，则调用其连接成功的回调函数<code>connectCallback</code>。上述逻辑相关的代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 开启 lookup 循环</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *NSQD)</span> <span class="title">lookupLoop</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> lookupPeers []*lookupPeer</span><br><span class="line">	<span class="keyword">var</span> lookupAddrs []<span class="keyword">string</span></span><br><span class="line">	connect := <span class="literal">true</span></span><br><span class="line">	hostname, err := os.Hostname()</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// for announcements, lookupd determines the host automatically</span></span><br><span class="line">	ticker := time.Tick(<span class="number">15</span> * time.Second)</span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="comment">// 1. 在 nsqd 刚创建时，先构造 nsqd 同各 nsqlookupd（从配置文件中读取）</span></span><br><span class="line">        <span class="comment">// 的 lookupPeer 连接，并执行一个回调函数</span></span><br><span class="line">		<span class="keyword">if</span> connect &#123; <span class="comment">// 在 nsqd 启动时会进入到这里，即创建与各 nsqlookupd 的连接</span></span><br><span class="line">			<span class="keyword">for</span> _, host := <span class="keyword">range</span> n.getOpts().NSQLookupdTCPAddresses &#123;</span><br><span class="line">				<span class="keyword">if</span> in(host, lookupAddrs) &#123;</span><br><span class="line">					<span class="keyword">continue</span></span><br><span class="line">				&#125;</span><br><span class="line">				n.logf(LOG_INFO, <span class="string">"LOOKUP(%s): adding peer"</span>, host)</span><br><span class="line">				lookupPeer := newLookupPeer(host, n.getOpts().MaxBodySize, n.logf,</span><br><span class="line">					connectCallback(n, hostname))</span><br><span class="line">				lookupPeer.Command(<span class="literal">nil</span>) <span class="comment">// 开始建立连接，nil 代表连接初始建立，没用实际命令请求</span></span><br><span class="line">				<span class="comment">// 更新 nsqlookupd 的连接实体和地址</span></span><br><span class="line">                lookupPeers = <span class="built_in">append</span>(lookupPeers, lookupPeer)</span><br><span class="line">				lookupAddrs = <span class="built_in">append</span>(lookupAddrs, host)</span><br><span class="line">			&#125;</span><br><span class="line">			n.lookupPeers.Store(lookupPeers)</span><br><span class="line">			connect = <span class="literal">false</span></span><br><span class="line">		&#125;</span><br><span class="line">        <span class="comment">// 这里是 nsqd 实例处理与 nsqlookupd 实例交互的主循环（在后面详细介绍）</span></span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">    &#125;</span><br><span class="line">exit:</span><br><span class="line">	n.logf(LOG_INFO, <span class="string">"LOOKUP: closing"</span>)</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/nsqd.go</span></span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// lookupPeer 代表 nsqd 同 nsqdlookupd 进行连接、读取以及写入操作的一种抽象类型结构</span></span><br><span class="line"><span class="comment">// lookupPeer 实例被设计成延迟连接到 nsqlookupd，并且会自动重连</span></span><br><span class="line"><span class="keyword">type</span> lookupPeer <span class="keyword">struct</span> &#123;</span><br><span class="line">	logf            lg.AppLogFunc</span><br><span class="line">	addr            <span class="keyword">string</span>            <span class="comment">// 需要连接到对端的地址信息，即为 nsqlookupd 的地址</span></span><br><span class="line">	conn            net.Conn          <span class="comment">// 网络连接</span></span><br><span class="line">	state           <span class="keyword">int32</span>             <span class="comment">// 当前 lookupPeer 连接的状态 5 种状态之一</span></span><br><span class="line">	connectCallback <span class="function"><span class="keyword">func</span><span class="params">(*lookupPeer)</span> // 成功连接到指定的地址后的回调函数</span></span><br><span class="line"><span class="function">	<span class="title">maxBodySize</span>     <span class="title">int64</span>             // 在读取命令请求的处理返回结果时，消息体的最大字节数</span></span><br><span class="line"><span class="function">	<span class="title">Info</span>            <span class="title">peerInfo</span></span></span><br><span class="line"><span class="function">&#125;  // /<span class="title">nsq</span>/<span class="title">nsqd</span>/<span class="title">lookup_peer</span>.<span class="title">go</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">// <span class="title">peerInfo</span> <span class="title">contains</span> <span class="title">metadata</span> <span class="title">for</span> <span class="title">a</span> <span class="title">lookupPeer</span> <span class="title">instance</span> <span class="params">(and is JSON marshalable)</span></span></span><br><span class="line"><span class="function">// <span class="title">peerInfo</span> 代表 <span class="title">lookupPeer</span> 实例的与网络连接相关的信息实体</span></span><br><span class="line"><span class="function"><span class="title">type</span> <span class="title">peerInfo</span> <span class="title">struct</span></span> &#123;</span><br><span class="line">	TCPPort          <span class="keyword">int</span>    <span class="string">`json:"tcp_port"`</span></span><br><span class="line">	HTTPPort         <span class="keyword">int</span>    <span class="string">`json:"http_port"`</span></span><br><span class="line">	Version          <span class="keyword">string</span> <span class="string">`json:"version"`</span></span><br><span class="line">	BroadcastAddress <span class="keyword">string</span> <span class="string">`json:"broadcast_address"`</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="comment">// Read implements the io.Reader interface, adding deadlines</span></span><br><span class="line"><span class="comment">// lookupPeer 实例从指定的连接中　lookupPeer.conn　中读取数据，并指定超时时间</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(lp *lookupPeer)</span> <span class="title">Read</span><span class="params">(data []<span class="keyword">byte</span>)</span> <span class="params">(<span class="keyword">int</span>, error)</span></span> &#123;</span><br><span class="line">	lp.conn.SetReadDeadline(time.Now().Add(time.Second))</span><br><span class="line">	<span class="keyword">return</span> lp.conn.Read(data)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Write implements the io.Writer interface, adding deadlines</span></span><br><span class="line"><span class="comment">// lookupPeer 实例将数据写入到指定连接中，并指定超时时间</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(lp *lookupPeer)</span> <span class="title">Write</span><span class="params">(data []<span class="keyword">byte</span>)</span> <span class="params">(<span class="keyword">int</span>, error)</span></span> &#123;</span><br><span class="line">	lp.conn.SetWriteDeadline(time.Now().Add(time.Second))</span><br><span class="line">	<span class="keyword">return</span> lp.conn.Write(data)</span><br><span class="line">&#125;  <span class="comment">// /nsq/nsqd/lookup_peer.go</span></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="comment">// 为 lookupPeer执行一个指定的命令，并且获取返回的结果。</span></span><br><span class="line"><span class="comment">// 如果在这之前没有连接到对端，则会先进行连接动作</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(lp *lookupPeer)</span> <span class="title">Command</span><span class="params">(cmd *nsq.Command)</span> <span class="params">([]<span class="keyword">byte</span>, error)</span></span> &#123;</span><br><span class="line">	initialState := lp.state</span><br><span class="line">	<span class="comment">// 1. 当连接尚未建立时，走这里</span></span><br><span class="line">	<span class="keyword">if</span> lp.state != stateConnected &#123;</span><br><span class="line">		err := lp.Connect() <span class="comment">// 2. 发起连接建立过程</span></span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		lp.state = stateConnected <span class="comment">// 3. 更新对应的连接状态</span></span><br><span class="line">		<span class="comment">// 4. 在发送正式的命令请求前，需要要先发送一个 4byte 的序列号，用于协定后面用于通信的协议版本</span></span><br><span class="line">		_, err = lp.Write(nsq.MagicV1)</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			lp.Close()</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 5. 在连接成功后，需要执行一个成功连接的回调函数（在正式发送命令请求之前）</span></span><br><span class="line">		<span class="keyword">if</span> initialState == stateDisconnected &#123;</span><br><span class="line">			lp.connectCallback(lp)</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> lp.state != stateConnected &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(<span class="string">"lookupPeer connectCallback() failed"</span>)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 6. 在创建 lookupPeer 时会发送一个空的命令请求，</span></span><br><span class="line">	<span class="comment">// 其目的为创建正式的网络连接，同时，执行连接成功的回调函数</span></span><br><span class="line">	<span class="keyword">if</span> cmd == <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 7. 发送指定的命令请求到对端（包括命令的 name、params，一个空行以及body（写body之前要先写入其长度））</span></span><br><span class="line">	_, err := cmd.WriteTo(lp)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// 8. 读取并返回响应内容</span></span><br><span class="line">	resp, err := readResponseBounded(lp, lp.maxBodySize)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">return</span> resp, <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/lookup_peer.go</span></span><br></pre></td></tr></table></figure>

<p>当连接建立成功后（不要忘记在这之前发送了一个<code>MagicV1</code>的消息），会执行一个回调函数。此回调函数的主要逻辑为<code>nsqd</code>向<code>nsqlookupd</code>发送一个<code>IDENTIFY</code>命令请求以表明自己身份信息，然后遍历自己所维护的<code>topicMap</code>集合，构建所有即将执行的<code>REGISTER</code>命令请求，最后依次执行每一个请求。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 连接成功后需要执行的回调函数</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">connectCallback</span><span class="params">(n *NSQD, hostname <span class="keyword">string</span>)</span> <span class="title">func</span><span class="params">(*lookupPeer)</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">(lp *lookupPeer)</span></span> &#123;</span><br><span class="line">		<span class="comment">// 1. 打包 nsqd 自己的信息，主要是与网络连接相关</span></span><br><span class="line">		ci := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125;)</span><br><span class="line">		ci[<span class="string">"version"</span>] = version.Binary</span><br><span class="line">		ci[<span class="string">"tcp_port"</span>] = n.RealTCPAddr().Port</span><br><span class="line">		ci[<span class="string">"http_port"</span>] = n.RealHTTPAddr().Port</span><br><span class="line">		ci[<span class="string">"hostname"</span>] = hostname</span><br><span class="line">		ci[<span class="string">"broadcast_address"</span>] = n.getOpts().BroadcastAddress</span><br><span class="line">		<span class="comment">// 2. 发送一个 IDENTIFY 命令请求，以提供自己的身份信息</span></span><br><span class="line">		cmd, err := nsq.Identify(ci)</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		resp, err := lp.Command(cmd)</span><br><span class="line">		<span class="comment">// 3. 解析并校验 IDENTIFY 请求的响应内容</span></span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		<span class="comment">// 4. 构建所有即将发送的 REGISTER 请求，用于向 nsqlookupd注册信息 topic 和channel信息</span></span><br><span class="line">		<span class="keyword">var</span> commands []*nsq.Command</span><br><span class="line">		n.RLock()</span><br><span class="line">		<span class="keyword">for</span> _, topic := <span class="keyword">range</span> n.topicMap &#123;</span><br><span class="line">			topic.RLock()</span><br><span class="line">			<span class="keyword">if</span> <span class="built_in">len</span>(topic.channelMap) == <span class="number">0</span> &#123;</span><br><span class="line">				commands = <span class="built_in">append</span>(commands, nsq.Register(topic.name, <span class="string">""</span>))</span><br><span class="line">			&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">				<span class="keyword">for</span> _, channel := <span class="keyword">range</span> topic.channelMap &#123;</span><br><span class="line">					commands = <span class="built_in">append</span>(commands, nsq.Register(</span><br><span class="line">                        channel.topicName, channel.name))</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">			topic.RUnlock()</span><br><span class="line">		&#125;</span><br><span class="line">		n.RUnlock()</span><br><span class="line">		<span class="comment">// 5. 最后，遍历 REGISTER 命令集合，依次执行它们，</span></span><br><span class="line">        <span class="comment">// 并忽略返回结果（当然肯定要检测请求是否执行成功）</span></span><br><span class="line">		<span class="keyword">for</span> _, cmd := <span class="keyword">range</span> commands &#123;</span><br><span class="line">			n.logf(LOG_INFO, <span class="string">"LOOKUPD(%s): %s"</span>, lp, cmd)</span><br><span class="line">			_, err := lp.Command(cmd)</span><br><span class="line">			<span class="comment">// ...</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/lookup.go</span></span><br></pre></td></tr></table></figure>

<h2 id="nsqd-与-nsqlookupd-交互主循环"><a href="#nsqd-与-nsqlookupd-交互主循环" class="headerlink" title="nsqd 与 nsqlookupd 交互主循环"></a>nsqd 与 nsqlookupd 交互主循环</h2><p>当<code>nsqd</code>启动后与<code>nsqlookup</code>之后，它便开启了和<code>nsqlookupd</code>交互的主循环，即<code>lookupLoop</code>方法剩余部分。主循环中的逻辑主要分为三个部分，通过<code>select</code>语法来触发执行。其一，<code>nsqd</code>每过15s（好像是硬编码的）向<code>nsqlookupd</code>发送一个心跳消息(<code>PING</code>)；其二，通过<code>notifyChan</code>通道从<code>nsqd</code>收到消息时（即<code>nsqd.Notify</code>方法被调用），表明<code>nsqd</code>所维护的<code>topic</code>集合（包括<code>channel</code>）发生了变更（添加或移除）。若接收到的消息为<code>channel</code>，则根据此<code>channel</code>是否存在，进而发送<code>REGISTER/UNREGISTER</code>通知所有的<code>nsqlookupd</code>有<code>channel</code> 添加或除移。而<code>topic</code>的执行逻辑完全类似；最后，当从<code>nsqd</code>通过<code>optsNotificationChan</code>通道收到<code>nsqlookupd</code>地址变更消息，则重新从配置文件中加载<code>nsqlookupd</code>的配置信息。当然，若<code>nsqd</code>退出了，此处理循环也需要退出。相关的代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 开启 lookup 循环</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *NSQD)</span> <span class="title">lookupLoop</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> lookupPeers []*lookupPeer</span><br><span class="line">	<span class="keyword">var</span> lookupAddrs []<span class="keyword">string</span></span><br><span class="line">	connect := <span class="literal">true</span></span><br><span class="line">	hostname, err := os.Hostname()</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// for announcements, lookupd determines the host automatically</span></span><br><span class="line">	ticker := time.Tick(<span class="number">15</span> * time.Second)</span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="comment">// 1. 在 nsqd 刚创建时，先构造 nsqd 同各 nsqlookupd（从配置文件中读取）</span></span><br><span class="line">        <span class="comment">// 的 lookupPeer 连接，并执行一个回调函数</span></span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="comment">// 2. 每 15s 就发送一个 heartbeat 消息给所有的 nsqlookupd，并读取响应。</span></span><br><span class="line">            <span class="comment">// 此目的是为了及时检测到已关闭的连接</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-ticker:</span><br><span class="line">			<span class="comment">// send a heartbeat and read a response (read detects closed conns)</span></span><br><span class="line">			<span class="keyword">for</span> _, lookupPeer := <span class="keyword">range</span> lookupPeers &#123;</span><br><span class="line">				n.logf(LOG_DEBUG, <span class="string">"LOOKUPD(%s): sending heartbeat"</span>, lookupPeer)</span><br><span class="line">				<span class="comment">// 发送一个 PING 命令请求，利用 lookupPeer 的 Command 方法发送此命令请求，</span></span><br><span class="line">                <span class="comment">// 并读取响应，忽略响应（正常情况下 nsqlookupd 端的响应为 ok）</span></span><br><span class="line">				cmd := nsq.Ping()</span><br><span class="line">				_, err := lookupPeer.Command(cmd)</span><br><span class="line">				<span class="comment">// ...</span></span><br><span class="line">			&#125;</span><br><span class="line">		<span class="comment">// 3. 收到 nsqd 的通知，即 nsqd.Notify 方法被调用，</span></span><br><span class="line">		<span class="comment">// 从 notifyChan 中取出对应的对象 channel 或 topic</span></span><br><span class="line">        <span class="comment">//（在 channel 或 topic 创建及退出/exit(Delete)会调用 nsqd.Notify 方法）</span></span><br><span class="line">		<span class="keyword">case</span> val := &lt;-n.notifyChan:</span><br><span class="line">			<span class="keyword">var</span> cmd *nsq.Command</span><br><span class="line">			<span class="keyword">var</span> branch <span class="keyword">string</span></span><br><span class="line">			<span class="keyword">switch</span> val.(<span class="keyword">type</span>) &#123;</span><br><span class="line">			<span class="comment">// 3.1 若是 Channel，则通知所有的 nsqlookupd 有 channel 更新（新增或者移除）</span></span><br><span class="line">			<span class="keyword">case</span> *Channel:</span><br><span class="line">				branch = <span class="string">"channel"</span></span><br><span class="line">				channel := val.(*Channel)</span><br><span class="line">                <span class="comment">// 若 channel 已退出，即 channel被 Delete，则构造 UNREGISTER 命令请求</span></span><br><span class="line">				<span class="keyword">if</span> channel.Exiting() == <span class="literal">true</span> &#123; </span><br><span class="line">					cmd = nsq.UnRegister(channel.topicName, channel.name)</span><br><span class="line">				&#125; <span class="keyword">else</span> &#123; <span class="comment">// 否则表明 channel 是新创建的，则构造 REGISTER 命令请求</span></span><br><span class="line">					cmd = nsq.Register(channel.topicName, channel.name)</span><br><span class="line">				&#125;</span><br><span class="line">			<span class="comment">// 3.2 若是 Topic，则通知所有的 nsqlookupd 有 topic 更新（新增或者移除），</span></span><br><span class="line">                <span class="comment">// 处理同 channel 类似</span></span><br><span class="line">			<span class="keyword">case</span> *Topic:</span><br><span class="line">				branch = <span class="string">"topic"</span></span><br><span class="line">				topic := val.(*Topic)</span><br><span class="line">                <span class="comment">// 若 topic 已经退出，即 topic 被 Delete，则 nsqd 构造 UNREGISTER 命令请求</span></span><br><span class="line">				<span class="keyword">if</span> topic.Exiting() == <span class="literal">true</span> &#123;</span><br><span class="line">					cmd = nsq.UnRegister(topic.name, <span class="string">""</span>)</span><br><span class="line">				&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                 <span class="comment">// 若 topic 已经退出，即 topic 被 Delete，则 nsqd 构造 UNREGISTER 命令请求</span></span><br><span class="line">					cmd = nsq.Register(topic.name, <span class="string">""</span>)</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">// 3.3 遍历所有 nsqd 保存的 nsqlookupd 实例的地址信息</span></span><br><span class="line">			<span class="comment">// 向每个 nsqlookupd 发送对应的 Command</span></span><br><span class="line">			<span class="keyword">for</span> _, lookupPeer := <span class="keyword">range</span> lookupPeers &#123;</span><br><span class="line">				n.logf(LOG_INFO, <span class="string">"LOOKUPD(%s): %s %s"</span>, lookupPeer, branch, cmd)</span><br><span class="line">                <span class="comment">// 这里忽略了返回的结果，nsqlookupd 返回的是 ok</span></span><br><span class="line">				_, err := lookupPeer.Command(cmd) </span><br><span class="line">				<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">					n.logf(LOG_ERROR, <span class="string">"LOOKUPD(%s): %s - %s"</span>, lookupPeer, cmd, err)</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		<span class="comment">// 4. 若是 nsqlookupd 的地址变更消息，则重新从配置文件中加载 nsqlookupd 的配置信息</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-n.optsNotificationChan:</span><br><span class="line">			<span class="keyword">var</span> tmpPeers []*lookupPeer</span><br><span class="line">			<span class="keyword">var</span> tmpAddrs []<span class="keyword">string</span></span><br><span class="line">			<span class="keyword">for</span> _, lp := <span class="keyword">range</span> lookupPeers &#123;</span><br><span class="line">				<span class="keyword">if</span> in(lp.addr, n.getOpts().NSQLookupdTCPAddresses) &#123;</span><br><span class="line">					tmpPeers = <span class="built_in">append</span>(tmpPeers, lp)</span><br><span class="line">					tmpAddrs = <span class="built_in">append</span>(tmpAddrs, lp.addr)</span><br><span class="line">					<span class="keyword">continue</span></span><br><span class="line">				&#125;</span><br><span class="line">				n.logf(LOG_INFO, <span class="string">"LOOKUP(%s): removing peer"</span>, lp)</span><br><span class="line">				lp.Close()</span><br><span class="line">			&#125;</span><br><span class="line">			lookupPeers = tmpPeers</span><br><span class="line">			lookupAddrs = tmpAddrs</span><br><span class="line">			connect = <span class="literal">true</span></span><br><span class="line">		<span class="comment">// 5. nsqd 退出消息</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-n.exitChan:</span><br><span class="line">			<span class="keyword">goto</span> exit</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">exit:</span><br><span class="line">	n.logf(LOG_INFO, <span class="string">"LOOKUP: closing"</span>)</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/lookup.go</span></span><br></pre></td></tr></table></figure>

<p>至此，<code>NSQD.lookupLoop</code>方法已经解析完毕。接下来，介绍<code>nsqd</code>网络连接<code>tpc/http</code>处理器的建立及注册。</p>
<h2 id="nsqd-的-tcp-amp-http-连接处理器"><a href="#nsqd-的-tcp-amp-http-连接处理器" class="headerlink" title="nsqd 的 tcp &amp; http 连接处理器"></a>nsqd 的 tcp &amp; http 连接处理器</h2><p><code>nsqd</code>为客户端（包括生产者和消费者）建立的<code>tcp/http</code>连接的请求处理器的逻辑，和<code>nsqlookupd</code>为客户端（包括<code>nsqd</code>和消费者）建立的<code>tcp/http</code>连接请求处理器是类似的。因此这里不会详细阐述。可参考<a href="https://qqzeng.top/2019/05/12/nsq-nsqlookupd-%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/#tcp-amp-http-%E8%AF%B7%E6%B1%82%E5%A4%84%E7%90%86" target="_blank" rel="noopener">这里</a>。另外，监听<code>tcp</code>连接请求的处理器（用于<code>accpet</code>连接）与<code>nsqlookupd</code>的建立的都是<code>tcpServer</code>，另外，当<code>accpet</code>到连接后，首先从连接中读取一个<code>4byte</code>的协议版本号，且目前源码中只支持<code>V2</code>，真正处理连接请求的方法为<code>protocolV2.IOLoop</code>。而<code>http</code>连接请求，则同样复用<code>httprouter</code>作为请求路由器。</p>
<h3 id="tcp-连接处理器"><a href="#tcp-连接处理器" class="headerlink" title="tcp 连接处理器"></a>tcp 连接处理器</h3><p><code>nsqd</code>为每一个客户端都会异步开启一个<code>protocolV2.IOLoop</code>方法处理作为参数的连接上的请求。本文只是涉及到<code>IOLoop</code>方法的主体结构，而对不同请求的特定处理过程，则留待后文分析。因此，这要包括两个方面的处理逻辑，其一为<code>IOLoop</code>中的主循环，其负责等待请求并从连接上读取请求内容，并分析命令请求类型（典型包括<code>PUB</code>、<code>SUB</code>等），调用对应的请求处理函数。另一个异步循环为<code>protocolV2.messagePump</code>，此方法更为复杂，其核心逻辑为负责处理此<code>nsqd</code>所维护的<code>channel</code>发送消息的流程。下面分别进行介绍。</p>
<h4 id="tcp-请求读取解析"><a href="#tcp-请求读取解析" class="headerlink" title="tcp 请求读取解析"></a>tcp 请求读取解析</h4><p>针对每个客户端，在<code>IOLoop</code>方法中，它首先创建此客户端在<code>nsqd</code>服务端所代表的通信实体<code>clientV2</code>(<code>/nsq/nsqd/client_v2.go</code>)，并将其添加到<code>nsqd</code>所维护的<code>clients</code>集合。然后通过<code>messagePumpStartedChan</code>同步等待<code>messagePump</code>先执行，之所以要先等待，原因是<code>messagePump</code>方法会从<code>client</code>获取的一些属性，因此需避免与执行<code>IDENTIFY</code>命令的<code>client</code>产生数据竞争，即在<code>IOLoop</code>方法后面可能修改相关的当前<code>client</code>的数据。而<code>messagePump</code>先执行的的部分为获取<code>client</code>的部分属性，然后通知<code>IOLoop</code>主循环可以继续执行。在<code>IOLoop</code>主循环中，其首先阻塞等待在客户端的连接上，需要注意的是，若客户端设置了心跳间隔(<code>HeartbeatInterval</code>)，则若间隔超过<code>2*HeartbeatInterval</code>未收到客户端的消息，则会关闭连接。相反，若未设置心跳间隔，则读取操作永不超时。当读取并解析请求内容后，会调用<code>protocolV2.Exec</code>方法来根据命令请求的类型来针对性处理。最后，将结果返回给客户端。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 针对连接到 nsqd 的每一个 client，都会单独在一个 goroutine 中执行这样一个 IOLoop请求处理循环</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *protocolV2)</span> <span class="title">IOLoop</span><span class="params">(conn net.Conn)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> err error</span><br><span class="line">	<span class="keyword">var</span> line []<span class="keyword">byte</span></span><br><span class="line">	<span class="keyword">var</span> zeroTime time.Time</span><br><span class="line">	clientID := atomic.AddInt64(&amp;p.ctx.nsqd.clientIDSequence, <span class="number">1</span>)</span><br><span class="line">	client := newClientV2(clientID, conn, p.ctx)</span><br><span class="line">	p.ctx.nsqd.AddClient(client.ID, client)</span><br><span class="line">	<span class="comment">// 1. 同步 messagePump 的启动过程，因为 messagePump会从client获取的一些属性</span></span><br><span class="line">	<span class="comment">// 而避免与执行 IDENTIFY 命令的 client 产生数据竞争，即当前client在后面可能修改相关的数据</span></span><br><span class="line">	messagePumpStartedChan := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">bool</span>)</span><br><span class="line">	<span class="keyword">go</span> p.messagePump(client, messagePumpStartedChan)</span><br><span class="line">	&lt;-messagePumpStartedChan</span><br><span class="line">	<span class="comment">// 2. 开始循环读取 client 的请求，然后解析参数并处理</span></span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="comment">// 如果在与客户端协商 negotiation过程中，客户端设置了 HeartbeatInterval，</span></span><br><span class="line">		<span class="comment">// 则在正常通信情况下，若间隔超过 2*HeartbeatInterval 未收到客户端的消息，</span></span><br><span class="line">		<span class="comment">// 则关闭连接。</span></span><br><span class="line">		<span class="keyword">if</span> client.HeartbeatInterval &gt; <span class="number">0</span> &#123;</span><br><span class="line">			client.SetReadDeadline(time.Now().Add(client.HeartbeatInterval * <span class="number">2</span>))</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			<span class="comment">// 若客户端未设置 HeartbeatInterval，则读取等待不会超时。</span></span><br><span class="line">			client.SetReadDeadline(zeroTime)</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 2.1 读取命令请求，并对它进行解析，解析命令的类型及参数</span></span><br><span class="line">		line, err = client.Reader.ReadSlice(<span class="string">'\n'</span>)</span><br><span class="line">		<span class="comment">// ..</span></span><br><span class="line">		line = line[:<span class="built_in">len</span>(line)<span class="number">-1</span>]</span><br><span class="line">		<span class="keyword">if</span> <span class="built_in">len</span>(line) &gt; <span class="number">0</span> &amp;&amp; line[<span class="built_in">len</span>(line)<span class="number">-1</span>] == <span class="string">'\r'</span> &#123;</span><br><span class="line">			line = line[:<span class="built_in">len</span>(line)<span class="number">-1</span>]</span><br><span class="line">		&#125;</span><br><span class="line">		params := bytes.Split(line, separatorBytes)</span><br><span class="line">		p.ctx.nsqd.logf(LOG_DEBUG, <span class="string">"PROTOCOL(V2): [%s] %s"</span>, client, params)</span><br><span class="line">		<span class="keyword">var</span> response []<span class="keyword">byte</span></span><br><span class="line">		<span class="comment">// 2.2 执行命令</span></span><br><span class="line">		response, err = p.Exec(client, params)</span><br><span class="line">		<span class="comment">// ..</span></span><br><span class="line">		<span class="comment">// 2.3 返回命令处理结果</span></span><br><span class="line">		<span class="keyword">if</span> response != <span class="literal">nil</span> &#123;</span><br><span class="line">			err = p.Send(client, frameTypeResponse, response)</span><br><span class="line">			<span class="comment">// ...</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	p.ctx.nsqd.logf(LOG_INFO, <span class="string">"PROTOCOL(V2): [%s] exiting ioloop"</span>, client)</span><br><span class="line">	conn.Close()</span><br><span class="line">	<span class="built_in">close</span>(client.ExitChan)</span><br><span class="line">	<span class="keyword">if</span> client.Channel != <span class="literal">nil</span> &#123;</span><br><span class="line">		client.Channel.RemoveClient(client.ID)</span><br><span class="line">	&#125;</span><br><span class="line">	p.ctx.nsqd.RemoveClient(client.ID)</span><br><span class="line">	<span class="keyword">return</span> err</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/protocol_v2.go</span></span><br></pre></td></tr></table></figure>

<h4 id="消息发送处理"><a href="#消息发送处理" class="headerlink" title="消息发送处理"></a>消息发送处理</h4><p>消息发送处理流程即为<code>protocolV2.messagePump</code>方法。此方法先获取客户端的一些属性信息，然后通知<code>protocolV2.IOLoop</code>主循环继续执行。接下来进入主循环，主循环主要包括两个部分的逻辑。</p>
<p>其一是更新<code>memoryMsgChan</code>、<code>backendMsgChan</code>和<code>flusherChan</code>通道，这三个<code>channel</code>在后面的作用至关重要，另外就是是否需要将发送给客户端的内容进行显式刷新（<code>V2</code>版本协议采用了选择性地将返回给<code>client</code>的数据进行缓冲，以通过减少系统调用频率来提高效率）。而<code>memoryMsgChan</code>和<code>backendMsgChan</code>都是<code>nsqd</code>所维护的<code>channel</code>的属性（不是拷贝），一个代表的是内存的消息队列，另一个代表的是持久化存储的消息队列，<code>messagePump</code>通过这从这两个<code>channel</code>中接收消息，以执行发送消息的逻辑，关于这两个<code>channel</code>会在分析<code>channel</code>时详细阐述。</p>
<p>其二，阻塞等待从各个<code>channel</code>通道中取出消息，通过一个<code>select</code>操作进行组织：</p>
<ul>
<li><code>flusherChan</code>表示需要进行显式地刷新（是一个<code>ticker</code>）；</li>
<li>而<code>ReadyStateChan</code>则表示客户端的消息处理能力发生了变化，其主要与消息处理状态相关，而在这里并没有对应的后续处理；</li>
<li><code>subEventChan</code>通道起到传递另外两个关键的通道相关，当客户端发送了<code>SUB</code>命令请求时，即请求订阅某个<code>topic</code>的某个<code>channel</code>时，对应的<code>channel</code>实例会被压入到此通道中（<code>SUB</code>方法的逻辑）；</li>
<li>类似的，<code>identifyEventChan</code>通道起到传递一些由客户端设置的一些参数的作用，这些参数包括<code>OutputBufferTimeout</code>、<code>HeartbeatInterval</code>、<code>SampleRate</code>以及<code>MsgTimeout</code>，它们是在客户端发出<code>IDENTIFY</code>命令请求时，被压入到<code>identifyEventChan</code>管道的。其中<code>OutputBufferTimeout</code>用于构建<code>flusherChan</code>定时刷新发送给客户端的消息数据，而<code>HeartbeatInterval</code>用于定时向客户端发送心跳消息，<code>SampleRate</code>则用于确定此次从<code>channel</code>中取出的消息，是否应该发送给此客户端，还记得在第一篇文章中所提到的对于多个客户端连接到同一个<code>channel</code>的情形，<code>channel</code>会将<code>topic</code>发送给它的消息随机发送给其中一个客户端，此处就体现了随机负载。最后的<code>MsgTimeout</code>则用于设置消息投递并被处理的超时时间，最后会被设置成<code>message.pri</code>作为消息先后发送顺序的依据；</li>
<li><code>heartbeatChan</code>的作用就比较明显了，定时向客户端发送心跳消息，由<code>HeartbeatInterval</code>确定；</li>
<li><code>backendMsgChan</code>，它是<code>channel</code>实例的一个关键属性，表示<code>channel实例</code>维护的持久化存储中的消息队列，当<code>channel</code>所接收到的消息的长度超过内存消息队列长度时，则将消息压入到持久化存储中的消息队列<code>backendMsgChan</code>。因此，当从此通道中收到消息时，表明有<code>channel</code>实例有消息需要发送给此客户端。它首先通过生成一个0到100范围内的随机数，若此随机数小于<code>SampleRate</code>则此消息会发送给此客户端，反之亦然。并更新消息尝试发送的次数<code>msg.Attempts</code>。然后，调用<code>channel</code>实例的<code>StartInFlightTimeout</code>将消息压入到<code>in-flight queue</code>中（代表正在发送的消息队列），等待被<code>queueScanWorker</code>处理。接下来，更新为此客户端保存的关于消息的计数信息（比如增加正在发送消息的数量）。最后将消息通过网络发送出去，并更新<code>flushed</code>表示可能需要更新了；</li>
<li><code>memoryMsgChan</code>和<code>backendMsgChan</code>的作用非常类似，只不过它表示的是内存消息队列。处理过程也一样；</li>
<li><code>client.ExitChan</code>表示当客户端退出时，则对应的处理循环也需要退出。</li>
</ul>
<p>这部分的逻辑较为复杂，希望上述的分析能够帮助读者理解，先看下相关代码：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// nsqd 针对每一个 client 的订阅消息的处理循环</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *protocolV2)</span> <span class="title">messagePump</span><span class="params">(client *clientV2, startedChan <span class="keyword">chan</span> <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> err error</span><br><span class="line">	<span class="keyword">var</span> memoryMsgChan <span class="keyword">chan</span> *Message</span><br><span class="line">	<span class="keyword">var</span> backendMsgChan <span class="keyword">chan</span> []<span class="keyword">byte</span></span><br><span class="line">	<span class="keyword">var</span> subChannel *Channel</span><br><span class="line">	<span class="keyword">var</span> flusherChan &lt;-<span class="keyword">chan</span> time.Time</span><br><span class="line">	<span class="keyword">var</span> sampleRate <span class="keyword">int32</span></span><br><span class="line">	<span class="comment">// 1. 获取客户端的属性</span></span><br><span class="line">	subEventChan := client.SubEventChan</span><br><span class="line">	identifyEventChan := client.IdentifyEventChan</span><br><span class="line">	outputBufferTicker := time.NewTicker(client.OutputBufferTimeout)</span><br><span class="line">	heartbeatTicker := time.NewTicker(client.HeartbeatInterval)</span><br><span class="line">	heartbeatChan := heartbeatTicker.C</span><br><span class="line">	msgTimeout := client.MsgTimeout</span><br><span class="line">	<span class="comment">// V2 版本的协议采用了选择性地将返回给 client 的数据进行缓冲，即通过减少系统调用频率来提高效率</span></span><br><span class="line">	<span class="comment">// 只有在两种情况下才采取显式地刷新缓冲数据</span></span><br><span class="line">	<span class="comment">// 		1. 当 client 还未准备好接收数据。</span></span><br><span class="line">	<span class="comment">// 			a. 若 client 所订阅的 channel 被 paused</span></span><br><span class="line">	<span class="comment">// 			b. client 的readyCount被设置为0，</span></span><br><span class="line">	<span class="comment">// 			c. readyCount小于当前正在发送的消息的数量 inFlightCount</span></span><br><span class="line">	<span class="comment">//		2. 当 channel 没有更多的消息给我发送了，在这种情况下，当前程序会阻塞在两个通道上</span></span><br><span class="line">	flushed := <span class="literal">true</span></span><br><span class="line">	<span class="comment">// 2. 向 IOLoop goroutine 发送消息，可以继续运行</span></span><br><span class="line">	<span class="built_in">close</span>(startedChan)</span><br><span class="line">	<span class="keyword">for</span> &#123;<span class="comment">// 1. 当前 client 未准备好接消息，原因包括 subChannel为空，即此客户端未订阅任何 channel</span></span><br><span class="line">		<span class="comment">// 或者客户端还未准备好接收消息，</span></span><br><span class="line">		<span class="comment">// 即 ReadyCount(通过 RDY 命令设置) &lt;= InFlightCount  \</span></span><br><span class="line">        <span class="comment">// InFlightCount (已经给此客户端正在发送的消息的数量) 或 ReadyCount &lt;= 0</span></span><br><span class="line">		<span class="comment">// 刚开始进入循环是肯定会执行这个分支</span></span><br><span class="line">		<span class="keyword">if</span> subChannel == <span class="literal">nil</span> || !client.IsReadyForMessages() &#123;</span><br><span class="line">			<span class="comment">// the client is not ready to receive messages...</span></span><br><span class="line">			<span class="comment">// 初始化各个消息 channel</span></span><br><span class="line">			memoryMsgChan = <span class="literal">nil</span></span><br><span class="line">			backendMsgChan = <span class="literal">nil</span></span><br><span class="line">			flusherChan = <span class="literal">nil</span></span><br><span class="line">			<span class="comment">// 强制刷新缓冲区</span></span><br><span class="line">			client.writeLock.Lock()</span><br><span class="line">			err = client.Flush()</span><br><span class="line">			client.writeLock.Unlock()</span><br><span class="line">			<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">				<span class="keyword">goto</span> exit</span><br><span class="line">			&#125;</span><br><span class="line">			flushed = <span class="literal">true</span></span><br><span class="line">		&#125; <span class="keyword">else</span> <span class="keyword">if</span> flushed &#123;</span><br><span class="line">			<span class="comment">// 2. 表明上一个循环中，我们已经显式地刷新过</span></span><br><span class="line">			<span class="comment">// 准确而言，应该上从 client.SubEventChan 中接收到了 subChannel</span></span><br><span class="line">            <span class="comment">//（client订阅某个 channel 导致的）</span></span><br><span class="line">			<span class="comment">// 因此 初始化 memoryMsgChan 和 backendMsgChan 两个 channel，</span></span><br><span class="line">            <span class="comment">// 实际上这两个 channel 即为 client 所订阅的 channel的两个消息队列</span></span><br><span class="line">			memoryMsgChan = subChannel.memoryMsgChan</span><br><span class="line">			backendMsgChan = subChannel.backend.ReadChan()</span><br><span class="line">			<span class="comment">// 同时，禁止从 flusherChan 取消息，</span></span><br><span class="line">            <span class="comment">// 因为才刚刚设置接收消息的 channel，缓冲区不会数据等待刷新</span></span><br><span class="line">			flusherChan = <span class="literal">nil</span></span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			<span class="comment">// 3. 在执行到此之前，subChannel 肯定已经被设置过了，</span></span><br><span class="line">            <span class="comment">// 且已经从 memoryMsgChan 或 backendMsgChan 取出过消息</span></span><br><span class="line">			<span class="comment">// 因此，可以准备刷新消息发送缓冲区了，即设置 flusherChan</span></span><br><span class="line">			memoryMsgChan = subChannel.memoryMsgChan</span><br><span class="line">			backendMsgChan = subChannel.backend.ReadChan()</span><br><span class="line">			flusherChan = outputBufferTicker.C</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="comment">// 4. 定时刷新消息发送缓冲区</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-flusherChan:</span><br><span class="line">			client.writeLock.Lock()</span><br><span class="line">			err = client.Flush()</span><br><span class="line">			client.writeLock.Unlock()</span><br><span class="line">			<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">				<span class="keyword">goto</span> exit</span><br><span class="line">			&#125;</span><br><span class="line">			flushed = <span class="literal">true</span></span><br><span class="line">		<span class="comment">// 5. 客户端处理消息的能力发生了变化，比如客户端刚消费了某个消息</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-client.ReadyStateChan:</span><br><span class="line">		<span class="comment">// 6. 发现 client 订阅了某个 channel，channel 是在 SUB命令请求方法中被压入的</span></span><br><span class="line">		<span class="comment">// 然后，将 subEventChan 重置为nil，重置为 nil原因表之后不能从此通道中接收到消息</span></span><br><span class="line">		<span class="comment">// 而置为nil的原因是，在SUB命令请求方法中第一行即为检查此客户端是否处于 stateInit 状态，</span></span><br><span class="line">        <span class="comment">// 而调用 SUB 了之后，状态变为 stateSubscribed</span></span><br><span class="line">		<span class="keyword">case</span> subChannel = &lt;-subEventChan:</span><br><span class="line">			<span class="comment">// you can't SUB anymore</span></span><br><span class="line">			subEventChan = <span class="literal">nil</span></span><br><span class="line">		<span class="comment">// 7. 当 nsqd 收到 client 发送的 IDENTIFY 请求时，会设置此 client 的属性信息，</span></span><br><span class="line">        <span class="comment">// 然后将信息 push 到	identifyEventChan。</span></span><br><span class="line">		<span class="comment">// 因此此处就会收到一条消息，同样将 identifyEventChan 重置为nil，</span></span><br><span class="line">		<span class="comment">// 这表明只能从 identifyEventChan 通道中接收一次消息，因为在一次连接过程中，</span></span><br><span class="line">        <span class="comment">// 只允许客户端初始化一次</span></span><br><span class="line">		<span class="comment">// 在 IDENTIFY 命令处理请求中可看到在第一行时进行了检查，</span></span><br><span class="line">        <span class="comment">// 若此时客户端的状态不是 stateInit，则会报错。</span></span><br><span class="line">		<span class="comment">// 最后，根据客户端设置的信息，更新部分属性，如心跳间隔 heartbeatTicker</span></span><br><span class="line">		<span class="keyword">case</span> identifyData := &lt;-identifyEventChan:</span><br><span class="line">			<span class="comment">// you can't IDENTIFY anymore</span></span><br><span class="line">			identifyEventChan = <span class="literal">nil</span></span><br><span class="line">			outputBufferTicker.Stop()</span><br><span class="line">			<span class="keyword">if</span> identifyData.OutputBufferTimeout &gt; <span class="number">0</span> &#123;</span><br><span class="line">				outputBufferTicker = time.NewTicker(identifyData.OutputBufferTimeout)</span><br><span class="line">			&#125;</span><br><span class="line">			heartbeatTicker.Stop()</span><br><span class="line">			heartbeatChan = <span class="literal">nil</span></span><br><span class="line">			<span class="keyword">if</span> identifyData.HeartbeatInterval &gt; <span class="number">0</span> &#123;</span><br><span class="line">				heartbeatTicker = time.NewTicker(identifyData.HeartbeatInterval)</span><br><span class="line">				heartbeatChan = heartbeatTicker.C</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">if</span> identifyData.SampleRate &gt; <span class="number">0</span> &#123;</span><br><span class="line">				sampleRate = identifyData.SampleRate</span><br><span class="line">			&#125;</span><br><span class="line">			msgTimeout = identifyData.MsgTimeout</span><br><span class="line">		<span class="comment">// 8. 定时向所连接的客户端发送 heartbeat 消息</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-heartbeatChan:</span><br><span class="line">			err = p.Send(client, frameTypeResponse, heartbeatBytes)</span><br><span class="line">			<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">				<span class="keyword">goto</span> exit</span><br><span class="line">			&#125;</span><br><span class="line">		<span class="comment">// 9. 从 backendMsgChan 队列中收到了消息</span></span><br><span class="line">		<span class="keyword">case</span> b := &lt;-backendMsgChan:</span><br><span class="line">			<span class="comment">// 根据 client 在与 nsqd 建立连接后，第一次 client 会向 nsqd 发送 IDENFITY 请求 \</span></span><br><span class="line">            <span class="comment">// 以为 nsqd 提供 client 自身的信息。</span></span><br><span class="line">			<span class="comment">// 即为 identifyData，而 sampleRate 就包含在其中。</span></span><br><span class="line">            <span class="comment">// 换言之，客户端会发送一个 0-100 的数字给 nsqd。</span></span><br><span class="line">			<span class="comment">// 在 nsqd 服务端，它通过从 0-100 之间随机生成一个数字，  \</span></span><br><span class="line">            <span class="comment">// 若其大于 客户端发送过来的数字 sampleRate    \</span></span><br><span class="line">			<span class="comment">// 则 client 虽然订阅了此 channel，且此 channel 中也有消息了， \</span></span><br><span class="line">            <span class="comment">// 但是不会发送给此 client。</span></span><br><span class="line">			<span class="comment">// 这里就体现了 官方文档 中所说的，当一个 channel 被 client 订阅时，  \</span></span><br><span class="line">            <span class="comment">// 它会将收到的消息随机发送给这一组 client 中的一个。</span></span><br><span class="line">			<span class="comment">// 而且，就算只有一个 client，从程序中来看，也不一定能够获取到此消息，  \</span></span><br><span class="line">            <span class="comment">// 具体情况也与 client 编写的程序规则相关</span></span><br><span class="line">			<span class="keyword">if</span> sampleRate &gt; <span class="number">0</span> &amp;&amp; rand.Int31n(<span class="number">100</span>) &gt; sampleRate &#123;</span><br><span class="line">				<span class="keyword">continue</span></span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">// 将消息解码</span></span><br><span class="line">			msg, err := decodeMessage(b)</span><br><span class="line">			<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">				p.ctx.nsqd.logf(LOG_ERROR, <span class="string">"failed to decode message - %s"</span>, err)</span><br><span class="line">				<span class="keyword">continue</span></span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">// 递增消息尝试发送次数</span></span><br><span class="line">            <span class="comment">// 注意： 当消息发送的次数超过一定限制时，可由 client 自己在应用程序中做处理</span></span><br><span class="line">			msg.Attempts++ </span><br><span class="line">			<span class="comment">// 调用client 所订阅 channel 的 StartInFlightTimeout 方法，将消息压入发送队列</span></span><br><span class="line">			subChannel.StartInFlightTimeout(msg, client.ID, msgTimeout)</span><br><span class="line">			<span class="comment">// 更新client 的关于正在发送消息的属性</span></span><br><span class="line">			client.SendingMessage()</span><br><span class="line">			<span class="comment">// 正式发送消息到指定的 client</span></span><br><span class="line">			err = p.SendMessage(client, msg)</span><br><span class="line">			<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">				<span class="keyword">goto</span> exit</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">// 重置 flused 变量</span></span><br><span class="line">			flushed = <span class="literal">false</span></span><br><span class="line">		<span class="comment">// 9. 从 memoryMsgChan 队列中收到了消息</span></span><br><span class="line">		<span class="keyword">case</span> msg := &lt;-memoryMsgChan:</span><br><span class="line">			<span class="keyword">if</span> sampleRate &gt; <span class="number">0</span> &amp;&amp; rand.Int31n(<span class="number">100</span>) &gt; sampleRate &#123;</span><br><span class="line">				<span class="keyword">continue</span></span><br><span class="line">			&#125;</span><br><span class="line">			msg.Attempts++</span><br><span class="line"></span><br><span class="line">			subChannel.StartInFlightTimeout(msg, client.ID, msgTimeout)</span><br><span class="line">			client.SendingMessage()</span><br><span class="line">			err = p.SendMessage(client, msg)</span><br><span class="line">			<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">				<span class="keyword">goto</span> exit</span><br><span class="line">			&#125;</span><br><span class="line">			flushed = <span class="literal">false</span></span><br><span class="line">		<span class="comment">// 10. 客户端退出</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-client.ExitChan:</span><br><span class="line">			<span class="keyword">goto</span> exit</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">exit:</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	heartbeatTicker.Stop()</span><br><span class="line">	outputBufferTicker.Stop()</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/protocol_v2.go</span></span><br></pre></td></tr></table></figure>

<p>读者在理解这一段代码时，先可以看懂每一段代码的含义，然后进行一次“肉眼DEBUG”，即走一遍正常的代码处理流程（注意那些<code>channel</code>上的竞争条件）。这里，我简要阐述一下（<code>for</code>循环中的处理逻辑）：</p>
<ul>
<li>首先刚开始肯定是进行第一个<code>if</code>执行，因为<code>subChannel == nil</code>且客户端也未准备好接收消息。注意此时会将各个<code>channel</code>，并刷新缓冲，而且将<code>flushed</code>设置为<code>true</code>；</li>
<li>然后，正常情况下，应该是<code>identifyEventChan</code>分支被触发，即客户端发送了<code>IDENTIFY</code>命令，此时，设置了部分<code>channel</code>。比如<code>heartbeatChan</code>，因此<code>nsqd</code>可以定期向客户端发送<code>hearbeat</code>消息了。并且<code>heartbeatChan</code>可能在下述的任何时刻触发，但都不影响程序核心执行逻辑；</li>
<li>此时，就算触发了<code>heartbeatChan</code>，上面的仍然执行第一个<code>if</code>分支，没有太多改变；</li>
<li>假如此时客户端发送了一个<code>SUB</code>请求，则此时<code>subEventChan</code>分支被触发，此时<code>subChannel</code>被设置，且<code>subEventChan</code>之后再也不能被触发。此时客户端的状态为<code>stateSubscribed</code>；</li>
<li>接下来，上面的代码执行的仍然是第一个<code>if</code>分支，因为此时<code>subChannel != nil</code>，但是客户端仍未准备好接收消息，即客户端的<code>ReadyCount</code>属性还未初始化；</li>
<li>按正常情况，此时客户端应该会发送<code>RDY</code>命令请求，设置自己的<code>ReadyCount</code>，即表示客户端能够处理消息的数量。</li>
<li>接下来，上面的代码总算可以执行第二个<code>if</code>分支，终于初始化了<code>memoryMsgChan</code>和<code>backendMsgChan</code>两个用于发送消息的消息队列了，同时将<code>flusherChan</code>设置为<code>nil</code>，显然，此时不需要刷新缓冲区；</li>
<li>此时，<code>ReadyStateChan</code>分支会被触发，因为客户端的消息处理能力确实发生了改化；</li>
<li>但<code>ReadyStateChan</code>分支的执行不影响上面代码中被触发的<code>if</code>分支，执行第二个分支。换言之，此时程序中涉及到的各属性没有发生变化；</li>
<li>现在，按正常情况终于要触发了<code>memoryMsgChan</code>分支，即有生产者向此<code>channel</code>所关联的<code>topic</code>投递了消息，因此<code>nsqd</code>将<code>channel</code>内存队列的消息发送给订阅了此<code>channel</code>的消费者。此时<code>flushed</code>为<code>false</code>；</li>
<li>接下来，按正常情况（假设客户端还可以继续消息消息，且消息消费未超时），上面代码应该执行第三个<code>if</code>分支，即设置两个消息队列，并设置<code>flusherChan</code>，因为此时确实可能需要刷新缓冲区了。</li>
<li>一旦触发了<code>flusherChan</code>分支，则<code>flushed</code>又被设置成<code>true</code>。表明暂时不需要刷新缓冲区，直到<code>nsqd</code>发送了消息给客户端，即触发了<code>memoryMsgChan</code>或<code>backendMsgChan</code>分支；</li>
<li>然后可能又进入第二个<code>if</code>分支，然后发送消息，刷新缓冲区，反复循环…</li>
<li>假如某个时刻，消费者的消息处理能力已经变为0了，则此时执行第一个<code>if</code>分支，两个消息队列被重置，执行强刷。显然，此时考虑到消费者已经不能再处理消息了，因此需要“关闭”消息发送的管道。</li>
</ul>
<p>至此，<code>nsqd</code>其为客户端提供的<code>tcp</code>请求处理器相关的处理逻辑已经阐述完毕。内容比较多，因为笔者也阐述的比较详细，尽可能希望读者能够清晰整个流程。下面阐述<code>nsqd</code>为客户端提供的<code>http</code>请求处理器的相关逻辑。</p>
<h3 id="http-连接处理器"><a href="#http-连接处理器" class="headerlink" title="http 连接处理器"></a>http 连接处理器</h3><p><code>http</code>连接处理器则相对简单很多，因为大部分内容已经由<code>httprouter</code>这个请求路由器完成了。我们简单看一下<code>http handler</code>的创建过程。同<code>nsqlookupd</code>创建<code>http handler</code>完全一样。首先设置了<code>httprouter</code>一些重要属性，然后构建<code>httpServer</code>实例，最后，调用<code>router.Handle</code>添加特定请求的处理器。关于具体请求的处理逻辑，后面会单开一篇文章来阐述。这里只涉及处理过程的框架。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 同 nsqlookupd.httpServer 类似，参考 nsqlookupd/http.go 的源码注释</span></span><br><span class="line"><span class="keyword">type</span> httpServer <span class="keyword">struct</span> &#123;</span><br><span class="line">	ctx         *context</span><br><span class="line">	tlsEnabled  <span class="keyword">bool</span></span><br><span class="line">	tlsRequired <span class="keyword">bool</span></span><br><span class="line">	router      http.Handler</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newHTTPServer</span><span class="params">(ctx *context, tlsEnabled <span class="keyword">bool</span>, tlsRequired <span class="keyword">bool</span>)</span> *<span class="title">httpServer</span></span> &#123;</span><br><span class="line">	log := http_api.Log(ctx.nsqd.logf)</span><br><span class="line">	router := httprouter.New()</span><br><span class="line">	router.HandleMethodNotAllowed = <span class="literal">true</span></span><br><span class="line">	router.PanicHandler = http_api.LogPanicHandler(ctx.nsqd.logf)</span><br><span class="line">	router.NotFound = http_api.LogNotFoundHandler(ctx.nsqd.logf)</span><br><span class="line">	router.MethodNotAllowed = http_api.LogMethodNotAllowedHandler(ctx.nsqd.logf)</span><br><span class="line">	s := &amp;httpServer&#123;</span><br><span class="line">		ctx:         ctx,</span><br><span class="line">		tlsEnabled:  tlsEnabled,</span><br><span class="line">		tlsRequired: tlsRequired,</span><br><span class="line">		router:      router,</span><br><span class="line">	&#125;</span><br><span class="line">	router.Handle(<span class="string">"GET"</span>, <span class="string">"/ping"</span>, http_api.Decorate(s.pingHandler, log, http_api.PlainText))</span><br><span class="line">	router.Handle(<span class="string">"GET"</span>, <span class="string">"/info"</span>, http_api.Decorate(s.doInfo, log, http_api.V1))</span><br><span class="line">	<span class="comment">// v1 negotiate</span></span><br><span class="line">	router.Handle(<span class="string">"POST"</span>, <span class="string">"/pub"</span>, http_api.Decorate(s.doPUB, http_api.V1))</span><br><span class="line">	<span class="comment">// only v1</span></span><br><span class="line">	router.Handle(<span class="string">"POST"</span>, <span class="string">"/topic/create"</span>, http_api.Decorate(s.doCreateTopic, log, http_api.V1))</span><br><span class="line">	router.Handle(<span class="string">"POST"</span>, <span class="string">"/channel/create"</span>, http_api.Decorate(s.doCreateChannel, log, http_api.V1))</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// debug</span></span><br><span class="line">	router.HandlerFunc(<span class="string">"GET"</span>, <span class="string">"/debug/pprof/"</span>, pprof.Index)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">return</span> s</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqd/http.go</span></span><br></pre></td></tr></table></figure>

<p>至此，<code>nsqd</code>服务启动相关的源码已经解析完毕了。整个文章非常长，读者能够看到这里实属不易。希望看完全文读者能够有所收获，源码分析也并不难。</p>
<p>最后，简单小结，本文从五个方面对<code>nsqd</code>服务启动相关的流程进行分析。具体地，其一，先以<code>nsqd</code>命令为切入点，简述服务启动流程；其二，紧追<code>nsqd</code>启动流程，进一步分析初始化过程中<code>NSQ</code>的创建及初始化相关逻辑；接下来，详细阐述<code>nsqd</code>异步开启<code>nsqlookupd</code>查询过程；其四，详细阐述了<code>nsqd</code>和<code>nsqlookupd</code>交互的主循环的逻辑。即第四点和第五点阐述的是<code>nsqd</code>与<code>nsqlookupd</code>交互部分；最后，分析了<code>nsqd</code>建立<code>tcp</code>和<code>http</code>请求处理器相关逻辑。其中，重点分析了<code>nsqd</code>为客户端（生产者和消费者）建立的<code>tcp</code>请求处理器，主要包括两个大的方面：<code>IOLoop</code>主循环主要是读取连接请求，调用对应的处理函数处理请求。另一个则是<code>messagePump</code>方法，其包含了<code>nsqd</code>处理消息发送的核心逻辑——即<code>nsqd</code>所维护的<code>channel</code>将消息发送给各个订阅了它的客户端，其涉及到的流程最为复杂。更详细内容可以参考笔者简要<a href="https://github.com/qqzeng/nsqio/tree/master/nsq" target="_blank" rel="noopener">注释的源码</a>。</p>
<p>参考文献</p>
<p>[1]. <a href="https://github.com/nsqio/nsq" target="_blank" rel="noopener">https://github.com/nsqio/nsq</a><br>[2]. <a href="https://nsq.io/overview/quick_start.html" target="_blank" rel="noopener">https://nsq.io/overview/quick_start.html</a></p>
]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title>nsq nsqlookupd 源码简析</title>
    <url>/2019/05/12/nsq-nsqlookupd-%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/</url>
    <content><![CDATA[<p>上一篇文章简要介绍了<code>nsq</code>以及它的几个值得注意的特性，以对<code>nsq</code>有大体认识，并在整体上把握<code>nsq</code>的工作流程。这对于后面的源码分析工作会有帮助。本文重点阐述<code>nsqlookup</code>组件设计实现相关的源码。<code>nsqlookupd</code>是一个中心管理服务，负责管理集群(<code>nsqd</code>)的拓扑信息，并且为客户端（消费者）提供最终一致性的发现服务。具体而言，<code>nsqlookupd</code>用作解耦消费者和生产者(<code>nsqd</code>)。因为<code>nsqd</code>节点会将<code>topic</code>和<code>channel</code>的信息通过<code>tcp</code>广播到<code>nsqlookupd</code>节点（允许水平扩展）以实施服务注册，而客户端或<code>nsqadmin</code>通过<code>http</code>接口查询<code>nsqlookupd</code>来发现指定<code>topic</code>的生产者。引入<code>nsqlookupd</code>使得整个系统的模块更加清晰，且维护起来更加方便。值得注意的是，<code>nsqlookupd</code>本身对存储在其上的数据不做任何持久化。</p>
<a id="more"></a>

<p>考虑到<code>nsqlookupd</code>本身所提供的功能比较简单，代码结构并不复杂，因此以<code>nsqlookupd</code>为分析入口。个人建议，查看或分析源码最好从某个业务逻辑流程切入，这样更具针对性，忽略某些旁支或细节，先从宏观上把握整个流程。按照惯例，读者可以自己<code>clone</code>源码进行分析。本文分析<code>nsqlookupd</code>关键流程，较为完整的<a href="https://github.com/qqzeng/nsqio/tree/master/nsq" target="_blank" rel="noopener"><code>nsq</code>源码注释</a>可在这里找到，其注释源码版本为<code>v1.1.0</code>，仅供参考。</p>
<p>本文主要从三个方面来阐述<code>nsqlookupd</code>：其一，以<code>nsqlookupd</code>命令为切入点，介绍其启动流程；其二，通过启动流程，继续追溯到<code>NSQLookupd</code>的创建及初始化过程。最后，阐述初始化过程中<code>tcp</code>和<code>http</code>请求处理器相关逻辑，并示例分析几个典型请求的详细处理逻辑，比如，<code>nsqd</code>通过<code>tcp</code>协议订阅<code>topic</code>。另外，<code>nsqd</code>通过<code>http</code>协议请求<code>nsqlookupd</code>执行<code>topic</code>的创建过程，以及客户端（消费者）请求<code>nsqlookupd</code>执行<code>topic</code>的查询过程。本文所涉及到源码主要为<code>/nsq/apps/nsqlookupd/</code>、<code>/nsq/nsqlookupd/</code>和<code>/nsq/internal/</code>下的若干子目录，<code>/nsq/apps</code>目录是官方提供的一些工具包，而<code>/nsq/nsqlookupd</code>会对应具体的实现，<code>/nsq/internal</code>则为<code>nsq</code>内部的核心（公共）库，目录结构比较简单，不多阐述。</p>
<p>当我们在命令行执行<code>nsqlookupd</code>命令时（同时可指定参数），相当于运行了<code>nsq/apps/nsqlookupd</code>程序的<code>main</code>方法。此方法启动了一个进程（服务），并且通过创建<code>NSQLookupd</code>并调用其<code>Main</code>方法执行启动逻辑。</p>
<h2 id="利用-svc-启动进程"><a href="#利用-svc-启动进程" class="headerlink" title="利用 svc 启动进程"></a>利用 svc 启动进程</h2><p>具体而言，其利用 <a href="https://github.com/judwhite/go-svc/svc" target="_blank" rel="noopener"><code>svc</code></a>的<code>Run</code>方法启动一个进程（守护进程或服务），在 <code>svc.Run</code> 方法中依次调用 <code>Init</code> 和 <code>Start</code> 方法，<code>Init</code> 和 <code>Start</code> 方法都是 <code>no-blocking</code>的；<code>Run</code> 方法会阻塞直到接收到 <code>SIGINT</code>(程序终止信号，如<code>ctrl+c</code>)或<code>SIGTERM</code>（程序结束信号，如<code>kill -15 PID</code>），然后调用 <code>stop</code>方法后退出，这通过传递一个<code>channel</code>及感兴趣的信号集(<code>SIGINT&amp;SGITERM</code>)给 <code>signal.Notify</code> 方法实现；<code>Run</code>方法中阻塞等待从<code>channel</code>中接收消息，一旦收到消息，则调用<code>stop</code>方法返回，进程退出。更多可以查看 <code>golang</code> 标准包的<code>signal.Notify</code>以及<code>svc</code>包是如何协助启动一个进程。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> program <span class="keyword">struct</span> &#123; <span class="comment">// 代表此进程结构，包装了一个 nsqlookupd 实例</span></span><br><span class="line">	once       sync.Once</span><br><span class="line">	nsqlookupd *nsqlookupd.NSQLookupd</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// nsqlookupd 服务程序执行入口</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span> </span></span><br><span class="line"><span class="function">	<span class="title">prg</span> := &amp;<span class="title">program</span></span>&#123;&#125;</span><br><span class="line">	<span class="comment">// 1. 利用 svc 启动一个进程，在 svc.Run 方法中会依次调用 Init 和 Start 方法，Init 和 Start 方法都是 no-blocking的；</span></span><br><span class="line">	<span class="comment">// 2. Run 方法会阻塞直到接收到 SIGINT(程序终止)或SIGTERM(程序结束信号)，然后调用stop方法后退出；</span></span><br><span class="line">	<span class="comment">// 3. 这是通过传递一个 channel 及感兴趣信号集(SIGINT&amp;SGITERM)给 signal.Notify 方法实现；</span></span><br><span class="line">	<span class="comment">// 4. Run方法中阻塞等待从 channel 中接收消息，一旦收到消息，则调用 stop 方法返回，进程退出。</span></span><br><span class="line">	<span class="keyword">if</span> err := svc.Run(prg, syscall.SIGINT, syscall.SIGTERM); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		logFatal(<span class="string">"%s"</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *program)</span> <span class="title">Init</span><span class="params">(env svc.Environment)</span> <span class="title">error</span></span> &#123;<span class="comment">// 初始化函数没有做实质性工作</span></span><br><span class="line">	<span class="keyword">if</span> env.IsWindowsService() &#123;</span><br><span class="line">		dir := filepath.Dir(os.Args[<span class="number">0</span>])</span><br><span class="line">		<span class="keyword">return</span> os.Chdir(dir)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Start 方法包含进程启动的主要执行逻辑</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *program)</span> <span class="title">Start</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 默认初始化 nsqlookupd 配置参数</span></span><br><span class="line">	opts := nsqlookupd.NewOptions()</span><br><span class="line">	<span class="comment">// 2. 根据命令行传递的参数更新默认参数</span></span><br><span class="line">	flagSet := nsqlookupdFlagSet(opts)</span><br><span class="line">	flagSet.Parse(os.Args[<span class="number">1</span>:])</span><br><span class="line">	<span class="comment">// 3. 输出版本号并退出</span></span><br><span class="line">	<span class="keyword">if</span> flagSet.Lookup(<span class="string">"version"</span>).Value.(flag.Getter).Get().(<span class="keyword">bool</span>) &#123;</span><br><span class="line">		fmt.Println(version.String(<span class="string">"nsqlookupd"</span>))</span><br><span class="line">		os.Exit(<span class="number">0</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 4. 解析配置文件获取用户设置参数</span></span><br><span class="line">	<span class="keyword">var</span> cfg <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">	configFile := flagSet.Lookup(<span class="string">"config"</span>).Value.String()</span><br><span class="line">	<span class="keyword">if</span> configFile != <span class="string">""</span> &#123;</span><br><span class="line">		_, err := toml.DecodeFile(configFile, &amp;cfg)</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			logFatal(<span class="string">"failed to load config file %s - %s"</span>, configFile, err)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	options.Resolve(opts, flagSet, cfg) <span class="comment">// 5. 合并默认参数及配置文件中的参数</span></span><br><span class="line">	nsqlookupd, err := nsqlookupd.New(opts) <span class="comment">// 6. 创建 nsqlookupd 进程</span></span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		logFatal(<span class="string">"failed to instantiate nsqlookupd"</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">	p.nsqlookupd = nsqlookupd</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; <span class="comment">// 7. 执行 nsqlookupd 的主函数</span></span><br><span class="line">		err := p.nsqlookupd.Main()</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			p.Stop()</span><br><span class="line">			os.Exit(<span class="number">1</span>)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;()</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 进程退出方法，注意使用 sync.Once 来保证 nsqlookupd.Exit 方法只被执行一次</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *program)</span> <span class="title">Stop</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	p.once.Do(<span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		p.nsqlookupd.Exit()</span><br><span class="line">	&#125;)</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /nsq/apps/nsqlookupd.go</span></span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 使用 Run 方法来开启一个进程</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Run</span><span class="params">(service Service, sig ...os.Signal)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	env := environment&#123;&#125;</span><br><span class="line">	<span class="keyword">if</span> err := service.Init(env); err != <span class="literal">nil</span> &#123; <span class="comment">// 1.初始化环境，没什么实质性内容</span></span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="keyword">if</span> err := service.Start(); err != <span class="literal">nil</span> &#123; <span class="comment">// 2. 调用上面的 Start 方法来执行进程启动逻辑</span></span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(sig) == <span class="number">0</span> &#123;<span class="comment">// 3. 默认响应 SIGINT和SIGTERM信号</span></span><br><span class="line">		sig = []os.Signal&#123;syscall.SIGINT, syscall.SIGTERM&#125;</span><br><span class="line">	&#125;</span><br><span class="line">    signalChan := <span class="built_in">make</span>(<span class="keyword">chan</span> os.Signal, <span class="number">1</span>) <span class="comment">// 4. 调用 signalNotify 方法，使用阻塞等待信号产生</span></span><br><span class="line">	signalNotify(signalChan, sig...)</span><br><span class="line">	&lt;-signalChan</span><br><span class="line">	<span class="comment">// 5. 在进程退出之前，调用 Stop 方法做清理工作</span></span><br><span class="line">	<span class="keyword">return</span> service.Stop()</span><br><span class="line">&#125; <span class="comment">// /svc/svc/svc_other.go</span></span><br></pre></td></tr></table></figure>

<p>代码中注释已经介绍得比较清晰，这里简单阐述下<code>Start</code>方法的逻辑：首先会通过默认参数创建配置参数实例<code>opts</code>，然后合并命令行参数及配置文件参数（若存在），接下来创建<code>nsqlookupd</code>实例，并调用<code>nsqlookupd.Main</code>函数，这是最关键的步骤。下面展开分析。</p>
<h2 id="NSQLookupd-启动初始化"><a href="#NSQLookupd-启动初始化" class="headerlink" title="NSQLookupd 启动初始化"></a>NSQLookupd 启动初始化</h2><p>在介绍构造方法前，先贴出<code>NSQLookupd</code>结构：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> NSQLookupd <span class="keyword">struct</span> &#123;</span><br><span class="line">	sync.RWMutex                       <span class="comment">// 读写锁</span></span><br><span class="line">	opts         *Options              <span class="comment">// 参数配置信息</span></span><br><span class="line">	tcpListener  net.Listener          <span class="comment">// tcp 监听器用于监听 tcp 连接</span></span><br><span class="line">	httpListener net.Listener          <span class="comment">// 监听 http 连接</span></span><br><span class="line">    <span class="comment">// sync.WaitGroup 增强体，功能类似于 sync.WaitGroup，一般用于等待所有的 goroutine 全部退出</span></span><br><span class="line">	waitGroup    util.WaitGroupWrapper </span><br><span class="line">    DB           *RegistrationDB       <span class="comment">// 生产者注册信息(topic、channel及producer) DB</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>构造方法中并没有太多逻辑，启用了日志输出，并构建<code>NSQLookupd</code>结构实例，然后开启了<code>tcp</code>和<code>http</code>连接的监听。代码如下所示（省去了一些错误处理及其它无关紧要的代码片段）：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 创建 NSQLookupd 实例</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">(opts *Options)</span> <span class="params">(*NSQLookupd, error)</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> err error</span><br><span class="line">	<span class="comment">// 1. 启用日志输出</span></span><br><span class="line">	<span class="keyword">if</span> opts.Logger == <span class="literal">nil</span> &#123;</span><br><span class="line">		opts.Logger = log.New(os.Stderr, opts.LogPrefix, log.Ldate|log.Ltime|log.Lmicroseconds)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 创建 NSQLookupd 实例</span></span><br><span class="line">	l := &amp;NSQLookupd&#123;</span><br><span class="line">		opts: opts, <span class="comment">// 配置参数实例</span></span><br><span class="line">		DB:   NewRegistrationDB(), <span class="comment">// topic、channel及producer的存储，一个 map 实例</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 3. 版本号等信息</span></span><br><span class="line">	l.logf(LOG_INFO, version.String(<span class="string">"nsqlookupd"</span>))</span><br><span class="line">	<span class="comment">// 4. 开启 tcp 和 http 连接监听</span></span><br><span class="line">	l.tcpListener, err = net.Listen(<span class="string">"tcp"</span>, opts.TCPAddress)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	l.httpListener, err = net.Listen(<span class="string">"tcp"</span>, opts.HTTPAddress)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">return</span> l, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>下面重点介绍其<code>Main</code>启动方法，即启动一个<code>NSQLookupd</code>实例，具体逻辑比较简单：构建了一个<code>Context</code>实例，它纯粹只是一个<code>NSQLookupd</code>实例的<code>wrapper</code>。然后注册了进程退出前需要执行的<code>hook</code>函数。关键步骤为创建用于处理<code>tcp</code>和<code>http</code>连接的<code>handler</code>，同时异步开启<code>tcp</code>和<code>http</code>连接的监听动作，最后通过一个<code>channel</code>阻塞等待方法退出，详细代码逻辑如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 启动 NSQLookupd 实例</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(l *NSQLookupd)</span> <span class="title">Main</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 构建 Context 实例， Context 是 NSQLookupd 的一个 wrapper</span></span><br><span class="line">	ctx := &amp;Context&#123;l&#125;</span><br><span class="line">	<span class="comment">// 2. 创建进程退出前需要执行的 hook 函数</span></span><br><span class="line">	exitCh := <span class="built_in">make</span>(<span class="keyword">chan</span> error)</span><br><span class="line">	<span class="keyword">var</span> once sync.Once</span><br><span class="line">	exitFunc := <span class="function"><span class="keyword">func</span><span class="params">(err error)</span></span> &#123;</span><br><span class="line">		once.Do(<span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">			<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">				l.logf(LOG_FATAL, <span class="string">"%s"</span>, err)</span><br><span class="line">			&#125;</span><br><span class="line">			exitCh &lt;- err</span><br><span class="line">		&#125;)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 3. 创建用于处理 tcp 连接的 handler，并开启 tcp 连接的监听动作</span></span><br><span class="line">    <span class="comment">// tcp协议处理函数其实是 LookupProtocolV1.IOLoop, 它支持 IDENTIFY、REGISTER及UNREGISTER等命令请求的处理</span></span><br><span class="line">	tcpServer := &amp;tcpServer&#123;ctx: ctx&#125;</span><br><span class="line">	l.waitGroup.Wrap(<span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		<span class="comment">// 3.1 在 protocol.TCPServer 方法中统一处理监听</span></span><br><span class="line">		exitFunc(protocol.TCPServer(l.tcpListener, tcpServer, l.logf))</span><br><span class="line">	&#125;)</span><br><span class="line">	<span class="comment">// 4. 创建用于处理 http 连接的 handler，并开启 http 连接的监听动作</span></span><br><span class="line">    <span class="comment">// 而 http连接处理，它利用了 httpServer，一个高效的请求路由库</span></span><br><span class="line">	httpServer := newHTTPServer(ctx)</span><br><span class="line">	l.waitGroup.Wrap(<span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		exitFunc(http_api.Serve(l.httpListener, httpServer, <span class="string">"HTTP"</span>, l.logf))</span><br><span class="line">	&#125;)</span><br><span class="line">	<span class="comment">// 5. 阻塞等待错误退出</span></span><br><span class="line">	err := &lt;-exitCh</span><br><span class="line">	<span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// NSQLookupd 服务退出方法中，关闭了网络连接，并且需等待 hook 函数被执行</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(l *NSQLookupd)</span> <span class="title">Exit</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> l.tcpListener != <span class="literal">nil</span> &#123;</span><br><span class="line">		l.tcpListener.Close()</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> l.httpListener != <span class="literal">nil</span> &#123;</span><br><span class="line">		l.httpListener.Close()</span><br><span class="line">	&#125;</span><br><span class="line">	l.waitGroup.Wait()</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqlookupd/nsqlookupd.go</span></span><br></pre></td></tr></table></figure>

<h2 id="tcp-amp-http-请求处理"><a href="#tcp-amp-http-请求处理" class="headerlink" title="tcp &amp; http 请求处理"></a>tcp &amp; http 请求处理</h2><p><code>Main</code>方法中关键代码为构建<code>tcp</code>及<code>http</code>请求的<code>handler</code>，并异步调用它们以处理请求。</p>
<h3 id="客户端-tcp-请求处理"><a href="#客户端-tcp-请求处理" class="headerlink" title="客户端 tcp 请求处理"></a>客户端 tcp 请求处理</h3><p>其中<code>tcp</code>请求的<code>handler</code>比较简单：直接使用标准库的<code>tcp</code>相关函数，在一个单独的<code>goroutine</code>中启用了<code>tcp handler</code>。对于监听到每一个连接，开启一个额外的<code>goroutine</code>来处理请求。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// tcp 连接处理器，只是一个统一的入口，当 accept 到一个连接后，将此连接交给对应的 handler 处理</span></span><br><span class="line"><span class="keyword">type</span> TCPHandler <span class="keyword">interface</span> &#123;</span><br><span class="line">	Handle(net.Conn)</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TCPServer</span><span class="params">(listener net.Listener, handler TCPHandler, logf lg.AppLogFunc)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	logf(lg.INFO, <span class="string">"TCP: listening on %s"</span>, listener.Addr())</span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		clientConn, err := listener.Accept()</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		<span class="comment">// 针对每一个连接到 nsqd 的 client，会单独开启一个 goroutine 去处理</span></span><br><span class="line">        <span class="comment">// 实际上是由 /nsq/nsqlookupd/tcp.go 中的 tcpServer.Handle 方法处理</span></span><br><span class="line">		<span class="keyword">go</span> handler.Handle(clientConn)</span><br><span class="line">	&#125;</span><br><span class="line">	logf(lg.INFO, <span class="string">"TCP: closing %s"</span>, listener.Addr())</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /nsq/internal/protocol/tcp_server.go</span></span><br></pre></td></tr></table></figure>

<p>对于<code>accpet</code>到的每一个连接，都交给了<code>tcpServer.Handle</code>方法异步处理。需要注意的是<code>tcpServer.Handle</code>只是对连接进行初步处理，不涉及到具体的业务逻辑。其主要是验证客户端使用的协议版本，然后就调用<code>lookup_protocol_v1.go</code>中的<code>LookupProtocolV1.IOLoop</code>方法处理。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// tcp 连接 handler。 Context/NSQLookupd 的一个 wrapper</span></span><br><span class="line"><span class="keyword">type</span> tcpServer <span class="keyword">struct</span> &#123;</span><br><span class="line">	ctx *Context</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *tcpServer)</span> <span class="title">Handle</span><span class="params">(clientConn net.Conn)</span></span> &#123;</span><br><span class="line">	p.ctx.nsqlookupd.logf(LOG_INFO, <span class="string">"TCP: new client(%s)"</span>, clientConn.RemoteAddr())</span><br><span class="line">	<span class="comment">// 在 client 同 NSQLookupd 正式通信前，需要发送一个 4byte 的序列号，以商定协议版本</span></span><br><span class="line">	buf := <span class="built_in">make</span>([]<span class="keyword">byte</span>, <span class="number">4</span>)</span><br><span class="line">	_, err := io.ReadFull(clientConn, buf)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	protocolMagic := <span class="keyword">string</span>(buf)</span><br><span class="line">	p.ctx.nsqlookupd.logf(LOG_INFO, <span class="string">"CLIENT(%s): desired protocol magic '%s'"</span>,</span><br><span class="line">		clientConn.RemoteAddr(), protocolMagic)</span><br><span class="line">	<span class="keyword">var</span> prot protocol.Protocol</span><br><span class="line">	<span class="keyword">switch</span> protocolMagic &#123;</span><br><span class="line">	<span class="comment">// 构建 LookupProtocolV1 来真正处理连接的业务请求</span></span><br><span class="line">	<span class="keyword">case</span> <span class="string">"  V1"</span>:</span><br><span class="line">		prot = &amp;LookupProtocolV1&#123;ctx: p.ctx&#125;</span><br><span class="line">	<span class="keyword">default</span>:</span><br><span class="line">		<span class="comment">// 只支持V1版本，否则发送 E_BAD_PROTOCOL，关闭连接</span></span><br><span class="line">		protocol.SendResponse(clientConn, []<span class="keyword">byte</span>(<span class="string">"E_BAD_PROTOCOL"</span>))</span><br><span class="line">		clientConn.Close()</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 调用 prot.IOLoop 方法循环处理指定连接的请求</span></span><br><span class="line">	err = prot.IOLoop(clientConn)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在<code>LookupProtocolV1.IOLoop</code>方法中，它开启了一个循环，为每一个连接创建对应的<code>client</code>（<code>/nsq/nsqlookupd/client_v1</code>的<code>ClientV1</code>）实例，然后读取请求内容，解析请求参数，并调用<code>Exec</code>方法执行请求，最后将结果返回，而在连接关闭时，它会清除<code>client</code>（其实代指的是<code>nsqd</code>实例）在<code>NSQLookupd</code>注册的信息（包括<code>topic</code>、<code>channel</code>和<code>producer</code>等）。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// LookupProtocolV1： Context/NSQLookupd 的一个 wrapper。是 protocol.Protocol 的一个实现。</span></span><br><span class="line"><span class="comment">// nsqd 使用 tcp 接口来广播</span></span><br><span class="line"><span class="keyword">type</span> LookupProtocolV1 <span class="keyword">struct</span> &#123;</span><br><span class="line">	ctx *Context</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *LookupProtocolV1)</span> <span class="title">IOLoop</span><span class="params">(conn net.Conn)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> err error</span><br><span class="line">	<span class="keyword">var</span> line <span class="keyword">string</span></span><br><span class="line">	<span class="comment">// 1. 先创建客户端实例，并构建对应的 reader</span></span><br><span class="line">	client := NewClientV1(conn)</span><br><span class="line">	reader := bufio.NewReader(client)</span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="comment">// 2. 读取一行内容，并分离出参数信息</span></span><br><span class="line">		line, err = reader.ReadString(<span class="string">'\n'</span>)</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		line = strings.TrimSpace(line)</span><br><span class="line">		params := strings.Split(line, <span class="string">" "</span>)</span><br><span class="line">		<span class="comment">// 3. 调用 Exec 方法获取响应内容</span></span><br><span class="line">		<span class="keyword">var</span> response []<span class="keyword">byte</span></span><br><span class="line">		response, err = p.Exec(client, reader, params)</span><br><span class="line">		<span class="comment">// 4. Exec 方法执行失败，返回对应的异常信息</span></span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">		<span class="comment">// 5. 执行成功，则返回响应内容</span></span><br><span class="line">		<span class="keyword">if</span> response != <span class="literal">nil</span> &#123;</span><br><span class="line">			_, err = protocol.SendResponse(client, response)</span><br><span class="line">			<span class="comment">// ...</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 6. 连接关闭时，清除  client(nsqd) 在 NSQLookupd 注册的信息</span></span><br><span class="line">	conn.Close()</span><br><span class="line">	p.ctx.nsqlookupd.logf(LOG_INFO, <span class="string">"CLIENT(%s): closing"</span>, client)</span><br><span class="line">	<span class="keyword">if</span> client.peerInfo != <span class="literal">nil</span> &#123;</span><br><span class="line">		registrations := p.ctx.nsqlookupd.DB.LookupRegistrations(client.peerInfo.id)</span><br><span class="line">		<span class="keyword">for</span> _, r := <span class="keyword">range</span> registrations &#123;</span><br><span class="line">			<span class="keyword">if</span> removed, _ := p.ctx.nsqlookupd.DB.RemoveProducer(</span><br><span class="line">                r, client.peerInfo.id); removed &#123;</span><br><span class="line">				p.ctx.nsqlookupd.logf(LOG_INFO, </span><br><span class="line">                    <span class="string">"DB: client(%s) UNREGISTER category:%s key:%s subkey:%s"</span>,</span><br><span class="line">					client, r.Category, r.Key, r.SubKey)</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>先了解<code>Exec</code>如何处理请求的。其实比较简单，对于通过<code>tcp</code>连接所发送请求，只支持<code>PING</code>、<code>IDENTIFY</code>、<code>REGISTER</code>和<code>UNREGISTER</code>这四种类型。针对每一种类型的请求，分别调用它们所关联的请求处理函数。如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *LookupProtocolV1)</span> <span class="title">Exec</span><span class="params">(client *ClientV1, reader *bufio.Reader, </span></span></span><br><span class="line"><span class="function"><span class="params">                                params []<span class="keyword">string</span>)</span> <span class="params">([]<span class="keyword">byte</span>, error)</span></span> &#123;</span><br><span class="line">	<span class="keyword">switch</span> params[<span class="number">0</span>] &#123;</span><br><span class="line">	<span class="keyword">case</span> <span class="string">"PING"</span>:</span><br><span class="line">		<span class="keyword">return</span> p.PING(client, params)</span><br><span class="line">	<span class="keyword">case</span> <span class="string">"IDENTIFY"</span>:</span><br><span class="line">		<span class="keyword">return</span> p.IDENTIFY(client, reader, params[<span class="number">1</span>:])</span><br><span class="line">	<span class="keyword">case</span> <span class="string">"REGISTER"</span>:</span><br><span class="line">		<span class="keyword">return</span> p.REGISTER(client, reader, params[<span class="number">1</span>:])</span><br><span class="line">	<span class="keyword">case</span> <span class="string">"UNREGISTER"</span>:</span><br><span class="line">		<span class="keyword">return</span> p.UNREGISTER(client, reader, params[<span class="number">1</span>:])</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(<span class="literal">nil</span>, <span class="string">"E_INVALID"</span>, </span><br><span class="line">                fmt.Sprintf(<span class="string">"invalid command %s"</span>, params[<span class="number">0</span>]))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在介绍具体的请求处理逻辑前，先介绍一下在构建<code>NSQLookupd</code>实例时，构建的<code>RegistrationDB</code>实例，因为它代表了客户端往<code>nsqlookupd</code>所注册信息的存储或容器。其实质上是一个<code>map</code>结构，其中<code>key</code>为<code>Registration</code>，值为<code>ProduceMap(map[string]*Producer)</code>。且<code>Registration</code>主要包含了<code>topic</code>和<code>channel</code>的信息，而<code>ProduceMap</code>则包含了生产者(<code>nsqd</code>)的信息。因此，围绕<code>RegistrationDB</code>的操作也比较简单，即对相关的数据的<code>CRUD</code>操作。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// NSQLookupd 的注册信息DB，即为 nqsd 的注册信息</span></span><br><span class="line"><span class="keyword">type</span> RegistrationDB <span class="keyword">struct</span> &#123;</span><br><span class="line">	sync.RWMutex			<span class="comment">// guards registrationMap</span></span><br><span class="line">	registrationMap <span class="keyword">map</span>[Registration]ProducerMap</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">type</span> Registration <span class="keyword">struct</span> &#123;</span><br><span class="line">	Category <span class="keyword">string</span> 		<span class="comment">// client|channel|topic</span></span><br><span class="line">	Key      <span class="keyword">string</span>			<span class="comment">// topic</span></span><br><span class="line">	SubKey   <span class="keyword">string</span>			<span class="comment">// channel</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">type</span> Registrations []Registration</span><br><span class="line"><span class="comment">// PeerInfo 封装了 client/sqsd 中与网络通信相关的字段，即client 在 NSQLookupd 端的逻辑视图</span></span><br><span class="line"><span class="keyword">type</span> PeerInfo <span class="keyword">struct</span> &#123;</span><br><span class="line">	lastUpdate       <span class="keyword">int64</span>		<span class="comment">// nsqd 上一次向 NSQLookupd 发送心跳的 timestamp</span></span><br><span class="line">	id               <span class="keyword">string</span>			<span class="comment">// nsqd 实例的 id</span></span><br><span class="line">	RemoteAddress    <span class="keyword">string</span> <span class="string">`json:"remote_address"`</span>		<span class="comment">// ip 地址</span></span><br><span class="line">	Hostname         <span class="keyword">string</span> <span class="string">`json:"hostname"`</span>			<span class="comment">// 主机名</span></span><br><span class="line">	BroadcastAddress <span class="keyword">string</span> <span class="string">`json:"broadcast_address"`</span>	<span class="comment">// 广播地址</span></span><br><span class="line">	TCPPort          <span class="keyword">int</span>    <span class="string">`json:"tcp_port"`</span>			<span class="comment">// TCP 端口</span></span><br><span class="line">	HTTPPort         <span class="keyword">int</span>    <span class="string">`json:"http_port"`</span>			<span class="comment">// http 端口</span></span><br><span class="line">	Version          <span class="keyword">string</span> <span class="string">`json:"version"`</span>			<span class="comment">// nsqd 版本号</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">type</span> Producer <span class="keyword">struct</span> &#123;</span><br><span class="line">	peerInfo     *PeerInfo		<span class="comment">// client/nsqd 的 PeerInfo</span></span><br><span class="line">	tombstoned   <span class="keyword">bool</span>			<span class="comment">// 标记 nsqd 是否被逻辑删除</span></span><br><span class="line">	tombstonedAt time.Time		<span class="comment">// 若被逻辑删除，则记录时间戳</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">type</span> Producers []*Producer</span><br><span class="line"><span class="keyword">type</span> ProducerMap <span class="keyword">map</span>[<span class="keyword">string</span>]*Producer</span><br><span class="line"><span class="comment">// /nsq/nsqlookupd/registration_db.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 当 nsqd 创建topic或channel时，需要将其注册到 NSQLookupd 的 DB 中</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *RegistrationDB)</span> <span class="title">AddRegistration</span><span class="params">(k Registration)</span> </span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">// 添加一个 <span class="title">Producer</span> 到 <span class="title">registration</span> 集合中，返回此 <span class="title">Producer</span> 之前是否已注册</span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="params">(r *RegistrationDB)</span> <span class="title">AddProducer</span><span class="params">(k Registration, p *Producer)</span> <span class="title">bool</span> </span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">// 从 <span class="title">Registration</span> 对应的 <span class="title">ProducerMap</span> 移除指定的 <span class="title">client</span>/<span class="title">peer</span></span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="params">(r *RegistrationDB)</span> <span class="title">RemoveProducer</span><span class="params">(k Registration, id <span class="keyword">string</span>)</span> <span class="params">(<span class="keyword">bool</span>, <span class="keyword">int</span>)</span> </span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">// 删除 <span class="title">DB</span> 中指定的 <span class="title">Registration</span> 实例（若此 <span class="title">channel</span> 为 <span class="title">ephemeral</span>，</span></span><br><span class="line"><span class="function">// 则当其对应的 <span class="title">producer</span>/<span class="title">client</span> 集合为空时，会被移除）所对应的 <span class="title">producerMap</span></span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="params">(r *RegistrationDB)</span> <span class="title">RemoveRegistration</span><span class="params">(k Registration)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">// 根据 <span class="title">category</span>、<span class="title">key</span>和 <span class="title">subkey</span> 来查找 <span class="title">Registration</span> 集合。注意 <span class="title">key</span> 或 <span class="title">subkey</span> 中可能包含 通配符*</span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="params">(r *RegistrationDB)</span> <span class="title">FindRegistrations</span><span class="params">(category <span class="keyword">string</span>, key <span class="keyword">string</span>, subkey <span class="keyword">string</span>)</span> <span class="title">Registrations</span> </span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">// 根据 <span class="title">category</span>、<span class="title">key</span>和 <span class="title">subkey</span> 来查找 <span class="title">Producer</span> 集合。注意 <span class="title">key</span> 或 <span class="title">subkey</span> 中可能包含 通配符*</span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="params">(r *RegistrationDB)</span> <span class="title">FindProducers</span><span class="params">(category <span class="keyword">string</span>, key <span class="keyword">string</span>, subkey <span class="keyword">string</span>)</span> <span class="title">Producers</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">// 根据 <span class="title">peer</span> <span class="title">id</span> 来查找 <span class="title">Registration</span> 集合。</span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="params">(r *RegistrationDB)</span> <span class="title">LookupRegistrations</span><span class="params">(id <span class="keyword">string</span>)</span> <span class="title">Registrations</span> </span></span><br><span class="line"><span class="function">// /<span class="title">nsq</span>/<span class="title">nsqlookupd</span>/<span class="title">registration_db</span>.<span class="title">go</span></span></span><br></pre></td></tr></table></figure>

<p>接下来具体介绍各具体的命令请求是如下处理的，其中<code>PING</code>命令用于维持<code>nsqd</code>与<code>nsqlookupd</code>实例之间的连接通信，其处理也比较简单，更新一下此客户端的活跃时间<code>lastUpdate</code>，并回复<code>OK</code>。当我们使用<code>nsqd --lookupd-tcp-address=127.0.0.1:4160</code>启动一个<code>nsqd</code>实例时，它会在它的<code>Main</code>方法中使用一个额外的<code>goroutine</code>来开启<code>lookupd</code>扫描。当第一次执行时，它会向它知道的<code>nsqlookupd</code>地址（通过配置文件或命令行指定）建立连接。当<code>nsqd</code>与<code>nsqlookupd</code>连接建立成功后，会向<code>nsqlookupd</code>发送一个<code>MagicV1</code>的命令请求以校验目前自己所使用的协议版本，然后，会向<code>nsqlookupd</code>发送一个<code>IDENTIFY</code>命令请求，以认证自己身份，在此处理方法中会将客户端构造成<code>Producer</code>添加到<code>RegistrationDB</code>，并且返回自己的一些信息，当<code>nsqd</code>收到这些信息后，会遍历自己所有的<code>topic</code>，针对每一个<code>topic</code>，若其没有关联的<code>channel</code>，则发送只包含<code>topic</code>的<code>REGISTER</code>命令请求，否则还会遍历<code>topic</code>所关联的<code>channel</code>集合，针对每一个<code>channel</code>，发送一个包含<code>topic</code>和<code>channel</code>的<code>REGISTER</code>命令。所谓的<code>REGISTER</code>命令请求表示<code>nsqd</code>向 <code>nsqlookupd</code> 发送注册 <code>topic</code>的请求，当<code>nsqlookupd</code>收到<code>REGISTER</code>命令请求时，且若消息中带有<code>channel</code>时，会为此客户端会注册两个<code>producer</code>，即分别针对<code>channel</code>和<code>topic</code>构建。注意，在这里个人对<code>nsqd</code>启动后与<code>nsqdlookupd</code>建立连接以及<code>REGISTER</code>的过程阐述得比较详细，希望读者能够对一个二者的交互有一个全局的把握，但这里面涉及到<code>nsqd</code>启动的过程，会在后续的文章中详细阐述。而各命令请求处理逻辑则比较简单：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// PING 消息： client 在发送其它命令之前，可能会先发送一个 PING 消息。</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *LookupProtocolV1)</span> <span class="title">PING</span><span class="params">(client *ClientV1, params []<span class="keyword">string</span>)</span> <span class="params">([]<span class="keyword">byte</span>, error)</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> client.peerInfo != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="comment">// we could get a PING before other commands on the same client connection</span></span><br><span class="line">		cur := time.Unix(<span class="number">0</span>, atomic.LoadInt64(&amp;client.peerInfo.lastUpdate))</span><br><span class="line">		now := time.Now()</span><br><span class="line">		<span class="comment">// 打印 PING 日志</span></span><br><span class="line">		p.ctx.nsqlookupd.logf(LOG_INFO, <span class="string">"CLIENT(%s): pinged (last ping %s)"</span>, client.peerInfo.id,</span><br><span class="line">			now.Sub(cur))</span><br><span class="line">		<span class="comment">// 更新上一次PING的时间</span></span><br><span class="line">		atomic.StoreInt64(&amp;client.peerInfo.lastUpdate, now.UnixNano())</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 回复 OK</span></span><br><span class="line">	<span class="keyword">return</span> []<span class="keyword">byte</span>(<span class="string">"OK"</span>), <span class="literal">nil</span></span><br><span class="line">&#125;  <span class="comment">// /nsq/nsqlookup/lookup_protocol_v1.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// client 向 NSQLookupd 发送认证身份的消息。 注意在此过程中会将客户端构造成Producer添加到 Registration DB中。</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *LookupProtocolV1)</span> <span class="title">IDENTIFY</span><span class="params">(client *ClientV1, reader *bufio.Reader, </span></span></span><br><span class="line"><span class="function"><span class="params">                                    params []<span class="keyword">string</span>)</span> <span class="params">([]<span class="keyword">byte</span>, error)</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> err error</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 1. client 不能重复发送 IDENTIFY 消息</span></span><br><span class="line">	<span class="keyword">if</span> client.peerInfo != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(err, <span class="string">"E_INVALID"</span>, <span class="string">"cannot IDENTIFY again"</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 读取消息体的长度</span></span><br><span class="line">	<span class="keyword">var</span> bodyLen <span class="keyword">int32</span></span><br><span class="line">	err = binary.Read(reader, binary.BigEndian, &amp;bodyLen)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// 3. 读取消息体内容，包含生产者的信息</span></span><br><span class="line">	body := <span class="built_in">make</span>([]<span class="keyword">byte</span>, bodyLen)</span><br><span class="line">	_, err = io.ReadFull(reader, body)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// 4. 根据消息体构建 PeerInfo 实例</span></span><br><span class="line">	peerInfo := PeerInfo&#123;id: client.RemoteAddr().String()&#125;</span><br><span class="line">	err = json.Unmarshal(body, &amp;peerInfo)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	peerInfo.RemoteAddress = client.RemoteAddr().String()</span><br><span class="line">	<span class="comment">// 5. 检验属性不能为空，同时更新上一次PING的时间</span></span><br><span class="line">	<span class="keyword">if</span> peerInfo.BroadcastAddress == <span class="string">""</span> || peerInfo.TCPPort == <span class="number">0</span> </span><br><span class="line">    || peerInfo.HTTPPort == <span class="number">0</span> || peerInfo.Version == <span class="string">""</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(<span class="literal">nil</span>, <span class="string">"E_BAD_BODY"</span>, <span class="string">"IDENTIFY missing fields"</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	atomic.StoreInt64(&amp;peerInfo.lastUpdate, time.Now().UnixNano())</span><br><span class="line">	<span class="comment">// 6. 将此 client 构建成一个 Producer 注册到 DB中</span></span><br><span class="line">	client.peerInfo = &amp;peerInfo</span><br><span class="line">	<span class="keyword">if</span> p.ctx.nsqlookupd.DB.AddProducer(Registration&#123;<span class="string">"client"</span>, <span class="string">""</span>, <span class="string">""</span>&#125;,</span><br><span class="line">                                       &amp;Producer&#123;peerInfo: client.peerInfo&#125;) &#123;</span><br><span class="line">		p.ctx.nsqlookupd.logf(LOG_INFO, <span class="string">"DB: client(%s) REGISTER category:%s key:%s subkey:%s"</span>, client, <span class="string">"client"</span>, <span class="string">""</span>, <span class="string">""</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 7. 构建响应消息，包含 NSQLookupd 的 hostname、port及 version</span></span><br><span class="line">	data := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125;)</span><br><span class="line">	data[<span class="string">"tcp_port"</span>] = p.ctx.nsqlookupd.RealTCPAddr().Port</span><br><span class="line">	data[<span class="string">"http_port"</span>] = p.ctx.nsqlookupd.RealHTTPAddr().Port</span><br><span class="line">	data[<span class="string">"version"</span>] = version.Binary</span><br><span class="line">	hostname, err := os.Hostname()</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		log.Fatalf(<span class="string">"ERROR: unable to get hostname %s"</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">	data[<span class="string">"broadcast_address"</span>] = p.ctx.nsqlookupd.opts.BroadcastAddress</span><br><span class="line">	data[<span class="string">"hostname"</span>] = hostname</span><br><span class="line">	response, err := json.Marshal(data)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">return</span> response, <span class="literal">nil</span></span><br><span class="line">&#125;  <span class="comment">// /nsq/nsqlookup/lookup_protocol_v1.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//  Client 向 NSQLookupd 发送取消注册/订阅 topic 的消息。即为 REGISTER 的逆过程</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *LookupProtocolV1)</span> <span class="title">UNREGISTER</span><span class="params">(client *ClientV1, reader *bufio.Reader, </span></span></span><br><span class="line"><span class="function"><span class="params">                                      params []<span class="keyword">string</span>)</span> <span class="params">([]<span class="keyword">byte</span>, error)</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 必须先要发送 IDENTIFY 消息进行身份认证</span></span><br><span class="line">	<span class="keyword">if</span> client.peerInfo == <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(<span class="literal">nil</span>, <span class="string">"E_INVALID"</span>, <span class="string">"client must IDENTIFY"</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 获取 client 注册的 topic 和 channel(若有的话)</span></span><br><span class="line">	topic, channel, err := getTopicChan(<span class="string">"UNREGISTER"</span>, params)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// 3. 若 channel 不为空，则在 DB 中移除一个 Producer 实例，</span></span><br><span class="line">    <span class="comment">// 其键(Category)为 channel 类型的 Registration。</span></span><br><span class="line">	<span class="keyword">if</span> channel != <span class="string">""</span> &#123;</span><br><span class="line">		key := Registration&#123;<span class="string">"channel"</span>, topic, channel&#125;</span><br><span class="line">		removed, left := p.ctx.nsqlookupd.DB.RemoveProducer(key, client.peerInfo.id)</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		<span class="comment">// 对于 ephemeral 类型的 channel，</span></span><br><span class="line">        <span class="comment">// 若它未被任何 Producer 订阅，则需要移除此 channel 代表的 Registration 对象</span></span><br><span class="line">		<span class="comment">// for ephemeral channels, remove the channel as well if it has no producers</span></span><br><span class="line">		<span class="keyword">if</span> left == <span class="number">0</span> &amp;&amp; strings.HasSuffix(channel, <span class="string">"#ephemeral"</span>) &#123;</span><br><span class="line">			p.ctx.nsqlookupd.DB.RemoveRegistration(key)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="comment">// 4. 取消注册 topic。因此它会删除掉 类型(Category)为 channel </span></span><br><span class="line">        <span class="comment">// 且 Key 为 topic 且 subKey不限的　Registration 集合；</span></span><br><span class="line">		<span class="comment">// 也会删除 Category 为 topic 且 Key 为 topic且 subKey为""的　Registration集合</span></span><br><span class="line">		registrations := p.ctx.nsqlookupd.DB.FindRegistrations(<span class="string">"channel"</span>, topic, <span class="string">"*"</span>)</span><br><span class="line">		<span class="keyword">for</span> _, r := <span class="keyword">range</span> registrations &#123;</span><br><span class="line">			removed, _ := p.ctx.nsqlookupd.DB.RemoveProducer(r, client.peerInfo.id)</span><br><span class="line">			<span class="comment">// ...</span></span><br><span class="line">		key := Registration&#123;<span class="string">"topic"</span>, topic, <span class="string">""</span>&#125;</span><br><span class="line">		removed, left := p.ctx.nsqlookupd.DB.RemoveProducer(key, client.peerInfo.id)</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		<span class="comment">// 同样，对于 ephemeral 类型的 topic，若它没有被任何 Producer 订阅，</span></span><br><span class="line">            <span class="comment">// 则需要移除此 channel 代表的 Registration 对象。</span></span><br><span class="line">		<span class="keyword">if</span> left == <span class="number">0</span> &amp;&amp; strings.HasSuffix(topic, <span class="string">"#ephemeral"</span>) &#123;</span><br><span class="line">			p.ctx.nsqlookupd.DB.RemoveRegistration(key)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> []<span class="keyword">byte</span>(<span class="string">"OK"</span>), <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /nsq/nsqlookup/lookup_protocol_v1.go</span></span><br></pre></td></tr></table></figure>

<h4 id="tcp-请求-REGISTER-处理过程"><a href="#tcp-请求-REGISTER-处理过程" class="headerlink" title="tcp 请求 REGISTER 处理过程"></a>tcp 请求 REGISTER 处理过程</h4><p>这里简要阐述<code>REGISTER</code>请求处理的过程：当<code>nsqlookupd</code>收到<code>REGISTER</code>命令请求后，它首先确认对方是否已经发送过<code>IDENTIFY</code>命令请求，确认完成后，解析请求中的<code>topic</code>名称和<code>channel</code>名称，然后，进一步检查<code>topic</code>和<code>channel</code>命名的合法性，最后若<code>channel</code>不为空，则向<code>RegistrationDB</code>中添加一个<code>Producer</code> 实例，其<code>Category</code>为<code>channel</code>类型的<code>Registration</code>。同样，若<code>topic</code>不为空，则还需要向<code>RegistrationDB</code>中添加一个<code>Producer</code>实例，其<code>Category</code>为<code>topic</code> 类型的 <code>Registration</code>。最后返回<code>OK</code>。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">//  Client 向 NSQLookupd 发送注册 topic 的消息。注意，当消息中带有 channel 时，</span></span><br><span class="line"><span class="comment">// 对于此 client会注册两个 producer，分别针对 channel 和 topic</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *LookupProtocolV1)</span> <span class="title">REGISTER</span><span class="params">(client *ClientV1, reader *bufio.Reader, </span></span></span><br><span class="line"><span class="function"><span class="params">                                    params []<span class="keyword">string</span>)</span> <span class="params">([]<span class="keyword">byte</span>, error)</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 必须先要发送 IDENTIFY 消息进行身份认证。</span></span><br><span class="line">	<span class="keyword">if</span> client.peerInfo == <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, protocol.NewFatalClientErr(<span class="literal">nil</span>, <span class="string">"E_INVALID"</span>, <span class="string">"client must IDENTIFY"</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 获取 client 注册的 topic 和 channel(若有的话)</span></span><br><span class="line">	topic, channel, err := getTopicChan(<span class="string">"REGISTER"</span>, params)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// 3. 若 channel 不为空，则向 DB 中添加一个 Producer 实例，其键(Category)为 channel 类型的 Registration</span></span><br><span class="line">	<span class="keyword">if</span> channel != <span class="string">""</span> &#123;</span><br><span class="line">		key := Registration&#123;<span class="string">"channel"</span>, topic, channel&#125;</span><br><span class="line">		<span class="keyword">if</span> p.ctx.nsqlookupd.DB.AddProducer(key, &amp;Producer&#123;peerInfo: client.peerInfo&#125;) &#123;</span><br><span class="line">			p.ctx.nsqlookupd.logf(</span><br><span class="line">                LOG_INFO, <span class="string">"DB: client(%s) REGISTER category:%s key:%s subkey:%s"</span>,</span><br><span class="line">				client, <span class="string">"channel"</span>, topic, channel)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 4. 若 topic 不为空，则还需要向 DB 中添加一个 Producer 实例，其键(Category)为 topic 类型的 Registration</span></span><br><span class="line">	key := Registration&#123;<span class="string">"topic"</span>, topic, <span class="string">""</span>&#125;</span><br><span class="line">	<span class="keyword">if</span> p.ctx.nsqlookupd.DB.AddProducer(key, &amp;Producer&#123;peerInfo: client.peerInfo&#125;) &#123;</span><br><span class="line">		p.ctx.nsqlookupd.logf(</span><br><span class="line">            LOG_INFO, <span class="string">"DB: client(%s) REGISTER category:%s key:%s subkey:%s"</span>,</span><br><span class="line">			client, <span class="string">"topic"</span>, topic, <span class="string">""</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 5. 返回 OK</span></span><br><span class="line">	<span class="keyword">return</span> []<span class="keyword">byte</span>(<span class="string">"OK"</span>), <span class="literal">nil</span></span><br><span class="line">&#125;  <span class="comment">// /nsq/nsqlookup/lookup_protocol_v1.go</span></span><br></pre></td></tr></table></figure>

<p>需要注意的是，这几个接口都是<code>tcp</code>连接请求的对应的处理函数，并非是<code>http</code>请求（可以通过命令行的方式发起）所对应的处理函数。<code>nsq</code>官方提供了一个<code>go-nsq</code>的客户端库。我们可以通过这个库来显式调试这些命令请求处理函数，当然源码包下也有对应的测试文件<code>/nsq/nsqlookupd/nsqlookupd_test.go</code>。到此为止通过<code>tcp</code>协议发起的请求的处理逻辑已经阐述完毕。下面介绍<code>http</code>协议的请求处理逻辑。</p>
<h3 id="客户端-http-请求处理"><a href="#客户端-http-请求处理" class="headerlink" title="客户端 http 请求处理"></a>客户端 http 请求处理</h3><p>前面提到，在<code>NSQLookupd.Main</code>方法中，同样创建了一个<code>http</code>请求处理器<code>httpServer</code>，并设置了请求的监听器<code>http_api.Serve</code>。它们的功能及用法可以<a href="https://nsq.io/components/nsqlookupd.html" target="_blank" rel="noopener">参考这里</a>。我们先来简单了解<code>http</code>请求的监听器是怎样工作的。很简单，它同样使用的是标准库中的<code>http</code>相关的接口，即调用<code>server.Serve</code>函数监听连接请求，但其采用的是自定义的<code>handler</code>，即前方所提到的<code>httprouter</code>来作为请求路由处理器。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// http 连接处理器，类似于 tcp_server 只是一个统一的入口，具体监听动作是在标准包 http.Server.Serve 方法中完成</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Serve</span><span class="params">(listener net.Listener, handler http.Handler, proto <span class="keyword">string</span>, logf lg.AppLogFunc)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	logf(lg.INFO, <span class="string">"%s: listening on %s"</span>, proto, listener.Addr())</span><br><span class="line">	server := &amp;http.Server&#123;</span><br><span class="line">		Handler:  handler,</span><br><span class="line">		ErrorLog: log.New(logWriter&#123;logf&#125;, <span class="string">""</span>, <span class="number">0</span>),</span><br><span class="line">	&#125;</span><br><span class="line">	err := server.Serve(listener)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	logf(lg.INFO, <span class="string">"%s: closing %s"</span>, proto, listener.Addr())</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>而<code>http</code>请求处理的重点在于<code>http</code>请求的路由器，即<code>/nsq/nsqlookupd/http.go</code>中所定义的<code>httpServer</code>，其仅仅是<a href="https://github.com/julienschmidt/httprouter" target="_blank" rel="noopener"><code>httprouter</code></a>的一个<code>wrapper</code>。关于<code>httprouter</code>具体工作原理，读者可以阅读源码（比较短）或参考其它文章。这里简要介绍一下<code>httpServer</code>实例化的过程，首先会创建<code>httprouter</code>实例，然后设置参数信息，比如对于<code>403</code>、<code>404</code>和<code>500</code>等错误的<code>handler</code>。接下来，构建<code>httpServer</code>实例，然后通过<code>httprouter</code>实例来添加特定的路由规则。各具体的请求处理器也比较简单，纯粹就调用<code>RegistrationDB</code>相关接口，不多阐述，读者可深入源码查看。最后，值得学习的是，程度采用装饰者模式构建强大且灵活的请求处理器。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// http 连接的 handler。</span></span><br><span class="line"><span class="comment">// 客户端（消费者）使用这些 http　接口来发现和管理。</span></span><br><span class="line"><span class="comment">// 实现了 http.Handler 接口，实现了 ServeHTTP(ResponseWriter, *Request) 处理函数</span></span><br><span class="line"><span class="keyword">type</span> httpServer <span class="keyword">struct</span> &#123;</span><br><span class="line">	ctx    *Context</span><br><span class="line">	router http.Handler</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// http 请求处理器构造函数</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newHTTPServer</span><span class="params">(ctx *Context)</span> *<span class="title">httpServer</span></span> &#123;</span><br><span class="line">	log := http_api.Log(ctx.nsqlookupd.logf)</span><br><span class="line">	<span class="comment">// 1. 创建 httprouter 实例。httprouter是一个高效的请求路由器，使用了一个后缀树来存储路由信息。</span></span><br><span class="line">	<span class="comment">// 更多 https://github.com/julienschmidt/httprouter 或参考博客 https://learnku.com/articles/27591</span></span><br><span class="line">	router := httprouter.New()</span><br><span class="line">	<span class="comment">// 2. 配置参数信息</span></span><br><span class="line">	router.HandleMethodNotAllowed = <span class="literal">true</span></span><br><span class="line">	router.PanicHandler = http_api.LogPanicHandler(ctx.nsqlookupd.logf)</span><br><span class="line">	router.NotFound = http_api.LogNotFoundHandler(ctx.nsqlookupd.logf)</span><br><span class="line">	router.MethodNotAllowed = http_api.LogMethodNotAllowedHandler(ctx.nsqlookupd.logf)</span><br><span class="line">	<span class="comment">// 3. 对此 httprouter 进行包装，构建 httpServer 实例</span></span><br><span class="line">	s := &amp;httpServer&#123;</span><br><span class="line">		ctx:    ctx,</span><br><span class="line">		router: router,</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 4. 为 httprouter 实例添加特定路由规则</span></span><br><span class="line">	<span class="comment">// 对于 PING 请求而言，其 handler 为调用 Decorate 后的返回值，</span></span><br><span class="line">	<span class="comment">// 以 pingHandler 作为被装饰函数，可变的装饰参数列表为 log, http_api.PlainText（用于返回纯文本内容）</span></span><br><span class="line">	<span class="comment">// 后面的程序结构类似</span></span><br><span class="line">	router.Handle(<span class="string">"GET"</span>, <span class="string">"/ping"</span>, http_api.Decorate(s.pingHandler, log, http_api.PlainText))</span><br><span class="line">	router.Handle(<span class="string">"GET"</span>, <span class="string">"/info"</span>, http_api.Decorate(s.doInfo, log, http_api.V1))</span><br><span class="line"></span><br><span class="line">	<span class="comment">// v1 negotiate</span></span><br><span class="line">	router.Handle(<span class="string">"GET"</span>, <span class="string">"/debug"</span>, http_api.Decorate(s.doDebug, log, http_api.V1))</span><br><span class="line">	router.Handle(<span class="string">"GET"</span>, <span class="string">"/lookup"</span>, http_api.Decorate(s.doLookup, log, http_api.V1))</span><br><span class="line">	router.Handle(<span class="string">"GET"</span>, <span class="string">"/topics"</span>, http_api.Decorate(s.doTopics, log, http_api.V1))</span><br><span class="line">	router.Handle(<span class="string">"GET"</span>, <span class="string">"/channels"</span>, http_api.Decorate(s.doChannels, log, http_api.V1))</span><br><span class="line">	router.Handle(<span class="string">"GET"</span>, <span class="string">"/nodes"</span>, http_api.Decorate(s.doNodes, log, http_api.V1))</span><br><span class="line"></span><br><span class="line">	<span class="comment">// only v1</span></span><br><span class="line">	router.Handle(<span class="string">"POST"</span>, <span class="string">"/topic/create"</span>, http_api.Decorate(s.doCreateTopic, log, http_api.V1))</span><br><span class="line">	router.Handle(<span class="string">"POST"</span>, <span class="string">"/topic/delete"</span>, http_api.Decorate(s.doDeleteTopic, log, http_api.V1))</span><br><span class="line">	router.Handle(<span class="string">"POST"</span>, <span class="string">"/channel/create"</span>, http_api.Decorate(s.doCreateChannel, log, http_api.V1))</span><br><span class="line">	router.Handle(<span class="string">"POST"</span>, <span class="string">"/channel/delete"</span>, http_api.Decorate(s.doDeleteChannel, log, http_api.V1))</span><br><span class="line">	router.Handle(<span class="string">"POST"</span>, <span class="string">"/topic/tombstone"</span>, http_api.Decorate(s.doTombstoneTopicProducer, log, http_api.V1))</span><br><span class="line"></span><br><span class="line">	<span class="comment">// debug</span></span><br><span class="line">	router.HandlerFunc(<span class="string">"GET"</span>, <span class="string">"/debug/pprof"</span>, pprof.Index)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">return</span> s</span><br><span class="line">&#125; <span class="comment">// /nsq/nsqlookupd/http.go</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *httpServer)</span> <span class="title">ServeHTTP</span><span class="params">(w http.ResponseWriter, req *http.Request)</span></span> &#123;</span><br><span class="line">	s.router.ServeHTTP(w, req)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// PING 请求处理器</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *httpServer)</span> <span class="title">pingHandler</span><span class="params">(w http.ResponseWriter, req *http.Request, </span></span></span><br><span class="line"><span class="function"><span class="params">                                 ps httprouter.Params)</span> <span class="params">(<span class="keyword">interface</span>&#123;&#125;, error)</span> </span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">// <span class="title">INFO</span>（版本信息）查询请求处理器</span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="params">(s *httpServer)</span> <span class="title">doInfo</span><span class="params">(w http.ResponseWriter, req *http.Request, </span></span></span><br><span class="line"><span class="function"><span class="params">                            ps httprouter.Params)</span> <span class="params">(<span class="keyword">interface</span>&#123;&#125;, error)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">// 查询所有 <span class="title">Category</span> 为 <span class="title">topic</span>的 <span class="title">Registration</span> 的集合所包含的 <span class="title">Key</span> 集合（<span class="title">topic</span>名称集合）</span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="params">(s *httpServer)</span> <span class="title">doTopics</span><span class="params">(w http.ResponseWriter, req *http.Request, </span></span></span><br><span class="line"><span class="function"><span class="params">                              ps httprouter.Params)</span> <span class="params">(<span class="keyword">interface</span>&#123;&#125;, error)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">// 查询所有 <span class="title">Category</span> 为 <span class="title">channel</span>，</span></span><br><span class="line"><span class="function">// 且 <span class="title">topic</span> 为请求参数中指定的 <span class="title">topic</span> 的 <span class="title">Registration</span> 的集合包含的 <span class="title">SubKey</span> 集合（<span class="title">channel</span>名称集合）</span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="params">(s *httpServer)</span> <span class="title">doChannels</span><span class="params">(w http.ResponseWriter, req *http.Request, </span></span></span><br><span class="line"><span class="function"><span class="params">                                ps httprouter.Params)</span> <span class="params">(<span class="keyword">interface</span>&#123;&#125;, error)</span> </span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">// 查询所有 <span class="title">Category</span> 为 <span class="title">topic</span>的 <span class="title">channels</span> 的集合以及<span class="title">producers</span>集合。</span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="params">(s *httpServer)</span> <span class="title">doLookup</span><span class="params">(w http.ResponseWriter, req *http.Request, </span></span></span><br><span class="line"><span class="function"><span class="params">                              ps httprouter.Params)</span> <span class="params">(<span class="keyword">interface</span>&#123;&#125;, error)</span> </span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">// 根据 <span class="title">topic</span> 来添加注册信息 <span class="title">Registration</span></span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="params">(s *httpServer)</span> <span class="title">doCreateTopic</span><span class="params">(w http.ResponseWriter, req *http.Request, </span></span></span><br><span class="line"><span class="function"><span class="params">                                   ps httprouter.Params)</span> <span class="params">(<span class="keyword">interface</span>&#123;&#125;, error)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">// 根据 <span class="title">topic</span> 来删移除注册信息 <span class="title">Registration</span></span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="params">(s *httpServer)</span> <span class="title">doDeleteTopic</span><span class="params">(w http.ResponseWriter, req *http.Request, </span></span></span><br><span class="line"><span class="function"><span class="params">                                   ps httprouter.Params)</span> <span class="params">(<span class="keyword">interface</span>&#123;&#125;, error)</span> </span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">// 为指定 <span class="title">topic</span> 关联的 <span class="title">producer</span> 设置为 <span class="title">tombstone</span> 状态。</span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="params">(s *httpServer)</span> <span class="title">doTombstoneTopicProducer</span><span class="params">(w http.ResponseWriter, req *http.Request, </span></span></span><br><span class="line"><span class="function"><span class="params">                    ps httprouter.Params)</span> <span class="params">(<span class="keyword">interface</span>&#123;&#125;, error)</span> </span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">// 根据 <span class="title">topic</span> 和 <span class="title">channel</span> 的名称添加注册信息</span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="params">(s *httpServer)</span> <span class="title">doCreateChannel</span><span class="params">(w http.ResponseWriter, </span></span></span><br><span class="line"><span class="function"><span class="params">                                     req *http.Request, ps httprouter.Params)</span> <span class="params">(<span class="keyword">interface</span>&#123;&#125;, error)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">// 根据 <span class="title">topic</span> 和 <span class="title">channel</span> 的名称移除注册信息</span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="params">(s *httpServer)</span> <span class="title">doDeleteChannel</span><span class="params">(w http.ResponseWriter, req *http.Request, </span></span></span><br><span class="line"><span class="function"><span class="params">                                     ps httprouter.Params)</span> <span class="params">(<span class="keyword">interface</span>&#123;&#125;, error)</span> </span></span><br><span class="line"><span class="function">// /<span class="title">nsq</span>/<span class="title">nsqlookupd</span>/<span class="title">http</span>.<span class="title">go</span></span></span><br></pre></td></tr></table></figure>

<h4 id="http-请求-topic-创建-查询处理过程"><a href="#http-请求-topic-创建-查询处理过程" class="headerlink" title="http 请求 topic 创建/查询处理过程"></a>http 请求 topic 创建/查询处理过程</h4><p>最后，笔者简要介绍，消费者请求<code>nsqlookupd</code>的完成的请求服务。比如，当消费者需要查询某个<code>topic</code>在哪些<code>nsqd</code>上时，它可以通过<code>/lookup</code>的<code>http GET</code>请求来查询结果，<code>nsqlookupd</code>所提供的查询的指定<code>topic</code>信息的接口为：<code>curl &#39;http://127.0.0.1:4161/lookup?topic=test-topic&#39;</code>，从返回结果为此<code>topic</code>所关联的<code>channels</code>列表和<code>producer</code>列表。其具体处理流程不再阐述，比较简单，其详细代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 查询所有 Category 为 topic的 channels 的集合以及producers集合。</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *httpServer)</span> <span class="title">doLookup</span><span class="params">(w http.ResponseWriter, req *http.Request, </span></span></span><br><span class="line"><span class="function"><span class="params">                              ps httprouter.Params)</span> <span class="params">(<span class="keyword">interface</span>&#123;&#125;, error)</span></span> &#123;</span><br><span class="line">	reqParams, err := http_api.NewReqParams(req) <span class="comment">// 1. 解析请求参数</span></span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	topicName, err := reqParams.Get(<span class="string">"topic"</span>) <span class="comment">// 2. 获取请求查询的 topic</span></span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">    <span class="comment">// 3. 根据 topic 查询 registration</span></span><br><span class="line">	registration := s.ctx.nsqlookupd.DB.FindRegistrations(<span class="string">"topic"</span>, topicName, <span class="string">""</span>)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">    <span class="comment">// 4. 根据 topic 查询 channel 列表</span></span><br><span class="line">	channels := s.ctx.nsqlookupd.DB.FindRegistrations(<span class="string">"channel"</span>, topicName, <span class="string">"*"</span>).SubKeys()</span><br><span class="line">    <span class="comment">// 5. 根据 topic 查询 producer 列表</span></span><br><span class="line">	producers := s.ctx.nsqlookupd.DB.FindProducers(<span class="string">"topic"</span>, topicName, <span class="string">""</span>)</span><br><span class="line">	<span class="comment">// 6. 过滤掉那些 inActive 的 producers，同时也过滤那些 tombstone 状态的 producers</span></span><br><span class="line">	producers = producers.FilterByActive(s.ctx.nsqlookupd.opts.InactiveProducerTimeout,</span><br><span class="line">		s.ctx.nsqlookupd.opts.TombstoneLifetime)</span><br><span class="line">	<span class="keyword">return</span> <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125;&#123; <span class="comment">// 7. 返回 topic 所关联的 channel 和 producer 列表</span></span><br><span class="line">		<span class="string">"channels"</span>:  channels,</span><br><span class="line">		<span class="string">"producers"</span>: producers.PeerInfo(),</span><br><span class="line">	&#125;, <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /nsq/nsqlookupd/http.go</span></span><br></pre></td></tr></table></figure>

<p>同样，也介绍一个<code>nsqd</code>请求<code>nsqlookupd</code>通过<code>http</code>协议完成的请求服务。比如，当<code>nsqd</code>需要请求<code>nsqlookupd</code>注册<code>topic</code>信息时，其可通过<code>/topic/create</code>的<code>http POST</code>请求来创建，而参数为<code>topic</code>名称，对应的请求处理函数为<code>doCreateTopic</code>，且没有返回值，处理函数的具体逻辑即为通过<code>topic</code>创建一个<code>Registration</code>实例，然后添加到<code>RegistrationDB</code>中。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 根据 topic 来添加注册信息 Registration</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *httpServer)</span> <span class="title">doCreateTopic</span><span class="params">(w http.ResponseWriter, req *http.Request, </span></span></span><br><span class="line"><span class="function"><span class="params">                                   ps httprouter.Params)</span> <span class="params">(<span class="keyword">interface</span>&#123;&#125;, error)</span></span> &#123;</span><br><span class="line">	reqParams, err := http_api.NewReqParams(req) <span class="comment">// 1. 解析请求参数</span></span><br><span class="line">	<span class="comment">// ... </span></span><br><span class="line">	topicName, err := reqParams.Get(<span class="string">"topic"</span>) <span class="comment">// 2. 获取请求创建的 topic</span></span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	s.ctx.nsqlookupd.logf(LOG_INFO, <span class="string">"DB: adding topic(%s)"</span>, topicName)</span><br><span class="line">	key := Registration&#123;<span class="string">"topic"</span>, topicName, <span class="string">""</span>&#125; <span class="comment">// 3. 构建一个 Registration</span></span><br><span class="line">	<span class="comment">// 4. 将其添加到 RegistrationDB（value 为空的 map）</span></span><br><span class="line">    s.ctx.nsqlookupd.DB.AddRegistration(key) </span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">nil</span></span><br><span class="line">&#125;<span class="comment">// /nsq/nsqlookupd/http.go</span></span><br></pre></td></tr></table></figure>

<p>至此，关于<code>nsqlookupd</code>相关的逻辑的源码已经分析完毕。相比<code>nsqd</code>要简单，没有复杂的流程。</p>
<p>简单小结，本文以执行<code>nsqlookupd</code>命令为切入点，先是简要分析了<code>nsqlookupd</code>其利用<code>svc</code>启动一个进程的过程。进而分析了<code>NSQLookupd</code>的<code>Main</code>方法的执行流程，其核心逻辑为创建了<code>tcp</code>及<code>http</code>请求的处理器，并注册了监听函数。本文的重点在于分析<code>tcp</code>请求处理器的详细内容，附带阐述了<code>nsqd</code>实例启动后与<code>nsqlookupd</code>实例的一个交互过程，具体包括<code>IDENTIFY</code>、<code>REGISTER</code>及<code>PING</code>等命令请求。然后，对于<code>http</code>请求处理器也进行了简要分析，侧重于处理器的创建过程。最后，对于<code>http</code>请求的方式，以两个示例分别阐述了客户端（消费者）及<code>nsqd</code>请求<code>nsqlookupd</code>完成<code>topic</code>查询和<code>topic</code>注册过程。更详细内容可以参考笔者简要<a href="https://github.com/qqzeng/nsqio/tree/master/nsq" target="_blank" rel="noopener">注释的源码</a>。</p>
<p>参考文献</p>
<p>[1].  <a href="https://github.com/nsqio/nsq" target="_blank" rel="noopener">https://github.com/nsqio/nsq</a><br>[2]. <a href="https://nsq.io/overview/quick_start.html" target="_blank" rel="noopener">https://nsq.io/overview/quick_start.html</a></p>
]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title>nsq 简介和特性理解</title>
    <url>/2019/05/11/nsq-%E7%AE%80%E4%BB%8B%E5%92%8C%E7%89%B9%E6%80%A7%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<p>前段时间写的分布式系统相关<code>lab</code>，都是使用<code>go</code>语言，还挺有趣的这门语言，但至今也没系统了解过它。不得不说，纯粹了解或学习语言特性，长时间下来会有点枯燥。个人更习惯阅读开源项目，以更深入了解其在实际工程项目的最佳实践（但似乎不能对语言特性本质有太多的了解，尴尬）。很自然地选择了一个对于初学者比较经典的<code>starter project</code>，一个<strong>分布式实时消息队列</strong>——<code>nsq</code>。大家比较熟悉的消息中间件可能是像<code>RabbitMQ</code>、<code>ActiveMQ</code>、<code>RocketMQ</code>以及<code>kafaka</code>之类的。我个人对这些消息中间件并没有实践经验，但感觉<code>nsq</code>更轻量级（代码量也少），而且正如官方对其的定义，其最主要优势在于<strong>分布式</strong>和<strong>实时</strong>。具体对比，可以参考<code>golang 2017</code>开发者大会上的一张图。<code>nsq</code>遵循的是一个去中心化的的拓扑结构，其具备<strong>高可用性</strong>（无单点故障<code>SPOF</code>）、<strong>可扩展</strong>（支持水平扩展节点）、<strong>低延迟</strong>（采用<code>push</code>的方式）、<strong>可靠消息传递</strong>（消息可被持久化和失败重入队列）、<strong>组合式负载均衡</strong>（消息推送为随机负载均衡）以及<strong>消费者自动发现和连接生产者</strong>（通过服务发现与注册系统实现）等特性。笔者打算后面通过一系列博文，深入到<code>nsq</code>源码，简析其各模块（组件）的设计实现。</p>
<a id="more"></a>

<p>按照惯例，先声明下阅读本文章的前提。本文不会详细介绍<a href="https://nsq.io/overview/quick_start.html" target="_blank" rel="noopener">nsq</a>基本特性，也不会过多阐述消息队列的基本功能和使用场景，也不会涉及到<code>nsq</code>如何使用及其最佳实践。换言之，阅读本文前最好对这些有初步了解，以在整体上有所把握和体会。关于<code>nsq</code>可参考官方文档的文献[1]、[2]、[3]和[4]，或者其它中文文章[4]。本文先简要介绍<code>nsq</code>各组件及基本工作流程，然后详细阐述<code>nsq</code>几个值得注意的特性。若有理解错误的地方，欢迎指正！</p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/blob/hexo/static/mq-comparison.png?raw=true" alt="mq-comparison"></p>
<h2 id="nsq-基本介绍"><a href="#nsq-基本介绍" class="headerlink" title="nsq 基本介绍"></a>nsq 基本介绍</h2><p>在本文最前面，简要阐述了<code>nsq</code>的几个重要特性（官方文档列举的更全），我们会重点阐述这些特性。关于它们中的一些，我们深入到代码以了解其是如何实现的。而其它的典型的包括：易于部署，因为它没有太多依赖配置（通过命令行就可以配置）；支持安全传输层协议 (<code>TLS</code>)；还提供了多种语言的客户端功能库；最后附带一个简易的集群管理界面<code>nsqadmin</code>。<code>nsq</code>主要包括两个组件<code>nsqd</code>和<code>nsqlookupd</code>，和一个管理界面<code>nsqdadmin</code>：</p>
<ul>
<li><code>nsqd</code>是一个负责接收、排队、转发消息到客户端的守护进程；</li>
<li><code>nsqlookupd</code>是一个管理集群(<code>nsqd</code>)拓扑信息并提供最终一致性的服务注册与发现的守护进程；</li>
<li><code>nsqadmin</code>是一个管理界面，提供实时的集群中<code>topic</code>、<code>channel</code>和<code>message</code>的统计信息，还提供与这些实体相关的各种管理接口。</li>
</ul>
<p>在这里简单阐述整个系统的典型流程。除了上述几个组件外，另外两个核心的概念为主题(<code>topic</code>)和通道<code>channel</code>，当然消息(<code>message</code>)也是重要的。它们的简单阐述如下：</p>
<ul>
<li><code>message</code>即代表的是数据，它被生产者创建并发送到指定的<code>topic</code>，而消费者可以从指定的<code>topic</code>和<code>channel</code>接收并消费消息。且每个被<code>nsqd</code>接收到的消息至少会被发送一次给消费者，因为消息消费超时会触发重入队过程，且消息附带有一个投递次数属性，以使得客户端对投递次数过大的消息灵活处理。</li>
<li><code>topic</code>代表生产者投递消息的一个逻辑键值，它可以将消息进行分类。一个<code>nsqd</code>上可包含多个<code>topic</code>，且它们可以不必在生产者投递消息前就创建，换言之，<code>topic</code>可在其第一次接收到生产者投递的消息时创建。</li>
<li><code>channel</code>代表消费者订阅某个<code>nsqd</code>上的<code>topic</code>的消息。你可以仍旧将它视作一个消息队列，只不过它与消费者相关。每当生产者将消息发布到一个<code>topic</code>上，消息会被<strong>拷贝</strong>（深拷贝，即构建一个消息副本）到与<code>topic</code>关联的所有的<code>channel</code>。而且，多个消费者可以订阅同一个<code>channel</code>，<code>channel</code>会将其接收到的消息<strong>随机</strong>（即随机负载均衡）发送到与其关联的一个客户端。同<code>topic</code>类似，<code>channel</code>也可不用提前创建，消费者在第一次订阅消息（在指定<code>topic</code>的某个<code>channel</code>）的时候会创建此<code>channel</code>（若其不存在）。最后，<code>channel</code>从<code>topic</code>接收的消息首先会在内存中排队，当达到内存队列长度上限，就被写到持久化存储。</li>
</ul>
<p><code>nsqd</code>在启动时通常会建与各<code>nsqlookupd</code>的连接。<code>nsqlookupd</code>为其提供目录服务，即<code>nsqd</code>可将<code>topic</code>、<code>channel</code>及<code>nsqd</code>(生产者)的信息注册到<code>nsqlookupd</code>，并且可通过与<code>nsqlookupd</code>之间的<code>TCP</code>连接动态更新自己的状态信息（<code>topic</code>及<code>channel</code>信息等）。而消费者可通过<code>http</code>请求连接到<code>nsqlookupd</code>，以查找其感兴趣的<code>nsqd</code>的地址。正是通过这种设计使得消费者与生产者分离，从而降低系统复杂性。在获取到生产者(<code>nsqd</code>)的地址后（准确而言，还包括<code>topic</code>及<code>channel</code>） ，消费者（<code>nsq</code>客户端）可直接连接到<code>nsqd</code>，以等待对方发送消息（不是主动去拉到消息，而是等被对方推送消息）。另外，为了提供更好的吞吐量，<code>nsq</code>允许消费者显式地向<code>nsqd</code>声明其能够处理的消息数量，这可以提高消息的吞吐量（避免消费者积压消息的情况）。针对每一个消息，当消费者消费完成后，其需要回复<code>nsqd</code>一个<code>FIN</code>消息，否则消息会被重入队，然后再一次被发送给消费者。最后，有一点需要注意，客户端（消费者）一次性只能订阅一个<code>channel</code>。官方文档提供的消息流动图如下：</p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/blob/hexo/static/nsqd-message-pub-sub-process.gif?raw=true" alt="mq-comparison"></p>
<h2 id="关键特性"><a href="#关键特性" class="headerlink" title="关键特性"></a>关键特性</h2><p>个人在阅读官方文档之后，对于其描述的一些特性比较模糊，甚至有一些误解，在后面的进一步了解过程（甚至有些东西未深入到源码是不太能理解的），因此个人总结下如下几点是需要特别理解和注意的：</p>
<ul>
<li><code>nsq</code>官方所声称的<strong>去中心化分布式</strong>特征，指的是，因为各节点(<code>nsqd</code>甚至也包括<code>nsqlookupd</code>)之间不会产生状态（数据）共享或依赖，因此可以直接通过添加节点来提升系统处理能力（即系统可通过水平扩展来来线性提升处理能力），且单个节点宕机不会影响其它节点的功能。因此，正是因为节点之间没有状态共享，没有数据冗余或副本的概念，使得它也不需要使用复杂的一致性算法来保证数据的一致；</li>
<li>虽然官方声称其是具体<strong>可靠消息传递</strong>，但是需要注意的是，其的确也存在消息丢失的情形，因为虽然它通过提供消息持久化来缓解这一问题，但并没有根本解决这一问题，一旦宕机，内存中的消息会丢失，当然你可以将内存队列长度<code>mem_queue_size</code>参数设置地更小一些以缓解此问题。甚至，你可以节点作冗余操作，以保证数据丢失的可能性在实际生产中几乎不可能发生（注意不是不可能发生），但对于那些需要高可靠性的消息发布的应用场景，<code>nsq</code>是无法保证的。</li>
<li>还有，官方文档提到一点，<code>nsq</code>并没有<code>kafaka</code>那么强大，它不能保证<strong>消息的严格顺序</strong>，换言之，生产者创建的消息可以随时（不确定性）地以任何顺序进入到<code>nsqd</code>的消息队列。典型地，官方推荐将消息生产者与<code>nsqd</code>实例协同部署，即部署在同一台机器上，这样即使发生网络分区，也不会影响生产者消息的投递，明显在此种情况下消息投递的效率理论上会被其它情况下的消息投递效率。但官方提供了一种解决方案，即将消息打上时间戳。尽管如此，它仍然不适合需要保证严格消息顺序的情况下。</li>
<li><code>nsq</code>保证的消息<strong>至少一次</strong>会被发送给生产者。换言之，消息可能被多次发送给消费者。因此，消费者应该能够识别消息重复(<code>message de-duplicate</code>)，或者保证消息所涉及的操作幂等性(<code>idempotent</code>)。更具体地，造成消息被多次发送的原因包括，客户端连接断开或消息超时时间内未返回响应，这些都会导致消息的重入队操作(<code>requeue</code>)。</li>
<li>关于<code>nsqlookupd</code>，其也是可<strong>水平扩展</strong>的，但各节点实例之间也是没有任何联系的，结合业务逻辑来阐述，即每个<code>nsqdlookupd</code>实例可分别接收部分或全部的<code>nsqd</code>实例的服务注册请求，这只需要客户端在连接到<code>nsqlookupd</code>获取所有的生产者(及<code>topic</code>和<code>channel</code>)信息后，对获取的数据进行一个<code>union</code>操作即可，便可得到整个系统中生产者的拓扑信息（这即是官方文档中所描述的将发现服务设计成<code>eventually consistent</code>）。</li>
<li>最后，不得不说的一点是，正是因为上面所描述的各种不足，造就了<code>nsq</code>的<strong>精简设计</strong>。简单实在是太重要了！因为简单意味着容易进行故障或bug查找，同时，容易部署和使用方便。不得不说，当满足了应用的基本功能之后，简单往往是最重要的一个因素。</li>
</ul>
<p>小结一下，本文先简要介绍了<code>nsq</code>的各个组件及基本工作流程，然后重点阐述了几个值得关注的特性，这些特性（包括未讨论的）以及<code>nsq</code>的各个组件，会在后面的博文中阐述。为了更好地理解<code>nsq</code>，个人建议，先仔细阅读官方文档，并简单实践，若有兴趣，深入源码查看会收获更多。</p>
<p>参考文献</p>
<p>[1]. <a href="https://nsq.io/overview/features_and_guarantees.html" target="_blank" rel="noopener">nsq Features &amp; Guarantees</a><br>[2]. <a href="https://nsq.io/overview/design.html" target="_blank" rel="noopener">nsq Design</a><br>[3]. <a href="https://nsq.io/overview/quick_start.html" target="_blank" rel="noopener">nsq Quick Start</a><br>[4]. <a href="https://speakerdeck.com/snakes/nsq-nyc-golang-meetup" target="_blank" rel="noopener">nsq - NYC Golang Meetup</a><br>[5]. <a href="https://juejin.im/entry/59ddae8151882578bb480d0e" target="_blank" rel="noopener">消息中间件NSQ深入与实践</a></p>
]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title>服务端的权鉴方式</title>
    <url>/2019/04/20/2019-04-20-%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%9A%84%E6%9D%83%E9%89%B4%E6%96%B9%E5%BC%8F/</url>
    <content><![CDATA[<p>&emsp;&emsp;<code>Http</code>请求是无状态，为了对<code>Http</code>请求进行身份识别和权限认证。<code>Token</code>，<code>Session</code>，<code>Cookie</code>都是实现的方式，本文旨在对这3中方式做分析比较。  </p>
<a id="more"></a>

<h1 id="Token特点"><a href="#Token特点" class="headerlink" title="Token特点"></a>Token特点</h1><ul>
<li>客户端存储，服务端不存储；</li>
<li>可扩展，无状态；</li>
<li>有加密，防篡改；</li>
<li>设置有效时间；</li>
<li>存储用户信息；</li>
<li>跨程序调用；</li>
<li>解密后可以拿到用户数据；</li>
<li>减少数据库查询的压力；</li>
<li>可以多端使用；</li>
<li>使用AOP注解解析Token；</li>
</ul>
<h1 id="Session特点"><a href="#Session特点" class="headerlink" title="Session特点"></a>Session特点</h1><ul>
<li>服务端和客户端都得存储；</li>
<li>每一次请求的刷新有效时间；</li>
<li>及时销毁；</li>
<li>使用缓存，增加服务端内存开销；</li>
<li>可扩展性差；</li>
<li>不会暴露用户数据</li>
</ul>
<h1 id="Cookie特点"><a href="#Cookie特点" class="headerlink" title="Cookie特点"></a>Cookie特点</h1><ul>
<li>客户端本地存储，服务端不存储；</li>
<li>浏览器Cookie空间有限；</li>
<li>浏览器确保Cookie数据的安全；</li>
<li>容易被恶意使用（Cookie欺骗）；</li>
</ul>
<h1 id="Token的主动吊销"><a href="#Token的主动吊销" class="headerlink" title="Token的主动吊销"></a>Token的主动吊销</h1><p>&emsp;&emsp;保存Token的ID在数据库（日后统计数据也可以用到），并同步到缓存，每一次认证Token都判断该Token的ID是否被删除，删除则是已被吊销。但是这样做便舍弃了Token的优点，即Token存在状态了！这违背了Token的设计初衷，相当于<code>Session</code>和<code>Token</code>的子集。  </p>
]]></content>
      <categories>
        <category>后端开发</category>
      </categories>
  </entry>
  <entry>
    <title>SpringCloud组件概览</title>
    <url>/2019/03/25/2019-03-25-SpringCloud%E7%BB%84%E4%BB%B6%E6%A6%82%E8%A7%88/</url>
    <content><![CDATA[<table>
<thead>
<tr>
<th>组件</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><a href="https://springcloud.cc/spring-cloud-config.html" target="_blank" rel="noopener">Spring Cloud Config</a></td>
<td>配置管理工具包，让你可以把配置放到远程服务器，集中化管理集群配置，目前支持本地存储、Git以及Subversion。</td>
</tr>
<tr>
<td><a href="https://springcloud.cc/spring-cloud-bus.html" target="_blank" rel="noopener">Spring Cloud Bus</a></td>
<td>事件、消息总线，用于在集群（例如，配置变化事件）中传播状态变化，可与Spring Cloud Config联合实现热部署。</td>
</tr>
<tr>
<td><a href="https://github.com/Netflix/eureka" target="_blank" rel="noopener">Eureka</a></td>
<td>云端服务发现，一个基于 REST 的服务，用于定位服务，以实现云端中间层服务发现和故障转移。</td>
</tr>
<tr>
<td><a href="https://github.com/Netflix/hystrix" target="_blank" rel="noopener">Hystrix</a></td>
<td>熔断器，容错管理工具，旨在通过熔断机制控制服务和第三方库的节点,从而对延迟和故障提供更强大的容错能力。</td>
</tr>
<tr>
<td><a href="https://github.com/Netflix/zuul" target="_blank" rel="noopener">Zuul</a></td>
<td>Zuul 是在云平台上提供动态路由,监控,弹性,安全等边缘服务的框架。Zuul 相当于是设备和 Netflix 流应用的 Web 网站后端所有请求的前门。</td>
</tr>
<tr>
<td><a href="https://github.com/Netflix/archaius" target="_blank" rel="noopener">Archaius</a></td>
<td>配置管理API，包含一系列配置管理API，提供动态类型化属性、线程安全配置操作、轮询框架、回调机制等功能。</td>
</tr>
<tr>
<td><a href="https://github.com/HashiCorp/consul" target="_blank" rel="noopener">Consul</a></td>
<td>封装了Consul操作，consul是一个服务发现与配置工具，与Docker容器可以无缝集成。</td>
</tr>
<tr>
<td><a href="https://github.com/spring-cloud/spring-cloud-cloudfoundry" target="_blank" rel="noopener">Spring Cloud for Cloud Foundry</a></td>
<td>通过Oauth2协议绑定服务到CloudFoundry，CloudFoundry是VMware推出的开源PaaS云平台。它支持多种框架、语言、运行时环境、云平台及应用服务，使开发人员能够在几秒钟内进行应用程序的部署和扩展，无需担心任何基础架构的问题</td>
</tr>
<tr>
<td><a href="https://github.com/spring-cloud/spring-cloud-sleuth" target="_blank" rel="noopener">Spring Cloud Sleuth</a></td>
<td>日志收集工具包，封装了Dapper和log-based追踪以及Zipkin和HTrace操作，为SpringCloud应用实现了一种分布式追踪解决方案。</td>
</tr>
<tr>
<td><a href="https://springcloud.cc/spring-cloud-dataflow.html" target="_blank" rel="noopener">Spring Cloud Data Flow</a></td>
<td>大数据操作工具，作为Spring XD的替代产品，它是一个混合计算模型，结合了流数据与批量数据的处理方式。</td>
</tr>
<tr>
<td><a href="https://github.com/spring-cloud/spring-cloud-security" target="_blank" rel="noopener">Spring Cloud Security</a></td>
<td>基于spring security的安全工具包，为你的应用程序添加安全控制。</td>
</tr>
<tr>
<td><a href="https://github.com/spring-cloud/spring-cloud-zookeeper" target="_blank" rel="noopener">Spring Cloud Zookeeper</a></td>
<td>操作Zookeeper的工具包，用于使用zookeeper方式的服务发现和配置管理。</td>
</tr>
<tr>
<td><a href="https://github.com/spring-cloud/spring-cloud-stream" target="_blank" rel="noopener">Spring Cloud Stream</a></td>
<td>数据流操作开发包，封装了与Redis,Rabbit、Kafka等发送接收消息。</td>
</tr>
<tr>
<td><a href="https://springcloud.cc/spring-cloud-cli.html" target="_blank" rel="noopener">Spring Cloud CLI</a></td>
<td>基于 Spring Boot CLI，可以让你以命令行方式快速建立云组件。</td>
</tr>
<tr>
<td><a href="https://github.com/Netflix/ribbon" target="_blank" rel="noopener">Ribbon</a></td>
<td>提供云端负载均衡，有多种负载均衡策略可供选择，可配合服务发现和断路器使用。</td>
</tr>
<tr>
<td><a href="https://github.com/Netflix/turbine" target="_blank" rel="noopener">Turbine</a></td>
<td>Turbine是聚合服务器发送事件流数据的一个工具，用来监控集群下hystrix的metrics情况。</td>
</tr>
<tr>
<td><a href="https://github.com/OpenFeign/feign" target="_blank" rel="noopener">Feign</a></td>
<td>Feign是一种声明式、模板化的HTTP客户端。</td>
</tr>
<tr>
<td><a href="https://github.com/spring-cloud/spring-cloud-task" target="_blank" rel="noopener">Spring Cloud Task</a></td>
<td>提供云端计划任务管理、任务调度。</td>
</tr>
<tr>
<td><a href="https://springcloud.cc/spring-cloud-connectors.html" target="_blank" rel="noopener">Spring Cloud Connectors</a></td>
<td>便于云端应用程序在各种PaaS平台连接到后端，如：数据库和消息代理服务。</td>
</tr>
<tr>
<td><a href="https://github.com/spring-cloud/spring-cloud-cluster" target="_blank" rel="noopener">Spring Cloud Cluster</a></td>
<td>提供Leadership选举，如：Zookeeper, Redis, Hazelcast, Consul,选举、集群的状态一致性、全局锁、tokens等常见状态模式的抽象和实现。提供在分布式系统中的集群所需要的基础功能支持，</td>
</tr>
<tr>
<td><a href="https://github.com/spring-cloud/spring-cloud-stream-starters" target="_blank" rel="noopener">Spring Cloud Starters</a></td>
<td>Spring Boot式的启动项目，为Spring Cloud提供开箱即用的依赖管理。</td>
</tr>
<tr>
<td><a href="https://github.com/Netflix/Turbine" target="_blank" rel="noopener">Turbine</a></td>
<td>Turbine是聚合服务器发送事件流数据的一个工具，用来监控集群下hystrix的metrics情况。</td>
</tr>
</tbody></table>]]></content>
      <categories>
        <category>后端开发</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 内存模型</title>
    <url>/2019/03/07/Java-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<p>并发编程中，需要处理两个关键问题：线程之间如何通信及线程之间如何同步。通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。<code>Java</code>语言是采用共享内存的方式来完成线程间通信的。为了保证共享内存的正确性（可见性、有序性、原子性），内存模型定义了共享内存系统中多线程程序读写操作行为的规范。因此，Java内存模型（<code>Java Memory Model ,JMM</code>）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了Java程序在各种平台下对内存的访问都能保证效果一致的机制及规范。</p>
<a id="more"></a>

<p>并发编程中为了保证数据的安全，需要满足以下三个特性：<br>(a) <strong>原子性</strong>是指在一个操作中就是 cpu 不可以在中途暂停然后再调度，既不被中断操作，要不执行完成，要不就不执行。<br>(b) <strong>可见性</strong>是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。<br>(c) <strong>有序性</strong>即程序执行的顺序按照代码的先后顺序执行。<br>且实际上，<strong>缓存一致性问题</strong>其实就是<strong>可见性问题</strong>。<strong>处理器优化</strong>可以导致<strong>原子性问题</strong>。<strong>指令重排</strong>会导致<strong>有序性问题</strong>。<strong>为了保证共享内存的正确性（可见性、有序性、原子性），内存模型定义了共享内存系统中多线程程序读写操作行为的规范。</strong></p>
<p><strong>Java内存模型（Java Memory Model ,JMM）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了Java程序在各种平台下对内存的访问都能保证效果一致的机制及规范。</strong><br>(a) <code>Java</code>内存模型规定所有的变量都存储在主内存中，每条线程还有自己的工作内存（本地内存），线程的工作内存中保存了该线程中是用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存。不同线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递需要自己的工作内存和主存之间进行数据同步进行。本地内存是 <code>JMM</code> 的一个抽象概念，并不真实存在。它涵盖缓存，写缓冲区，寄存器及其他硬件和编译器优化。<br>(b) <code>JMM</code>就作用于工作内存和主存之间数据同步过程。它规定了如何做数据同步以及什么时候做数据同步。因此，它决定一个线程对共享变量的写入何时对另一个线程可见。</p>
<p><strong>重排序</strong>。从源代码到最终的指令序列，经历的重排序过程如下：源代码 -&gt; <strong>编译器优化重排序</strong> -&gt; <strong>指令级并行重排序</strong> -&gt; <strong>内存系统重排序</strong> -&gt; 最终执行的指令序列。<br>(a) 对于编译器，<code>JMM</code> 的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，<code>JMM</code> 的处理器重排序规则会要求 <code>java</code> 编译器在生成指令序列时，插入特定类型的内存屏障指令，通过内存屏障指令来禁止特定类型的处理器重排序。<br>(b) 现代的多处理器大都支持<code>StoreLoad</code>屏障（其他 3 种类型的屏障不一定被所有处理器支持）。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中。</p>
<p><strong><code>happens-before</code></strong>。通过<code>happens-before</code>概念来阐述操作之间的内存可见性。如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在 <code>happens-before</code> 关系。与程序员密切相关的<code>happens-before</code>规则如下（另外的规则可以参考文献[2]或[3]）：<br>(1) <strong>程序顺序规则</strong>：一个线程中的每个操作，<code>happens-before</code> 于该线程中的任意后续操作。<br>(2) <strong>监视器锁规则</strong>：对一个监视器锁的解锁，<code>happens-before</code> 于随后对这个监视器锁的加锁。<br>(3) <strong><code>volatile</code> 变量规则</strong>：对一个 <code>volatile</code> 域的写，<code>happens-before</code> 于任意后续对这个 <code>volatile</code> 域的读。<br>(4) <strong>传递性</strong>：如果 A <code>happens-before</code> B，且 B happens-before C，那么 A <code>happens-before</code> C。<br>注意，两个操作之间具有 <code>happens-before</code> 关系，并不意味着前一个操作必须要在后一个操作之前执行！<code>happens-before</code> 仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前。</p>
<p><strong>重排序</strong>。如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在<strong>数据依赖性</strong>（读写、写写 和 写读三种情况）。<br>(a) 针对单个处理器中执行的指令序列和单个线程中执行的操作，编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。<br>(b) 不管怎么重排序（为了提高并行度），（单线程）程序的执行结果不能被改变。即编译器，<code>runtime</code> 和处理器都必须遵守 <code>as-if-serial</code> 语义。为了遵守 <code>as-if-serial</code> 语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作可能被编译器和处理器重排序。<br>(c) 在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果（这也是 <code>as-if-serial</code> 语义允许对存在控制依赖的操作做重排序的原因）；但在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。</p>
<p><strong>顺序一致性</strong>。顺序一致性内存模型为程序员提供了极强的内存可见性保证：(1) 一个线程中的所有操作必须按照程序的顺序来执行。(2) （不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见。<br>(a) <code>JMM</code> 对正确同步的多线程程序的内存一致性做了如下保证：如果程序是正确同步的，程序的执行将具有顺序一致性—— 即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同。换言之，未正确同步程序在 <code>JMM</code> 中不但整体的执行顺序是无序的，而且所有线程看到的操作执行顺序也可能不一致。<br>(b) 在顺序一致性模型中，所有操作完全按程序的顺序串行执行。而在 <code>JMM</code> 中，临界区内的代码可以重排序，以尽可能执行编译器和处理器优化（但 <code>JMM</code> 不允许临界区内的代码“逸出”到临界区之外，那样会破坏监视器的语义）。<br>(c) 对于未同步或未正确同步的多线程程序，<code>JMM</code> 只提供最小安全性：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值。<code>JMM</code>不保证未同步程序的执行结果与该程序在顺序一致性模型中的执行结果一致。</p>
<p><strong><code>volatile</code></strong>。对一个 <code>volatile</code> 变量的单个读 / 写操作，与对一个普通变量的读 / 写操作使用同一个监视器锁来同步，它们之间的执行效果相同。简而言之，<code>volatile</code> 变量自身具有下列特性：(1) 可见性。对一个 <code>volatile</code> 变量的读，总是能看到（任意线程）对这个 <code>volatile</code> 变量最后的写入。(2) 原子性：对任意单个 <code>volatile</code> 变量的读 / 写具有原子性，但类似于 <code>volatile++</code> 这种复合操作不具有原子性。<br>(a) 从内存语义的角度来说，<code>volatile</code> 与监视器锁有相同的效果：<code>volatile</code> 写和监视器的释放有相同的内存语义；<code>volatile</code> 读与监视器的获取有相同的内存语义。<br>(b) <code>volatile</code> 写的内存语义如下：当写一个 volatile 变量时，<code>JMM</code> 会把该线程对应的本地内存中的共享变量刷新到主内存。 <code>volatile</code> 读的内存语义如下：当读一个 volatile 变量时，<code>JMM</code> 会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。<br>(c) 若我们把 <code>volatile</code> 写和 <code>volatile</code> 读这两个步骤综合起来看的话，在读线程 B 读一个 <code>volatile</code> 变量后，写线程 A 在写这个 <code>volatile</code> 变量之前所有可见的共享变量的值都将立即变得对读线程 B 可见。<br>(d) JSR-133 专家组决定增强 <code>volatile</code> 的内存语义：严格限制编译器和处理器对 <code>volatile</code> 变量与普通变量的重排序，确保 <code>volatile</code> 的写 - 读和监视器的释放 - 获取一样，具有相同的内存语义。<br>(e) <code>JMM</code> 针对编译器制定的 <code>volatile</code> 重排序规则表：<br>(1) 当第二个操作是 <code>volatile</code> 写时，不管第一个操作是什么，都不能重排序。这个规则确保 <code>volatile</code> 写之前的操作不会被编译器重排序到 <code>volatile</code> 写之后。<br>(2) 当第一个操作是 <code>volatile</code> 读时，不管第二个操作是什么，都不能重排序。这个规则确保 volatile 读之后的操作不会被编译器重排序到 <code>volatile</code> 读之前。<br>(3) 当第一个操作是 <code>volatile</code> 写，第二个操作是 <code>volatile</code> 读时，不能重排序。</p>
<p><strong>锁</strong>。当线程释放锁时，<code>JMM</code> 会把该线程对应的本地内存中的共享变量刷新到主内存中。当线程获取锁时，<code>JMM</code> 会把该线程对应的本地内存置为无效，从而使得被监视器保护的临界区代码必须要从主内存中去读取共享变量。<br>(a) <code>CAS</code> 同时具有 <code>volatile</code> 读和 <code>volatile</code> 写的内存语义。<br>(b) <code>AQS</code>，非阻塞数据结构和原子变量类（<code>java.util.concurrent.atomic</code> 包中的类）都是基于 <code>volatile</code>变量的读/写及 <code>CAS</code> 操作实现。而前三者又构成了<code>java</code>并发包中的同步器的基础。</p>
<p> <strong><code>final</code></strong>。与前面介绍的锁和 <code>volatile</code> 相比较，对 <code>final</code> 域的读和写更像是普通的变量访问。对于 <code>final</code> 域，编译器和处理器要遵守两个重排序规则：(1) 在构造函数内对一个 <code>final</code> 域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。(2) 初次读一个包含 <code>final</code> 域的对象的引用，与随后初次读这个<code>final</code> 域，这两个操作之间不能重排序。<br>(a) 写 final 域的重排序规则会要求译编器在 <code>final</code> 域的写之后，构造函数 <code>return</code> 之前，插入一个 <code>StoreStore</code> 障屏。读 final 域的重排序规则要求编译器在读 <code>final</code> 域的操作前面插入一个 <code>LoadLoad</code> 屏障。<br>(b) 当<code>final</code> 域为一个引用类型，比如它引用一个 <code>int</code> 型的数组对象。此时写<code>final</code>域的重排序规则对编译器和处理器增加了如下约束：在构造函数内对一个 <code>final</code> 引用的对象的成员域的写入，与随后在构造函数外把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。<br>(c) JSR-133 专家组增强了 <code>final</code> 的语义。通过为 <code>final</code> 域增加写和读重排序规则，可以为 <code>java</code> 程序员提供初始化安全保证：只要对象是正确构造的（被构造对象的引用在构造函数中没有“逸出”），那么不需要使用同步（指 <code>lock</code> 和 <code>volatile</code> 的使用），就可以保证任意线程都能看到这个 <code>final</code> 域在构造函数中被初始化之后的值。</p>
<p><strong>总结</strong>。<strong>(a)</strong> 由于常见的处理器内存模型比 <code>JMM</code> 要弱，<code>java</code> 编译器在生成字节码时，会在执行指令序列的适当位置插入内存屏障来限制处理器的重排序。同时，由于各种处理器内存模型的强弱并不相同，为了在不同的处理器平台向程序员展示一个一致的内存模型，<code>JMM</code> 在不同的处理器中需要插入的内存屏障的数量和种类也不相同。<br><strong>(b)</strong> 顺序一致性内存模型是一个理论参考模型，<code>JMM</code> 和处理器内存模型在设计时通常会把顺序一致性内存模型作为参照。<br><strong>(c)</strong> <code>JMM</code> 是一个语言级的内存模型，处理器内存模型是硬件级的内存模型，顺序一致性内存模型是一个理论参考模型。<br><strong>(d)</strong> 从 JMM 设计者的角度来说，在设计 <code>JMM</code> 时，需要考虑两个关键因素：<br>(1) 程序员对内存模型的使用。程序员希望内存模型易于理解，易于编程。程序员希望基于一个强内存模型来编写代码。<br>(2) 编译器和处理器对内存模型的实现。编译器和处理器希望内存模型对它们的束缚越少越好，这样它们就可以做尽可能多的优化来提高性能。编译器和处理器希望实现一个弱内存模型。<br>由于这两个因素互相矛盾，所以 JSR-133 专家组在设计 JMM 时的核心目标就是找到一个好的平衡点：一方面要为程序员提供足够强的内存可见性保证；另一方面，对编译器和处理器的限制要尽可能的放松。<br><strong>(e)</strong> Java 程序的内存可见性保证按程序类型可以分为下列三类：<br>(1) 单线程程序。单线程程序不会出现内存可见性问题。编译器，<code>runtime</code> 和处理器会共同确保单线程程序的执行结果与该程序在顺序一致性模型中的执行结果相同。<br>(2) 正确同步的多线程程序。正确同步的多线程程序的执行将具有顺序一致性（程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同）。这是 <code>JMM</code> 关注的重点，<code>JMM</code> 通过限制编译器和处理器的重排序来为程序员提供内存可见性保证。<br>(3) 未同步 / 未正确同步的多线程程序。<code>JMM</code> 为它们提供了最小安全性保障：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值。</p>
<p>以上内容大部分自文献[1]，并整合了个人的思考。</p>
<p>参考文献</p>
<p>[1]. 深入理解Java内存模型  程晓明<br>[2]. JSR-133_JavaTM Memory Model and Thread Specification<br>[3]. 周志明. 深入理解 Java 虚拟机一 JVM 高级特性与最佳实践[J]. 2014.</p>
]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
        <tag>内存模型</tag>
      </tags>
  </entry>
  <entry>
    <title>每天5分钟玩转Docker容器技术目录</title>
    <url>/2019/03/02/2019-03-02-%E6%AF%8F%E5%A4%A95%E5%88%86%E9%92%9F%E7%8E%A9%E8%BD%ACDocker%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF%E7%9B%AE%E5%BD%95/</url>
    <content><![CDATA[<ol>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6693772.html" target="_blank" rel="noopener">写在最前面</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6706546.html" target="_blank" rel="noopener">容器生态系统</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6718464.html" target="_blank" rel="noopener">容器生态系统 (续)</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6727146.html" target="_blank" rel="noopener">运行第一个容器</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6740469.html" target="_blank" rel="noopener">【视频】运行第一个容器</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6751516.html" target="_blank" rel="noopener">容器 What, Why, How</a>{:target=”_blank”}<a id="more"></a></li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6763789.html" target="_blank" rel="noopener">Docker 架构详解</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6774519.html" target="_blank" rel="noopener">Docker 组件如何协作？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6788841.html" target="_blank" rel="noopener">最小的镜像</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6799197.html" target="_blank" rel="noopener">base 镜像</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6806193.html" target="_blank" rel="noopener">镜像的分层结构</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6821332.html" target="_blank" rel="noopener">构建镜像</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6830067.html" target="_blank" rel="noopener">Dockerfile 构建镜像</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6839420.html" target="_blank" rel="noopener">镜像的缓存特性</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6853329.html" target="_blank" rel="noopener">调试 Dockerfile</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6864000.html" target="_blank" rel="noopener">Dockerfile 常用指令</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6875834.html" target="_blank" rel="noopener">RUN vs CMD vs ENTRYPOINT</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6885700.html" target="_blank" rel="noopener">镜像命名的最佳实践</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6896488.html" target="_blank" rel="noopener">使用公共 Registry</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6902325.html" target="_blank" rel="noopener">搭建本地 Registry</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6913993.html" target="_blank" rel="noopener">Docker 镜像小结</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6921132.html" target="_blank" rel="noopener">如何运行容器？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6928772.html" target="_blank" rel="noopener">两种进入容器的方法</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6942370.html" target="_blank" rel="noopener">运行容器的最佳实践</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6952115.html" target="_blank" rel="noopener">容器常用操作</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6961665.html" target="_blank" rel="noopener">一张图搞懂容器所有操作</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/6986499.html" target="_blank" rel="noopener">限制容器对内存的使用</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7003199.html" target="_blank" rel="noopener">限制容器对CPU的使用</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7016050.html" target="_blank" rel="noopener">限制容器的 Block IO</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7045784.html" target="_blank" rel="noopener">实现容器的底层技术</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7053617.html" target="_blank" rel="noopener">none 和 host 网络的适用场景</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7066851.html" target="_blank" rel="noopener">学容器必须懂 bridge 网络</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7077198.html" target="_blank" rel="noopener">如何自定义容器网络？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7087765.html" target="_blank" rel="noopener">理解容器之间的连通性</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7096731.html" target="_blank" rel="noopener">容器间通信的三种方式</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7107407.html" target="_blank" rel="noopener">容器如何访问外部世界？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7118860.html" target="_blank" rel="noopener">外部世界如何访问容器？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7127843.html" target="_blank" rel="noopener">Docker 的两类存储资源</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7142150.html" target="_blank" rel="noopener">Data Volume 之 bind mount</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7152775.html" target="_blank" rel="noopener">docker managed volume</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7163399.html" target="_blank" rel="noopener">如何共享数据？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7188479.html" target="_blank" rel="noopener">用 volume container 共享数据</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7203285.html" target="_blank" rel="noopener">data-packed volume container</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7214828.html" target="_blank" rel="noopener">volume 生命周期管理</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7223599.html" target="_blank" rel="noopener">安装 Docker Machine</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7237420.html" target="_blank" rel="noopener">创建 Machine</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7248188.html" target="_blank" rel="noopener">管理 Machine</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7259266.html" target="_blank" rel="noopener">跨主机网络概述</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7270551.html" target="_blank" rel="noopener">准备 overlay 网络实验环境</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7280787.html" target="_blank" rel="noopener">创建 overlay 网络</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7294501.html" target="_blank" rel="noopener">在 overlay 中运行容器</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7305989.html" target="_blank" rel="noopener">overlay 如何实现跨主机通信？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7341487.html" target="_blank" rel="noopener">overlay 是如何隔离的？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7352620.html" target="_blank" rel="noopener">准备 macvlan 环境</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7364332.html" target="_blank" rel="noopener">创建 macvlan 网络</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7383919.html" target="_blank" rel="noopener">macvlan 网络结构分析</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7400580.html" target="_blank" rel="noopener">macvlan 网络隔离和连通</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7412150.html" target="_blank" rel="noopener">flannel 概述</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7424858.html" target="_blank" rel="noopener">安装配置 flannel</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7441188.html" target="_blank" rel="noopener">在 Docker 中使用 flannel</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7447716.html" target="_blank" rel="noopener">flannel 的连通与隔离</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7457653.html" target="_blank" rel="noopener">如何使用 flannel host-gw backend？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7471162.html" target="_blank" rel="noopener">如何使用 Weave 网络？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7482035.html" target="_blank" rel="noopener">Weave 网络结构分析</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7491831.html" target="_blank" rel="noopener">容器在 Weave 中如何通信和隔离？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7500550.html" target="_blank" rel="noopener">Weave 如何与外网通信？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7509975.html" target="_blank" rel="noopener">如何部署 Calico 网络？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7520164.html" target="_blank" rel="noopener">Calico 的网络结构是什么？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7536746.html" target="_blank" rel="noopener">Calico 的默认连通性</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7552618.html" target="_blank" rel="noopener">如何定制 Calico 网络 Policy</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7571272.html" target="_blank" rel="noopener">如何定制 Calico 的 IP 池？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7587532.html" target="_blank" rel="noopener">一文搞懂各种 Docker 网络</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7594225.html" target="_blank" rel="noopener">新书发布《每天5分钟玩转Docker容器技术》</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7595437.html" target="_blank" rel="noopener">如何实现跨 Docker 主机存储？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7607705.html" target="_blank" rel="noopener">如何安装和配置 Rex-Ray？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7617211.html" target="_blank" rel="noopener">配置 VirtualBox backend</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7624556.html" target="_blank" rel="noopener">创建 Rex-Ray volume</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7630205.html" target="_blank" rel="noopener">跨主机使用 Rex-Ray volume</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7637361.html" target="_blank" rel="noopener">Docker 最常用的监控方案</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7646995.html" target="_blank" rel="noopener">监控利器 sysdig</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7655294.html" target="_blank" rel="noopener">Weave Scope 容器地图</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7674011.html" target="_blank" rel="noopener">Weave Scope 多主机监控</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7683190.html" target="_blank" rel="noopener">数据收集利器 cAdvisor</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7692765.html" target="_blank" rel="noopener">Prometheus 架构</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7709970.html" target="_blank" rel="noopener">Prometheus 到底 NB 在哪里？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7724576.html" target="_blank" rel="noopener">如何快速部署 Prometheus？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7736176.html" target="_blank" rel="noopener">一张表搞懂各种 Docker 监控方案</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7749304.html" target="_blank" rel="noopener">日志管理之 Docker logs</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7762369.html" target="_blank" rel="noopener">Docker 如何支持多种日志方案？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7770916.html" target="_blank" rel="noopener">初探 ELK</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7787870.html" target="_blank" rel="noopener">ELK 完整部署和使用</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7798224.html" target="_blank" rel="noopener">万能日志数据收集器 Fluentd</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7808708.html" target="_blank" rel="noopener">部署 Graylog 日志系统</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7821817.html" target="_blank" rel="noopener">如何用 Graylog 管理日志？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7834113.html" target="_blank" rel="noopener">预告 — 容器平台技术</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7845365.html" target="_blank" rel="noopener">Docker Swarm 中最重要的概念</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7862254.html" target="_blank" rel="noopener">如何创建 Swarm 集群？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7874609.html" target="_blank" rel="noopener">运行第一个 Service</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7885667.html" target="_blank" rel="noopener">如何实现 Service 伸缩？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7898245.html" target="_blank" rel="noopener">Swarm 如何实现 Failover？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7909136.html" target="_blank" rel="noopener">如何访问 Service？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7930321.html" target="_blank" rel="noopener">神奇的 routing mesh </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7967419.html" target="_blank" rel="noopener">Service 之间如何通信？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/7988455.html" target="_blank" rel="noopener">如何滚动更新 Service？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8000906.html" target="_blank" rel="noopener">Swarm 如何存储数据？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8016994.html" target="_blank" rel="noopener">验证 Swarm 数据持久性 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8028712.html" target="_blank" rel="noopener">replicated mode vs global mode </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8038799.html" target="_blank" rel="noopener">用 Label 控制 Service 的位置 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8053323.html" target="_blank" rel="noopener">如何配置 Health Check？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8068057.html" target="_blank" rel="noopener">如何使用 Secret？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8082429.html" target="_blank" rel="noopener">Secret 的使用场景 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8098761.html" target="_blank" rel="noopener">通过案例学习 Secret </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8119150.html" target="_blank" rel="noopener">什么是 stack？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8135714.html" target="_blank" rel="noopener">如何使用 stack？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8157391.html" target="_blank" rel="noopener">stack 的优势 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8178483.html" target="_blank" rel="noopener">学习 Kubernetes 的 Why 和 How </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8194895.html" target="_blank" rel="noopener">5 秒创建 k8s 集群 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8231789.html" target="_blank" rel="noopener">k8s 核心功能 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8252204.html" target="_blank" rel="noopener">k8s 重要概念 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8269620.html" target="_blank" rel="noopener">部署 k8s Cluster（上）</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8282367.html" target="_blank" rel="noopener">部署 k8s Cluster（下）</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8294766.html" target="_blank" rel="noopener">Kubernetes 架构（上）</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8308334.html" target="_blank" rel="noopener">Kubernetes 架构（下）</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8323420.html" target="_blank" rel="noopener">通过例子理解 k8s 架构 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8336904.html" target="_blank" rel="noopener">用 Deployment 运行应用 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8351975.html" target="_blank" rel="noopener">k8s 创建资源的两种方式 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8370501.html" target="_blank" rel="noopener">读懂 Deployment YAML </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8383356.html" target="_blank" rel="noopener">如何 Scale Up/Down Deployment？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8400717.html" target="_blank" rel="noopener">k8s 如何 Failover？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8440366.html" target="_blank" rel="noopener">用 label 控制 Pod 的位置 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8445954.html" target="_blank" rel="noopener">DaemonSet 典型应用场景 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8449209.html" target="_blank" rel="noopener">DaemonSet 案例分析 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8452453.html" target="_blank" rel="noopener">运行自己的 DaemonSet </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8454758.html" target="_blank" rel="noopener">用 k8s 运行一次性任务 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8457932.html" target="_blank" rel="noopener">Job 失败了怎么办？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8468533.html" target="_blank" rel="noopener">并行执行 Job </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8476883.html" target="_blank" rel="noopener">定时执行 Job </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8486913.html" target="_blank" rel="noopener">通过 Service 访问 Pod </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8503685.html" target="_blank" rel="noopener">Service IP 原理 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8512231.html" target="_blank" rel="noopener">DNS 访问 Service </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8526293.html" target="_blank" rel="noopener">外网如何访问 Service？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8543006.html" target="_blank" rel="noopener">Rolling Update </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8553331.html" target="_blank" rel="noopener">回滚 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8571325.html" target="_blank" rel="noopener">Health Check </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8594143.html" target="_blank" rel="noopener">Liveness 探测 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8606866.html" target="_blank" rel="noopener">Readiness 探测 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8621305.html" target="_blank" rel="noopener">在 Scale Up 中使用 Health Check </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8642831.html" target="_blank" rel="noopener">在 Rolling Update 中使用 Health Check </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8655279.html" target="_blank" rel="noopener">数据管理 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8667779.html" target="_blank" rel="noopener">hostPath Volume </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8685547.html" target="_blank" rel="noopener">外部 Storage Provider </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8705515.html" target="_blank" rel="noopener">PV &amp; PVC </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8721078.html" target="_blank" rel="noopener">NFS PersistentVolume </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8742573.html" target="_blank" rel="noopener">回收 PV </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8776073.html" target="_blank" rel="noopener">PV 动态供给 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8806237.html" target="_blank" rel="noopener">MySQL 如何使用 PV 和 PVC？</a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8848295.html" target="_blank" rel="noopener">用 k8s 管理机密信息 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8861341.html" target="_blank" rel="noopener">查看 Secret </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8868352.html" target="_blank" rel="noopener">volume 方式使用 Secret </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8905466.html" target="_blank" rel="noopener">环境变量方式使用 Secret </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8925374.html" target="_blank" rel="noopener">用 ConfigMap 管理配置 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8949347.html" target="_blank" rel="noopener">Why Helm? </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8970314.html" target="_blank" rel="noopener">Helm 架构 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8974338.html" target="_blank" rel="noopener">部署 Helm </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8983824.html" target="_blank" rel="noopener">使用 Helm </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/8997225.html" target="_blank" rel="noopener">chart 目录结构 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/9006203.html" target="_blank" rel="noopener">chart 模板 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/9017730.html" target="_blank" rel="noopener">再次实践 MySQL chart </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/9030880.html" target="_blank" rel="noopener">开发自己的 chart </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/9039236.html" target="_blank" rel="noopener">管理和安装 chart </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/9048205.html" target="_blank" rel="noopener">网络模型 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/9064712.html" target="_blank" rel="noopener">k8s 各种网络方案 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/9073610.html" target="_blank" rel="noopener">Network Policy </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/9085187.html" target="_blank" rel="noopener">实践 Network Policy </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/9097274.html" target="_blank" rel="noopener">Kubernetes Dashboard </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/9103197.html" target="_blank" rel="noopener">使用 Dashboard </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/9118943.html" target="_blank" rel="noopener">用 Weave Scope 监控集群 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/9127893.html" target="_blank" rel="noopener">用 Heapster 监控集群 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/9141757.html" target="_blank" rel="noopener">Prometheus Operator </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/9148723.html" target="_blank" rel="noopener">Prometheus Operator 架构 </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/9162353.html" target="_blank" rel="noopener">部署 Prometheus Operator </a>{:target=”_blank”}</li>
<li><a href="https://www.cnblogs.com/CloudMan6/p/9173360.html" target="_blank" rel="noopener">Kubernetes 集群日志管理 </a>{:target=”_blank”}</li>
</ol>
]]></content>
      <categories>
        <category>后端开发</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker学习笔记</title>
    <url>/2019/03/01/2019-03-01-Docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="什么是Docker"><a href="#什么是Docker" class="headerlink" title="什么是Docker"></a>什么是Docker</h1><hr>
<p>&emsp;&emsp;我记得，我最早接触Docker的时候是2017年，吴树鑫老师的信息安全课上讲的，那个时候他推荐了CloudMan的教程。时间真TM快啊。<br>&emsp;&emsp;回到正题。<br>&emsp;&emsp;正确答案是：<strong>Docker 是世界领先的软件容器平台。</strong>  </p>
<h1 id="为什么用Docker"><a href="#为什么用Docker" class="headerlink" title="为什么用Docker"></a>为什么用Docker</h1><hr>
<h2 id="解决什么问题"><a href="#解决什么问题" class="headerlink" title="解决什么问题"></a>解决什么问题</h2><p>&emsp;&emsp;使得软件在任何环境中都能够始终如一地运行，不受外部系统环境差异的影响。   </p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><h3 id="虚拟机"><a href="#虚拟机" class="headerlink" title="虚拟机"></a>虚拟机</h3><p>&emsp;&emsp;虚拟机 (VM) 是一个物理硬件层抽象，用于将一台服务器变成多台服务器。  </p>
<blockquote>
<p>缺点：</p>
</blockquote>
<ul>
<li>占用资源多</li>
<li>操作麻烦</li>
<li>启动缓慢</li>
</ul>
<h3 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h3><p>&emsp;&emsp;容器是一个应用层抽象，用于将代码和依赖资源打包在一起。多个容器可以在同一台机器上运行，共享操作系统内核，但各自作为独立的进程在用户空间中运行。容器镜像是轻量的、可执行的独立软件包，包含软件运行所需的所有内容：代码、运行时环境、系统工具、系统库和设置。  </p>
<blockquote>
<p>优势：</p>
</blockquote>
<ul>
<li>启动快</li>
<li>占用资源少</li>
<li>命令操作简单</li>
</ul>
<h3 id="Docker用途"><a href="#Docker用途" class="headerlink" title="Docker用途"></a>Docker用途</h3><p>Docker 属于容器的一种封装，提供简单易用的容器使用接口。</p>
<ul>
<li>提供一次性一致的测试，构建和部署环境；</li>
<li>提供弹性操作服务；</li>
<li>构建微服务架构。</li>
</ul>
<a id="more"></a>

<h1 id="怎么样用Docker"><a href="#怎么样用Docker" class="headerlink" title="怎么样用Docker"></a>怎么样用Docker</h1><hr>
<p><strong>常用命令</strong>  </p>
<h2 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install docker</span><br><span class="line">或者</span><br><span class="line">apt install docker</span><br></pre></td></tr></table></figure>

<h2 id="验证安装"><a href="#验证安装" class="headerlink" title="验证安装"></a>验证安装</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker verison</span><br><span class="line">或者</span><br><span class="line">docker info</span><br></pre></td></tr></table></figure>

<h2 id="服务操作"><a href="#服务操作" class="headerlink" title="服务操作"></a>服务操作</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo service docker start（restart/stop/status）</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo systemctl start（restart/stop/status） docker</span><br></pre></td></tr></table></figure>

<h2 id="image操作"><a href="#image操作" class="headerlink" title="image操作"></a>image操作</h2><p>image 是引用程序及其依赖的载体，image是二进制文件，在Docker中是通用的，可继承其他image，比较常用的image都是从<a href="https://hub.docker.com/" target="_blank" rel="noopener">Docker Hub</a>拉取。</p>
<h3 id="拉取image"><a href="#拉取image" class="headerlink" title="拉取image"></a>拉取image</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker image pull 'imageName'</span><br><span class="line">或者</span><br><span class="line">docker iamge pull 'pathName'/'imageName'</span><br></pre></td></tr></table></figure>

<h3 id="列出image"><a href="#列出image" class="headerlink" title="列出image"></a>列出image</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker image ls</span><br></pre></td></tr></table></figure>

<h3 id="删除image"><a href="#删除image" class="headerlink" title="删除image"></a>删除image</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker image rm 'imageName'</span><br></pre></td></tr></table></figure>

<h3 id="运行image"><a href="#运行image" class="headerlink" title="运行image"></a>运行image</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker container run 'imageName'</span><br></pre></td></tr></table></figure>
<p>解释：先创建一个容器实例，然后运行image,会产生一个containID，如果本地没有改image，则自动从<a href="https://hub.docker.com/" target="_blank" rel="noopener">Docker Hub</a>拉取。</p>
<h3 id="停止运行image"><a href="#停止运行image" class="headerlink" title="停止运行image"></a>停止运行image</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker container kill 'containID'</span><br></pre></td></tr></table></figure>

<h2 id="container操作"><a href="#container操作" class="headerlink" title="container操作"></a>container操作</h2><p>container是image运行的载体，也就是容器实例。</p>
<h3 id="列出正在运行container"><a href="#列出正在运行container" class="headerlink" title="列出正在运行container"></a>列出正在运行container</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker container ls</span><br></pre></td></tr></table></figure>

<h3 id="列出所有container"><a href="#列出所有container" class="headerlink" title="列出所有container"></a>列出所有container</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker container ls -a</span><br></pre></td></tr></table></figure>

<h3 id="删除container"><a href="#删除container" class="headerlink" title="删除container"></a>删除container</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker container rm 'containerID'</span><br></pre></td></tr></table></figure>

<h3 id="启动container"><a href="#启动container" class="headerlink" title="启动container"></a>启动container</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker start 'containerID/containerName'</span><br></pre></td></tr></table></figure>

<h3 id="停止container"><a href="#停止container" class="headerlink" title="停止container"></a>停止container</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker stop 'containerID/containerName'</span><br></pre></td></tr></table></figure>

<h3 id="重启container"><a href="#重启container" class="headerlink" title="重启container"></a>重启container</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker restart 'containerID/containerName'</span><br></pre></td></tr></table></figure>


<h2 id="container与image的关系"><a href="#container与image的关系" class="headerlink" title="container与image的关系"></a>container与image的关系</h2><p>镜像是文件, 容器是进程。 容器是基于镜像创建的, 即容器中的进程依赖于镜像中的文件, 这里的文件包括进程运行所需要的可执行文件， 依赖软件， 库文件， 配置文件等等…  </p>
<h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@izwz951e3fbtauq6d7ez9gz ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES</span><br><span class="line">[root@izwz951e3fbtauq6d7ez9gz ~]# docker image ls</span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">[root@izwz951e3fbtauq6d7ez9gz ~]# docker run -d -p 8001:80 httpd</span><br><span class="line">Unable to find image 'httpd:latest' locally</span><br><span class="line">Trying to pull repository docker.io/library/httpd ... </span><br><span class="line">latest: Pulling from docker.io/library/httpd</span><br><span class="line">6ae821421a7d: Pull complete </span><br><span class="line">0ceda4df88c8: Pull complete </span><br><span class="line">24f08eb4db68: Pull complete </span><br><span class="line">ddf4fc318081: Pull complete </span><br><span class="line">fc5812428ac0: Pull complete </span><br><span class="line">Digest: sha256:5e7992fcdaa214d5e88c4dfde274befe60d5d5b232717862856012bf5ce31086</span><br><span class="line">Status: Downloaded newer image for docker.io/httpd:latest</span><br><span class="line">e760d48833f63f7f60688944798ce558e976e366cc3b7550a57c1dc680335a15</span><br><span class="line">[root@izwz951e3fbtauq6d7ez9gz ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND              CREATED             STATUS              PORTS                  NAMES</span><br><span class="line">e760d48833f6        httpd               "httpd-foreground"   21 seconds ago      Up 20 seconds       0.0.0.0:8001-&gt;80/tcp   kickass_hypatia</span><br><span class="line">[root@izwz951e3fbtauq6d7ez9gz ~]# docker image ls</span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">docker.io/httpd     latest              d3a13ec4a0f1        2 weeks ago         132 MB</span><br><span class="line">[root@izwz951e3fbtauq6d7ez9gz ~]#</span><br></pre></td></tr></table></figure>

<p><strong>操作结果</strong>  </p>
<p><img src="https://www.google.cn/assets/private/images/image-82.jpg" alt="操作结果"> </p>
<p><strong>命令解释</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -d -p 8001:80 httpd</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run --name jenkins -p 8008:8080 docker.io/jenkins/jenkins</span><br></pre></td></tr></table></figure>

<ul>
<li><code>docker run</code>: 运行一个Docker容器</li>
<li><code>-d</code>: 表示容器在后台运行</li>
<li><code>-p 8001:80</code>: 表示将宿主机的8001端口映射到容器的80端口</li>
<li><code>--name</code>: 设置容器名字</li>
<li><code>httpd</code>: 表示容器名称或者镜像名称，首先查找本地容器，否则查找本地镜像，否则查找DockerHub云端仓库开放的镜像，没有容器则自动创建容器。</li>
<li><code>CONTAINER ID</code>: 容器ID，对容器的操作可以根据ID进行。（start、restart、stop、rm）</li>
<li><code>IMAGE ID</code>: 镜像ID，和容器ID是一样的属性</li>
<li><code>PORTS</code>: 容器端口映射关系</li>
<li><code>NAMES</code>: 容器名称，不指定则随机分配。</li>
<li><code>REPOSITORY</code>: 镜像来源，可以是本地，也可以是云端仓库</li>
</ul>
<h2 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h2><p>Dockerfile是镜像的描述文件，是YAML标准格式的配置文件，定义了如何构建容器。关于Dockerfile的内容再另外写博文。</p>
<h2 id="Docker容器命令"><a href="#Docker容器命令" class="headerlink" title="Docker容器命令"></a>Docker容器命令</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker --help</span><br></pre></td></tr></table></figure>

<p>有关命令的详细信息，请运行“ Docker 命令 –help ”。  </p>
<h3 id="选项参数"><a href="#选项参数" class="headerlink" title="选项参数"></a>选项参数</h3><table>
<thead>
<tr>
<th>选项</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>–config</td>
<td>string</td>
<td>客户端配置文件的位置 (default”/root/.docker”)</td>
</tr>
<tr>
<td>-D, –debug</td>
<td></td>
<td>启用调试模式</td>
</tr>
<tr>
<td>–help</td>
<td></td>
<td>打印使用方法</td>
</tr>
<tr>
<td>-H, –host</td>
<td>list</td>
<td>连接到的守护程序套接字</td>
</tr>
<tr>
<td>-l, –log-level</td>
<td>string</td>
<td>设置日志记录级别(“debug”/“info”/“warn”/“error”/“fatal”)(default “info”)</td>
</tr>
<tr>
<td>–tls</td>
<td></td>
<td>使用TLS  ; implied by –tlsverify</td>
</tr>
<tr>
<td>–tlscacert</td>
<td>string</td>
<td>仅由本ca签署的信任证书(default”/root/.docker/ca.pem”)</td>
</tr>
<tr>
<td>–tlscert</td>
<td>string</td>
<td>TLS证书文件路径(default”/root/.docker/cert.pem”)</td>
</tr>
<tr>
<td>–tlskey</td>
<td>string</td>
<td>TLS密钥文件的路径(default “/root/.docker/key.pem”)</td>
</tr>
<tr>
<td>–tlsverify</td>
<td></td>
<td>使用TLS并验证远程</td>
</tr>
<tr>
<td>-v, –version</td>
<td></td>
<td>打印版本信息并退出</td>
</tr>
</tbody></table>
<h3 id="管理命令"><a href="#管理命令" class="headerlink" title="管理命令"></a>管理命令</h3><table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>config</td>
<td>管理Docker 配置</td>
</tr>
<tr>
<td>container</td>
<td>管理容器</td>
</tr>
<tr>
<td>image</td>
<td>管理图像</td>
</tr>
<tr>
<td>network</td>
<td>管理网络</td>
</tr>
<tr>
<td>node</td>
<td>管理群集节点</td>
</tr>
<tr>
<td>plugin</td>
<td>管理插件</td>
</tr>
<tr>
<td>secret</td>
<td>管理Docker秘钥</td>
</tr>
<tr>
<td>service</td>
<td>管理服务</td>
</tr>
<tr>
<td>stack</td>
<td>管理 Docker 堆栈</td>
</tr>
<tr>
<td>swarm</td>
<td>管理集群</td>
</tr>
<tr>
<td>system</td>
<td>管理Docker</td>
</tr>
<tr>
<td>volume</td>
<td>管理Docker卷</td>
</tr>
</tbody></table>
<h3 id="控制命令"><a href="#控制命令" class="headerlink" title="控制命令"></a>控制命令</h3><table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>attach</td>
<td>将本地标准输入、输出和错误流附加到运行的容器</td>
</tr>
<tr>
<td>build</td>
<td>从Dockerfile构建镜像</td>
</tr>
<tr>
<td>commit</td>
<td>将已经修改的容器镜像保存为新镜像</td>
</tr>
<tr>
<td>cp</td>
<td>在容器和本地文件系统之间复制文件/文件夹</td>
</tr>
<tr>
<td>create</td>
<td>创建新容器</td>
</tr>
<tr>
<td>diff</td>
<td>检查容器文件系统上文件或目录的更改</td>
</tr>
<tr>
<td>events</td>
<td>从服务器获取实时事件</td>
</tr>
<tr>
<td>exec</td>
<td>在正在运行的容器中运行命令</td>
</tr>
<tr>
<td>export</td>
<td>将容器的文件系统导出为tar压缩包</td>
</tr>
<tr>
<td>history</td>
<td>显示历史镜像</td>
</tr>
<tr>
<td>images</td>
<td>镜像列表</td>
</tr>
<tr>
<td>import</td>
<td>从容器中导入并创建新的系统镜像</td>
</tr>
<tr>
<td>info</td>
<td>显示系统范围内的信息</td>
</tr>
<tr>
<td>inspect</td>
<td>返回Docker对象的底层信息</td>
</tr>
<tr>
<td>kill</td>
<td>杀死一个或多个正在运行的容器</td>
</tr>
<tr>
<td>load</td>
<td>从一个tar压缩文件或标准输入加载图像</td>
</tr>
<tr>
<td>login</td>
<td>登录到Docker注册表</td>
</tr>
<tr>
<td>logout</td>
<td>退出Docker</td>
</tr>
<tr>
<td>logs</td>
<td>获取容器的日志</td>
</tr>
<tr>
<td>pause</td>
<td>在一个或多个容器中暂停所有进程</td>
</tr>
<tr>
<td>port</td>
<td>列出容器的端口映射或特定映射</td>
</tr>
<tr>
<td>ps</td>
<td>容器列表</td>
</tr>
<tr>
<td>pull</td>
<td>从注册表中提取图像或存储库</td>
</tr>
<tr>
<td>push</td>
<td>将图像或存储库推送到注册表</td>
</tr>
<tr>
<td>rename</td>
<td>重命名容器</td>
</tr>
<tr>
<td>restart</td>
<td>重新启动一个或多个容器</td>
</tr>
<tr>
<td>rm</td>
<td>删除一个或多个容器container</td>
</tr>
<tr>
<td>rmi</td>
<td>删除一个或多个图像images</td>
</tr>
<tr>
<td>run</td>
<td>在新容器中运行命令</td>
</tr>
<tr>
<td>save</td>
<td>将一个或多个图像保存到TAR归档文件中</td>
</tr>
<tr>
<td>search</td>
<td>从 Docker Hub搜索镜像</td>
</tr>
<tr>
<td>start</td>
<td>启动一个或多个已停止的容器</td>
</tr>
<tr>
<td>stats</td>
<td>显示容器资源使用率统计的动态流</td>
</tr>
<tr>
<td>stop</td>
<td>停止一个或多个正在运行的容器</td>
</tr>
<tr>
<td>tag</td>
<td>创建tag压缩 TARGET_IMAGE 指向SOURCE_IMAGE</td>
</tr>
<tr>
<td>top</td>
<td>显示容器中运行的线程</td>
</tr>
<tr>
<td>unpause</td>
<td>取消所有一个或多个容器的进程的暂停</td>
</tr>
<tr>
<td>update</td>
<td>更新一个或多个容器的配置</td>
</tr>
<tr>
<td>version</td>
<td>显示Docker 版本信息</td>
</tr>
<tr>
<td>wait</td>
<td>等到一个或多个容器停止，然后打印他们的退出代码</td>
</tr>
</tbody></table>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><hr>
<p><a href="https://docs.docker-cn.com/engine/installation/" target="_blank" rel="noopener">Docker官方中文文档</a><br><a href="http://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html" target="_blank" rel="noopener">Docker入门教程</a><br><a href="https://www.cnblogs.com/CloudMan6/tag/Docker/default.html?page=9" target="_blank" rel="noopener">每天5分钟玩转Docker容器技术</a>  </p>
]]></content>
      <categories>
        <category>持续集成</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>写博客的好与坏</title>
    <url>/2019/01/19/2019-01-19-%E5%86%99%E5%8D%9A%E5%AE%A2%E7%9A%84%E5%A5%BD%E4%B8%8E%E5%9D%8F/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><hr>
<p>&emsp;&emsp;前天，我在<code>V2EX</code>提了一个问题：<strong><a href="https://www.v2ex.com/t/528050#reply120" target="_blank" rel="noopener">程序员坚持写博客有那些好处？或者也有坏处？</a></strong>，截止目前<code>2019-01-19 20:07:03 +08:00</code>，已经都到了共计<code>7581</code>次点击，<code>122</code>次回复，<code>4683</code>人次查看，<code>38</code>人收藏。本博文是为了对该问题进行概括总结。</p>
<a id="more"></a>

<h1 id="好处"><a href="#好处" class="headerlink" title="好处"></a>好处</h1><hr>
<ol>
<li>互联网上留下自己的痕迹；</li>
<li>学习，讨论，记录，积累，巩固，思考，感悟，整理，总结，分享；</li>
<li>能够强化记忆，锻炼写作能力和逻辑，锻炼语言组织能力；</li>
<li>沉淀人的心性，提升思考纬度，开拓眼界，认识自己的不足；</li>
<li>日常踩坑和学习的记录，总结经验，锻炼自己，方便自己，也方便别人；</li>
<li>形成技能上升的闭环：总结归纳知识，推广普及给其他人，取得反馈，然后自己也进步，写下更好的文章。</li>
<li>充实感，成就感；</li>
<li>温故而知新；</li>
<li>其他人展示自己，传递价值观，拓宽影响力的手段；</li>
<li>量的积累造就质的飞跃；</li>
</ol>
<h1 id="坏处"><a href="#坏处" class="headerlink" title="坏处"></a>坏处</h1><hr>
<ol>
<li>可能被 leader 发现工作不够饱满；</li>
<li>写好一篇有深度的好文章耗费时间和精力，否则没有什么技术沉淀，也无意义，还会给人造成不好的印象；</li>
<li>写博客并不是抄博客，简单敷衍不求甚解不可取，写东西要有自己的创造和总结，要讲明逻辑和细节；</li>
</ol>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><hr>
<p style="color:red; font-size:30px;">利大于弊</p>  


<h1 id="附"><a href="#附" class="headerlink" title="附"></a>附</h1><hr>
<p><strong><code>费曼技巧</code></strong>：</p>
<ol>
<li>明确学习目标；</li>
<li>模拟教学学习法；</li>
<li>回顾整个内容；</li>
<li>总结提炼精髓，简化牢记知识。</li>
</ol>
]]></content>
      <categories>
        <category>博客</category>
      </categories>
  </entry>
  <entry>
    <title>教你用认知和人性来做最棒的程序员</title>
    <url>/2019/01/19/%E6%95%99%E4%BD%A0%E7%94%A8%E8%AE%A4%E7%9F%A5%E5%92%8C%E4%BA%BA%E6%80%A7%E6%9D%A5%E5%81%9A%E6%9C%80%E6%A3%92%E7%9A%84%E7%A8%8B%E5%BA%8F%E5%91%98/</url>
    <content><![CDATA[<h2 id="分享"><a href="#分享" class="headerlink" title="分享"></a>分享</h2><p>  今天早上在掘金社区看到一篇文章“教你用认知和人性来做最棒的程序员”，我觉得文章写的不错，也让我产生了一些共鸣，<br>  于是想跟大家一起分享一下，已经通过作者的许可，也会贴出文章的原地址。</p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>不久前，在团队内部和大家做了一次分享，内容就是这次要讲的“用认知和人性来提升自己的技术水平”，大家反响不错，所以这次整理一下也分享给大家。<br>最初我是想用“借优秀的产品经理思维来做最棒程序员”的这个标题，但想想还是要有同理心，技术同学平时和产品同学已经是相爱相杀了，就不刺激大家啦。但是必须要说的是优秀的产品经理思维和优秀的程序员思维确实是殊途同归的，两者是想通的，就是来自认知和人性。</p><a id="more"></a>

<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>这里我不会过多去梳理认知和人性的概念，后面会用很多例子来说明，保证通俗易懂，只想先提2个概念：</p>
<ul>
<li>对人性的理解能帮助提升认知</li>
<li>狭义的技术是指java,php,android,spring,vue等的掌握和实践，它们只是帮助你提升认知的工具，却绝不等同于认知。</li>
</ul>
<p>下面我来逐一举例说明：</p>
<h2 id="例子1-技术选型"><a href="#例子1-技术选型" class="headerlink" title="例子1-技术选型"></a>例子1-技术选型</h2><ul>
<li>问题：今年开始慢慢火的一个移动端跨平台技术是google发布的”flutter”，如果你作为一名移动端的开发人员来评估这门技术是否值得选型作为公司产品的语言框架，你怎么能保证评估不会看走眼？</li>
<li>认知：flutter强化了跨平台的生产效率，且性能比前端框架更好。</li>
<li>解释：很多同学会想，怎么第一句感觉就像废话一样，人家官方文档也是这么写的，这叫什么认知。别急，所谓的认知，就是能够提炼成外人看上去貌似一句很普通的话，但只有经过深度思考的你才知道它真正的价值。在flutter没有出现前，我存在一个认知偏差，我认为客户端一定会被前端诸如react，vue这样的技术取代。<br>因为它们既可以跨平台，也可以随时更新，符合互联网快速变化的节奏。但我的认知存在一个非常严重的漏洞，那就是跨平台和随时更新在客户端技术里的占比各应该是多少？哪个更重要？经过分析思考，以我们公司当前用户量的发展阶段，提升跨平台的生产效率且不损失太多性能更重要，所谓的运营快速需求变化有时候可以通过事先想清楚，而降低频率。<br>flutter带来的生产效率提升，不仅仅是一个开发可以同时产出android和ios两端应用。更在于产品经理以后只需要和一个开发沟通需求细节，不会再担心出现android和ios功能细节实现偏差的问题了。由于有了这样的认知，虽然flutter作为新技术，还有需要完善的地方。但这不是主要问题，我们愿意为它去冒险，在我们的产品里去尽快实践。</li>
<li>人性：最后多说一句，为什么google先做了kotlin后又做了flutter呢？我的认知是：大公司两个部门做重复轮子很正常，互相竞争，看谁更好。一个想试探性取代java以避免被oracle捏住命脉（如果接受的人多，将来把底层的jvm再抽掉），一个野心更大希望统一所有平台，不同部门的想法而已。大家不要把google的布局想得那么纯粹技术化，大家都是人嘛。人脱离不了：竞争，征服，自保的人性。:)</li>
</ul>
<h2 id="例子2-查线上问题"><a href="#例子2-查线上问题" class="headerlink" title="例子2-查线上问题"></a>例子2-查线上问题</h2><ul>
<li>问题：觉得查线上问题很痛苦，压力很大，查得也不快怎么办？</li>
<li>认知：1 查线上问题是成本最小的，锻炼逻辑思维的方式，相比写代码更有效率。 2 查问题要看本质，抓住案发第一现场</li>
<li>解释：很多同学碰到线上问题的时候，都很痛苦，因为要加班了耽误我学习技术的时间，所以有时查问题态度也不积极。这个认知是非常错误的，大家平时都会认可优秀程序员的核心特质看的是思维逻辑，而不是用哪个语言哪个技术。那如果是思维逻辑优先，写代码就能比查线上问题更能提升吗？显然不是，大家知道我们在写代码时，往往要花费很多时间在编写冗余代码（如get,set代码，配置文件），<br>普通的crud逻辑，编译，部署等这些非核心点上，它们并不能帮助我们提升思维（动手写代码前的思考才是最核心的）。但是查线上问题就不一样了，你不需要写任何代码，但是需要在很短时间内，让自己理清思路，按正确的步骤去查出代码的核心问题，底层系统的核心问题。你需要对系统很了解，对业务逻辑很了解，对代码细节很了解，这真是一个几乎没有任何冗余步骤，但是却能快速提升严谨思维的好方式！<br>怎么让查问题更有效率？其实很简单，我们如果借鉴名侦探柯南的想法，那就是“抓住案发第一现场”。举两个例子，对于JAVA这样的静态语言，查询线上日志的方法是非常重要的。很多同学发现某个请求出问题了，就去看当次请求的日志，这种方式不一定准确。因为对于静态语言，它的案发第一现场可能已经不是当次请求了，很有可能是首次发生这个问题的时候，或者服务器刚刚启动的时候（静态语言的”缓存”特色）。<br>当你发现上层的业务系统发生了mysql死锁的报错，就不要太纠结于上层业务系统的日志了。应该去看mysql的bin log，抓住这个案发第一现场，看看到底发生了什么。不知道怎么解决线上问题，99%是因为连案发第一现场都没找到，等你找到了，基本也有解决方法了。</li>
<li>人性：每个人都喜欢做省力的事情，喜欢的事情。但是人往往有偏见，根本没有想明白查线上问题的价值，就认为这是一个很low的事，是不可取的。对自己不了解的，未知的事物，应该敬畏和学习。</li>
</ul>
<h2 id="例子3-技术面试"><a href="#例子3-技术面试" class="headerlink" title="例子3-技术面试"></a>例子3-技术面试</h2><ul>
<li>问题：很多同学的技术经验已经很扎实了，也能写出很稳定的代码，但是作为技术面试官，为什么老是会看走眼呢？</li>
<li>认知：对应聘者而言，能否独立解决问题是能通过面试的及格线，应聘者专业技术的掌握程度只决定offer薪资的高低。</li>
<li>解释：是不是觉得又来歪论拉？恩，继续解释一番。首先问你，你为什么要招人，我想信很多人都会这么说：当然是找你来帮我干活啊，我现在天天干到11点，累死了，急需人帮忙啊。恩，所以你很清楚，这个人是要能独立解决问题的，能帮你分担的，不是来了还要你天天在那里盯着的。但是我们看到很多同学的内心认知是混乱的，虽然他能看懂这句话，但是在面试的时候他会这么做：准备10个左右他擅长的技术细节问题，一个个问，应聘者只能答出5个，废柴，不送。答出7个，恩，可以进来。<br>答出10个，还说了1个我不知道的，好牛逼，绝不能让他看出来我比他弱，否则进来后还怎么带他。但是这个和你之前痛恨的应试教育又有什么区别呢？这种招聘方式有很大的风险招进来的人是研究手机屏幕从几楼摔下去不会碎，而不是研究让屏幕显示更清晰的人。<br>正确的方式应该是：让他讲一个之前投入度比较高的项目，描述下自己是怎么独立去解决问题的。对每一个点的描述，只要你觉得还不能体现他“独立解决问题”的能力，那就继续扒皮深问，直到他竭尽全力，被你”逼到墙角”。特别优秀的人被逼到墙角后，具备现场把墙砸掉的能力，这样的人是死也不能放过的，具体什么意思大家可以去体会思考。<br>之前我们曾经面试过一个性能测试工程师，从技术细节看对性能测试的工具和方法是比较了解的。在项目描述中我们问了他一个问题：你之前通过性能压测发现的服务端问题，有去了解过发生的原因吗？他给的答复是：因为我们是外企，制度比较明确，开发也是另外一个部门，所以我没有去了解。不好意思，这个回答基本体现了没有独立解决问题的能力乃至意识。碰到一堵很小的墙，他都没有办法独立解决，好奇和学习的欲望也很弱。他在技术细节上的积累只是因为看了几本书，用了几次工具，这些都只是为了应付面试和不懂的领导，根本没有深入实践，他未来的瓶颈一定非常大。<br>只要能够独立解决问题，就一定能通过面试，有些技术不了解，最多就是被砍点薪资而已。在这一点上，10年工作经验的同学还真未必比得上2-3年工作经验的同学，如果没有独立解决问题的能力，那只是多累积了一些所谓的专业经验，但还是无法解决问题。很多大公司喜欢校招优秀的毕业生，也是这个原因，虽然这些学生还没有实际工作过，但已经具备了很强的独立解决问题能力。我们曾经招过一名同济大学的测试实习生，有一次她独立组织了部门的团建活动，搞得井井有条，方方面面都考虑到了，这样的同学做好技术只是时间问题。:)</li>
<li>人性：应聘者的人性有哪些呢？懒：影响独立解决问题的意识。 要面子：比如刚刚举的例子，拿公司制度掩盖自己无法独立解决问题的现状。（并且他自己是意识不到的，因为他内心的认知是混乱的） 盲目自信又不自信：对自己做的熟的东西盲目自信，对没接触过的技术很不自信。</li>
</ul>
<h2 id="例子4-最严重的线上故障"><a href="#例子4-最严重的线上故障" class="headerlink" title="例子4-最严重的线上故障"></a>例子4-最严重的线上故障</h2><ul>
<li>问题：到底是什么原因，会导致严重的线上故障呢？是我们团队的技术水平不高，还是流程问题才造成了如此严重的故障呢？</li>
<li>认知：个体的过失很难造成严重的线上故障。真正的原因是：集体性的认知出错。</li>
<li>解释：在现代微服务的架构下，各服务之间的解耦性已经做得非常好了，总体来说出现全面严重问题的概率已经降得非常多了。就像一个国家一样，不怕局部的腐败，怕的是整个链条的腐败。举个例子，如果一个系统上线前，需要在数据库里配置一个关键的参数，如果不配置会导致很多请求处理错误。但是开发同学发生了错误的认知，潜意识里认为配置不是写代码=配置没有写代码技术含量高=配置没有写代码重要，最后把它忘了。测试同学认为测试配置不是测试新写的代码=优先测试新写的代码，再测试配置=测试代码比测试配置更重要，最后把它也忘了。<br>那这基本上是救不回来了，上线后一定会发生严重的问题，每个链条的检查机制都失灵了。坚决预防集体性的认知出错，就可以避免很多严重的问题。<br>集体性的认知出错往往是从一些小现象开始的，比如我们的团队曾经发生过一次正常的项目延期，原因是周五到了，没有完成测试，为了避免仓促上线出问题，所以延期一天发布。其实到这里都是非常正常的，但是当测试同学在钉钉群里发出这个原因的时候，有一些同学发出了大拇指的表情。注意，这个时候大家是没有犯错的，但是认知已经出现了偏差，变成了“以后就算测不完，只要说项目风险，就可以延期”。群里很多同学都看着，一旦这个集体性的认知偏差形成，未来项目的延期就会越来越多。所以需要立刻出来说一句：因为风险项目暂时不上可以，但是延期的原因要总结反思。<br>通过这样一句让大家心里不太舒服的话，尽快把集体性认知偏差扭转过来。<br>马云说过”小事要大做”，就是这个道理，不大做，等发生大事的时候就来不及了。</li>
<li>人性：盲目自信：对自己做的领域有天然的偏见，哪个重要，哪个不重要。随大流：别人也这么做了，应该不会错，还省力，我也这么做。懒：默守所谓的安全方案，其实在那个场景下已经不安全了，但是内心认知出现偏差，懒得去破局改进。</li>
</ul>
<h2 id="例子5-如何看待代码逻辑复用"><a href="#例子5-如何看待代码逻辑复用" class="headerlink" title="例子5-如何看待代码逻辑复用"></a>例子5-如何看待代码逻辑复用</h2><ul>
<li>问题：对于代码逻辑的复用，大家的看法往往不一样，有些同学认为只要是有公共性的代码都该不断抽出通用函数复用。有些则认为对重要的通用逻辑才该复用，过度复用反而增加成本。</li>
<li>认知：能力该复用，业务不该复用。分久必合，合久必分。</li>
<li>解释：这里提出了两个认知，我们来分别解释下。能力该复用，业务不该复用，这个很好理解。能力是指对这个系统有价值的功能，会长期存在且扩展下去的。而业务是一个泛指，既可以表示单一的产品需求，也可以表示某个局部的功能。比如你的应用里接入了一个支付宝支付，对支付这个事情我们判断下来是一个基础核心能力，且将来很有可能也要接入微信支付，所以应该抽出公共的函数。<br>再比如对于客户端的登录页面和注册页面，虽然渲染逻辑90%是一样的，但是不应该复用，因为它们是单一功能，不是能力，贸然复用反而带来了很大的风险。<br>分久必合，合久必分，这个的理解就很有意思了。大家都知道，这句话的出处来自三国演义，说的是一个国家分裂久了就会合并，合并久了也会分裂，其实对代码逻辑的复用也是如此。大家在合并抽出公共函数时，会发现有10%-20%的逻辑不是那么顺眼，总感觉暂时放在里面是可以的，但将来可能会拆出来。那么在写公共函数时，就要特别注意这部分逻辑。它虽然暂时在函数里，但是需要做到和上下文相对隔离，甚至还可以加入明显的换行和TO DO，为下一次的拆做好准备。<br>而在拆出一些独立逻辑的时候，也要思考这些逻辑可能和其它的哪些逻辑有机会是合起来的，那么尽量放在一个类里，一个包里，为后续的合做好准备。</li>
<li>人性：不要刻舟求剑，妄图用一套规则来应对外部复杂变化的世界，要因地制宜，实事求是，学会变通。</li>
</ul>
<h2 id="例子6-开源的意义"><a href="#例子6-开源的意义" class="headerlink" title="例子6-开源的意义"></a>例子6-开源的意义</h2><ul>
<li>问题：为什么现在很多中国的互联网公司开始重视开源的宣传了？</li>
<li>认知：开源直接决定了公司的成本收入，以及人才储备</li>
<li>解释：是不是要崩溃了，开源无偿写代码，然后免费给别人用，不是在消耗公司成本吗？别急，还记得马云说过的一句话吗，“免费的才是最贵的”。恩，这个道理同样适用于开源。今天中国很多的互联网公司已经非常明白了，甭管你的开源技术到底好不好用，宣传一定要大，一定要让大家参与进来。<br>带来的好处太多了，因为用了你的开源消息队列，之后就会用你的云计算平台。因为程序员都很懒，开发环境和线上保持一套嘛，你后面一定能赚大钱。因为开源项目非常知名，让你公司的技术形象立刻高大起来（先不管这个项目到底创造了多少有价值的产品），每年校招的优质学生资源尽收囊中，其他公司要抢人，只能花更多的钱。而每年中国优秀的毕业生就那么多，早就供需失衡，谁抢到了大部分，那之后在技术上一定能保持绝对优势。<br>最后万一公司财报不好看了，不好意思开始收授权费，就像google收android的费用一样。不作恶只是口号，开源带来了无比巨大的利益，不能赚钱，谁开源？！现在微软也懂了这个道理，成为了开源社区的标杆，但在早期的鲍尔默时代可是出现了认知偏差呢。</li>
<li>人性：开源者的人性：追求利益，喜欢声誉。 接受开源的人：渴望进步，赚便宜，崇拜权威。</li>
</ul>
<h2 id="关键点：如何提升认知"><a href="#关键点：如何提升认知" class="headerlink" title="关键点：如何提升认知"></a>关键点：如何提升认知</h2><h3 id="内心简单"><a href="#内心简单" class="headerlink" title="内心简单"></a>内心简单</h3><p>  内心越简单的人，将来能到达的境界就越高。大家千万不要误解了，我说的不是思想浅薄，而是内心简单纯粹要像少年一样。一个很好的例子，郭靖，用世俗的眼光来看他天资不高，开始学什么都慢。但是他有一个很大的优点，就是想法简单，无私心，持之以恒。报家仇，报国仇，保护好他爱的人，不会去想是不是别人骗了他，他多做一点是不是亏了。20岁就达到五绝水平，最后终于融合“降龙十八掌”、“九阴真经”和“左右互搏”三大盖世武功为一体，武林尊为“天下第一侠士”。<br>  内心越简单，就越不会花费额外的精力在一些无关紧要的事上面。随着时间的推移，你的认知水平就一定能提升得更快。不要去想今天你学的语言明天是否还流行，先利用当前语言训练好你的思维模式。不要去想我作为测试给开发指出太多问题后，开发会不会不爽，做为测试你的核心是保证产品质量。不要去想今天我帮组内的开发分担了额外的代码编写，我是不是亏了，这些付出一定会在将来某个时候兑现，因为你比他们有更多的代码实践。</p>
<h3 id="相信跨界的力量"><a href="#相信跨界的力量" class="headerlink" title="相信跨界的力量"></a>相信跨界的力量</h3><p>  ipod+手机诞生了iphone，手机+钱包诞生了支付宝，c,python+java诞生了go，人类的创新其实都是来自于跨界的结合。很多时候大家去看一个技术大神，会认为他一定是看了很多专业的书，看了很多牛逼开源项目的代码，写了很多项目才达到现在的这个水平。然后又看到别人的兴趣爱好：音乐，滑雪，画画，牛逼，大神就是大神，做好技术的同时还能“兼顾”这些兴趣。<br>  这个认知完全错了好吗，我告诉你，写代码看书固然很重要，但如果他没有这些兴趣，他在技术上可能根本达不到今天的程度。一个有画画功底的人，理解向量，理解数据的PCA分析就是快好吗。一个财务出身的人，写支付系统的代码就是不容易出错好吗。人类的大脑从来都是一个网状的，互相关联的知识图谱，根本不存在靠”单一事物”修炼成功的好吗。千万不要成为技术上的孔乙己，天天学各种API的写法，和学习茴香豆的茴字有几种写法没有任何区别。<br>  在方案想不出来的时候，在代码水平感觉到瓶颈的时候，在看不懂一些专业书籍的时候，一定要跳出来，和自己的兴趣结合，和自己经历结合，和自己的生活结合，这样才能突破瓶颈，提升到更上一层的认知。</p>
<h2 id="相信更高认知人的指引"><a href="#相信更高认知人的指引" class="headerlink" title="相信更高认知人的指引"></a>相信更高认知人的指引</h2><p> 科幻神作三体里，外星人看地球人就像纸片一样，在三体人的眼中，地球人是二维的，而不是三维的。回到现实中，高认知的人看低认知的人也是一样的，不是低认知的人不够努力，而是你的知识图谱里比高认知的人少了一些维度。所以不管你怎么努力，你会发现仍旧无法超过他，他还比你轻松，学霸给大家留下的阴影就是这么来的。<br> 在实际工作中，你的leader，你的架构师只要不是水货，往往他们的认知就是比你高的。一旦你觉得这个人的本性是靠谱的，你就该无条件去相信他给你的建议和指引。因为他能看到在你那个维度上感受不到的东西，照他的话去实践几次，你才有机会到达他那个维度，才能升级认知。不过在现实情况中，我们往往看到很多leader和架构给下面的同学苦口婆心说了很多，但是他们不理解，反而更叛逆。这份痛苦我懂，你是拼了命想拉他到你那个维度，但是他还年轻着呢。:)</p>
<h2 id="持之以恒地实践"><a href="#持之以恒地实践" class="headerlink" title="持之以恒地实践"></a>持之以恒地实践</h2><p>人就是一个如此奇妙，如此复杂的生物，不管你看多少书，看多少源码，写多少demo，你不真刀真枪地去实践，去写代码，这些知识无论如何都无法进入你大脑的知识图谱。它们永远只能是“狭义上的知识”，而不是“有价值的认知”。相信大家人生中都有过类似的经历了，越是辛苦的实践，越是坚持，你最后的收获一定越大。简单来说，认知不通过持之以恒的实践是不可能升级的。<br>还有一点我必须要强调，实践应该尽量和公司的项目去结合，而不是依靠于自己写demo。这里面有一个很大的误区，自己私下写demo经常是没有“明确，高压的”目标的（人性总是偏懒的），这种实践往往很难提升认知。而公司的项目往往不同，会提出”支持多少用户访问”，“为什么你每次开发都不能更快一点”（核心挑战的是你架构的扩展能力），“为什么这个功能这么卡”（性能优化），这些“明确的，高压的”目标能督促你去拼命提升自己的认知（只是写demo是很难给自己设下这些障碍的，是反人性的）。<br>当然从结果来看，又是公司的压榨剥削拉，让我们回忆一下前面说的，如果你觉得这个公司是靠谱的，那就让我们的“内心简单一点”，持之以恒地实践升级认知吧。:)<br>最后总结一下，现在已经不是一个单纯比拼知识量的时代，而是比拼认知高低的时代。作为程序员我们并不特殊，和市场，财务，产品，运营的这些同学一样，核心看的是认知，并不存在谁比谁困难，谁比谁辛苦的这种浅层比较。<br>而我们学习的那些语言，框架，工具，和我们大学时期学习的微积分，高等物理没有区别，都只是帮助我们不断训练提升认知的实践工具，而不是认知本身。让我们不要再局限于程序员狭义技术的范畴内，把提升自己的认知作为最重要的目标，我们要努力做到“既是程序员，也不是程序员”。</p>
<p>最后总结一下，现在已经不是一个单纯比拼知识量的时代，而是比拼认知高低的时代。作为程序员我们并不特殊，和市场，财务，产品，运营的这些同学一样，核心看的是认知，并不存在谁比谁困难，谁比谁辛苦的这种浅层比较。<br>而我们学习的那些语言，框架，工具，和我们大学时期学习的微积分，高等物理没有区别，都只是帮助我们不断训练提升认知的实践工具，而不是认知本身。让我们不要再局限于程序员狭义技术的范畴内，把提升自己的认知作为最重要的目标，我们要努力做到“既是程序员，也不是程序员”。</p>
<p>作者：刘轶<br>链接：<a href="https://juejin.im/post/5c3f23606fb9a049b50715f0" target="_blank" rel="noopener">https://juejin.im/post/5c3f23606fb9a049b50715f0</a><br>来源：掘金</p>
]]></content>
      <tags>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title>etcd-raft LeaseRead 线性一致性源码简析</title>
    <url>/2019/01/16/etcd-raft-LeaseRead-%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/</url>
    <content><![CDATA[<p>上篇文章阐述的是<code>etcd-raft</code>基于<code>ReadIndex</code>实现线性一致性的相关逻辑，这包括上层应用程序对客户端读请求的控制，以及底层协议库实现<code>ReadIndex</code>线性一致性的逻辑，另外，也简单阐述了线性一致性相关理论，包括顺序一致性及严格一致性。本文的主题同样是线性一致性，但是是<code>etcd-raft</code>提供的另一种实现方式：<code>LeaseRead</code>。相比于基于<code>ReadIndex</code>的实现，它性能更好，因为它没有<code>heartbeat</code>开销，但它却不能保证绝对意义上的线性一致性读，这依赖于机器时钟，工程实现只能尽可能保证在实际运行中不出错。基于<code>lease</code>的线性一致性读的原理和实现都比较简单。</p>
<a id="more"></a>

<p>上篇文章谈到过，基于<code>ReadIndex</code>实现的线性一致性的一个关键步骤即为<code>leader</code>通过广播心跳来确保自己的领导地位，显然这会带来网络开销（虽然实际中这种开销已经很小了）。因此可以考虑进一步优化。在<code>Raft</code>论文中提到了一种通过<code>clock + heartbeat</code>的<code>lease read</code>的优化方法，即每次当<code>leader</code>发送心时，先记录一个时间<code>start</code>，当<code>quorum</code>节点回复<code>leader</code>心跳消息时，它就可以将此<code>lease</code>续约到<code>start + election timeout</code>时间点，当然实际上还要考虑时钟偏移（<code>clock drift</code>），其中的原理也比较简单，因为任何时候若<code>follower</code>节点想发起新的一轮选举，必须等到<code>election timeout</code>后才能进行，这也就间接保证了在这段时间内无论什么情况（比如网络分区），<code>leader</code>都绝对拥有领导地位。再次强调，这依赖于机器的时钟飘移速率，换言之，若各机器之间的时钟差别过在，则此种基于<code>lease</code>的机制就可能出现问题。</p>
<p>下面结合<code>etcd-raft</code>的源码来简单梳理这个过程。我们重点关注两个逻辑：其一，在<code>lease</code>有效期内，<code>leader</code>如何处理读请求。其二，<code>leader</code>如何更新（续约）其<code>lease</code>。</p>
<h2 id="基于-lease-read-的线性一致性"><a href="#基于-lease-read-的线性一致性" class="headerlink" title="基于 lease read 的线性一致性"></a>基于 lease read 的线性一致性</h2><p>基于<code>lease read</code>同基于<code>ReadIndex</code>实现的线性一致性在应用程序层的逻辑是一致的，不作多阐述。重点了解协议库是如何处理的。同样，我们定位到<code>leader</code>的<code>stepLeader()</code>函数，同样是<code>MsgReadIndex</code>分支：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">stepLeader</span><span class="params">(r *raft, m pb.Message)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">switch</span> m.Type &#123;</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">case</span> pb.MsgReadIndex:</span><br><span class="line">		<span class="keyword">if</span> r.quorum() &gt; <span class="number">1</span> &#123;</span><br><span class="line">			<span class="comment">// 1. 如果 leader 在当前任期内没有提交过日志，则直接返回，不处理此 ReadIndex 请求</span></span><br><span class="line">			<span class="comment">// 否则会造成 过期读 甚至不正确的读</span></span><br><span class="line">			<span class="keyword">if</span> r.raftLog.zeroTermOnErrCompacted(r.raftLog.term(r.raftLog.committed)) != r.Term &#123;</span><br><span class="line">				<span class="comment">// Reject read only request when this leader has not committed any log entry at its term.</span></span><br><span class="line">				<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">// 2. 判断线性一致性读的实现方式</span></span><br><span class="line">			<span class="keyword">switch</span> r.readOnly.option &#123;</span><br><span class="line">			<span class="keyword">case</span> ReadOnlySafe: <span class="comment">// 3. 采用 ReadIndex 实现</span></span><br><span class="line">				<span class="comment">// ...</span></span><br><span class="line">			<span class="keyword">case</span> ReadOnlyLeaseBased: <span class="comment">// 4. 采用 leaseBase 实现</span></span><br><span class="line">				ri := r.raftLog.committed <span class="comment">// 4.1 获取当前的 commit index</span></span><br><span class="line">				<span class="comment">// 4.2 如果是本地的请求，则直接将 ReadState 追加到数组中，里面包含了 leader 的 commit index 及 ctx（请求唯一标识）</span></span><br><span class="line">				<span class="keyword">if</span> m.From == None || m.From == r.id &#123; <span class="comment">// from local member</span></span><br><span class="line">					r.readStates = <span class="built_in">append</span>(r.readStates, ReadState&#123;Index: r.raftLog.committed, RequestCtx: m.Entries[<span class="number">0</span>].Data&#125;)</span><br><span class="line">				&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">					<span class="comment">// 4.3 如果 follower 节点转发的，则直接向其回复 MsgReadIndexResp 消息，并带上commit index 及 Entries</span></span><br><span class="line">					r.send(pb.Message&#123;To: m.From, Type: pb.MsgReadIndexResp, Index: ri, Entries: m.Entries&#125;)</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			r.readStates = <span class="built_in">append</span>(r.readStates, ReadState&#123;Index: r.raftLog.committed, RequestCtx: m.Entries[<span class="number">0</span>].Data&#125;)</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125; <span class="comment">// /etcd/raft/raft.go</span></span><br></pre></td></tr></table></figure>

<p>上面的流程很简单，不多阐述。需要注意的一点是，若是 <code>follower</code> 收到读请求，其基于<code>lease read</code>的处理逻辑同基于<code>ReadIndex</code>一致，即要先向<code>leader</code>查询<code>commit index</code>。下面重点了解<code>lease</code>的续约逻辑。</p>
<h2 id="lease-续约"><a href="#lease-续约" class="headerlink" title="lease 续约"></a>lease 续约</h2><p>在阐述<code>lease</code>具体的续约准则之前，我们先了解下在<code>etcd-raft</code>中，触发检测<code>lease</code>是否过期的相关代码，因为<code>leader</code>要确保自己的领导地位，因此它必须周期性地检查自己是否具备领导地位。它通过周期性地向自己发送<code>MsgCheckQuorum</code>类型消息来验证自己是否具备领导地位（即此次<code>lease</code>是否能成功续约）。代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// leader 会周期性地给自己发送 MsgCheckQuorum 消息</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *raft)</span> <span class="title">tickHeartbeat</span><span class="params">()</span></span> &#123;</span><br><span class="line">	r.heartbeatElapsed++</span><br><span class="line">	r.electionElapsed++</span><br><span class="line">	<span class="comment">// 若达到了 electionTimeout 的时间（并非 heartbeat timeout），则需要向自己发送消息</span></span><br><span class="line">	<span class="keyword">if</span> r.electionElapsed &gt;= r.electionTimeout &#123;</span><br><span class="line">		r.electionElapsed = <span class="number">0</span></span><br><span class="line">		<span class="keyword">if</span> r.checkQuorum &#123;</span><br><span class="line">			r.Step(pb.Message&#123;From: r.id, Type: pb.MsgCheckQuorum&#125;)</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// If current leader cannot transfer leadership in electionTimeout, it becomes leader again.</span></span><br><span class="line">		<span class="keyword">if</span> r.state == StateLeader &amp;&amp; r.leadTransferee != None &#123;</span><br><span class="line">			r.abortLeaderTransfer()</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">&#125; <span class="comment">// /etcd/raft/raft.go</span></span><br></pre></td></tr></table></figure>

<p><code>leader</code>同样在<code>stepLeader()</code>函数中处理<code>MsgCheckQuorum</code>类型的消息：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">stepLeader</span><span class="params">(r *raft, m pb.Message)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">switch</span> m.Type &#123;</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">case</span> pb.MsgCheckQuorum:</span><br><span class="line">		<span class="keyword">if</span> !r.checkQuorumActive() &#123;  <span class="comment">// 检查是否 quorum 节点仍然活跃</span></span><br><span class="line">			r.logger.Warningf(<span class="string">"%x stepped down to follower since quorum is not active"</span>, r.id)</span><br><span class="line">			r.becomeFollower(r.Term, None)</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125; <span class="comment">// /etcd/raft/raft.go</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *raft)</span> <span class="title">checkQuorumActive</span><span class="params">()</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> act <span class="keyword">int</span></span><br><span class="line">	<span class="comment">// 循环检查 leader 维护的 progress 对象数组，来判断对应的节点是否活跃</span></span><br><span class="line">	r.forEachProgress(<span class="function"><span class="keyword">func</span><span class="params">(id <span class="keyword">uint64</span>, pr *Progress)</span></span> &#123;</span><br><span class="line">		<span class="keyword">if</span> id == r.id &#123; <span class="comment">// self is always active</span></span><br><span class="line">			act++</span><br><span class="line">			<span class="keyword">return</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> pr.RecentActive &amp;&amp; !pr.IsLearner &#123;</span><br><span class="line">			act++</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 并且在每次检查完毕后，都要重置它，以确保下一次检查不会受到此次结果的影响</span></span><br><span class="line">		pr.RecentActive = <span class="literal">false</span></span><br><span class="line">	&#125;)</span><br><span class="line">	<span class="comment">// 若存在 quorum 节点活跃，则返回 true</span></span><br><span class="line">	<span class="keyword">return</span> act &gt;= r.quorum()</span><br><span class="line">&#125; <span class="comment">// etc/raft/raft.go</span></span><br></pre></td></tr></table></figure>

<p>关于<code>lease</code>续约不同的系统可能有不能的实现，但其目的只有一个：确认<code>follower</code>依然遵从<code>leader</code>的领导地位。这可以从几个方面体现出来，其一，如果每次<code>leader</code>发送的心跳消息(<code>MsgHeartbeat</code>)，节点都响应了，则证明此节点依然受到<code>leader</code>的领导。其二，若每次<code>leader</code>发送的日志同步消息(<code>MsgApp</code>)，节点都响应了，则同样能够证明<code>leader</code>的领导地位。最后，其实在节点刚刚加入集群时，也标记其接受<code>leader</code>的领导。这就是<code>RecentActive</code>所被标记为<code>true</code>的地方。因此，每当触发了<code>election timeout</code>事件，<code>leader</code>都需要重新检查自己是否仍然具备领导地位，实质上就是检查每个节点的<code>RecentActive</code>是否被设置，如果具备，则表明成功续约了<code>lease</code>，因此可以不经额外的处理，就能够直接返回自身的<code>commit index</code>作为<code>ReadIndex</code>的响应。整个流程比较简单，其中原理也较容易理解。</p>
<p>简单小结，本文先是简单阐述了关于<code>lease read</code>实现线性一致性（比基于<code>ReadIndex</code>的实现更有效率）的基本原理，然后结合<code>etcd-raft</code>的实现来进一步细化理解整个过程，这包括两方面：其一是基于<code>lease read</code>线性一致性的处理逻辑（在<code>lease</code>有效期内）。其二是<code>lease</code>的续约过程，即何时触发续约事件，以及续约的条件是什么。值得一提的是，不同的系统的对续约条件的实现可能不同，而且为了尽可能保证基于<code>lease</code>实现的线性一致性的正确性，会加入一些优化动作。</p>
<p>参考文献</p>
<p>[1]. <a href="https://github.com/etcd-io/etcd/tree/master/raft" target="_blank" rel="noopener">https://github.com/etcd-io/etcd/tree/master/raft</a><br>[2]. <a href="https://zhuanlan.zhihu.com/p/31118381" target="_blank" rel="noopener">etcd-raft的线性一致读方法二：LeaseRead</a></p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>分布式协调服务</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>线性一致性</tag>
      </tags>
  </entry>
  <entry>
    <title>etcd-raft ReadIndex 线性一致性读源码简析</title>
    <url>/2019/01/15/etcd-raft-ReadIndex-%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7%E8%AF%BB%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/</url>
    <content><![CDATA[<p>上篇文章阐述了<code>etcd-raft</code>集群配置变更源码的相关逻辑，同时，在理论层面，从正反两个方面简要y论述了一次集群配置变更只能涉及到一个节点的原因。本文的主题为<code>etcd-raft</code>使用<code>ReadIndex</code>来实现线性一致性(<code>linearizability</code>)的实现原理。这包括两个方面，首先简要阐述线性一致性的理论知识，其次是结合<code>etcd-raft</code>的源码来简单梳理其如何使用<code>ReadIndex</code>来保证读请求的线性一致性。线性一致性广泛被应用于分布式应用中，是用于衡量一个并发系统是否正确的重要标准，我们通常谈论的<code>CAP</code>中的<code>C</code>指的即为线性一致性。需要说明的是，<code>etcd</code>是基于<code>raft</code>来提供一致性保证，虽然共识算法被用于保证状态的一致性，但并不代表实现共识算法的系统就自动具备了线性一致性，这是两个概念，换言之，<code>etcd-raft</code>必须在实现<code>raft</code>的基础上额外增加一些逻辑来保证系统具备线性一致性。</p>
<a id="more"></a>

<h2 id="线性一致性"><a href="#线性一致性" class="headerlink" title="线性一致性"></a>线性一致性</h2><p>简单而言，线性一致性是针对单个对象的单个操作的一种保证，它对单个对象的一系列操作（读和写）提供了一种实时的保证，即它们可以按照时间进行排序。不精确地说，<code>linearizability</code>可以保证：</p>
<ul>
<li>一旦写操作写入了某个值，后面的（由<code>wall-clock</code>定义）读操作应该至少能够返回之前写的最新的值，换言之，它也可以返回之后的写操作所写入的值（注意不一定是读操作之前的最新的写的值）</li>
<li>一旦读操作返回了某个值，后面的读操作应该返回前一个读操作所返回的值，或者返回之后的写操作所写入的值。（注意不一定的是读之前最新的值）</li>
</ul>
<p>并且线性一致性是可组合的(<code>composable</code>)，如果系统中每一个对象上的操作都符合线性一致性，那么系统中的所有操作都符合线性一致性。</p>
<p>另外，顺序一致性(<code>serializability</code>)很容易同线性一致性混淆。但实际上二者有较大的区别。且不严谨地说，线性一致性比顺序一致性提供更强的一致性保障语义。另外，不同于线性一致性属于分布式系统（并发编程系统）的概念，而顺序一致性是数据库领域的概念，它是对事务的一种保证，或者说，顺序一致性是针对一个或多个对象的一个或多个操作的一种保证。具体而言，它保证了多个事务（每个都可能包含了一组对于不同对象的读或写操作）的执行的效果等同于对这些事务的某一个顺序执行的效果。</p>
<p>顺序一致性是<code>ACID</code>中的<code>I</code>，且若每个事务都保证了正确性（<code>ACID</code>中的<code>C</code>），则这些事务的顺序执行也会保证正确性，可见，顺序一致性是数据库关于事务执行正确性的一种保证。不同于线性一致性，顺序一致性不会对事务执行的顺序强加任何实时的约束，换言之，其不需要事务的所有操作按照真实时间（应用程序指定的）严格排序的，只需要存在一个满足条件的顺序执行的顺序即可。最后顺序一致性也是不可组合的(<code>composable</code>)。</p>
<p>将线性一致性同顺序一致性结合起来，便是严格一致性(<code>serializability</code>)，即事务执行的行为等同于某一个顺序（串行）执行的效果，且这些串行的顺序对应实时的顺序。举一个简单的例子，如果存在两个事务<code>T1</code>及<code>T2</code>，我们先执行<code>T1</code>，<code>T1</code>中包含写<code>x</code>的操作，最后提交<code>T1</code>。我们然后执行<code>T2</code>，包含了读<code>x</code>的操作，然后提交它。若一个数据库系统满足严格一致性，则其会先执行<code>T1</code>并提交，然后才执行<code>T2</code>提交<code>T2</code>，因此<code>T2</code>能够读到<code>T1</code>中写入<code>x</code>的值，但如果数据库系统只提供顺序一致性，则其可能会将<code>T2</code>排序到<code>T1</code>之前。因此，可以将线性一致性看成是严格一致性的一种特殊情况，即一次执行只针对单个对象的单个操作。</p>
<p>另外论文 <a href="https://cs.brown.edu/~mph/HerlihyW90/p463-herlihy.pdf" target="_blank" rel="noopener">Linearizability: Correctness Condition for Concurrent Objects</a>中给出了线性一致性的定义：</p>
<blockquote>
<p>Linearizability is a correctness condition for concurrent objects that provides the illusion that each operation applied by concurrent processes takes effect instantaneously at some point between its invocation and its response, implying that the meaning of a concurrent object’s operations can be given by pre- and post-conditions</p>
</blockquote>
<p>因此，为了提供线性一致性，一个系统应该保证存在这样一个时间点，在这个时间点之后，系统需要被提交到一个新的状态，并且绝不能返回到之前旧的状态。而且，这样的转变是瞬时的，具备原子性。最后，概括而言，线性一致性必须提供三个方面的保证：a) 瞬间完成（保证原子性），b) 发生在invocation <code>和</code>response`两个事件之间，c) 能够反映出”最新的”值（特别注意这个最新的意义）。</p>
<p>关于此处对顺序一致性的顺序简单（可能不是完全精度）的阐述来源于 <a href="https://pingcap.com/blog-cn/linearizability-and-raft/" target="_blank" rel="noopener">线性一致性和 Raft</a>、<a href="https://medium.com/p/6e579965c4ce/edit" target="_blank" rel="noopener">On Ways To Agree, Part 2: Path to Atomic Broadcast</a> 、 <a href="http://www.bailis.org/blog/linearizability-versus-serializability/" target="_blank" rel="noopener">Linearizability versus Serializability</a> 以及<a href="https://aphyr.com/posts/313-strong-consistency-models" target="_blank" rel="noopener">Strong consistency models</a>。当然你也可以参照 <a href="https://cs.brown.edu/~mph/HerlihyW90/p463-herlihy.pdf" target="_blank" rel="noopener">论文</a>。其中文献[1]举例了一个非常通俗易理解的实例来帮助解读对线性一致性理解的普遍的误区。特别地，文献[2]的<code>comment</code>讨论了关于”实时性”以及”可组合”更精确的含义。</p>
<h2 id="etcd-raft-ReadIndex-线性一致性简析"><a href="#etcd-raft-ReadIndex-线性一致性简析" class="headerlink" title="etcd-raft ReadIndex 线性一致性简析"></a>etcd-raft ReadIndex 线性一致性简析</h2><p>在<code>etcd-raft</code>实现中，所有的写请求都会由<code>leader</code>执行并将请求日志同步到<code>follower</code>节点，且若<code>follower</code>节点收到客户端的写请求，则一般是把写请求转发给<code>leader</code>。那么对于读请求又如何处理呢？虽然<code>etcd-raft</code>能够对日志提供一致性保证，但若不加以协调，两个原因导致在<code>etcd-raft</code>中从不同节点读数据可能会出现不一致：</p>
<ul>
<li><code>leader</code>节点与<code>follower</code>节点存在状态差，因为日志是从<code>leader</code>节点同步至<code>follower</code>节点，但不能保证任何时刻 ，二者的日志完全相同，即<code>follower</code>完全有可能落后于<code>leader</code>。另外<code>follower</code>之间同样如此，即也不能保证所有的<code>follower</code>节点的日志完全一致。因此必须对读操作进行协调。</li>
<li>如果限制只能从<code>leader</code>节点读取（至少<code>leader</code>状态机中最有可能包含最新的数据），这样仍然存在一个问题：若网络发生分区，则包含<code>quorum</code>节点的分区可能选举出一个新<code>leader</code>代替了旧<code>leader</code>，而旧<code>leader</code>却仍然以为自己是作法的<code>leader</code>，并依然处理客户端的读请求，则此时其可能会返回过期的数据，即与从包含<code>quorum</code>节点的分区读到的数据很有可能不同。</li>
</ul>
<p>由此可见，必须对读请求作出限制，首先总结<code>etcd-raft</code>针对<code>leader</code>完成<code>ReadIndex</code>线性一致性读所作的协调处理的大致过程：</p>
<ul>
<li><p><code>leader</code>需要同集群中<code>quorum</code>节点通信，以确保自己仍然是合法的<code>leader</code>。这一点容易理解，在上面的举例当中，若<code>leader</code>处于网络分区中的非<code>quorum</code>中，则其很可能会被取代，因此必须让<code>leader</code>确保自己仍然是<code>leader</code>。</p>
</li>
<li><p>等待状态机至少已经应用<code>ReadIndex</code>记录的日志。注意此处的<strong>至少</strong>两个字，简单而言，若状态机应用到<code>RedaIndex/commit index</code>之后的状态也能够使请求满足线性一致性，这同上文对线性一致性的解释中所强调的是一致的。需要这一条保证的原因是，虽然应用状态机的状态能达成一致，但不能保证多个节点会同时将同一个日志应用到状态机，换言之，各个节点的状态机所处的状态不能<strong>实时一致</strong>。因此，必须根据<code>commit index</code>对请求进行排序，以保证每个请求都至少能反映出状态机在执行完前一请求后的状态，因此，可以认为<code>commit</code>决定了读（也包括写）请求发生的顺序。日志是全局有序的，那么自然而然读请求也被严格排序了。因此这能保证线性一致性。</p>
</li>
</ul>
<p>下文结合源码我们来了解<code>etcd-raft</code>是如何协调处理的。</p>
<p>首先简单了解相关数据结构，相关注释已概述了各结构的含义，主要涉及的代码目录为：<code>/etcd/raft/</code>。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// ReadState 负责记录每个客户端的读请求的状态</span></span><br><span class="line"><span class="comment">// ReadState 最终会被打包放在 Ready 结构中以返回给应用，具体由应用负责处理客户端的读请求</span></span><br><span class="line"><span class="comment">// 即根据 commit index 确定何时才能从状态机中读对应的数据返回给客户端</span></span><br><span class="line"><span class="keyword">type</span> ReadState <span class="keyword">struct</span> &#123;</span><br><span class="line">	Index      <span class="keyword">uint64</span> <span class="comment">// 读请求对应的当前节点的 commit index</span></span><br><span class="line">    RequestCtx []<span class="keyword">byte</span> <span class="comment">// 请求唯一标识，etcd 使用的是 8 位的请求 ID (/etcd/pkg/idutil/id.go)</span></span><br><span class="line">&#125; <span class="comment">// /etcd/raft/read_only.go</span></span><br><span class="line"><span class="comment">// readIndexStatus 用来记录 follower 对 leader 的心跳消息的响应</span></span><br><span class="line"><span class="keyword">type</span> readIndexStatus <span class="keyword">struct</span> &#123;</span><br><span class="line">	req   pb.Message <span class="comment">// 原始 ReadIndex 请求，是应用在处理客户端读请求时向底层协议加发送的请求。</span></span><br><span class="line">	index <span class="keyword">uint64</span> <span class="comment">// leader 当前的 commit index，在收到此读请求时</span></span><br><span class="line">	acks  <span class="keyword">map</span>[<span class="keyword">uint64</span>]<span class="keyword">struct</span>&#123;&#125; <span class="comment">// 记录了 follower 对 leader 的心跳的响应消息，</span></span><br><span class="line">    <span class="comment">// map 的键为 follower 节点的 ID，值是一个空的 struct，没有意义</span></span><br><span class="line">&#125; <span class="comment">// /etcd/raft/read_only.go</span></span><br><span class="line"><span class="comment">// readyOnly 负责全局的 ReadIndex 请求</span></span><br><span class="line"><span class="keyword">type</span> readOnly <span class="keyword">struct</span> &#123;</span><br><span class="line">	option           ReadOnlyOption <span class="comment">// 表示为 ReadOnlySafe 或者 ReadOnlyLeaseBased</span></span><br><span class="line">    <span class="comment">// （两种不同的实现线性一致性的方式，官方推荐前者，也是默认的处理方式）</span></span><br><span class="line">	pendingReadIndex <span class="keyword">map</span>[<span class="keyword">string</span>]*readIndexStatus <span class="comment">// 为一个保存所有待处理的 ReadIndex 请求的 map，</span></span><br><span class="line">    <span class="comment">// 其中的 key 表示请求的唯一标识（转换成了字符串），而 value 为 readIndexStatus 结构实例</span></span><br><span class="line">    readIndexQueue   []<span class="keyword">string</span> <span class="comment">// 请求标识 (RequestCtx) 的数组，同样转换成了 string 进行保存</span></span><br><span class="line">&#125; <span class="comment">// /etcd/raft/read_only.go</span></span><br></pre></td></tr></table></figure>

<p>了解这些数据结构，能够基本感知到它们会被使用在什么地方，或者说它们各自的作用是什么。下面来梳理下<code>etcd-raft</code>所实现的<code>ReadIndex</code>线性一致性的关键流程。</p>
<h2 id="关键流程"><a href="#关键流程" class="headerlink" title="关键流程"></a>关键流程</h2><p>我们仍然从客户端接收请求入手，但由于<code>raftexample</code>中并没有示例读请求的线性一致性的处理流程，因此，只能选择<code>etcd-server</code>来示例（要比 <code>raftexample</code>更复杂，但我们只关注与<code>ReadIndex</code>线性一致性相关逻辑，其它的不作多阐述）。整个过程包括两个大的部分：应用程序处理读请求（对读请求进行协调）以及底层协议库处理<code>ReadIndex</code>请求。</p>
<h3 id="应用程序处理读请求"><a href="#应用程序处理读请求" class="headerlink" title="应用程序处理读请求"></a>应用程序处理读请求</h3><p>此部分相关逻辑涉及到的代码目录为<code>/etcd/etcdserver/</code>。在<code>etcd-server</code>在启动创建是会执行<code>Start()</code>函数，以进行一些在接收并处理请求之前的初始化工作，<code>Start()</code>函数会开启若干个<code>go routine</code>来处理初始化任务，其代码如下所示，其中关键的代码为<code>s.goAttach(s.linearizableReadLoop)</code>，顾名思义，其会开启一个协程来循环处理线性一致性读请求。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 循环处理线性一致性读请求</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *EtcdServer)</span> <span class="title">linearizableReadLoop</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> rs raft.ReadState</span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="comment">// 1. 构建 requestCtx 即请求 ID，且为全局唯一，具体查看 /etcd/pkg/idutil/id.go</span></span><br><span class="line">		ctxToSend := <span class="built_in">make</span>([]<span class="keyword">byte</span>, <span class="number">8</span>)</span><br><span class="line">		id1 := s.reqIDGen.Next()</span><br><span class="line">		binary.BigEndian.PutUint64(ctxToSend, id1)</span><br><span class="line">		<span class="comment">// 2. 判断是否发生了 leader change 事件，若是，则重新执行</span></span><br><span class="line">		leaderChangedNotifier := s.leaderChangedNotify()</span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> &lt;-leaderChangedNotifier:</span><br><span class="line">			<span class="keyword">continue</span></span><br><span class="line">		<span class="comment">// 3. 等待 readwaitc 管道中 pop 出通知，</span></span><br><span class="line">		<span class="comment">// 显然，即为等待客户端发起读请求，具体是在函数 linearizableReadNotify 中 push 通知的</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-s.readwaitc:</span><br><span class="line">		<span class="keyword">case</span> &lt;-s.stopping:</span><br><span class="line">			<span class="keyword">return</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 4. 创建一个 notifier，替换原有的。它类似于一个 condition 并发语义</span></span><br><span class="line">		nextnr := newNotifier()</span><br><span class="line">		s.readMu.Lock()</span><br><span class="line">		nr := s.readNotifier</span><br><span class="line">		s.readNotifier = nextnr</span><br><span class="line">		s.readMu.Unlock()</span><br><span class="line">		lg := s.getLogger()</span><br><span class="line">		<span class="comment">// 这里构建一个可取消的机制</span></span><br><span class="line">		cctx, cancel := context.WithTimeout(context.Background(), s.Cfg.ReqTimeout())</span><br><span class="line">		<span class="comment">// 5. 一旦收到一个客户端的读请求，则向底层协议库发送 ReadIndex 请求</span></span><br><span class="line">		<span class="comment">// 底层协议库会构建一个类库 MsgReadIndex 的消息，并将 ctxToSend 作为 Message 的 Entry.Data</span></span><br><span class="line">		<span class="keyword">if</span> err := s.r.ReadIndex(cctx, ctxToSend); err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="comment">// ...</span></span><br><span class="line">		&#125;</span><br><span class="line">		cancel()</span><br><span class="line">		<span class="keyword">var</span> (</span><br><span class="line">			timeout <span class="keyword">bool</span></span><br><span class="line">			done    <span class="keyword">bool</span></span><br><span class="line">		)</span><br><span class="line">		<span class="comment">// 6. 设置了超时处理</span></span><br><span class="line">		<span class="keyword">for</span> !timeout &amp;&amp; !done &#123;</span><br><span class="line">			<span class="keyword">select</span> &#123;</span><br><span class="line">			<span class="comment">// 7. 若从 readStateC 收到了 ReadState 通知，则说明底层协议库已经处理完成。</span></span><br><span class="line">			<span class="comment">// 事实上，上层应用程序（在此处是/etcd/etcdserver/raft.go）当收到底层协议库的 Ready 通知时，</span></span><br><span class="line">			<span class="comment">// 并且 Ready 结构中包含的 ReadState 不为空，则会向 readStateC 管道中压入 ReadState 实例，</span></span><br><span class="line">			<span class="comment">// 此处就能 pop 出 ReadState 实例。总而言之，ReadIndex 请求执行至此处表示底层协议库已经处理完毕</span></span><br><span class="line">			<span class="comment">// 只需要等待状态机至少已经应用 ReadIndex 的日志记录即可</span></span><br><span class="line">			<span class="keyword">case</span> rs = &lt;-s.r.readStateC:</span><br><span class="line">				done = bytes.Equal(rs.RequestCtx, ctxToSend)</span><br><span class="line">				<span class="comment">// ...</span></span><br><span class="line">			<span class="keyword">case</span> &lt;-leaderChangedNotifier:</span><br><span class="line">				<span class="comment">// ...</span></span><br><span class="line">			<span class="keyword">case</span> &lt;-time.After(s.Cfg.ReqTimeout()):</span><br><span class="line">				<span class="comment">// ...</span></span><br><span class="line">			<span class="keyword">case</span> &lt;-s.stopping:</span><br><span class="line">				<span class="keyword">return</span></span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> !done &#123;</span><br><span class="line">			<span class="keyword">continue</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 8. 获取 appliedIndex，判断其是否小于 ReadIndex，若是，则要继续等待，说明状态机此时仍未应用 ReadIndex 处日志</span></span><br><span class="line">		<span class="keyword">if</span> ai := s.getAppliedIndex(); ai &lt; rs.Index &#123;</span><br><span class="line">			<span class="keyword">select</span> &#123;</span><br><span class="line">			<span class="comment">// 9. 等待被调用 s.applyWait.Trigger(index)，那些在index之前的索引上调用的 Wait，都会收到通知而返回。</span></span><br><span class="line">			<span class="comment">// 具体而言，在 server.go 中的 start() -&gt; applyAll() 触发了通知</span></span><br><span class="line">			<span class="comment">// 且 触发调用 applyAll() 是由 etcdsever/raft.go 中 start() 函数往 applyc 中 push 了通知</span></span><br><span class="line">			<span class="keyword">case</span> &lt;-s.applyWait.Wait(rs.Index):</span><br><span class="line">			<span class="keyword">case</span> &lt;-s.stopping:</span><br><span class="line">				<span class="keyword">return</span></span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// unblock all l-reads requested at indices before rs.Index</span></span><br><span class="line">		<span class="comment">// 8. 否则，说明状态机已经至少应用到了 ReadIndex 日志，表明此时可以读取状态机中的内容，返回给客户端</span></span><br><span class="line">		nr.notify(<span class="literal">nil</span>)</span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="comment">// /etcd/etcdserver/v3_server.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 用于触发 linearizableReadLoop() 函数执行一遍循环中的等待处理 ReadIndex 请求的逻辑</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *EtcdServer)</span> <span class="title">linearizableReadNotify</span><span class="params">(ctx context.Context)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 获取 notifier</span></span><br><span class="line">	s.readMu.RLock()</span><br><span class="line">	nc := s.readNotifier</span><br><span class="line">	s.readMu.RUnlock()</span><br><span class="line">	<span class="comment">// signal linearizable loop for current notify if it hasn't been already</span></span><br><span class="line">	<span class="comment">// 2. 向 readwaitc 管道中 push 一个空结构，以通知有 ReadIndex 请求到达</span></span><br><span class="line">	<span class="keyword">select</span> &#123;</span><br><span class="line">	<span class="keyword">case</span> s.readwaitc &lt;- <span class="keyword">struct</span>&#123;&#125;&#123;&#125;:</span><br><span class="line">	<span class="keyword">default</span>:</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// wait for read state notification</span></span><br><span class="line">	<span class="comment">// 3. 等待 notifier 的通知，即等待 linearizableReadLoop() 调用 notifier.notify() 函数</span></span><br><span class="line">	<span class="comment">// 一旦触发 notifier 管道中 pop 的信号，则表明已经 ReadIndex 请求的准备工作已全部完毕</span></span><br><span class="line">	<span class="comment">// 这包含两个部分：其一是底层协议库的工作，leader 确认自己仍旧是 leader</span></span><br><span class="line">	<span class="comment">// 其二，等待节点的状态机至少已经应用到 ReadIndex 处的日志</span></span><br><span class="line">	<span class="comment">// 此时，就可以正式从状态机中读取对应的请求的内容</span></span><br><span class="line">	<span class="keyword">select</span> &#123;</span><br><span class="line">	<span class="keyword">case</span> &lt;-nc.c:</span><br><span class="line">		<span class="keyword">return</span> nc.err</span><br><span class="line">	<span class="keyword">case</span> &lt;-ctx.Done():</span><br><span class="line">		<span class="keyword">return</span> ctx.Err()</span><br><span class="line">	<span class="keyword">case</span> &lt;-s.done:</span><br><span class="line">		<span class="keyword">return</span> ErrStopped</span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="comment">// /etcd/etcdserver/v3_server.go</span></span><br></pre></td></tr></table></figure>

<p>总结而言，上述两个函数 <code>linearizableReadNotify()</code>及<code>linearizableReadLoop()</code>相当于锁的功能（此锁中包含多个条件等待操作），底层协议库未走完<code>ReadIndex</code>请求之前，或者应用层还未将<code>ReadIndex</code>应用到状态机之前，这把锁保证应用不会从状态机中读取请求数据，因此也不会返回对客户端读请求的响应。另外，顺便提一名，<code>linearizableReadNotify()</code>是当应用收到客户端的读请求时调用的，即在函数<code>Range()</code>中被调用，关键部分代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *EtcdServer)</span> <span class="title">Range</span><span class="params">(ctx context.Context, r *pb.RangeRequest)</span> <span class="params">(*pb.RangeResponse, error)</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> resp *pb.RangeResponse</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">if</span> !r.Serializable &#123;</span><br><span class="line">		err = s.linearizableReadNotify(ctx)</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">return</span> resp, err</span><br><span class="line">&#125; <span class="comment">// // /etcd/etcdserver/v3_server.go</span></span><br></pre></td></tr></table></figure>

<p>关于<code>ReadIndex</code>请求在应用程序层（服务端层）被处理的过程已经解析完毕。下文阐述底层协议库的处理。</p>
<h3 id="底层协议库处理-ReadIndex-请求"><a href="#底层协议库处理-ReadIndex-请求" class="headerlink" title="底层协议库处理 ReadIndex 请求"></a>底层协议库处理 ReadIndex 请求</h3><p>底层协议库提供处理<code>ReadIndex</code>请求的一个接口：<code>ReadIndex()</code>，上层应用程序也正是调用此函数来使用协议库的协调功能。其中完整的调用栈为<code>ReadIndex() -&gt; step() -&gt; stepWithWaitOption</code>，然后通过将消息压入<code>recvc</code>管道，使得在<code>run()</code>函数从管道中收到消息，然后调用<code>raft.Step()</code>函数，经过一系列的检查之后，进入了<code>stepLeader()</code>函数，对应<code>leader</code>节点的处理流程，重要的代码如下所示：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 接收上层应用程序的 ReadIndex 请求</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *node)</span> <span class="title">ReadIndex</span><span class="params">(ctx context.Context, rctx []<span class="keyword">byte</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="comment">// 创建一个 MsgReadIndex 的消息，其中 message 中的 entry 的 data 为请求的标识</span></span><br><span class="line">	<span class="keyword">return</span> n.step(ctx, pb.Message&#123;Type: pb.MsgReadIndex, Entries: []pb.Entry&#123;&#123;Data: rctx&#125;&#125;&#125;)</span><br><span class="line">&#125; <span class="comment">// /etcd/raft/node.go</span></span><br></pre></td></tr></table></figure>

<p>进入到<code>stepLeader()</code>函数后，随即根据消息类型进行<code>MsgReadIndex</code>分支。代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">stepLeader</span><span class="params">(r *raft, m pb.Message)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">switch</span> m.Type &#123;</span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">		<span class="keyword">case</span> pb.MsgReadIndex:</span><br><span class="line">		<span class="keyword">if</span> r.quorum() &gt; <span class="number">1</span> &#123;</span><br><span class="line">            <span class="comment">// 1. 如果 leader 在当前任期内没有提交过日志，则直接返回，不处理此 ReadIndex 请求</span></span><br><span class="line">			<span class="comment">// 否则会造成 过期读 甚至不正确的读</span></span><br><span class="line">			<span class="keyword">if</span> r.raftLog.zeroTermOnErrCompacted(r.raftLog.term(r.raftLog.committed)) != r.Term &#123;</span><br><span class="line">				<span class="comment">// Reject read only request when this leader has not committed any log entry at its term.</span></span><br><span class="line">				<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">// 2. 判断线性一致性读的实现方式</span></span><br><span class="line">			<span class="keyword">switch</span> r.readOnly.option &#123;</span><br><span class="line">			<span class="keyword">case</span> ReadOnlySafe: <span class="comment">// 3. 采用 ReadIndex 实现</span></span><br><span class="line">				<span class="comment">// 3.1 使用 leader 节点当前的 commit index 及 ReadIndex 消息 m 构造一个 readIndexStatus，并追加到 pendingReadIndex 中</span></span><br><span class="line">				r.readOnly.addRequest(r.raftLog.committed, m)</span><br><span class="line">				<span class="comment">// 3.2 将此请求的ID(rctx)作为参数，并向集群中的节点广播心跳消息</span></span><br><span class="line">				r.bcastHeartbeatWithCtx(m.Entries[<span class="number">0</span>].Data)</span><br><span class="line">			<span class="keyword">case</span> ReadOnlyLeaseBased: <span class="comment">// 4. 采用 leaseBase 实现</span></span><br><span class="line">				<span class="comment">// ...</span></span><br><span class="line">			&#125;</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			r.readStates = <span class="built_in">append</span>(r.readStates, ReadState&#123;Index: r.raftLog.committed, RequestCtx: m.Entries[<span class="number">0</span>].Data&#125;)</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">&#125; <span class="comment">// /etcd/raft/raf.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 并负责更新 pendingReadIndex(当前正在被处理的 ReadIndex 请求)，以及 readIndexQueue</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(ro *readOnly)</span> <span class="title">addRequest</span><span class="params">(index <span class="keyword">uint64</span>, m pb.Message)</span></span> &#123;</span><br><span class="line">	ctx := <span class="keyword">string</span>(m.Entries[<span class="number">0</span>].Data)</span><br><span class="line">	<span class="keyword">if</span> _, ok := ro.pendingReadIndex[ctx]; ok &#123;</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	ro.pendingReadIndex[ctx] = &amp;readIndexStatus&#123;index: index, req: m, acks: <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">uint64</span>]<span class="keyword">struct</span>&#123;&#125;)&#125;</span><br><span class="line">	ro.readIndexQueue = <span class="built_in">append</span>(ro.readIndexQueue, ctx)</span><br><span class="line">&#125; <span class="comment">// /etcd/raft/read_only.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 向集群中所有的节点发送心跳消息</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *raft)</span> <span class="title">bcastHeartbeatWithCtx</span><span class="params">(ctx []<span class="keyword">byte</span>)</span></span> &#123;</span><br><span class="line">	r.forEachProgress(<span class="function"><span class="keyword">func</span><span class="params">(id <span class="keyword">uint64</span>, _ *Progress)</span></span> &#123;</span><br><span class="line">		<span class="keyword">if</span> id == r.id &#123;</span><br><span class="line">			<span class="keyword">return</span></span><br><span class="line">		&#125;</span><br><span class="line">		r.sendHeartbeat(id, ctx)</span><br><span class="line">	&#125;)</span><br><span class="line">&#125; <span class="comment">// /etcd/raft/raf.go</span></span><br><span class="line"><span class="comment">// 向指定节点发送心跳消息，并带上 ctx</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *raft)</span> <span class="title">sendHeartbeat</span><span class="params">(to <span class="keyword">uint64</span>, ctx []<span class="keyword">byte</span>)</span></span> &#123;</span><br><span class="line">	commit := min(r.getProgress(to).Match, r.raftLog.committed)</span><br><span class="line">	m := pb.Message&#123;</span><br><span class="line">		To:      to,</span><br><span class="line">		Type:    pb.MsgHeartbeat,</span><br><span class="line">		Commit:  commit,</span><br><span class="line">		Context: ctx,</span><br><span class="line">	&#125;</span><br><span class="line">	r.send(m)</span><br><span class="line">&#125; <span class="comment">// /etcd/raft/raf.go</span></span><br></pre></td></tr></table></figure>

<p>当消息经网络传输到达<code>follower</code>节点后，<code>follower</code>收到此心跳消息时，其相关的处理如下所示：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">stepFollower</span><span class="params">(r *raft, m pb.Message)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">switch</span> m.Type &#123;</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		<span class="keyword">case</span> pb.MsgHeartbeat:</span><br><span class="line">            r.electionElapsed = <span class="number">0</span></span><br><span class="line">            r.lead = m.From</span><br><span class="line">            r.handleHeartbeat(m)</span><br><span class="line">         <span class="comment">// ...</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /etcd/raft/raf.go</span></span><br><span class="line"><span class="comment">// 处理心跳消息的逻辑也很简单，应用 commit index，然后发送心跳消息响应，并带上消息中的 ctx</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *raft)</span> <span class="title">handleHeartbeat</span><span class="params">(m pb.Message)</span></span> &#123;</span><br><span class="line">	r.raftLog.commitTo(m.Commit)</span><br><span class="line">	r.send(pb.Message&#123;To: m.From, Type: pb.MsgHeartbeatResp, Context: m.Context&#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>同样，当<code>leader</code>收到心跳消息响应的处理逻辑如下所示：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">stepLeader</span><span class="params">(r *raft, m pb.Message)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">switch</span> m.Type &#123;</span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">		<span class="keyword">case</span> pb.MsgHeartbeatResp:</span><br><span class="line">		<span class="comment">// 1. 更新 leader 为消息中的节点的 progress 对象实例</span></span><br><span class="line">		pr.RecentActive = <span class="literal">true</span></span><br><span class="line">		pr.resume()</span><br><span class="line">		<span class="comment">// free one slot for the full inflights window to allow progress.</span></span><br><span class="line">		<span class="keyword">if</span> pr.State == ProgressStateReplicate &amp;&amp; pr.ins.full() &#123;</span><br><span class="line">			pr.ins.freeFirstOne()</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 2. 若发现节点日志落后，则进行日志同步</span></span><br><span class="line">		<span class="keyword">if</span> pr.Match &lt; r.raftLog.lastIndex() &#123;</span><br><span class="line">			r.sendAppend(m.From)</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 3. 只有 ReadOnlySafe 类型的消息需要针对性处理，且其 ctx 不能为空</span></span><br><span class="line">		<span class="keyword">if</span> r.readOnly.option != ReadOnlySafe || <span class="built_in">len</span>(m.Context) == <span class="number">0</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 4. 更新 pendingReadIndex 中的 ack 字典（因为收到了 follower 的响应），并查看此时心跳响应是否达到 quorum</span></span><br><span class="line">		ackCount := r.readOnly.recvAck(m)</span><br><span class="line">		<span class="comment">// 5. 若没达到 quorum 的心跳响应，则直接返回，说明此时流程还未走完</span></span><br><span class="line">		<span class="keyword">if</span> ackCount &lt; r.quorum() &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 6. 在 pendingReadIndex 中返回 m 以前的所有的 readIndexStatus，一个 slice</span></span><br><span class="line">		<span class="comment">// 因为此请求依次顺序处理的，若此请求满足了底层协议库的条件，那么此请求之前的消息也会满足。</span></span><br><span class="line">		rss := r.readOnly.advance(m)</span><br><span class="line">		<span class="comment">// 7. 循环 readIndexStatus，并将其追加到</span></span><br><span class="line">		<span class="keyword">for</span> _, rs := <span class="keyword">range</span> rss &#123;</span><br><span class="line">			req := rs.req</span><br><span class="line">			<span class="comment">// 7.1 若是节点本地的 ReadIndex 请求，则直接将其追加到 ReadState 结构中，最后会打包到 Ready 结构，由 node 返回给上层应用程序</span></span><br><span class="line">			<span class="keyword">if</span> req.From == None || req.From == r.id &#123; <span class="comment">// from local member</span></span><br><span class="line">				r.readStates = <span class="built_in">append</span>(r.readStates, ReadState&#123;Index: rs.index, RequestCtx: req.Entries[<span class="number">0</span>].Data&#125;)</span><br><span class="line">			&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">				<span class="comment">// 7.2 否则此消息则是来源于 follower，则向 follower 发送 MsgReadIndexResp 类型的消息</span></span><br><span class="line">				r.send(pb.Message&#123;To: req.From, Type: pb.MsgReadIndexResp, Index: rs.index, Entries: req.Entries&#125;)</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /etcd/raft/raf.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 通知 readonly 结构，leader 节点收到了 follower 节点的心跳消息响应（此心跳消息是针对 ReadIndex 请求而发送的）</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(ro *readOnly)</span> <span class="title">recvAck</span><span class="params">(m pb.Message)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">	rs, ok := ro.pendingReadIndex[<span class="keyword">string</span>(m.Context)]</span><br><span class="line">	<span class="keyword">if</span> !ok &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">	&#125;</span><br><span class="line">	rs.acks[m.From] = <span class="keyword">struct</span>&#123;&#125;&#123;&#125;</span><br><span class="line">	<span class="comment">// 返回此时 leader 已经收到的响应消息的数量</span></span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">len</span>(rs.acks) + <span class="number">1</span></span><br><span class="line">&#125; <span class="comment">// /etcd/raft/read_only.go</span></span><br></pre></td></tr></table></figure>

<p>至此，关于<code>leader</code>节点处理<code>ReadIndex</code>请求的流程已经阐述完毕，总的流程比较简单，即<code>leader</code>通过一轮心跳消息来确认自己仍然是<code>leader</code>。另外，若客户端将读请求发送给了<code>follower</code>节点，<code>etcd-raft</code>的实现是：应用层会调用协议的核心库的<code>ReadIndex</code>()方法，然后让<code>follower</code>节点先将<code>ReadIndex</code>消息发送给<code>leader</code>，接下来<code>leader</code>同样走一圈上面的流程，在确认自己依旧为<code>leader</code>后，将确认的<code>ReadIndex</code>通过<code>MsgReadIndexResp</code>消息发送给<code>follower</code>节点，最后同样，<code>follower</code>节点将构造<code>ReadState</code>并记录<code>commit index</code>，最后由上层应用收到<code>Ready</code>结构后，从中取出<code>ReadState</code>。因此，综合来看，若<code>ReadIndex</code>请求发送给了<code>follower</code>，则<code>follower</code>先要去问<code>leader</code>查询<code>commit index</code>，然后同样构造<code>ReadState</code>返回给上层应用，这和<code>leader</code>的处理是一样的。关于<code>follower</code>收到<code>MsgReadIndex</code>消息的核心代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">stepFollower</span><span class="params">(r *raft, m pb.Message)</span></span> &#123;</span><br><span class="line">    <span class="keyword">switch</span> m.Type &#123;</span><br><span class="line">    ......</span><br><span class="line">    <span class="keyword">case</span> pb.MsgReadIndex:</span><br><span class="line">        <span class="keyword">if</span> r.lead == None &#123;</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        &#125;</span><br><span class="line">        m.To = r.lead </span><br><span class="line">        r.send(m) <span class="comment">// 先将消息转发给 leader</span></span><br><span class="line">    <span class="keyword">case</span> pb.MsgReadIndexResp: <span class="comment">// 最后收到 leader 的 MsgReadIndexResp 消息回复后，</span></span><br><span class="line">        <span class="comment">// 追加到其 ReadStates 结构中，以通过 Ready 返回给上层应用程序</span></span><br><span class="line">        r.readStates = <span class="built_in">append</span>(r.readStates, ReadState&#123;Index: m.Index, RequestCtx: m.Entries[<span class="number">0</span>].Data&#125;)</span><br><span class="line">    ......</span><br><span class="line">&#125; <span class="comment">// /etcd/raft/raf.go</span></span><br></pre></td></tr></table></figure>

<p>至此，关于<code>etcd-raft</code>如何处理<code>ReadIndex</code>线性一致性读的相关逻辑已经分析完毕。</p>
<p>最后，简单提一点，当节点刚被选举成为<code>leader</code>时，如果其未在新的<code>term</code>中提交过日志，那么其所在的任期内的<code>commit index</code>是无法得知的，因此，在<code>etcd-raft</code>具体实现中，会在<code>leader</code>刚选举成功后，马上提交追加提交一个<code>no-op</code>的日志（代码如下所示），在这之前所有客户端（应用程序）发送的读请求都会被阻塞（写请求肯定不会，其实若是有写请求了，也就不用提交空日志了）。通过此种方式可以确定新的<code>term</code>的<code>commit index</code>。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *raft)</span> <span class="title">becomeLeader</span><span class="params">()</span></span> &#123;</span><br><span class="line">	r.step = stepLeader</span><br><span class="line">	r.reset(r.Term)</span><br><span class="line">	r.tick = r.tickHeartbeat</span><br><span class="line">	r.lead = r.id</span><br><span class="line">	r.state = StateLeader</span><br><span class="line">	r.prs[r.id].becomeReplicate()</span><br><span class="line">	r.pendingConfIndex = r.raftLog.lastIndex()</span><br><span class="line">	<span class="comment">// 提交了一条 no-op 日志</span></span><br><span class="line">	emptyEnt := pb.Entry&#123;Data: <span class="literal">nil</span>&#125;</span><br><span class="line">	<span class="keyword">if</span> !r.appendEntry(emptyEnt) &#123;</span><br><span class="line">		r.logger.Panic(<span class="string">"empty entry was dropped"</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	r.reduceUncommittedSize([]pb.Entry&#123;emptyEnt&#125;)</span><br><span class="line">	r.logger.Infof(<span class="string">"%x became leader at term %d"</span>, r.id, r.Term)</span><br><span class="line">&#125; <span class="comment">// /etcd/raft/raft.go</span></span><br></pre></td></tr></table></figure>

<p>简单小结，本文先是从理论角度阐述了什么是线性一致性，并且它具备什么特征。相比于顺序一致性，它们的不同点在哪里，最后线性一致性结合顺序一致性，即为严格一致性。关于这部分理论内容，读者若有兴趣，可以参考参考文献的[1]-[5]，讲得更完备和精确。后一部分内容就结合<code>etcd</code> 的代码阐述了其具体如何保证<code>ReadIndex</code>线性一致性，大概的流程为：先执行应用程序层对读请求的控制，它类似于一把锁的功能，在底层协议库未完成线性一致性相关的逻辑处理之前，会阻塞应用的读请求的处理，直至底层协议库走一圈后返回，才能继续处理，然后继续判断此时<code>ReadIndex</code>处的日志是否有被应用（若状态机已应用到<code>ReadIndex</code>之后的日志也完全可以），直至<code>ReadIndex</code>日志被提交才能返回，即才能释放锁，允许应用程序读取状态机。</p>
<p>参考文献</p>
<p>[1]. <a href="https://pingcap.com/blog-cn/linearizability-and-raft/" target="_blank" rel="noopener">线性一致性和 Raft</a><br>[2]. <a href="https://medium.com/p/6e579965c4ce/edit" target="_blank" rel="noopener">On Ways To Agree, Part 2: Path to Atomic Broadcast</a><br>[3]. <a href="http://www.bailis.org/blog/linearizability-versus-serializability/" target="_blank" rel="noopener">Linearizability versus Serializability</a><br>[4]. <a href="https://aphyr.com/posts/313-strong-consistency-models" target="_blank" rel="noopener">Strong consistency models</a><br>[5]. <a href="https://cs.brown.edu/~mph/HerlihyW90/p463-herlihy.pdf" target="_blank" rel="noopener">Linearizability: Correctness Condition for Concurrent Objects</a><br>[6]. <a href="https://github.com/etcd-io/etcd" target="_blank" rel="noopener">https://github.com/etcd-io/etcd</a></p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>分布式协调服务</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>线性一致性</tag>
        <tag>顺序一致性</tag>
      </tags>
  </entry>
  <entry>
    <title>etcd-raft 集群配置变更源码简析</title>
    <url>/2019/01/15/etcd-raft-%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE%E5%8F%98%E6%9B%B4%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/</url>
    <content><![CDATA[<p>上一篇文章阐述了<code>etcd-raft snopshot</code>相关逻辑，并从整体上把握<code>etcd-raft snapshot</code>的设计规范。本文的主题是集群配置变更的理论及实际的相关流程，即<code>etcd-raft</code>如何处理集群配置变更，且在配置变更前后必须保证集群任何时刻只存在一个<code>leader</code>。在<code>raft</code>论文中提出每次只能处理一个节点的变更请求，若一次性处理多个节点变更请求（如添加多个节点），可能会造成某一时刻集群中存在两个<code>leader</code>，但这是<code>raft</code>协议规范所不允许的。而<code>etcd-raft</code>的实现同样只允许每次处理一个配置变更请求。大概地，<code>etcd-raft</code>首先将配置变更请求同普通请求日志进行类似处理，即复制到<code>quorum</code>节点，然后提交配置变更请求。一旦<code>quorum</code>节点完配置变更日志的追加操作后，便触发<code>leader</code>节点所维护的集群拓扑信息变更（此时原集群拓扑所包含的节点才知道新的集群拓扑结构），而其它节点在收到<code>leader</code>的消息后，也会更新其维护的集群拓扑。</p>
<a id="more"></a>

<h2 id="集群配置信息变更"><a href="#集群配置信息变更" class="headerlink" title="集群配置信息变更"></a>集群配置信息变更</h2><p>在结合代码阐述集群配置信息变更的流程之前，先简单了解论文中所阐述的集群配置变更理论。为什么一次集群配置信息变更（此处以增加新节点示例）只能增加一个节点？这包含两个部分：其一解释若一次增加两个节点会使得集群在某一时刻存在两个<code>leader</code>的情况。其二，阐述若一次只允许增加一个节点，则不会出现某一时刻存在两个两个<code>leader</code>的情况。</p>
<p><img src="https://github.com/qqzeng/6.824/blob/master/src/raft/ConfChange.png?raw=true" alt="raft集群配置信息变更"></p>
<p>如图（论文原图）所示，集群配置变更前集群中节点数量为 3（包括<code>s1、s2</code>及<code>s3</code>），且假设最最初的<code>leader</code>为<code>s3</code>。假设集群配置变更时允许 2 个节点同时加入到集群中，那么原来的 3 个节点在知道新的集群拓扑结构前（即集群配置变更的请求日志被提交之前），它们认为集群中只包含 3 个节点。而当新加入的节点（<code>s4及s5</code>）提出加入请求时，<code>leader</code>节点开始对节点加入请求日志进行同步复制，假设在<code>s1</code>及<code>s2</code>提交日志之前，<code>s3、s4</code>于它们之前收到日志并成功回复，那么<code>leader</code>此时收到了    <code>quorum</code>个回复（<code>s1、s4</code>及<code>s5</code>），因此可以提交节点请求加入的日志，换言之，此时节点<code>s1、s4</code>及<code>s5</code>认为集群中存在 5 个节点，而<code>s2</code>和<code>s3</code>仍然认为集群中只包含 3 个节点（因为它们还未提交配置变更请求）。此时假设某种网络原因，<code>s1</code>与<code>s3</code>（<code>leader</code>节点）失联，则<code>s1</code>重新发起选举，并成功收到<code>s2</code>的回复（<code>s2</code>可以给<code>s1</code>投票的），因此<code>s1</code>成功选举为<code>leader</code>（因为它它认为自己收到了<code>quorum=3/2+1</code>=2节点的投票）。而<code>s3</code>此时也同样发起选举，它可以获得<code>s3、s4</code>及<code>s5</code>的选票，因此它也能成功当选为<code>leader</code>（它认为自己收到了<code>quorum=5/2+1=3</code>节点的投票）。此时，集群中存在两个<code>leader</code>，是不安全且不允许的（显然，两个<code>leader</code>会导致对于同一索引处的日志不同，违反一致性）。</p>
<p>那为什么每次只入一个节点就能保证安全性呢（即任何时刻都只能有一个<code>leader</code>存在）？同样，假设我们最初的集群中包含三个节点（<code>s1、s2</code>及<code>s3</code>），且最初的<code>leader</code>为<code>s1</code>，但此时只有一个节点加入（假设为<code>s4</code>）。那么我们从三个方面来讨论为什么能保证任意时刻只存在一个<code>leader</code>：</p>
<ul>
<li><p>配置变更请求日志提交前。即此时原集群的节点（<code>s1、s2</code>及<code>s3</code>）都只知道原始集群拓扑结构信息，不知道新加入的节点信息（其<code>quorum=3/2+1=2</code>）。但新加入的节点认为集群中存在 4 个节点（因此其<code>quorum=4/2+1=3</code>）。因此，在<code>s1、s2</code>或<code>s3</code>当中任意一个或多个发起选举时，它们最多只能产生 1 个<code>leader</code>（与原始集群的选举一致，因为它们的集群拓扑视角均未变化）。而<code>s4</code>发起选举时，它不能得到<code>s1、s2</code>或<code>s3</code>任何一张选票（因为很明显它的日志比它们的要旧）。</p>
</li>
<li><p>配置变更请求日志提交中。即此时配置变更请求的日志已经被<code>leader</code>提交了，但并不是所有的节点都提交了。比如，<code>s1</code>及<code>s2</code>成功提交了日志，则此时若<code>s4</code>发起选举，它不能获取<code>quorum=3/1+1=3</code>张选票，因为它的日志要比<code>s1</code>和<code>s2</code>的要更旧，即只能获取<code>s3</code>的选票（不能成功当选 ），<code>若s3</code>发起选举的结果也类似（注意，其此刻不知道<code>s4</code>的存在，因此其<code>quorum=2</code>）。总而言之，已提交了日志的节点能够获取<code>quorum</code>张选票，而未提交日志的节点因为日志不够新因此不能获得<code>quorum</code>张选票。</p>
</li>
<li><p>配置变更请求日志提交后。这种情况比较简单，当配置变更请求已经提交了，集群中任意一个节点当选的条件必须是获得<code>quorum</code>张选票，且任意两个<code>quorum</code>存在交集，但一个节点只能投出一张选票（在一个<code>term</code>内），因此不可能存在两个节点同时当选为<code>leader</code>。</p>
</li>
</ul>
<p>至此，关于论文中的理论已经阐述完毕。而<code>etcd-raft</code>也只允许一次只能存在一个配置变更的请求。下面来简单了解<code>etcd-raft</code>是如何处理配置变更请求。</p>
<h2 id="关键流程"><a href="#关键流程" class="headerlink" title="关键流程"></a>关键流程</h2><p>我们同样从<code>raftexample</code>着手，当客户端发起配置变更请求（这里以加入一个新节点作为示例）时，<code>etcd-raft</code>是如何处理的。上文提过，这主要包含两个过程：其一，配置变更请求日志的同步过程（同普通的日志请求复制流程类似）。其二，在日志提交之后，节点正式更新集群拓扑信息，直至此时，原集群中的节点才知道新节点的存在。主要涉及的代码的目录为：<code>/etcd/contribe/raftexample</code>及<code>/etcd/raft</code>。</p>
<p>在阐述配置变更相关流程逻辑前，我们简要帖出核心数据结构，比较简单：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> ConfChange <span class="keyword">struct</span> &#123;</span><br><span class="line">    <span class="comment">// ID 为节点变更的消息id</span></span><br><span class="line">	ID               <span class="keyword">uint64</span>         <span class="string">`protobuf:"varint,1,opt,name=ID" json:"ID"`</span></span><br><span class="line">    <span class="comment">// 配置信息变更的类型，目前包含四种</span></span><br><span class="line">	Type             ConfChangeType <span class="string">`protobuf:"varint,2,opt,name=Type,enum=raftpb.ConfChangeType" json:"Type"`</span></span><br><span class="line">    <span class="comment">// 配置信息变更所涉及到的节点的 ID</span></span><br><span class="line">	NodeID           <span class="keyword">uint64</span>         <span class="string">`protobuf:"varint,3,opt,name=NodeID" json:"NodeID"`</span></span><br><span class="line">	Context          []<span class="keyword">byte</span>         <span class="string">`protobuf:"bytes,4,opt,name=Context" json:"Context,omitempty"`</span></span><br><span class="line">&#125; <span class="comment">// /etc/raft/raftpb/raft.pb.go</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> ConfChangeType <span class="keyword">int32</span></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">	ConfChangeAddNode        ConfChangeType = <span class="number">0</span></span><br><span class="line">	ConfChangeRemoveNode     ConfChangeType = <span class="number">1</span></span><br><span class="line">	ConfChangeUpdateNode     ConfChangeType = <span class="number">2</span></span><br><span class="line">	ConfChangeAddLearnerNode ConfChangeType = <span class="number">3</span></span><br><span class="line">) <span class="comment">// /etc/raft/raftpb/raft.pb.go</span></span><br></pre></td></tr></table></figure>

<p>我们知道，关于<code>raftexample</code>示例，它可以通过两种方式加入集群，其一是集群节点信息初始化，即在集群启动时便知道存在哪些节点，这不属于我们本文讨论的范围。其二是集群正常运行过程中，一个节点要加入集群，它可以通过向客户端发出一个 HTTP POST 请求以加入集群：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -L http://127.0.0.1:12380/4 -XPOST -d http://127.0.0.1:42379 </span><br><span class="line">raftexample --id 4 --cluster http://127.0.0.1:12379,http://127.0.0.1:22379,http://127.0.0.1:32379,http://127.0.0.1:42379 --port 42380 --join</span><br></pre></td></tr></table></figure>

<p>在应用的 HTTP 处理器模块接收到请求后，会构建一个配置变更对象，通过<code>confChangeC</code>管道将其传递给<code>raftNode</code>模块，由<code>raftNode</code>进一步调用<code>node</code>实例的<code>ProposeConfChange()</code>函数。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h *httpKVAPI)</span> <span class="title">ServeHTTP</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">	key := r.RequestURI</span><br><span class="line">	<span class="keyword">switch</span> &#123;</span><br><span class="line">	<span class="keyword">case</span> r.Method == <span class="string">"PUT"</span>:</span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">case</span> r.Method == <span class="string">"GET"</span>:</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">case</span> r.Method == <span class="string">"POST"</span>:</span><br><span class="line">		url, err := ioutil.ReadAll(r.Body)</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		<span class="comment">// 解析参数</span></span><br><span class="line">		nodeId, err := strconv.ParseUint(key[<span class="number">1</span>:], <span class="number">0</span>, <span class="number">64</span>)</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			log.Printf(<span class="string">"Failed to convert ID for conf change (%v)\n"</span>, err)</span><br><span class="line">			http.Error(w, <span class="string">"Failed on POST"</span>, http.StatusBadRequest)</span><br><span class="line">			<span class="keyword">return</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 构建 ConfChang 对象</span></span><br><span class="line">		cc := raftpb.ConfChange&#123;</span><br><span class="line">			Type:    raftpb.ConfChangeAddNode,</span><br><span class="line">			NodeID:  nodeId,</span><br><span class="line">			Context: url,</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 将对象放入管道，通知 raftNode</span></span><br><span class="line">		h.confChangeC &lt;- cc</span><br><span class="line">		w.WriteHeader(http.StatusNoContent)</span><br><span class="line">	<span class="keyword">case</span> r.Method == <span class="string">"DELETE"</span>:</span><br><span class="line">		nodeId, err := strconv.ParseUint(key[<span class="number">1</span>:], <span class="number">0</span>, <span class="number">64</span>)</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		cc := raftpb.ConfChange&#123;</span><br><span class="line">			Type:   raftpb.ConfChangeRemoveNode,</span><br><span class="line">			NodeID: nodeId,</span><br><span class="line">		&#125;</span><br><span class="line">		h.confChangeC &lt;- cc</span><br><span class="line">		<span class="comment">// As above, optimistic that raft will apply the conf change</span></span><br><span class="line">		w.WriteHeader(http.StatusNoContent)</span><br><span class="line">	 <span class="comment">// ...</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="comment">// /etcd/contribe/raftexample/httpapi.go</span></span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rc *raftNode)</span> <span class="title">serveChannels</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		confChangeCount := <span class="keyword">uint64</span>(<span class="number">0</span>)</span><br><span class="line">		<span class="keyword">for</span> rc.proposeC != <span class="literal">nil</span> &amp;&amp; rc.confChangeC != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">select</span> &#123;</span><br><span class="line">			<span class="keyword">case</span> prop, ok := &lt;-rc.proposeC:</span><br><span class="line">				<span class="comment">// ...</span></span><br><span class="line">			<span class="comment">// 收到客户端的配置变更请求</span></span><br><span class="line">			<span class="keyword">case</span> cc, ok := &lt;-rc.confChangeC:</span><br><span class="line">				<span class="keyword">if</span> !ok &#123;</span><br><span class="line">					rc.confChangeC = <span class="literal">nil</span></span><br><span class="line">				&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">					confChangeCount++</span><br><span class="line">					cc.ID = confChangeCount</span><br><span class="line">					<span class="comment">// 调用底层协议核心来处理配置变更请求（实际上即追加配置变更日志）</span></span><br><span class="line">					rc.node.ProposeConfChange(context.TODO(), cc)</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// client closed channel; shutdown raft if not already</span></span><br><span class="line">		<span class="built_in">close</span>(rc.stopc)</span><br><span class="line">	&#125;()</span><br><span class="line">&#125; <span class="comment">// /etcd/contribe/raftexample/raft.go</span></span><br></pre></td></tr></table></figure>

<p>在底层协议收到此调用请求后，会构建一个<code>MsgProp</code>类型的日志消息（这同普通的日志请求的类型是一致的），但消息中的<code>Entry</code>类型为<code>EntryConfChange</code>。通过一系列的函数调用，会将此请求消息放入<code>proc</code>管道，而在<code>node</code>的<code>run()</code>函数中会将消息从管理中取出，然后调用底层协议的核心处理实例<code>raft</code>的<code>Step()</code>函数，进而在最后调用其<code>stepLeader()</code>函数。部分代码如下（完整的函数调用栈为：<code>ProposeConfChange() -&gt; Step() -&gt; step() -&gt; stepWithWaitOption() -&gt;  r.Step() -&gt; r.stepLeader()</code>）：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *node)</span> <span class="title">ProposeConfChange</span><span class="params">(ctx context.Context, cc pb.ConfChange)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	data, err := cc.Marshal()</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> n.Step(ctx, pb.Message&#123;Type: pb.MsgProp, Entries: []pb.Entry&#123;&#123;Type: pb.EntryConfChange, Data: data&#125;&#125;&#125;)</span><br><span class="line">&#125; <span class="comment">// /etcd/raft/node.go</span></span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">stepLeader</span><span class="params">(r *raft, m pb.Message)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">switch</span> m.Type &#123;</span><br><span class="line">	<span class="keyword">case</span> pb.MsgBeat:</span><br><span class="line">		r.bcastHeartbeat()</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">	<span class="keyword">case</span> pb.MsgCheckQuorum:</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">case</span> pb.MsgProp: <span class="comment">// 配置变更请求消息也走这里，因此其处理流程同普通的日志请求是类似的</span></span><br><span class="line">		<span class="keyword">if</span> <span class="built_in">len</span>(m.Entries) == <span class="number">0</span> &#123;</span><br><span class="line">			r.logger.Panicf(<span class="string">"%x stepped empty MsgProp"</span>, r.id)</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> _, ok := r.prs[r.id]; !ok &#123;</span><br><span class="line">			<span class="keyword">return</span> ErrProposalDropped</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> r.leadTransferee != None &#123;</span><br><span class="line">			r.logger.Debugf(<span class="string">"%x [term %d] transfer leadership to %x is in progress; dropping proposal"</span>, r.id, r.Term, r.leadTransferee)</span><br><span class="line">			<span class="keyword">return</span> ErrProposalDropped</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">for</span> i, e := <span class="keyword">range</span> m.Entries &#123;</span><br><span class="line">			<span class="keyword">if</span> e.Type == pb.EntryConfChange &#123; <span class="comment">// 若为配置变更请求消息，先判断其 pendingConfIndex（它限制了一次只能进行一个节点的变更）</span></span><br><span class="line">			<span class="comment">// 并且保证其不能超过 appliedIndex，因为只有一个变更请求被 pending，因此其肯定还未提交，因此正常情况下必须小于 appliedIndex</span></span><br><span class="line">				<span class="keyword">if</span> r.pendingConfIndex &gt; r.raftLog.applied &#123;</span><br><span class="line">					r.logger.Infof(<span class="string">"propose conf %s ignored since pending unapplied configuration [index %d, applied %d]"</span>,</span><br><span class="line">						e.String(), r.pendingConfIndex, r.raftLog.applied)</span><br><span class="line">					m.Entries[i] = pb.Entry&#123;Type: pb.EntryNormal&#125;</span><br><span class="line">				&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">					<span class="comment">// 否则，若符合条件，则更新 pendingConfIndex 为对应的索引</span></span><br><span class="line">					r.pendingConfIndex = r.raftLog.lastIndex() + <span class="keyword">uint64</span>(i) + <span class="number">1</span></span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 追加配置变更消息到节点的 unstable</span></span><br><span class="line">		<span class="keyword">if</span> !r.appendEntry(m.Entries...) &#123;</span><br><span class="line">			<span class="keyword">return</span> ErrProposalDropped</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 广播配置变更消息到 follower 节点</span></span><br><span class="line">		r.bcastAppend()</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="comment">// /etcd/raft/raft.go</span></span><br></pre></td></tr></table></figure>

<p>关于<code>bcastAppend()</code>之后的逻辑，这里不再重复阐述，其同正常的日志消息的逻辑是一致的。因此，当上层应用调用网络传输组件将配置变更消息转发到集群其它节点时，其它节点同样会完成配置变更日志追加操作（同普通的日志请求消息追加的流程一致），而且<code>leader</code>节点处理响应同样与同步普通日志的响应的逻辑一致，这里也不再重复阐述。</p>
<p>最后，我们来了解当配置变更请求已经被同步到<code>quorum</code>节点后，准备提交的相关逻辑。这包括两个部分：其一是上层应用程序准备应用配置变更请求日志到状态机，然后会触发底层协议正式更新集群拓扑结构信息。</p>
<p>步骤一的相关代码如下（完整调用栈为：<code>serverChannels() -&gt; publishEntries()</code>）：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// whether all entries could be published.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rc *raftNode)</span> <span class="title">publishEntries</span><span class="params">(ents []raftpb.Entry)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">	<span class="keyword">for</span> i := <span class="keyword">range</span> ents &#123;</span><br><span class="line">		<span class="keyword">switch</span> ents[i].Type &#123;</span><br><span class="line">         <span class="comment">// 准备应用普通的日志</span></span><br><span class="line">		<span class="keyword">case</span> raftpb.EntryNormal:</span><br><span class="line">			<span class="comment">// ...</span></span><br><span class="line">		<span class="comment">// 若为配置变更请求日志</span></span><br><span class="line">		<span class="keyword">case</span> raftpb.EntryConfChange:</span><br><span class="line">			<span class="keyword">var</span> cc raftpb.ConfChange</span><br><span class="line">			<span class="comment">// 1. 反序列化</span></span><br><span class="line">			cc.Unmarshal(ents[i].Data)</span><br><span class="line">			<span class="comment">// 2. 调用 node 的 ApplyConfChange 正式更新对应节点所维护的集群拓扑结构信息</span></span><br><span class="line">			<span class="comment">// 即更新 progress 结构信息，这可能包括 learners 信息</span></span><br><span class="line">			<span class="comment">// 并且会返回集群的配置信息，即各节点的具体角色</span></span><br><span class="line">			rc.confState = *rc.node.ApplyConfChange(cc)</span><br><span class="line">			<span class="keyword">switch</span> cc.Type &#123;</span><br><span class="line">			<span class="comment">// 3. 调用网络传输组件变更对应的代表节点网络传输实例的信息</span></span><br><span class="line">			<span class="keyword">case</span> raftpb.ConfChangeAddNode:</span><br><span class="line">				<span class="keyword">if</span> <span class="built_in">len</span>(cc.Context) &gt; <span class="number">0</span> &#123;</span><br><span class="line">					rc.transport.AddPeer(types.ID(cc.NodeID), []<span class="keyword">string</span>&#123;<span class="keyword">string</span>(cc.Context)&#125;)</span><br><span class="line">				&#125;</span><br><span class="line">			<span class="keyword">case</span> raftpb.ConfChangeRemoveNode:</span><br><span class="line">				<span class="keyword">if</span> cc.NodeID == <span class="keyword">uint64</span>(rc.id) &#123;</span><br><span class="line">					log.Println(<span class="string">"I've been removed from the cluster! Shutting down."</span>)</span><br><span class="line">					<span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">				&#125;</span><br><span class="line">				rc.transport.RemovePeer(types.ID(cc.NodeID))</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 4. 更新当前已应用的日志索引</span></span><br><span class="line">		rc.appliedIndex = ents[i].Index</span><br><span class="line">		<span class="comment">// special nil commit to signal replay has finished</span></span><br><span class="line">		<span class="keyword">if</span> ents[i].Index == rc.lastIndex &#123;</span><br><span class="line">			<span class="keyword">select</span> &#123;</span><br><span class="line">			<span class="keyword">case</span> rc.commitC &lt;- <span class="literal">nil</span>:</span><br><span class="line">			<span class="keyword">case</span> &lt;-rc.stopc:</span><br><span class="line">				<span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125; <span class="comment">// /etcd/contrib/raftexample/raft.go</span></span><br></pre></td></tr></table></figure>

<p>而底层协议会执行具体的更新集群拓扑（包括更换已有节点的角色）的操作。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *node)</span> <span class="title">ApplyConfChange</span><span class="params">(cc pb.ConfChange)</span> *<span class="title">pb</span>.<span class="title">ConfState</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> cs pb.ConfState</span><br><span class="line">	<span class="keyword">select</span> &#123;</span><br><span class="line">	<span class="comment">// 将配置变更请求实例放入 confc 管道，n.run() 函数会循环从 confc 管道中取</span></span><br><span class="line">	<span class="keyword">case</span> n.confc &lt;- cc:</span><br><span class="line">	<span class="keyword">case</span> &lt;-n.done:</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">select</span> &#123;</span><br><span class="line">	<span class="comment">// 从 confstatec 管道中取出集群配置信息实例，返回给上层应用 raftNode</span></span><br><span class="line">	<span class="keyword">case</span> cs = &lt;-n.confstatec:</span><br><span class="line">	<span class="keyword">case</span> &lt;-n.done:</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> &amp;cs</span><br><span class="line">&#125; <span class="comment">// /etcd/raft/node.go</span></span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *raft)</span> <span class="title">addNode</span><span class="params">(id <span class="keyword">uint64</span>)</span></span> &#123;</span><br><span class="line">	r.addNodeOrLearnerNode(id, <span class="literal">false</span>)</span><br><span class="line">&#125; <span class="comment">// etcd/raft/raft.go</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *raft)</span> <span class="title">addLearner</span><span class="params">(id <span class="keyword">uint64</span>)</span></span> &#123;</span><br><span class="line">	r.addNodeOrLearnerNode(id, <span class="literal">true</span>)</span><br><span class="line">&#125; <span class="comment">// etcd/raft/raft.go</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *raft)</span> <span class="title">addNodeOrLearnerNode</span><span class="params">(id <span class="keyword">uint64</span>, isLearner <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 获取此新加入节点的 progress 实例</span></span><br><span class="line">	pr := r.getProgress(id)</span><br><span class="line">	<span class="comment">// 2. 若为空，则表示为新加入的节点，设置其 progress 对象信息</span></span><br><span class="line">	<span class="keyword">if</span> pr == <span class="literal">nil</span> &#123;</span><br><span class="line">		r.setProgress(id, <span class="number">0</span>, r.raftLog.lastIndex()+<span class="number">1</span>, isLearner)</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123; <span class="comment">// 3. 否则节点已存在，可能是更新节点的具体的角色</span></span><br><span class="line">		<span class="keyword">if</span> isLearner &amp;&amp; !pr.IsLearner &#123;</span><br><span class="line">			<span class="comment">// can only change Learner to Voter</span></span><br><span class="line">			r.logger.Infof(<span class="string">"%x ignored addLearner: do not support changing %x from raft peer to learner."</span>, r.id, id)</span><br><span class="line">			<span class="keyword">return</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> isLearner == pr.IsLearner &#123;</span><br><span class="line">			<span class="keyword">return</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// change Learner to Voter, use origin Learner progress</span></span><br><span class="line">		<span class="comment">// 3.1 考虑从 Learner 切换到 Voter 的角色（Voter 角色的节点保存在 prs 数组）</span></span><br><span class="line">		<span class="built_in">delete</span>(r.learnerPrs, id)</span><br><span class="line">		pr.IsLearner = <span class="literal">false</span></span><br><span class="line">		r.prs[id] = pr</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 4. 如果当前节点即为新加入的节点，则设置是否是 Learner</span></span><br><span class="line">	<span class="keyword">if</span> r.id == id &#123;</span><br><span class="line">		r.isLearner = isLearner</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// When a node is first added, we should mark it as recently active.</span></span><br><span class="line">	<span class="comment">// Otherwise, CheckQuorum may cause us to step down if it is invoked</span></span><br><span class="line">	<span class="comment">// before the added node has a chance to communicate with us.</span></span><br><span class="line">	<span class="comment">// 5. 当节点第一次被加入时，需要标记节点最近为 活跃，否则在节点正式与 leader 通信前，可能会导致 leader 节点下台</span></span><br><span class="line">	pr = r.getProgress(id)</span><br><span class="line">	pr.RecentActive = <span class="literal">true</span></span><br><span class="line">&#125; <span class="comment">// etcd/raft/raft.go</span></span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 从集群中移除指定节点</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *raft)</span> <span class="title">removeNode</span><span class="params">(id <span class="keyword">uint64</span>)</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 从当前节点维护的其它节点的 progress 对象数组中移除欲删除节点的信息</span></span><br><span class="line">	r.delProgress(id)</span><br><span class="line">	<span class="comment">// do not try to commit or abort transferring if there is no nodes in the cluster.</span></span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(r.prs) == <span class="number">0</span> &amp;&amp; <span class="built_in">len</span>(r.learnerPrs) == <span class="number">0</span> &#123;</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 节点删除操作，更新了 quorum 的大小，因此需要检查是否有 pending 的日志项已经达到提交的条件了</span></span><br><span class="line">	<span class="keyword">if</span> r.maybeCommit() &#123;</span><br><span class="line">		<span class="comment">// 2.1 若确实提交了日志项，则将此消息进行广播</span></span><br><span class="line">		r.bcastAppend()</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 3. 如果当前被移除的节点是即将当选为 Leader 的节点则中断此 Leader 交接过程</span></span><br><span class="line">	<span class="keyword">if</span> r.state == StateLeader &amp;&amp; r.leadTransferee == id &#123;</span><br><span class="line">		r.abortLeaderTransfer()</span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="comment">// /etcd/raft/raft.go</span></span><br></pre></td></tr></table></figure>

<p>至此，集群配置信息的变更的相关流程源码已经简单分析完毕。</p>
<p>简单小结，本文主要从两个方面阐述集群配置变更：首先结合论文从理论角度阐述为什么一次集群配置变更只能涉及到单个节点，从正反两个方面进行简单讨论证明。其次，结合<code>etcd-raft</code>中集群配置信息变更的代码具体叙述其中的流程，流程的第一阶段大部分已略过，这同普通日志的提交、追加、同步及响应过程类似，流程的第二阶段为节点执行集群拓扑配置信息的更新过程，直至此时，原集群中的节点，才能感知到新加入节点的存在，因此会更新其<code>quorum</code>。</p>
<p>参考文献</p>
<p>[1]. Ongaro D, Ousterhout J K. In search of an understandable consensus algorithm[C]//USENIX Annual Technical Conference. 2014: 305-319.<br>[2]. <a href="https://github.com/etcd-io/etcd" target="_blank" rel="noopener">https://github.com/etcd-io/etcd</a></p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>分布式协调服务</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>分布式协调服务</tag>
      </tags>
  </entry>
  <entry>
    <title>etcd-raft snapshot实现源码简析</title>
    <url>/2019/01/14/etcd-raft-snapshot%E5%AE%9E%E7%8E%B0%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/</url>
    <content><![CDATA[<p>上一篇文章阐述了<code>etcd-raft</code>存储模块相关逻辑源码，准确而言是与日志存储相关，主要是围绕<code>raftLog</code>、<code>unstable</code>以及<code>Storage/MemoryStorage</code>展开，涉及流程较多，且结合流程逻辑阐述得比较详细。本文主题是<code>snapshot</code>，快照也属于存储的范畴，因此本文内容与上一篇文章存在重叠。不同的是，本文是围绕<code>snapshot</code>展开相关逻辑的分析。具体而言，首先简要介绍<code>snapshot</code>数据结构及重要接口实现，然后重点分析<code>snapshot</code>的全局逻辑（大部分源码已在上篇文章中分析），这主要包括如下四个子问题：其一，<code>leader</code>节点何时执行<code>snapshot</code>同步复制，其二，（应用程序）何时触发<code>snapshot</code>操作及，其三，（应用程序）如何应用<code>snapshot</code>数据，最后，<code>follower</code>节点何时以及如何应用<code>snapshot</code>数据事实上，第一、四两点是从底层协议的角度阐述与<code>snapshot</code>的相关操作，而第二、三点是从应用程序的角度来阐述<code>snapshot</code>相关操作（这其实涵盖了所有节点的操作）。但总的原则不变，目的是从整体上把握<code>snapshot</code>的逻辑，希望读者不要混淆。</p>
<a id="more"></a>

<p>需要注意，<code>etcd-raft</code>中关于存储的组件<code>unstable</code>、<code>Storage</code>以及<code>WAL</code>都包含快照，其中前二者的日志项包括快照存储在内存中，<code>WAL</code>将日志项以及快照数据存储在磁盘上。所谓快照实际上表示的是某一时刻系统的状态数据，那么在此时刻之前所保留的日志可以清除，因此它明显具有压缩日志项、节约磁盘空间的作用（在<code>unstable</code>及<code>Storage</code>中仍旧存储在内存）。但<code>WAL</code>与前二者不同，实际上它存储的<code>snapshot</code>数据是指存储它的元数据信息（原因是进行日志重放时，只要从快照元数据记录的日志索引开始即可，在【<a href="https://qqzeng.top/2019/01/11/etcd-raft-WAL%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/" target="_blank" rel="noopener">etcd-raft WAL日志管理源码简析</a>】章节详述），并且每次构建快照数据，它不会覆盖已有的快照数据，而<code>unstable</code>及<code>Storage</code>在更新快照时则会进行替换。另外，<code>etcd-raft</code>还提供一个<code>Snapshotter</code>组件来构建<code>Snapshot</code>数据，它也属于快照数据，而且是增量更新并保存并持久化到磁盘的快照数据目录下的。下面介绍的<code>Snapshot</code>数据结构指的便是此<code>Snapshot</code>类型数据。因为它们相互关联，但作用不同。因此希望读者不要将这几种类型的<code>snapshot</code>混淆，仔细理解每一处的含义。</p>
<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p><code>Snapshot</code>的数据结构及其相关接口的实现较为简单，大致了解下即可，其中数据结构相关代码的主要目录为<code>/etcd/etcdserver/api/snap/</code>。</p>
<h3 id="Snapshot"><a href="#Snapshot" class="headerlink" title="Snapshot"></a>Snapshot</h3><p><code>Snapshot</code>的数据结构如下所示：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Snapshot <span class="keyword">struct</span> &#123;</span><br><span class="line">	Data             []<span class="keyword">byte</span>           <span class="string">`protobuf:"bytes,1,opt,name=data" json:"data,omitempty"`</span></span><br><span class="line">	Metadata         SnapshotMetadata <span class="string">`protobuf:"bytes,2,opt,name=metadata" json:"metadata"`</span></span><br><span class="line">&#125; <span class="comment">// raft.pb.go</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> SnapshotMetadata <span class="keyword">struct</span> &#123;</span><br><span class="line">	ConfState        ConfState <span class="string">`protobuf:"bytes,1,opt,name=conf_state,json=confState" json:"conf_state"`</span></span><br><span class="line">    <span class="comment">// 系统构建快照时，最后一条日志项的索引值</span></span><br><span class="line">	Index            <span class="keyword">uint64</span>    <span class="string">`protobuf:"varint,2,opt,name=index" json:"index"`</span></span><br><span class="line">	Term             <span class="keyword">uint64</span>    <span class="string">`protobuf:"varint,3,opt,name=term" json:"term"`</span></span><br><span class="line">&#125; <span class="comment">// raft.pb.go</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> ConfState <span class="keyword">struct</span> &#123; </span><br><span class="line">    <span class="comment">// 表示集群中的节点的信息， Nodes 表示 leader及follower的id数组，</span></span><br><span class="line">    <span class="comment">// 而 Learners 表示集群中 learner 的 id 数组</span></span><br><span class="line">	Nodes            []<span class="keyword">uint64</span> <span class="string">`protobuf:"varint,1,rep,name=nodes" json:"nodes,omitempty"`</span></span><br><span class="line">	Learners         []<span class="keyword">uint64</span> <span class="string">`protobuf:"varint,2,rep,name=learners" json:"learners,omitempty"`</span></span><br><span class="line">&#125; <span class="comment">// raft.pb.go</span></span><br></pre></td></tr></table></figure>

<p><code>Snapshot</code>的数据结构比较简单。我们下面简单了解其几个关键接口实现，首先是创建快照（文件）：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 构建快照文件，应用程序使用此接口来创建持久化的快照文件</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *Snapshotter)</span> <span class="title">SaveSnap</span><span class="params">(snapshot raftpb.Snapshot)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> raft.IsEmptySnap(snapshot) &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> s.save(&amp;snapshot)</span><br><span class="line">&#125; <span class="comment">// snapshotter.go</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *Snapshotter)</span> <span class="title">save</span><span class="params">(snapshot *raftpb.Snapshot)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	start := time.Now()</span><br><span class="line">	<span class="comment">// 1. snapshot 文件命令规则：Term-Index.snap</span></span><br><span class="line">	fname := fmt.Sprintf(<span class="string">"%016x-%016x%s"</span>, snapshot.Metadata.Term, snapshot.Metadata.Index, snapSuffix)</span><br><span class="line">	<span class="comment">// 2. 序列化快照结构体数据</span></span><br><span class="line">	b := pbutil.MustMarshal(snapshot)</span><br><span class="line">	<span class="comment">// 3. 生成 crc 检验数据</span></span><br><span class="line">	crc := crc32.Update(<span class="number">0</span>, crcTable, b)</span><br><span class="line">	<span class="comment">// 4. 生成快照 pb 结构数据</span></span><br><span class="line">	snap := snappb.Snapshot&#123;Crc: crc, Data: b&#125;</span><br><span class="line">	<span class="comment">// 5. 序列化</span></span><br><span class="line">	d, err := snap.Marshal()</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	snapMarshallingSec.Observe(time.Since(start).Seconds())</span><br><span class="line">	<span class="comment">// 6. 构建快照文件路径</span></span><br><span class="line">	spath := filepath.Join(s.dir, fname)</span><br><span class="line">	fsyncStart := time.Now()</span><br><span class="line">	<span class="comment">// 7. 快照文件存盘</span></span><br><span class="line">	err = pioutil.WriteAndSyncFile(spath, d, <span class="number">0666</span>)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// snapshotter.go</span></span><br></pre></td></tr></table></figure>

<p>再简单也解加载快照文件的过程：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 加载快照文件，应用程序使用此接口来加载已存盘的快照文件</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *Snapshotter)</span> <span class="title">Load</span><span class="params">()</span> <span class="params">(*raftpb.Snapshot, error)</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 获取快照文件目录下的所有快照谁的，并排序</span></span><br><span class="line">	names, err := s.snapNames()</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// 2. 遍历快照文件集合，并加载每一个快照文件到内存，形成*raftpb.Snapshot实例</span></span><br><span class="line">	<span class="comment">// load 的过程也比较简单，为创建的逆过程，包括反序列化及校验 crc</span></span><br><span class="line">	<span class="keyword">var</span> snap *raftpb.Snapshot</span><br><span class="line">	<span class="keyword">for</span> _, name := <span class="keyword">range</span> names &#123;</span><br><span class="line">		<span class="keyword">if</span> snap, err = loadSnap(s.lg, s.dir, name); err == <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">break</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">return</span> snap, <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// snapshotter.go</span></span><br></pre></td></tr></table></figure>

<p>快照数据结构比较简单，而且其相关接口的实现也比较简单，不多阐述。</p>
<h2 id="关键流程"><a href="#关键流程" class="headerlink" title="关键流程"></a>关键流程</h2><p>上文提到，<code>snapshot</code>是系统某时刻状态的数据，在<code>etcd-raft</code>中会在多个地方存储<code>snapshot</code>数据，这包括<code>unstable</code>、<code>Storage/MemoryStorage</code>、<code>WAL</code>以及<code>snap</code>日志文件。正是因为涉及到多个存储的结构，因此整个关于<code>snapshot</code>的逻辑也稍显啰嗦。此部分代码的主要目录为：<code>/etcd/raft/</code>、<code>/etcd/contrib/raftexample/</code>。</p>
<h3 id="snapshot-相关逻辑总结"><a href="#snapshot-相关逻辑总结" class="headerlink" title="snapshot 相关逻辑总结"></a>snapshot 相关逻辑总结</h3><p>大概地，关于<code>unstable</code>日志存储，它与底层协议库直接交互，当<code>leader</code>节点发现<code>follower</code>节点进度过慢时（这也包括节点新加入的情形），会尝试发送<code>MsgSnap</code>，以加快节点状态同步（关于<code>leader</code>如何知道<code>follower</code>节点的日志过旧的原因是<code>leader</code>为每个<code>follower</code>维护了其目前的日志进度视图，这通过<code>progress.go</code>实现）。更准确来说，<code>leader</code>节点在发现本节点的日志过长时（<code>MemoryStorage</code>的实现规则是将长度大于 10000  ），会将更早的日志<code>compact</code>掉以节约内存（这在应用每次收到<code>raft</code>协议核心的<code>Ready</code>通知时，都会检查是否可以触发构建快照）。因此，若<code>leader</code>在给<code>follower</code>节点同步日志时，其可能发现对应的（需要从哪一项日志开始同步）日志项不存在，那么它会认为对应的日志已经被<code>compact</code>掉，因此尝试使用同步快照来代替（即发送<code>MsgSnap</code>消息）。换言之，<code>unstable</code>中的<code>snapshot</code>是来自于<code>leader</code>节点的同步（若<code>follower</code>节点允许直接执行快照同步，会将<code>unstable</code>中的快照直接进行替换）。</p>
<p>而关于<code>Storage</code>日志存储中的快照的来源，则可能来自两处，其一是节点自身主动构建<code>snapshot</code>，即应用程序发现达到快照构建条件时，便触发快照创建，所以这部分快照所对应的数据已存在于节点的应用状态机中，因此也不需要被重放，其主要目的是进行日志压缩。其二是<code>leader</code>节点通过<code>MsgSnap</code>将快照同步到<code>follower</code>节点的<code>unstable</code>中，然后<code>follower</code>的会生成<code>Ready</code>结构并传递给上层应用（里面封装了<code>unstable</code>的<code>snapshot</code>数据），因此最终由<code>follower</code>节点的应用将<code>unstable</code>中的<code>snapshot</code>应用到节点的<code>Storage</code>中。此处的快照的作用使用同步快照数据来代替同步日志项数据，因此减少了网络及 IO 开销，并加速了节点状态的同步。</p>
<p>对比<code>unstable</code>和<code>Storage</code>中快照数据的来源可知，<code>unstable</code>中的快照数据也必须交给上层应用，由上层应用进行<code>WAL</code>持久化、保存<code>snap</code>日志并应用到<code>Storage</code>中。而<code>Storage</code>中的快照数据的另外一个来源则由节点应用层自身直接创建，当然，此时也要作<code>WAL</code>持久化并且记录<code>snap</code>日志。由此可见，<code>unstable</code>与<code>Storage</code>中的日志存储的内容差别较大。另外需要强调的是，<code>WAL</code>日志中的快照部分存储<code>snapshot</code>元信息。而<code>snap</code>的数据存储方法由使用<code>etcd-raft</code>的应用实现，这取决于应用存储的数据类型（在<code>etcd-raft</code>中使用的是<code>Snapshot</code>数据结构来存储）。</p>
<p>综上，基本涵盖了整个关于<code>snapshot</code>流程的逻辑。下面结合代码更详细地阐述各个逻辑，本文将它分为四个方面进行叙述：其一，<code>leader</code>节点何时执行<code>snapshot</code>同步复制，其二，（应用程序）何时触发<code>snapshot</code>操作及，其三，（应用程序）如何应用<code>snapshot</code>数据，最后，<code>follower</code>节点何时以及如何应用<code>snapshot</code>数据。（这四点其实可以串联在一起叙述，但本文还是将它们分开叙述，希望读者能够理清并串联好整个逻辑）</p>
<h3 id="leader-节点执行-snapshot-同步复制"><a href="#leader-节点执行-snapshot-同步复制" class="headerlink" title="leader 节点执行 snapshot 同步复制"></a>leader 节点执行 snapshot 同步复制</h3><p>上文提到当<code>leader</code>节点发现<code>follower</code>节点日志过旧时会使用同步<code>snapshot</code>复制来代替普通的日志同步（即发送<code>MsgSnap</code>而非<code>MsgApp</code>消息），这<code>leadaer</code>节点之所以能够发现<code>follower</code>节点的日志进度过慢的原因是，它使用为此<code>follower</code>节点保存的当前已同步日志索引来获取其<code>unstable</code>（也包括<code>Storage</code>）中的日志项（集合）时，发现不能成功获取对应的日志项，由此说明对应的日志项已经被<code>compact</code>掉了，即已经创建了快照。（关于如何创建快照，在下小节详述），因此，<code>leader</code>节点会向<code>follower</code>节点发送<code>MsgSnap</code>消息。相关代码及部分关键注释如下（下面只展示了关键函数的代码，整个流程为：<code>stepLeader() -&gt; bcastAppend() -&gt; sendAppend() -&gt; maybeSendAppend()</code>）：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *raft)</span> <span class="title">maybeSendAppend</span><span class="params">(to <span class="keyword">uint64</span>, sendIfEmpty <span class="keyword">bool</span>)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 获取 id 为 to 的 follower 的日志同步进度视图（具体查看 progress.go）</span></span><br><span class="line">	pr := r.getProgress(to)</span><br><span class="line">	<span class="comment">// 2. 若对应 follower 节点未停止接收消息（停止的原因可能是在执行一个耗时操作，如应用快照数据）</span></span><br><span class="line">	<span class="keyword">if</span> pr.IsPaused() &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 3. 构建消息实例</span></span><br><span class="line">	m := pb.Message&#123;&#125;</span><br><span class="line">	m.To = to</span><br><span class="line">	<span class="comment">// 4. 通过 Next(为节点维护的下一个需要同步的日志索引)查找对应的 term 及 ents</span></span><br><span class="line">	<span class="comment">// 注意：1. maxMsgSize 是作为控制最大的传输日志项数量</span></span><br><span class="line">	<span class="comment">// 		2. 其在查找对应的 term 及 ents 时，也会查找 Storage 中的日志项集合</span></span><br><span class="line">	term, errt := r.raftLog.term(pr.Next - <span class="number">1</span>)</span><br><span class="line">	ents, erre := r.raftLog.entries(pr.Next, r.maxMsgSize)</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(ents) == <span class="number">0</span> &amp;&amp; !sendIfEmpty &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 5. 如果查找失败，则考虑发送 MsgSnap 消息</span></span><br><span class="line">	<span class="keyword">if</span> errt != <span class="literal">nil</span> || erre != <span class="literal">nil</span> &#123; <span class="comment">// send snapshot if we failed to get term or entries</span></span><br><span class="line">		<span class="comment">// 此处记录对应节点最近是活跃</span></span><br><span class="line">		<span class="keyword">if</span> !pr.RecentActive &#123;</span><br><span class="line">			r.logger.Debugf(<span class="string">"ignore sending snapshot to %x since it is not recently active"</span>, to)</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">		&#125;</span><br><span class="line">		m.Type = pb.MsgSnap</span><br><span class="line">		<span class="comment">// 5.1 通过 raftLog 获取 snapshot 数据，若 unstable 中没有，则从 Storage 中获取</span></span><br><span class="line">		snapshot, err := r.raftLog.snapshot()</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		m.Snapshot = snapshot</span><br><span class="line">		sindex, sterm := snapshot.Metadata.Index, snapshot.Metadata.Term</span><br><span class="line">		r.logger.Debugf(<span class="string">"%x [firstindex: %d, commit: %d] sent snapshot[index: %d, term: %d] to %x [%s]"</span>,</span><br><span class="line">			r.id, r.raftLog.firstIndex(), r.raftLog.committed, sindex, sterm, to, pr)</span><br><span class="line">		<span class="comment">// 5.2 更新对应节点的 progress 实例对象</span></span><br><span class="line">		pr.becomeSnapshot(sindex)</span><br><span class="line">		r.logger.Debugf(<span class="string">"%x paused sending replication messages to %x [%s]"</span>, r.id, to, pr)</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123; <span class="comment">// 6. 否则进行日志同步，即发送正常的 MsgApp 消息</span></span><br><span class="line">		m.Type = pb.MsgApp</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 此处会将此消息打包到 raft.msgs 中，进一步会由 node 将其打包到 Ready 结构中，并转发给上层应用程序，</span></span><br><span class="line">	<span class="comment">// 由应用程序调用启用网络传输的组件，将消息发送出去（在上一篇文章中已经详述）</span></span><br><span class="line">	r.send(m)</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125; <span class="comment">// /etcd/raft/raft.go</span></span><br></pre></td></tr></table></figure>

<h3 id="何时触发-snapshot-操作"><a href="#何时触发-snapshot-操作" class="headerlink" title="何时触发  snapshot  操作"></a>何时触发  snapshot  操作</h3><p>事实上，触发<code>snapshot</code>操作是由上层应用程序完成的（并非底层<code>raft</code>协议核心库的功能）。触发构建快照的规则是：<code>Storage</code>中的日志条目的数量大于 10000，一旦达到此条件，则会将日志项索引不在过去 10000 条索引范围内的日志执行<code>compact</code>操作，并创建对应的快照数据，记录到<code>WAL</code>日志文件，以及<code>snap</code>快照文件中。相关代码及部分关键注释如下（下面只展示了关键函数的代码，整个流程为：<code>startRaft() -&gt; serveChannels() -&gt; maybeTriggerSnapshot()</code>）：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 针对 memoryStorage 触发快照操作（如果满足条件）（注意这是对 memoryStorage 中保存的日志信息作快照）</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rc *raftNode)</span> <span class="title">maybeTriggerSnapshot</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="comment">// 0. 判断是否达到创建快照（compact）的条件</span></span><br><span class="line">	<span class="keyword">if</span> rc.appliedIndex-rc.snapshotIndex &lt;= rc.snapCount &#123;</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	log.Printf(<span class="string">"start snapshot [applied index: %d | last snapshot index: %d]"</span>, rc.appliedIndex, rc.snapshotIndex)</span><br><span class="line">	<span class="comment">// 1. 加载状态机中当前的状态数据（此方法由应用程序提供，在 kvstore 中）</span></span><br><span class="line">	data, err := rc.getSnapshot()</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		log.Panic(err)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 利用上述快照数据、以及 appliedIndex 等为 memoryStorage 实例创建快照（它会覆盖/更新 memoryStorage 已有的快照信息）</span></span><br><span class="line">	snap, err := rc.raftStorage.CreateSnapshot(rc.appliedIndex, &amp;rc.confState, data)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="built_in">panic</span>(err)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 3. 保存快照到 WAL 日志（快照的索引/元数据信息）</span></span><br><span class="line">	<span class="comment">// 以及到 snap 日志文件中（它包含所有信息，一般而言，此 snap 结构由应用程序决定，etcd-raft 的实现包含了元数据及实际数据）</span></span><br><span class="line">	<span class="keyword">if</span> err := rc.saveSnap(snap); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="built_in">panic</span>(err)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 4. 如果满足日志被 compact 的条件（防止内存中的日志项过多），则对内存中的日志项集合作 compact 操作</span></span><br><span class="line">	<span class="comment">// compact 操作会丢弃 memoryStorage 日志项集中 compactIndex 之前的日志</span></span><br><span class="line">	compactIndex := <span class="keyword">uint64</span>(<span class="number">1</span>)</span><br><span class="line">	<span class="keyword">if</span> rc.appliedIndex &gt; snapshotCatchUpEntriesN &#123;</span><br><span class="line">		compactIndex = rc.appliedIndex - snapshotCatchUpEntriesN</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> err := rc.raftStorage.Compact(compactIndex); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="built_in">panic</span>(err)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	log.Printf(<span class="string">"compacted log at index %d"</span>, compactIndex)</span><br><span class="line">    <span class="comment">// 5. 更新应用程序的快照位置(进度)信息</span></span><br><span class="line">	rc.snapshotIndex = rc.appliedIndex</span><br><span class="line">&#125; <span class="comment">// /etcd/contrib/raftexample/raft.go</span></span><br></pre></td></tr></table></figure>

<h3 id="如何应用-snapshot-数据"><a href="#如何应用-snapshot-数据" class="headerlink" title="如何应用 snapshot 数据"></a>如何应用 snapshot 数据</h3><p>本小节所涉及的如何应用<code>snapshot</code>数据亦是针对应用程序而言（因为<code>follower</code>节点的<code>unstable</code>也会由协议库来应用<code>leader</code>节点发送的快照数据）。大概地，应用程序应用快照数据包含两个方面：其一，在节点刚启动时（宕机后重启）会进行日志重放，因此在重放过程中，若快照数据不为空（由<code>snap</code>存盘的快照数据，包括元信息及实际数据），则加载快照数据，并将其应用到<code>Storage</code>的快照中，而且会重放快照数据后的<code>WAL</code>日志项数据，并将其追加到<code>Storage</code>的日志项集。如此以来，节点便能重构其状态数据。其相关代码如下（实际完整调用为：<code>startRaft() -&gt; serveChannels()</code>）：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rc *raftNode)</span> <span class="title">replayWAL</span><span class="params">()</span> *<span class="title">wal</span>.<span class="title">WAL</span></span> &#123;</span><br><span class="line">	log.Printf(<span class="string">"replaying WAL of member %d"</span>, rc.id)</span><br><span class="line">	<span class="comment">// 1. 从 snap 快照文件中加载 快照数据（包含元信息及实际数据）</span></span><br><span class="line">	snapshot := rc.loadSnapshot()</span><br><span class="line">	<span class="comment">// 2. 从指定日志索引位置打开 WAL 日志，以准备读取快照之后的日志项</span></span><br><span class="line">	w := rc.openWAL(snapshot)</span><br><span class="line">	<span class="comment">// 3. 读取指定索引位置后的所有日志</span></span><br><span class="line">	_, st, ents, err := w.ReadAll()</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		log.Fatalf(<span class="string">"raftexample: failed to read WAL (%v)"</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 4. 应用程序创建一个 MemoryStorage 实例</span></span><br><span class="line">	rc.raftStorage = raft.NewMemoryStorage()</span><br><span class="line">	<span class="comment">// 5. 若快照数据不为空，则将快照数据应用到 memoryStorage 中，替换掉已有的 snapshot 实例</span></span><br><span class="line">	<span class="keyword">if</span> snapshot != <span class="literal">nil</span> &#123;</span><br><span class="line">		rc.raftStorage.ApplySnapshot(*snapshot)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 6. 设置 HardState 到 memoryStorage 实例</span></span><br><span class="line">	rc.raftStorage.SetHardState(st)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// append to storage so raft starts at the right place in log</span></span><br><span class="line">	<span class="comment">// 7. 将 WAL 重放的日志项集追加到 memoryStorage 实例（显然，此日志项不包含已经快照的日志项）</span></span><br><span class="line">	rc.raftStorage.Append(ents)</span><br><span class="line">	<span class="comment">// send nil once lastIndex is published so client knows commit channel is current</span></span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(ents) &gt; <span class="number">0</span> &#123;</span><br><span class="line">		<span class="comment">// 8. 如果在快照后，仍存在日志项记录，则设置 lastIndex</span></span><br><span class="line">		rc.lastIndex = ents[<span class="built_in">len</span>(ents)<span class="number">-1</span>].Index</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="comment">// 9. 通知 kvstore，日志重放已经完毕，因此 kvstore 状态机也会从 snap 快照文件中加载数据</span></span><br><span class="line">		<span class="comment">// 参见下面的代码片段</span></span><br><span class="line">        rc.commitC &lt;- <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> w</span><br><span class="line">&#125; <span class="comment">// /etcd/raftexample/raft.go</span></span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *kvstore)</span> <span class="title">readCommits</span><span class="params">(commitC &lt;-<span class="keyword">chan</span> *<span class="keyword">string</span>, errorC &lt;-<span class="keyword">chan</span> error)</span></span> &#123;</span><br><span class="line">	<span class="comment">// raftNode 会将日志项 或 nil 放入 commitC 管道</span></span><br><span class="line">	<span class="keyword">for</span> data := <span class="keyword">range</span> commitC &#123;</span><br><span class="line">		<span class="keyword">if</span> data == <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="comment">// done replaying log; new data incoming</span></span><br><span class="line">			<span class="comment">// OR signaled to load snapshot</span></span><br><span class="line">			<span class="comment">// 从 snap 快照文件中加载数据，这包括两种情形：</span></span><br><span class="line">			<span class="comment">// 一是重启时重放日志，</span></span><br><span class="line">			<span class="comment">// 二是当 leader 向 follower 同步 snapshot 数据时，节点会将其应用到 unstable 及 Storage 中，同样会保存到 WAL 及 snap 文件</span></span><br><span class="line">			<span class="comment">// 因此让状态机重新加载 snap 快照数据</span></span><br><span class="line">			snapshot, err := s.snapshotter.Load()</span><br><span class="line">			<span class="comment">// ...</span></span><br><span class="line">			<span class="keyword">if</span> err := s.recoverFromSnapshot(snapshot.Data); err != <span class="literal">nil</span> &#123;</span><br><span class="line">				log.Panic(err)</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">continue</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 有新的数据已经被提交，因此将其应用到状态机中</span></span><br><span class="line">		<span class="keyword">var</span> dataKv kv</span><br><span class="line">		dec := gob.NewDecoder(bytes.NewBufferString(*data))</span><br><span class="line">		<span class="keyword">if</span> err := dec.Decode(&amp;dataKv); err != <span class="literal">nil</span> &#123;</span><br><span class="line">			log.Fatalf(<span class="string">"raftexample: could not decode message (%v)"</span>, err)</span><br><span class="line">		&#125;</span><br><span class="line">		s.mu.Lock()</span><br><span class="line">		s.kvStore[dataKv.Key] = dataKv.Val</span><br><span class="line">		s.mu.Unlock()</span><br><span class="line">	&#125;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">&#125; <span class="comment">// /etcd/raftexample/kvstore.go</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *kvstore)</span> <span class="title">recoverFromSnapshot</span><span class="params">(snapshot []<span class="keyword">byte</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> store <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span></span><br><span class="line">	<span class="keyword">if</span> err := json.Unmarshal(snapshot, &amp;store); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	s.mu.Lock()</span><br><span class="line">	s.kvStore = store</span><br><span class="line">	s.mu.Unlock()</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /etcd/raftexample/kvstore.go</span></span><br></pre></td></tr></table></figure>

<p>其二，当<code>leader</code>节点同步快照数据给<code>follower</code>节点时，协议库会将快照数据应用到<code>unstable</code>（如果合法的话），然后，将<code>Ready</code>实例返回给应用程序，应用程序会检测到<code>Ready</code>结构中包含快照数据，因此，会将快照数据应用到<code>Storage</code>中。其相关代码如下（实际完整调用为：<code>startRaft() -&gt; serveChannels()</code>）：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rc *raftNode)</span> <span class="title">serveChannels</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="comment">// 节点刚启动时，通过加载 snap 快照 &amp;&amp; 重放 WAL 日志，以将其应用到 memoryStorage 中</span></span><br><span class="line">    <span class="comment">// 因此可以从 memoryStorage 中取出相关数据</span></span><br><span class="line">	snap, err := rc.raftStorage.Snapshot()</span><br><span class="line">	rc.confState = snap.Metadata.ConfState</span><br><span class="line">	rc.snapshotIndex = snap.Metadata.Index</span><br><span class="line">	rc.appliedIndex = snap.Metadata.Index</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// 应用程序状态机更新的事件循环，即循环等待底层协议库的 Ready 通知</span></span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> &lt;-ticker.C:</span><br><span class="line">			rc.node.Tick()</span><br><span class="line">		<span class="comment">// 1. 收到底层协议库的 Ready 通知，关于 Ready 的结构已经在介绍 raftexample 文章中简要介绍</span></span><br><span class="line">		<span class="keyword">case</span> rd := &lt;-rc.node.Ready():</span><br><span class="line">			<span class="comment">// 2. 先将 Ready 中需要被持久化的数据保存到 WAL 日志文件（在消息转发前）</span></span><br><span class="line">			rc.wal.Save(rd.HardState, rd.Entries)</span><br><span class="line">			<span class="comment">// 3. 如果 Ready 中的需要被持久化的快照不为空</span></span><br><span class="line">			<span class="comment">// 此部分快照数据的来源是 leader 节点通过 MsgSnap 消息同步给 follower 节点</span></span><br><span class="line">			<span class="keyword">if</span> !raft.IsEmptySnap(rd.Snapshot) &#123;</span><br><span class="line">				<span class="comment">// 3.1 保存快照到 WAL 日志（快照的索引/元数据信息）以及到</span></span><br><span class="line">				<span class="comment">// snap 日志文件中（由应用程序来实现 snap 的数据结构，etcd-raft 的实现包含了快照的元信息及实际数据）</span></span><br><span class="line">				<span class="comment">// snap 日志文件会作为 状态机 (kvstore) 加载快照数据的来源（重启时加载，以及快照更新时重新加载）</span></span><br><span class="line">				rc.saveSnap(rd.Snapshot)</span><br><span class="line">				<span class="comment">// 3.2 将快照应用到 memoryStorage 实例，替换掉其 snapshot 实例</span></span><br><span class="line">				rc.raftStorage.ApplySnapshot(rd.Snapshot)</span><br><span class="line">				<span class="comment">// 3.3 更新应用程序保存的快照信息</span></span><br><span class="line">				<span class="comment">// 这包括更新 snapshotIndex、appliedIndex以及confState</span></span><br><span class="line">				<span class="comment">// 另外，还会通知 kvstore 重新加载 snap 文件的快照数据</span></span><br><span class="line">				rc.publishSnapshot(rd.Snapshot)</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">// 4. 追加 Ready 结构中需要被持久化的信息（在消息转发前）</span></span><br><span class="line">			rc.raftStorage.Append(rd.Entries)</span><br><span class="line">			<span class="comment">// 5. 转发 Ready 结构中的消息</span></span><br><span class="line">			rc.transport.Send(rd.Messages)</span><br><span class="line">			<span class="comment">// 6. 将日志应用到状态机（如果存在已经提交，即准备应用的日志项）</span></span><br><span class="line">			<span class="comment">// 会更新 appliedIndex</span></span><br><span class="line">			<span class="keyword">if</span> ok := rc.publishEntries(rc.entriesToApply(rd.CommittedEntries)); !ok &#123;</span><br><span class="line">				rc.stop()</span><br><span class="line">				<span class="keyword">return</span></span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">// 7. 触发快照操作（如果满足条件）</span></span><br><span class="line">			rc.maybeTriggerSnapshot()</span><br><span class="line">			<span class="comment">// 8. 通知底层 raft 协议库实例 node，即告知当前 Ready 已经处理完毕，可以准备下一个</span></span><br><span class="line">			rc.node.Advance()</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="comment">// /etcd/contrib/raftexample/raft.go</span></span><br></pre></td></tr></table></figure>

<h3 id="follower-节点何时以及如何应用-snapshot-数据"><a href="#follower-节点何时以及如何应用-snapshot-数据" class="headerlink" title="follower 节点何时以及如何应用 snapshot 数据"></a>follower 节点何时以及如何应用 snapshot 数据</h3><p> 最后，我们来简单了解<code>follower</code>节点收到<code>leader</code>节点的<code>MsgSnap</code>消息时，如何应用<code>snapshot</code>数据。其大致的逻辑为：当<code>follower</code>节点收到<code>MsgSnap</code>消息时，会判断此快照是否合法，若合法，则将共应用到<code>unstable</code>，并且更新相关的记录索引（如<code>offset</code>等），返回快照应用成功的消息。否则，返回快照已应用的消息（事实上回复消息没有明显区分应用失败还是成功，实际上是以<code>lastIndex</code>及<code>commited</code>来区分，这足以使得<code>leader</code>节点获悉<code>follower</code>节点日志进度）。同时<code>follower</code>节点还会更新集群的拓扑结构信息。再提醒一次，其最后调用的<code>send()</code>函数使得节点的上层应用程序将<code>snapshot</code>应用到<code>Storage</code>，并且作<code>WAL</code>日志以及<code>snap</code>快照。其相关代码为（实际完整调用为：<code>stepFollower() -&gt; handleSnapshot() -&gt; restore()</code>）：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *raft)</span> <span class="title">handleSnapshot</span><span class="params">(m pb.Message)</span></span> &#123;</span><br><span class="line">	sindex, sterm := m.Snapshot.Metadata.Index, m.Snapshot.Metadata.Term</span><br><span class="line">	<span class="comment">// 1. 若应用成功，则发送当前 raftLog 中（包括 unstable 及 Storage）的最后一项日志（之前的日志已作为快照数据存储）</span></span><br><span class="line">	<span class="keyword">if</span> r.restore(m.Snapshot) &#123;</span><br><span class="line">		r.logger.Infof(<span class="string">"%x [commit: %d] restored snapshot [index: %d, term: %d]"</span>,</span><br><span class="line">			r.id, r.raftLog.committed, sindex, sterm)</span><br><span class="line">		<span class="comment">// 1.1 此 send 函数会将消息最终放入 Ready 结构中，node 会将 Ready 实例进行打包，以发送给节点上层应用程序</span></span><br><span class="line">		<span class="comment">// 上层应用程序收到 Ready 通知后，检查到此消息中包含 snapshot 数据，则应用到 Storage，并作 WAL日志以及 snap 快照记录</span></span><br><span class="line">		r.send(pb.Message&#123;To: m.From, Type: pb.MsgAppResp, Index: r.raftLog.lastIndex()&#125;)</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="comment">// 1.2 否则说明此快照数据已应用，则发送目前已提交的日志项的索引给 leader</span></span><br><span class="line">		r.logger.Infof(<span class="string">"%x [commit: %d] ignored snapshot [index: %d, term: %d]"</span>,</span><br><span class="line">			r.id, r.raftLog.committed, sindex, sterm)</span><br><span class="line">		r.send(pb.Message&#123;To: m.From, Type: pb.MsgAppResp, Index: r.raftLog.committed&#125;)</span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="comment">// /etcd/raft/raft.go</span></span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *raft)</span> <span class="title">restore</span><span class="params">(s pb.Snapshot)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 若快照消息中的快照索引小于已提交的日志项的日志索引，则不能应用此快照（之前已应用）</span></span><br><span class="line">	<span class="keyword">if</span> s.Metadata.Index &lt;= r.raftLog.committed &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 否则，若此索引与任期匹配</span></span><br><span class="line">	<span class="keyword">if</span> r.raftLog.matchTerm(s.Metadata.Index, s.Metadata.Term) &#123;</span><br><span class="line">		r.logger.Infof(<span class="string">"%x [commit: %d, lastindex: %d, lastterm: %d] fast-forwarded commit to snapshot [index: %d, term: %d]"</span>,</span><br><span class="line">			r.id, r.raftLog.committed, r.raftLog.lastIndex(), r.raftLog.lastTerm(), s.Metadata.Index, s.Metadata.Term)</span><br><span class="line">		<span class="comment">// 2.1 则更新 raftLog 中的 commited 字段，因为 committed 之前的日志代表已经提交</span></span><br><span class="line">		r.raftLog.commitTo(s.Metadata.Index)</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// The normal peer can't become learner.</span></span><br><span class="line">	<span class="comment">// 3. 这里是更新当前节点的集群的拓扑结构信息，即集群中包含哪些节点，它们各自的角色是什么</span></span><br><span class="line">	<span class="keyword">if</span> !r.isLearner &#123;</span><br><span class="line">		<span class="keyword">for</span> _, id := <span class="keyword">range</span> s.Metadata.ConfState.Learners &#123;</span><br><span class="line">			<span class="keyword">if</span> id == r.id &#123;</span><br><span class="line">				r.logger.Errorf(<span class="string">"%x can't become learner when restores snapshot [index: %d, term: %d]"</span>, r.id, s.Metadata.Index, s.Metadata.Term)</span><br><span class="line">				<span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	r.logger.Infof(<span class="string">"%x [commit: %d, lastindex: %d, lastterm: %d] starts to restore snapshot [index: %d, term: %d]"</span>,</span><br><span class="line">		r.id, r.raftLog.committed, r.raftLog.lastIndex(), r.raftLog.lastTerm(), s.Metadata.Index, s.Metadata.Term)</span><br><span class="line"> 	<span class="comment">// 4. 更新 raftLog 的 commited 为快照消息中的索引，以及更换 unstable 中的 snapshot 实例为快照消息中的快照实例</span></span><br><span class="line"> 	<span class="comment">// 并更新 unstable 的 offset 为 快照消息索引+1，更新 ents 字段为空</span></span><br><span class="line">	r.raftLog.restore(s)</span><br><span class="line">	<span class="comment">// 5. 以下同样是重构节点的拓扑信息</span></span><br><span class="line">	r.prs = <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">uint64</span>]*Progress)</span><br><span class="line">	r.learnerPrs = <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">uint64</span>]*Progress)</span><br><span class="line">	r.restoreNode(s.Metadata.ConfState.Nodes, <span class="literal">false</span>)</span><br><span class="line">	r.restoreNode(s.Metadata.ConfState.Learners, <span class="literal">true</span>)</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125; <span class="comment">// /etcd/raft/raft.go</span></span><br></pre></td></tr></table></figure>

<p>至此，关于<code>snapshot</code>的逻辑已经阐述完毕。</p>
<p>简单小结，本文先是简单介绍了<code>Snapshot</code>的数据结构及接口实现（该<code>Snapshot</code>为重启的快照数据加载来源，并配合<code>WAL</code>日志重放记录，以重构节点宕机前的状态），然后围绕<code>unstable</code>及<code>Storage</code>总结了关于<code>snapshot</code>的流程逻辑，以在总体上把握<code>snapshot</code>的核心设计流程。最后，结合代码分析从四个方面梳理<code>snapshot</code>的相关流程，目的是加深读者对整个系统中如何使用<code>snapshot</code>的印象，并且需要理解为何如此设计。</p>
<p>参考文献</p>
<p>[1]. <a href="https://github.com/etcd-io/etcd" target="_blank" rel="noopener">https://github.com/etcd-io/etcd</a><br>[2]. <a href="https://zhuanlan.zhihu.com/p/29865583" target="_blank" rel="noopener">etcd-raft snapshot实现分析</a></p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>分布式协调服务</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>snapshot管理</tag>
      </tags>
  </entry>
  <entry>
    <title>etcd-raft 存储模块源码简析</title>
    <url>/2019/01/12/etcd-raft-%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9D%97%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/</url>
    <content><![CDATA[<p>上一篇文章简单分析了<code>etcd-raft WAL</code>日志管理模块相关的源码。文章集中在<code>WAL</code>库提供的相关接口的阐述，而未将其与<code>raft</code>协议核心库关联起来，即尚未阐述<code>raft</code>协议核心库如何使用<code>WAL</code>日志库，并且上一篇文章虽然是以应用程序使用<code>WAL</code>库为切入点分析，但并没有阐述清楚<code>WAL</code>、<code>Storage</code>以及<code>unstable</code>三者的关联，鉴于三者提供日志存储的功能。本文的重点是分析<code>etcd-raft</code> 存储模块，它包括<code>Storage</code>及其实现<code>memoryStorage</code>（<code>etcd</code>为应用程序提供的一个<code>Storage</code>实现的范例）、<code>unstable</code>以及<code>raftLog</code>三个核心数据结构。另外，阐述<code>Storage</code>同应用程序的交互的细节以及<code>raft</code>协议库与<code>raftLog</code>的交互相关的逻辑，后者包括<code>raftLog</code>重要接口的实现，以及<code>raft</code>协议库的一个典型的简单的日志追加流程（即从<code>leader</code>追加日志，然后广播给<code>follower</code>节点，然后<code>follower</code>节点同样进行日志项的追加，最后<code>leader</code>节点处理<code>follower</code>节点的响应各个环节中日志追加的具体逻辑）。</p>
<a id="more"></a>

<p>（<strong>需要提醒的是，整篇文章较长，因此读者可以选择部分小节进行针对性参考，每个小节的最开始都有概括该小节的内容，各小节的分析是独立进行的</strong>。）同样我们先重点了解几个数据结构，主要包括<code>raftLog</code>、<code>unstable</code>以及<code>Storage &amp; MemoryStorage</code>，读者可以深入源码文件仔细查看相关字段及逻辑（主要涉及的目录<code>/etcd/raft/</code>，也有示例应用的部分代码<code>/etcd/contrib/raftexample</code>）。通过了解相关数据结构，就能大概推测出其相关功能。</p>
<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><h3 id="raftLog"><a href="#raftLog" class="headerlink" title="raftLog"></a>raftLog</h3><p><code>raftLog</code>为<code>raft</code>协议核心处理日志复制提供接口，<code>raft</code>协议库对日志的操作都基于<code>raftLog</code>实施。换言之，协议核心库不会直接同<code>Storage</code>及<code>WAL</code>直接交互。<code>raftLog</code>的数据结构如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> raftLog <span class="keyword">struct</span> &#123;</span><br><span class="line">	<span class="comment">// 包含从上一次快照以来的所有已被持久化的日志项集合</span></span><br><span class="line">	storage Storage</span><br><span class="line">	<span class="comment">// 包含所有未被持久化（一旦宕机便丢失）的日志项集合及快照</span></span><br><span class="line">	<span class="comment">// 它们会被持久化到 storage</span></span><br><span class="line">	unstable unstable</span><br><span class="line">	<span class="comment">// 已被持久化的最高的日志项的索引编号</span></span><br><span class="line">	committed <span class="keyword">uint64</span></span><br><span class="line">	<span class="comment">// 已经被应用程序应用到状态机的最高手日志项索引编号</span></span><br><span class="line">	<span class="comment">// 必须保证： applied &lt;= committed</span></span><br><span class="line">	applied <span class="keyword">uint64</span></span><br><span class="line">	logger Logger</span><br><span class="line">	<span class="comment">// 调用 nextEnts 时，返回的日志项集合的最大的大小</span></span><br><span class="line">	<span class="comment">// nextEnts 函数返回应用程序已经可以应用到状态机的日志项集合</span></span><br><span class="line">	maxNextEntsSize <span class="keyword">uint64</span></span><br><span class="line">&#125; <span class="comment">// log.go</span></span><br></pre></td></tr></table></figure>

<p>关于<code>storage</code>及<code>unstable</code>两个数据我们暂时不知道其具体作用，比如它们是如何被<code>raftLog</code>使用的，它们的区别是什么？我们先继续了解这两个数据结构的内容。</p>
<h3 id="unstable"><a href="#unstable" class="headerlink" title="unstable"></a>unstable</h3><p><code>unstable</code>顾名思义，表示非持久化的存储。其数据结构如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// unstable.entries[i] 存储的日志的索引为 i+unstable.offset</span></span><br><span class="line"><span class="comment">// 另外，unstable.offset 可能会小于 storage.entries 中的最大的索引</span></span><br><span class="line"><span class="comment">// 此时，当继续向 storage 同步日志时，需要先截断其大于 unstable.offset 的部分</span></span><br><span class="line"><span class="keyword">type</span> unstable <span class="keyword">struct</span> &#123;</span><br><span class="line">	<span class="comment">// the incoming unstable snapshot, if any.</span></span><br><span class="line">	<span class="comment">// unstable 包含的快照数据</span></span><br><span class="line">	snapshot *pb.Snapshot</span><br><span class="line">	<span class="comment">// 所有未被写入 storage 的日志</span></span><br><span class="line">	entries []pb.Entry</span><br><span class="line">	<span class="comment">// entries 日志集合中起始的日志项编号</span></span><br><span class="line">	offset  <span class="keyword">uint64</span></span><br><span class="line"></span><br><span class="line">	logger Logger</span><br><span class="line">&#125; <span class="comment">// log_unstable.go</span></span><br></pre></td></tr></table></figure>

<h3 id="Storage-amp-MemoryStorage"><a href="#Storage-amp-MemoryStorage" class="headerlink" title="Storage &amp; MemoryStorage"></a>Storage &amp; MemoryStorage</h3><p><code>Storage</code>表示<code>etcd-raft</code>提供的持久化存储的接口。应用程序负责实现此接口，以将日志信息落盘。并且，若在操作过程此持久化存储时出现错误，则应用程序应该停止对相应的 raft 实例的操作，并需要执行清理或恢复的操作。其数据结构如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Storage 接口需由应用程序来实现，以从存储中以出日志信息</span></span><br><span class="line"><span class="comment">// 如果在操作过程中出现错误，则应用程序应该停止对相应的 raft 实例的操作，并需要执行清理或恢复的操作</span></span><br><span class="line"><span class="keyword">type</span> Storage <span class="keyword">interface</span> &#123;</span><br><span class="line">	<span class="comment">// 返回 HardState 及 ConfState 数据</span></span><br><span class="line">	InitialState() (pb.HardState, pb.ConfState, error)</span><br><span class="line">	<span class="comment">// 返回 [lo, hi) 范围的日志项集合</span></span><br><span class="line">	Entries(lo, hi, maxSize <span class="keyword">uint64</span>) ([]pb.Entry, error)</span><br><span class="line">	<span class="comment">// 返回指定日志项索引的 term</span></span><br><span class="line">	Term(i <span class="keyword">uint64</span>) (<span class="keyword">uint64</span>, error)</span><br><span class="line">	<span class="comment">// 返回日志项中最后一条日志的索引编号</span></span><br><span class="line">	LastIndex() (<span class="keyword">uint64</span>, error)</span><br><span class="line">	<span class="comment">// 返回日志项中最后第一条日志的索引编号，注意在其被创建时，日志项集合会被填充一项 dummy entry</span></span><br><span class="line">	FirstIndex() (<span class="keyword">uint64</span>, error)</span><br><span class="line">	<span class="comment">// 返回最近一次的快照数据，如果快照不可用，则返回出错</span></span><br><span class="line">	Snapshot() (pb.Snapshot, error)</span><br><span class="line">&#125; <span class="comment">// storage.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// MemoryStorage 实现了 Storage 接口，注意 MemoryStorage 也是基于内存的</span></span><br><span class="line"><span class="keyword">type</span> MemoryStorage <span class="keyword">struct</span> &#123;</span><br><span class="line">	sync.Mutex</span><br><span class="line">	hardState pb.HardState</span><br><span class="line">	snapshot  pb.Snapshot</span><br><span class="line">	<span class="comment">// ents[i] 存储的日志项的编号为 i+snapshot.Metadata.Index，即要把快照考虑在内</span></span><br><span class="line">	ents []pb.Entry</span><br><span class="line">&#125; <span class="comment">// storage.go</span></span><br></pre></td></tr></table></figure>

<h2 id="关键流程"><a href="#关键流程" class="headerlink" title="关键流程"></a>关键流程</h2><p>从上述数据结构中发现<code>raftLog</code>封装了<code>storage</code>及<code>unstable</code>。而且大概看一下<code>raftLog</code>中各个接口，发现主要不是同<code>unstable</code>进行交互（也有利用<code>storage</code>的数据）。所以，我们决定从两个方面来明晰主几个数据结构的作用。包括应用程序与<code>Storage</code>交互，以及<code>raft</code>协议核心同<code>raftLog(unstable/storage)</code>交互。希望通过从具体功能实现切入来摸索梳理相关逻辑，并结合数据结构，以达到由外至里尽可能把握其设计原理的效果。</p>
<h3 id="应用程序与-Storage-交互"><a href="#应用程序与-Storage-交互" class="headerlink" title="应用程序与  Storage 交互"></a>应用程序与  Storage 交互</h3><p>为了让读者有更好的理解，本文仍旧从<code>raftexample</code>中的<code>startRaft()</code>开始追溯与上述三个数据结构相关的逻辑，以明晰它们三者的作用。我们从两个方面来阐述交互的大致逻辑，包括应用程序启动（此时<code>raft</code>实例也会被初始化）以及上层应用收到底层<code>raft</code>协议核心的通知(<code>Ready</code>)时所执行的相关操作。</p>
<h4 id="应用初始化"><a href="#应用初始化" class="headerlink" title="应用初始化"></a>应用初始化</h4><p>首先来看第一个：在<code>startRaft()</code>函数中，我们先深入日志重放代码<code>rc.wal = rc.replayWAL()</code>：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 重放 WAL 日志到 raft 实例</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rc *raftNode)</span> <span class="title">replayWAL</span><span class="params">()</span> *<span class="title">wal</span>.<span class="title">WAL</span></span> &#123;</span><br><span class="line">	log.Printf(<span class="string">"replaying WAL of member %d"</span>, rc.id)</span><br><span class="line">	<span class="comment">// 1. 从持久化存储中加载 快照数据</span></span><br><span class="line">	snapshot := rc.loadSnapshot()</span><br><span class="line">	<span class="comment">// 2. 从指定日志索引位置打开 WAL 日志，以准备读取日志</span></span><br><span class="line">	w := rc.openWAL(snapshot)</span><br><span class="line">	<span class="comment">// 3. 读取指定索引位置后的所有日志</span></span><br><span class="line">	_, st, ents, err := w.ReadAll()</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		log.Fatalf(<span class="string">"raftexample: failed to read WAL (%v)"</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 4. 应用程序创建一个 MemoryStorage 实例</span></span><br><span class="line">	rc.raftStorage = raft.NewMemoryStorage()</span><br><span class="line">	<span class="comment">// 5. 若快照数据不为空，则将快照数据应用到 memoryStorage 中</span></span><br><span class="line">	<span class="keyword">if</span> snapshot != <span class="literal">nil</span> &#123;</span><br><span class="line">		rc.raftStorage.ApplySnapshot(*snapshot)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 6. 设置 HardState 到 memoryStorage 实例</span></span><br><span class="line">	rc.raftStorage.SetHardState(st)</span><br><span class="line">	<span class="comment">// append to storage so raft starts at the right place in log</span></span><br><span class="line">	<span class="comment">// 7. 将日志项追加到 memoryStorage 实例，注意，此日志项不包含已经快照的日志项</span></span><br><span class="line">	rc.raftStorage.Append(ents)</span><br><span class="line">	<span class="comment">// send nil once lastIndex is published so client knows commit channel is current</span></span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(ents) &gt; <span class="number">0</span> &#123;</span><br><span class="line">		<span class="comment">// 8. 如果在快照后，仍存在日志项记录，则设置 lastIndex</span></span><br><span class="line">		rc.lastIndex = ents[<span class="built_in">len</span>(ents)<span class="number">-1</span>].Index</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="comment">// 9. 通知 kvstore，日志重放已经完毕</span></span><br><span class="line">		rc.commitC &lt;- <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> w</span><br><span class="line">&#125; <span class="comment">// raft.go</span></span><br></pre></td></tr></table></figure>

<p>我们重点关注与<code>memoryStorage</code>相关的逻辑。步骤 4 创建了一个<code>memoryStorage</code>实例，创建逻辑也比较简单：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// NewMemoryStorage creates an empty MemoryStorage.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewMemoryStorage</span><span class="params">()</span> *<span class="title">MemoryStorage</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> &amp;MemoryStorage&#123;</span><br><span class="line">		<span class="comment">// When starting from scratch populate the list with a dummy entry at term zero.</span></span><br><span class="line">		ents: <span class="built_in">make</span>([]pb.Entry, <span class="number">1</span>),</span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="comment">// storage.go</span></span><br></pre></td></tr></table></figure>

<p>而步骤 5 将快照数据应用到了<code>memoryStorage</code>实例，其逻辑也较为简单：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// ApplySnapshot overwrites the contents of this Storage object with</span></span><br><span class="line"><span class="comment">// those of the given snapshot.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(ms *MemoryStorage)</span> <span class="title">ApplySnapshot</span><span class="params">(snap pb.Snapshot)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	ms.Lock()</span><br><span class="line">	<span class="keyword">defer</span> ms.Unlock()</span><br><span class="line"></span><br><span class="line">	<span class="comment">//handle check for old snapshot being applied</span></span><br><span class="line">	msIndex := ms.snapshot.Metadata.Index</span><br><span class="line">	snapIndex := snap.Metadata.Index</span><br><span class="line">	<span class="keyword">if</span> msIndex &gt;= snapIndex &#123;</span><br><span class="line">		<span class="keyword">return</span> ErrSnapOutOfDate</span><br><span class="line">	&#125;</span><br><span class="line">	ms.snapshot = snap</span><br><span class="line">	ms.ents = []pb.Entry&#123;&#123;Term: snap.Metadata.Term, Index: snap.Metadata.Index&#125;&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// storage.go</span></span><br></pre></td></tr></table></figure>

<p>从代码可以看出，其只是将快照直接进行替换，并将快照的当前索引及任期存入日志项集合。而步骤 6 较为简单，在此略过。简单了解一下步骤 7，它往<code>memoryStorage</code>的日志项集合中追加日志项集合，其代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 新追加的日志项必须是连续的，且 entries[0].Index &gt; ms.entries[0].Index</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(ms *MemoryStorage)</span> <span class="title">Append</span><span class="params">(entries []pb.Entry)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(entries) == <span class="number">0</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">	ms.Lock()</span><br><span class="line">	<span class="keyword">defer</span> ms.Unlock()</span><br><span class="line">	first := ms.firstIndex()</span><br><span class="line">	last := entries[<span class="number">0</span>].Index + <span class="keyword">uint64</span>(<span class="built_in">len</span>(entries)) - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// shortcut if there is no new entry.</span></span><br><span class="line">	<span class="keyword">if</span> last &lt; first &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// truncate compacted entries</span></span><br><span class="line">	<span class="comment">// 若已有的 ms.ents 被 compact 了，则新追加的日志项集有可能为被 compact 掉中的一部分</span></span><br><span class="line">	<span class="comment">// 因此，需要将那一部进行移除，以免重复追加</span></span><br><span class="line">	<span class="keyword">if</span> first &gt; entries[<span class="number">0</span>].Index &#123;</span><br><span class="line">		entries = entries[first-entries[<span class="number">0</span>].Index:]</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 判断新追加日志与已有日志是否有重叠，若是，则需要覆盖已有日志，否则直接追加到已有日志后面</span></span><br><span class="line">	offset := entries[<span class="number">0</span>].Index - ms.ents[<span class="number">0</span>].Index</span><br><span class="line">	<span class="keyword">switch</span> &#123;</span><br><span class="line">	<span class="keyword">case</span> <span class="keyword">uint64</span>(<span class="built_in">len</span>(ms.ents)) &gt; offset:</span><br><span class="line">		ms.ents = <span class="built_in">append</span>([]pb.Entry&#123;&#125;, ms.ents[:offset]...)</span><br><span class="line">		ms.ents = <span class="built_in">append</span>(ms.ents, entries...)</span><br><span class="line">	<span class="keyword">case</span> <span class="keyword">uint64</span>(<span class="built_in">len</span>(ms.ents)) == offset:</span><br><span class="line">		ms.ents = <span class="built_in">append</span>(ms.ents, entries...)</span><br><span class="line">	<span class="keyword">default</span>:</span><br><span class="line">		raftLogger.Panicf(<span class="string">"missing log entry [last: %d, append at: %d]"</span>,</span><br><span class="line">			ms.lastIndex(), entries[<span class="number">0</span>].Index)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// storage.go</span></span><br></pre></td></tr></table></figure>

<p>日志追加流程基本符合逻辑，但需要注意如果已有日志项集合被<code>compact</code>，且追加的日志与已有日志重叠的情况。关于日志项被<code>compact</code>的相关逻辑，后面会叙述。现在作一个小结，上述逻辑发生在应用启动初始化时机，换言之，这包括两种情况，其一是整个集群刚启动，应用程序所在的节点没有任何持久化的快照记录；其二是此节点宕机，并且错过了部分日志的追加与快照操作，因此，应用程序需要恢复此节点对应的<code>raft</code>实例的<code>memoryStorge</code>信息以及增加快照数据（节点新加入时，也大致符合这种情况）。换言之，在有节点落后、刚重启、新加入的情况下，给这些节点的数据多数来自已落盘部分（持久化的快照及<code>WAL</code>日志）。</p>
<h4 id="处理-raft-协议库-Ready-消息"><a href="#处理-raft-协议库-Ready-消息" class="headerlink" title="处理 raft 协议库 Ready 消息"></a>处理 raft 协议库 Ready 消息</h4><p>接下来，继续了解第二处交互逻辑：在<code>serverChannels()</code>函数中，应用等待接收底层<code>raft</code>协议库的通知：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 应用程序状态机更新的事件循环，即循环等待底层协议库的 Ready 通知</span></span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">	<span class="keyword">select</span> &#123;</span><br><span class="line">	<span class="keyword">case</span> &lt;-ticker.C:</span><br><span class="line">		rc.node.Tick()</span><br><span class="line"></span><br><span class="line">	<span class="comment">// store raft entries to wal, then publish over commit channel</span></span><br><span class="line">	<span class="comment">// 1. 收到底层协议库的 Ready 通知，关于 Ready 结构已经在介绍 raftexample 文章中简要介绍</span></span><br><span class="line">	<span class="keyword">case</span> rd := &lt;-rc.node.Ready():</span><br><span class="line">		<span class="comment">// 2. 先将 Ready 中需要被持久化的数据保存到 WAL 日志文件（在消息转发前）</span></span><br><span class="line">		rc.wal.Save(rd.HardState, rd.Entries)</span><br><span class="line">		<span class="comment">// 3. 如果 Ready 中的需要被持久化的快照不为空</span></span><br><span class="line">		<span class="keyword">if</span> !raft.IsEmptySnap(rd.Snapshot) &#123;</span><br><span class="line">               <span class="comment">// 3.1 保存快照到 WAL 日志（快照索引/元数据信息）以及到 snap (后面文章会介绍)中</span></span><br><span class="line">			rc.saveSnap(rd.Snapshot)</span><br><span class="line">			<span class="comment">// 3.2 将快照应用到 memoryStorage 实例</span></span><br><span class="line">			rc.raftStorage.ApplySnapshot(rd.Snapshot)</span><br><span class="line">			<span class="comment">// 3.3 更新应用程序保存的快照信息</span></span><br><span class="line">			rc.publishSnapshot(rd.Snapshot)</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 4. 追加 Ready 结构中需要被持久化的信息（在消息转发前）</span></span><br><span class="line">		rc.raftStorage.Append(rd.Entries)</span><br><span class="line">		<span class="comment">// 5. 转发 Ready 结构中的消息</span></span><br><span class="line">		rc.transport.Send(rd.Messages)</span><br><span class="line">		<span class="comment">// 6. 将日志应用到状态机（如果存在已经提交，即准备应用的日志项）</span></span><br><span class="line">		<span class="keyword">if</span> ok := rc.publishEntries(rc.entriesToApply(rd.CommittedEntries)); !ok &#123;</span><br><span class="line">			rc.stop()</span><br><span class="line">			<span class="keyword">return</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 7. 触发快照操作（如果满足条件）</span></span><br><span class="line">		rc.maybeTriggerSnapshot()</span><br><span class="line">		<span class="comment">// 8. 通知底层 raft 协议库实例 node，即告知当前 Ready 已经处理完毕，可以准备下一个</span></span><br><span class="line">		rc.node.Advance()</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="comment">// raft.go</span></span><br></pre></td></tr></table></figure>

<p>同样，重点关注与<code>memoryStorage</code>相关的逻辑（其余的逻辑在【<a href="https://qqzeng.top/2019/01/09/etcd-raftexample-%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/" target="_blank" rel="noopener">etcd raftexample 源码简析</a>】中已阐述）。在步骤 3 中，当<code>Ready</code>结构中的快照不为空时，需要保存快照至一系列地方。其中步骤 3.1 的调用代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rc *raftNode)</span> <span class="title">saveSnap</span><span class="params">(snap raftpb.Snapshot)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="comment">// must save the snapshot index to the WAL before saving the</span></span><br><span class="line">	<span class="comment">// snapshot to maintain the invariant that we only Open the</span></span><br><span class="line">	<span class="comment">// wal at previously-saved snapshot indexes.</span></span><br><span class="line">	walSnap := walpb.Snapshot&#123; <span class="comment">// 1. 构建快照索引（在【WAL 日志管理源码解析】文章有阐述）信息</span></span><br><span class="line">		Index: snap.Metadata.Index,</span><br><span class="line">		Term:  snap.Metadata.Term,</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="comment">// 2. 保存快照索引信息到 WAL 日志</span></span><br><span class="line">	<span class="keyword">if</span> err := rc.wal.SaveSnapshot(walSnap); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125; <span class="comment">// 3. 保存快照完整数据到 snap（后面文章阐述）</span></span><br><span class="line">	<span class="keyword">if</span> err := rc.snapshotter.SaveSnap(snap); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125; <span class="comment">// 4. 更新 WAL 日志文件锁范围</span></span><br><span class="line">	<span class="keyword">return</span> rc.wal.ReleaseLockTo(snap.Metadata.Index)</span><br><span class="line">&#125; <span class="comment">// raft.go</span></span><br></pre></td></tr></table></figure>

<p>而步骤  3.2 在上文已阐述过，即将快照替换到<code>memoryStorage</code>关联的快照实例。而最后 3.3 的相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 更新应用程序保存的快照位置信息，并且通知上层应用(kvstore)可以重新加载快照</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rc *raftNode)</span> <span class="title">publishSnapshot</span><span class="params">(snapshotToSave raftpb.Snapshot)</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> raft.IsEmptySnap(snapshotToSave) &#123;</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	log.Printf(<span class="string">"publishing snapshot at index %d"</span>, rc.snapshotIndex)</span><br><span class="line">	<span class="keyword">defer</span> log.Printf(<span class="string">"finished publishing snapshot at index %d"</span>, rc.snapshotIndex)</span><br><span class="line">	<span class="comment">// 1. 检验快照数据</span></span><br><span class="line">	<span class="keyword">if</span> snapshotToSave.Metadata.Index &lt;= rc.appliedIndex &#123;</span><br><span class="line">		log.Fatalf(<span class="string">"snapshot index [%d] should &gt; progress.appliedIndex [%d]"</span>, snapshotToSave.Metadata.Index, rc.appliedIndex)</span><br><span class="line">	&#125; <span class="comment">// 2. 通知上层应用(kvstore)可以重新加载快照</span></span><br><span class="line">	rc.commitC &lt;- <span class="literal">nil</span> <span class="comment">// trigger kvstore to load snapshot</span></span><br><span class="line">	<span class="comment">// 3. 更新应用程序(raftNode)保存的快照位置信息，以及当前已应用到状态机的日志的索引信息</span></span><br><span class="line">	rc.confState = snapshotToSave.Metadata.ConfState</span><br><span class="line">	rc.snapshotIndex = snapshotToSave.Metadata.Index</span><br><span class="line">	rc.appliedIndex = snapshotToSave.Metadata.Index</span><br><span class="line">&#125; <span class="comment">// raft.go</span></span><br></pre></td></tr></table></figure>

<p>小结步骤 3 逻辑（包括 3.1-3.3）：若底层协议传来的<code>Ready</code>结构中包含的快照不为空，则首先将快照保存到<code>WAL</code>日志（索引信息），并保存完整快照信息到<code>snap</code>，然后将快照替换掉内存(<code>memoryStorage</code>)关联的快照实例，最后更新应用保存的快照位置信息及当前已应用日志位置信息，并触发应用（状态机）重新加载快照。</p>
<p>同样，步骤 4 已在上文阐述过。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 针对 memoryStorage 触发快照操作（如果满足条件）</span></span><br><span class="line"><span class="comment">//（注意这是对 memoryStorage 中保存的日志信息作快照）</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rc *raftNode)</span> <span class="title">maybeTriggerSnapshot</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> rc.appliedIndex-rc.snapshotIndex &lt;= rc.snapCount &#123;</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	log.Printf(<span class="string">"start snapshot [applied index: %d | last snapshot index: %d]"</span>, rc.appliedIndex, rc.snapshotIndex)</span><br><span class="line">	<span class="comment">// 1. 加载状态机中当前的信息（此方法由应用程序提供，在 kvstore 中）</span></span><br><span class="line">	data, err := rc.getSnapshot()</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		log.Panic(err)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 利用上述快照数据、以及 appliedIndex 等为 memoryStorage 实例创建快照（它会覆盖/更新 memoryStorage 已有的快照信息）</span></span><br><span class="line">	snap, err := rc.raftStorage.CreateSnapshot(rc.appliedIndex, &amp;rc.confState, data)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="built_in">panic</span>(err)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 3. 保存快照到 WAL 日志（快照的索引/元数据信息）以及到 snap（后面文章会介绍）中</span></span><br><span class="line">	<span class="keyword">if</span> err := rc.saveSnap(snap); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="built_in">panic</span>(err)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 4. 若满足日志被 compact 的条件（防止内存中日志项过多），则对内存中日志项集合作 compact 操作</span></span><br><span class="line">	<span class="comment">// compact 操作会丢弃 memoryStorage 日志项中 compactIndex 之前的日志</span></span><br><span class="line">	compactIndex := <span class="keyword">uint64</span>(<span class="number">1</span>)</span><br><span class="line">	<span class="keyword">if</span> rc.appliedIndex &gt; snapshotCatchUpEntriesN &#123;</span><br><span class="line">		compactIndex = rc.appliedIndex - snapshotCatchUpEntriesN</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> err := rc.raftStorage.Compact(compactIndex); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="built_in">panic</span>(err)</span><br><span class="line">	&#125;</span><br><span class="line">	log.Printf(<span class="string">"compacted log at index %d"</span>, compactIndex)</span><br><span class="line">	<span class="comment">// 5. 更新应用程序的快照位置信息</span></span><br><span class="line">	rc.snapshotIndex = rc.appliedIndex</span><br><span class="line">&#125; <span class="comment">// raft.go</span></span><br></pre></td></tr></table></figure>

<p>上述代码逻辑比较简单，简单而言，它会从状态机中加载快照，然后覆盖<code>raft</code>实例关联的<code>memoryStorage</code>中的快照实例，而且，还会保存快照信息（上文已阐述），最后检查<code>memoryStorage</code>是否可以执行<code>compact</code>操作。其中<code>memoryStorage</code>的<code>compact</code>操作的逻辑也比较简单，即丢弃<code>compactIndex</code>之前的日志（注意：并不是丢弃 <code>appliedIndex</code>之前的日志，也不是丢弃<code>snapshotIndex</code>之前的日志）：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// compact 操作会丢弃 compactIndex 之前的日志，</span></span><br><span class="line"><span class="comment">// 应用程序应该检查 compactIndex 应该在 appliedIndex 之前，因为，只允许 compact 掉已经 apply</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(ms *MemoryStorage)</span> <span class="title">Compact</span><span class="params">(compactIndex <span class="keyword">uint64</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	ms.Lock()</span><br><span class="line">	<span class="keyword">defer</span> ms.Unlock()</span><br><span class="line">	offset := ms.ents[<span class="number">0</span>].Index</span><br><span class="line">	<span class="keyword">if</span> compactIndex &lt;= offset &#123;</span><br><span class="line">		<span class="keyword">return</span> ErrCompacted</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> compactIndex &gt; ms.lastIndex() &#123;</span><br><span class="line">		raftLogger.Panicf(<span class="string">"compact %d is out of bound lastindex(%d)"</span>, compactIndex, ms.lastIndex())</span><br><span class="line">	&#125;</span><br><span class="line">	i := compactIndex - offset</span><br><span class="line">	ents := <span class="built_in">make</span>([]pb.Entry, <span class="number">1</span>, <span class="number">1</span>+<span class="keyword">uint64</span>(<span class="built_in">len</span>(ms.ents))-i)</span><br><span class="line">	ents[<span class="number">0</span>].Index = ms.ents[i].Index</span><br><span class="line">	ents[<span class="number">0</span>].Term = ms.ents[i].Term</span><br><span class="line">	ents = <span class="built_in">append</span>(ents, ms.ents[i+<span class="number">1</span>:]...)</span><br><span class="line">	ms.ents = ents</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// storage.go</span></span><br></pre></td></tr></table></figure>

<p>至此，关于应用程序与<code>memoryStorage/Storage</code>的简单交互过程已经阐述完毕。作个简单小结：通过上述的分析，我们仔细关联各个流程，可以发现<code>WAL</code>中的日志项是已落盘的，而<code>Storage</code>则是<code>etcd-raft</code>提供的被应用程序访问已落盘数据的接口，<code>memoryStorage</code>实现了这个接口(<code>Storage</code>)（而且，从它的各个操作逻辑来看，它只是简单地将<code>WAL</code>已落盘的数据进行了拷贝，当然还有一个<code>compact</code>过程，如果满足条件的话），个人感觉似乎有一点多余（从网上查找资料发现，一般而言，<code>Storage</code>的实现应该是<code>WAL</code>与<code>cache</code>算法的组合，那显然，在这里的<code>memoryStorage</code>并没有实现某种<code>cache</code>算法）。另外值得注意的是，在<code>etcd-raft</code>的实现中，协议核心并不与<code>memoryStorage</code>直接交互，都是应用程序与<code>memoryStorage</code>交互。</p>
<h3 id="raft-协议库与-raftLog-交互"><a href="#raft-协议库与-raftLog-交互" class="headerlink" title="raft 协议库与  raftLog  交互"></a>raft 协议库与  raftLog  交互</h3><p>这部分内容包括两个部分：其一是先继续了解<code>raftLog</code>内部一些重要接口的实现，以更进一步理解直接与<code>raft</code>协议库交互的<code>raftLog</code>的实现原理。其二挑选一个简单的<code>raft</code>协议库的逻辑——日志追加操作以查看协议库使用<code>raftLog</code>的细节。</p>
<h4 id="raftLog-接口实现逻辑"><a href="#raftLog-接口实现逻辑" class="headerlink" title="raftLog 接口实现逻辑"></a>raftLog 接口实现逻辑</h4><p>首先了解<code>raftLog</code>相关接口的实现细则。在上文已经初步了解过<code>raftLog</code>的数据结构。其构造函数如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newLog</span><span class="params">(storage Storage, logger Logger)</span> *<span class="title">raftLog</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> newLogWithSize(storage, logger, noLimit)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// newLogWithSize returns a log using the given storage and max</span></span><br><span class="line"><span class="comment">// message size.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newLogWithSize</span><span class="params">(storage Storage, logger Logger, maxNextEntsSize <span class="keyword">uint64</span>)</span> *<span class="title">raftLog</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> storage == <span class="literal">nil</span> &#123; <span class="comment">// storage 不能为空！</span></span><br><span class="line">		log.Panic(<span class="string">"storage must not be nil"</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 利用应用传入的 storage 及 logger 以及 maxNextEntsSize（如果有的话）构建 raftLog 实例</span></span><br><span class="line">	log := &amp;raftLog&#123;</span><br><span class="line">		storage:         storage,</span><br><span class="line">		logger:          logger,</span><br><span class="line">		maxNextEntsSize: maxNextEntsSize,</span><br><span class="line">	&#125;</span><br><span class="line">	firstIndex, err := storage.FirstIndex()</span><br><span class="line">	lastIndex, err := storage.LastIndex()</span><br><span class="line">	<span class="comment">// 将 unstable 的 offset 初始化为 storage 的 lastIndex+1</span></span><br><span class="line">	log.unstable.offset = lastIndex + <span class="number">1</span></span><br><span class="line">	log.unstable.logger = logger</span><br><span class="line">	<span class="comment">// Initialize our committed and applied pointers to the time of the last compaction.</span></span><br><span class="line">	<span class="comment">// 将 raftLog 的 commited 及 applied 初始化为 firstIndex-1，即 storage 中第一项日志的索引号，</span></span><br><span class="line">	<span class="comment">// 因为第一项日志为已经被提交的（也是已经被快照的），可以仔细察看 storage 的 ApplySnapshot 逻辑</span></span><br><span class="line">	log.committed = firstIndex - <span class="number">1</span></span><br><span class="line">	log.applied = firstIndex - <span class="number">1</span></span><br><span class="line">	<span class="keyword">return</span> log</span><br><span class="line">&#125; <span class="comment">// log.go</span></span><br></pre></td></tr></table></figure>

<p>此构造函数在初始化<code>raft</code>结构时会被调用（具体可以查看代码）。从上述构造函数逻辑来看，<code>unstable</code>似乎是从<code>storage</code>最后一条日志后开始存储，换言之，从<code>raft</code>协议库的角度，<code>unstable</code>存储更新的日志。。我们可以从下面的几个函数来进一步证实这一点：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(l *raftLog)</span> <span class="title">snapshot</span><span class="params">()</span> <span class="params">(pb.Snapshot, error)</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> l.unstable.snapshot != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> *l.unstable.snapshot, <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> l.storage.Snapshot()</span><br><span class="line">&#125; <span class="comment">// log.go</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(l *raftLog)</span> <span class="title">firstIndex</span><span class="params">()</span> <span class="title">uint64</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> i, ok := l.unstable.maybeFirstIndex(); ok &#123;</span><br><span class="line">		<span class="keyword">return</span> i</span><br><span class="line">	&#125;</span><br><span class="line">	index, err := l.storage.FirstIndex()</span><br><span class="line">	<span class="keyword">return</span> index</span><br><span class="line">&#125; <span class="comment">// log.go</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(l *raftLog)</span> <span class="title">lastIndex</span><span class="params">()</span> <span class="title">uint64</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> i, ok := l.unstable.maybeLastIndex(); ok &#123;</span><br><span class="line">		<span class="keyword">return</span> i</span><br><span class="line">	&#125;</span><br><span class="line">	i, err := l.storage.LastIndex()</span><br><span class="line">	<span class="keyword">return</span> i</span><br><span class="line">&#125; <span class="comment">// log.go</span></span><br></pre></td></tr></table></figure>

<p>当<code>raftLog</code>都是先将<code>unstable</code>关联的数据返回给<code>raft</code>核心库。我们后面会来仔细了解这些函数如何被调用。我们继续了解两个较为重要的接口：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 日志追加，返回(0, false)若日志项不能被追加，否则返回 (最后一条日志索引, true)</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(l *raftLog)</span> <span class="title">maybeAppend</span><span class="params">(index, logTerm, committed <span class="keyword">uint64</span>, ents ...pb.Entry)</span> <span class="params">(lastnewi <span class="keyword">uint64</span>, ok <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> l.matchTerm(index, logTerm) &#123; <span class="comment">// 1. 检验 index 与 term 是否匹配</span></span><br><span class="line">		lastnewi = index + <span class="keyword">uint64</span>(<span class="built_in">len</span>(ents)) <span class="comment">// 2. 最后一条日志索引</span></span><br><span class="line">		ci := l.findConflict(ents) <span class="comment">// 3. 检查此次追加的日志项是否与已有的存在冲突（论文中有详述冲突情况）</span></span><br><span class="line">		<span class="keyword">switch</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> ci == <span class="number">0</span>: <span class="comment">// 3.1 没有冲突，则直接提交（如果可以提交的话）</span></span><br><span class="line">		<span class="keyword">case</span> ci &lt;= l.committed: <span class="comment">// 3.2 冲突的索引不能比已经提交的索引还要小！</span></span><br><span class="line">			l.logger.Panicf(<span class="string">"entry %d conflict with committed entry [committed(%d)]"</span>, ci, l.committed)</span><br><span class="line">		<span class="keyword">default</span>: <span class="comment">// 3.3 否则，与已有日志（未提交的）有冲突</span></span><br><span class="line">            <span class="comment">//（也有可能没有冲突，详情在 findConflict 函数中说明），并追加日志，最后提交</span></span><br><span class="line">			offset := index + <span class="number">1</span></span><br><span class="line">			l.<span class="built_in">append</span>(ents[ci-offset:]...)</span><br><span class="line">		&#125;</span><br><span class="line">		l.commitTo(min(committed, lastnewi))</span><br><span class="line">		<span class="keyword">return</span> lastnewi, <span class="literal">true</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>, <span class="literal">false</span></span><br><span class="line">&#125; <span class="comment">// log.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 即检查追加的日志项集合与已有的日志项（包括已提交与未提交）是否存在冲突，返回第一次冲突的日志索引（如果有的话）</span></span><br><span class="line"><span class="comment">// 另外，需要注意的是，要追加的日志必须要连续</span></span><br><span class="line"><span class="comment">// 如果没有冲突，并且已有的日志包含了要追加的所有日志项，则返回 0</span></span><br><span class="line"><span class="comment">// 如果没有冲突，并且要追加的日志包含有新日志项，则返回第一次新的日志项</span></span><br><span class="line"><span class="comment">// 日志项冲突判定的条件是: 相同的 index 不同的 term</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(l *raftLog)</span> <span class="title">findConflict</span><span class="params">(ents []pb.Entry)</span> <span class="title">uint64</span></span> &#123;</span><br><span class="line">	<span class="keyword">for</span> _, ne := <span class="keyword">range</span> ents &#123;</span><br><span class="line">		<span class="keyword">if</span> !l.matchTerm(ne.Index, ne.Term) &#123;</span><br><span class="line">			<span class="keyword">if</span> ne.Index &lt;= l.lastIndex() &#123;</span><br><span class="line">				l.logger.Infof(<span class="string">"found conflict at index %d [existing term: %d, conflicting term: %d]"</span>,</span><br><span class="line">					ne.Index, l.zeroTermOnErrCompacted(l.term(ne.Index)), ne.Term)</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">return</span> ne.Index</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="raft-协议库追加日志"><a href="#raft-协议库追加日志" class="headerlink" title="raft 协议库追加日志"></a>raft 协议库追加日志</h4><p>接下来，我们把重点放在<code>/etcd/raft.log</code>文件中，并梳理日志追加的整体逻辑（关于文件中的数据结构以及一些细节我们暂且忽略，重点关注其逻辑流程）。为了让读者更容易理解整个过程的来龙去脉，我们仍然从应用程序提交日志开始切入，以将整个流程梳理一遍（同时，下文所展示的代码大部分只包含关键的逻辑）。下面的逻辑分析会大致依据实际逻辑顺利展开，即从应用程序提交日志开始，到<code>leader</code>节点在本地追加日志（若是<code>follower</code>节点收到请求消息，则一般是转发给<code>leader</code>节点），然后到<code>leader</code>节点广播日志给<code>follower</code>节点，最后到<code>follower</code>节点的日志追加，以及<code>leader</code>如何处理<code>follower</code>节点日志追加的响应消息。</p>
<h5 id="leader-节点追加日志"><a href="#leader-节点追加日志" class="headerlink" title="leader 节点追加日志"></a>leader 节点追加日志</h5><p>我们从应用程序向<code>raft</code>协议库提交日志请求开始，当然，在应用启动初始化时，其实也涉及到<code>raft</code>协议库的初始化启动，如下代码所示：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rc *raftNode)</span> <span class="title">startRaft</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	rpeers := <span class="built_in">make</span>([]raft.Peer, <span class="built_in">len</span>(rc.peers))</span><br><span class="line">	<span class="keyword">for</span> i := <span class="keyword">range</span> rpeers &#123;</span><br><span class="line">		rpeers[i] = raft.Peer&#123;ID: <span class="keyword">uint64</span>(i + <span class="number">1</span>)&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	c := &amp;raft.Config&#123;</span><br><span class="line">		ID:                        <span class="keyword">uint64</span>(rc.id),</span><br><span class="line">		ElectionTick:              <span class="number">10</span>,</span><br><span class="line">		HeartbeatTick:             <span class="number">1</span>,</span><br><span class="line">		Storage:                   rc.raftStorage,</span><br><span class="line">		MaxSizePerMsg:             <span class="number">1024</span> * <span class="number">1024</span>,</span><br><span class="line">		MaxInflightMsgs:           <span class="number">256</span>,</span><br><span class="line">		MaxUncommittedEntriesSize: <span class="number">1</span> &lt;&lt; <span class="number">30</span>,</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> oldwal &#123;</span><br><span class="line">		rc.node = raft.RestartNode(c)</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		startPeers := rpeers</span><br><span class="line">		<span class="keyword">if</span> rc.join &#123;</span><br><span class="line">			startPeers = <span class="literal">nil</span></span><br><span class="line">		&#125;</span><br><span class="line">        <span class="comment">// 启动底层 raft 协议核心库，并将 Config 及集群中节点信息传入</span></span><br><span class="line">		rc.node = raft.StartNode(c, startPeers)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">go</span> rc.serveRaft()</span><br><span class="line">	<span class="keyword">go</span> rc.serveChannels()</span><br><span class="line">&#125; <span class="comment">// /etcd/contrib/raftexample/raft.go</span></span><br></pre></td></tr></table></figure>

<p>在<code>raft.StartNode()</code>函数中，创建<code>node</code>，它表示底层<code>raft</code>协议的实例，构建了<code>raft</code>实例（封装协议实现的核心逻辑），并且调用了<code>n.run()</code>以等待上层应用程序向<code>node</code>提交请求，关键代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">StartNode</span><span class="params">(c *Config, peers []Peer)</span> <span class="title">Node</span></span> &#123;</span><br><span class="line">	r := newRaft(c)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	n := newNode()</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">go</span> n.run(r)</span><br><span class="line">	<span class="keyword">return</span> &amp;n</span><br><span class="line">&#125; <span class="comment">// node.go</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *node)</span> <span class="title">run</span><span class="params">(r *raft)</span></span> &#123;</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="keyword">if</span> advancec != <span class="literal">nil</span> &#123;</span><br><span class="line">			readyc = <span class="literal">nil</span></span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			rd = newReady(r, prevSoftSt, prevHardSt)</span><br><span class="line">			<span class="keyword">if</span> rd.containsUpdates() &#123;</span><br><span class="line">				readyc = n.readyc</span><br><span class="line">			&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">				readyc = <span class="literal">nil</span></span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> pm := &lt;-propc:</span><br><span class="line">			m := pm.m</span><br><span class="line">			m.From = r.id</span><br><span class="line">			err := r.Step(m) <span class="comment">// 调用 Step 函数来进行处理</span></span><br><span class="line">			<span class="keyword">if</span> pm.result != <span class="literal">nil</span> &#123;</span><br><span class="line">				pm.result &lt;- err</span><br><span class="line">				<span class="built_in">close</span>(pm.result)</span><br><span class="line">			&#125;</span><br><span class="line">        <span class="keyword">case</span> m := &lt;-n.recvc: <span class="comment">// 此处的逻辑会在 follower 节点接收 leader 节点广播的消息时调用</span></span><br><span class="line">            <span class="comment">// 具体地，会在下文的 【follower 节点追加日志】 小节涉及到</span></span><br><span class="line">			<span class="comment">// filter out response message from unknown From.</span></span><br><span class="line">			<span class="keyword">if</span> pr := r.getProgress(m.From); pr != <span class="literal">nil</span> || !IsResponseMsg(m.Type) &#123;</span><br><span class="line">				r.Step(m)</span><br><span class="line">			&#125;</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		<span class="keyword">case</span> readyc &lt;- rd:</span><br><span class="line">			<span class="keyword">if</span> rd.SoftState != <span class="literal">nil</span> &#123;</span><br><span class="line">				prevSoftSt = rd.SoftState</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">if</span> <span class="built_in">len</span>(rd.Entries) &gt; <span class="number">0</span> &#123;</span><br><span class="line">				prevLastUnstablei = rd.Entries[<span class="built_in">len</span>(rd.Entries)<span class="number">-1</span>].Index</span><br><span class="line">				prevLastUnstablet = rd.Entries[<span class="built_in">len</span>(rd.Entries)<span class="number">-1</span>].Term</span><br><span class="line">				havePrevLastUnstablei = <span class="literal">true</span></span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">if</span> !IsEmptyHardState(rd.HardState) &#123;</span><br><span class="line">				prevHardSt = rd.HardState</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">if</span> !IsEmptySnap(rd.Snapshot) &#123;</span><br><span class="line">				prevSnapi = rd.Snapshot.Metadata.Index</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">if</span> index := rd.appliedCursor(); index != <span class="number">0</span> &#123;</span><br><span class="line">				applyingToI = index</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			r.msgs = <span class="literal">nil</span></span><br><span class="line">			r.readStates = <span class="literal">nil</span></span><br><span class="line">			r.reduceUncommittedSize(rd.CommittedEntries)</span><br><span class="line">			advancec = n.advancec</span><br><span class="line">		<span class="keyword">case</span> &lt;-advancec:</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="comment">// node.go</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newReady</span><span class="params">(r *raft, prevSoftSt *SoftState, prevHardSt pb.HardState)</span> <span class="title">Ready</span></span> &#123;</span><br><span class="line">	rd := Ready&#123;</span><br><span class="line">		Entries:          r.raftLog.unstableEntries(),</span><br><span class="line">		CommittedEntries: r.raftLog.nextEnts(),</span><br><span class="line">		Messages:         r.msgs, <span class="comment">// Step 函数将消息进行广播实际上会发送到此 msg 结构中</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> softSt := r.softState(); !softSt.equal(prevSoftSt) &#123;</span><br><span class="line">		rd.SoftState = softSt</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> hardSt := r.hardState(); !isHardStateEqual(hardSt, prevHardSt) &#123;</span><br><span class="line">		rd.HardState = hardSt</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> r.raftLog.unstable.snapshot != <span class="literal">nil</span> &#123;</span><br><span class="line">		rd.Snapshot = *r.raftLog.unstable.snapshot</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(r.readStates) != <span class="number">0</span> &#123;</span><br><span class="line">		rd.ReadStates = r.readStates</span><br><span class="line">	&#125;</span><br><span class="line">	rd.MustSync = MustSync(r.hardState(), prevHardSt, <span class="built_in">len</span>(rd.Entries))</span><br><span class="line">	<span class="keyword">return</span> rd</span><br><span class="line">&#125; <span class="comment">// node.go</span></span><br></pre></td></tr></table></figure>

<p>从上面展示的三个函数，可以发现程序会开一个<code>go routine</code>通过<code>channel</code>来处理所有现应用程序（当然也有内部的一些逻辑）的交互。当<code>node</code>从<code>propc</code>管道中收到应用程序提交的请求后，它会将此请求交给<code>Step</code>函数处理，<code>Step</code>函数在经过一系列检查之后（比如检查<code>term</code>），会调用<code>step</code>函数（这里只考虑正常的<code>MsgProp</code>消息），<code>step</code>函数对于不同的角色的节点其实现不同，典型的，对于<code>leader</code>节点，其实现为<code>stepLeader</code>。另外，在循环中，程序会将打包好<code>Ready</code>结构通过<code>readc</code>的管道发送给应用程序，然后等待从<code>advancec</code>管道中接收应用程序的返回消息。下面，我们从<code>stepLeader</code>函数开始来一步步梳理<code>leader</code>的日志追加逻辑：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">stepLeader</span><span class="params">(r *raft, m pb.Message)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="comment">// These message types do not require any progress for m.From.</span></span><br><span class="line">	<span class="keyword">switch</span> m.Type &#123;</span><br><span class="line">	<span class="keyword">case</span> pb.MsgBeat:</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">	<span class="keyword">case</span> pb.MsgProp:</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">        <span class="comment">// 1. 追加日志</span></span><br><span class="line">		<span class="keyword">if</span> !r.appendEntry(m.Entries...) &#123;</span><br><span class="line">			<span class="keyword">return</span> ErrProposalDropped</span><br><span class="line">		&#125;</span><br><span class="line">        <span class="comment">// 2. 广播日志追加</span></span><br><span class="line">		r.bcastAppend()</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">	<span class="keyword">case</span> pb.MsgReadIndex:</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /etcd/raft/raft.go</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *raft)</span> <span class="title">appendEntry</span><span class="params">(es ...pb.Entry)</span> <span class="params">(accepted <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">	<span class="comment">// use latest "last" index after truncate/append</span></span><br><span class="line">	li = r.raftLog.<span class="built_in">append</span>(es...)</span><br><span class="line">	r.getProgress(r.id).maybeUpdate(li)</span><br><span class="line">	<span class="comment">// Regardless of maybeCommit's return, our caller will call bcastAppend.</span></span><br><span class="line">	r.maybeCommit()</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125; <span class="comment">// /etcd/raft/raft.go</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(l *raftLog)</span> <span class="title">append</span><span class="params">(ents ...pb.Entry)</span> <span class="title">uint64</span></span> &#123;</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	l.unstable.truncateAndAppend(ents)</span><br><span class="line">	<span class="keyword">return</span> l.lastIndex()</span><br><span class="line">&#125; <span class="comment">// log.go</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(u *unstable)</span> <span class="title">truncateAndAppend</span><span class="params">(ents []pb.Entry)</span></span> &#123;</span><br><span class="line">	after := ents[<span class="number">0</span>].Index</span><br><span class="line">	<span class="keyword">switch</span> &#123;</span><br><span class="line">	<span class="comment">// 若需要追加的日志项集合中的第一条日志恰好是已有的日志的最后一条日志的后一条日志，则直接追加</span></span><br><span class="line">	<span class="keyword">case</span> after == u.offset+<span class="keyword">uint64</span>(<span class="built_in">len</span>(u.entries)):</span><br><span class="line">		<span class="comment">// after is the next index in the u.entries</span></span><br><span class="line">		<span class="comment">// directly append</span></span><br><span class="line">		u.entries = <span class="built_in">append</span>(u.entries, ents...)</span><br><span class="line">	<span class="comment">// 若需要追加的日志项集合中的第一条日志，要比 unstable 中的 offset 还要小</span></span><br><span class="line">        <span class="comment">//（即比 unstable 中日志项集合的开始日志的索引要小）</span></span><br><span class="line">	<span class="comment">// 则需要把重新设置 offset 索引，并且将 unstable 的日志项集合中的日志覆盖</span></span><br><span class="line">	<span class="keyword">case</span> after &lt;= u.offset:</span><br><span class="line">		u.logger.Infof(<span class="string">"replace the unstable entries from index %d"</span>, after)</span><br><span class="line">		<span class="comment">// The log is being truncated to before our current offset</span></span><br><span class="line">		<span class="comment">// portion, so set the offset and replace the entries</span></span><br><span class="line">		u.offset = after</span><br><span class="line">		u.entries = ents</span><br><span class="line">	<span class="keyword">default</span>:</span><br><span class="line">		<span class="comment">// 否则，分段次进行日志追加</span></span><br><span class="line">        <span class="comment">//（包含两种情况，u.offset &lt; after &lt; u.offset+len(u.entries) 或者 after &gt; u.offset+len(u.entries)）</span></span><br><span class="line">		<span class="comment">// 此种情况也可能涉及到 unstable 中已有日志的截断（前一种情况）</span></span><br><span class="line">		<span class="comment">// truncate to after and copy to u.entries</span></span><br><span class="line">		<span class="comment">// then append</span></span><br><span class="line">		u.logger.Infof(<span class="string">"truncate the unstable entries before index %d"</span>, after)</span><br><span class="line">		u.entries = <span class="built_in">append</span>([]pb.Entry&#123;&#125;, u.slice(u.offset, after)...)</span><br><span class="line">		u.entries = <span class="built_in">append</span>(u.entries, ents...)</span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="comment">// log_unstable.go</span></span><br></pre></td></tr></table></figure>

<p>在<code>stepLeader</code>函数中，首先调用 了<code>appendEntry()</code>函数，它会将日志项集合追加到<code>raftLog</code>中（实际上是调用了<code>r.raftLog.append(es...)</code>追加到<code>unstable</code>日志项集合），并且提交本地的日志项（如果满足条件的话）。</p>
<h5 id="leader-节点向-follower-节点广播日志"><a href="#leader-节点向-follower-节点广播日志" class="headerlink" title="leader 节点向 follower 节点广播日志"></a>leader 节点向 follower 节点广播日志</h5><p>并且，在<code>stepLeader()</code>上会继续调用<code>r.bcastAppend()</code>函数向集群中其它节点广播日志，具体代码如下所示：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *raft)</span> <span class="title">bcastAppend</span><span class="params">()</span></span> &#123;</span><br><span class="line">	r.forEachProgress(<span class="function"><span class="keyword">func</span><span class="params">(id <span class="keyword">uint64</span>, _ *Progress)</span></span> &#123;</span><br><span class="line">		<span class="keyword">if</span> id == r.id &#123;</span><br><span class="line">			<span class="keyword">return</span></span><br><span class="line">		&#125;</span><br><span class="line">		r.sendAppend(id)</span><br><span class="line">	&#125;)</span><br><span class="line">&#125; <span class="comment">// /etcd/raft/raft.go</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *raft)</span> <span class="title">sendAppend</span><span class="params">(to <span class="keyword">uint64</span>)</span></span> &#123;</span><br><span class="line">	r.maybeSendAppend(to, <span class="literal">true</span>)</span><br><span class="line">&#125; <span class="comment">// /etcd/raft/raft.go</span></span><br></pre></td></tr></table></figure>

<p>而<code>sendAppend()</code>函数又会调用<code>maybeSendAppend()</code>函数来向特定的节点发送日志同步命令。代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *raft)</span> <span class="title">maybeSendAppend</span><span class="params">(to <span class="keyword">uint64</span>, sendIfEmpty <span class="keyword">bool</span>)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">	pr := r.getProgress(to)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	m := pb.Message&#123;&#125;</span><br><span class="line">	m.To = to</span><br><span class="line">	term, errt := r.raftLog.term(pr.Next - <span class="number">1</span>)</span><br><span class="line">	ents, erre := r.raftLog.entries(pr.Next, r.maxMsgSize)</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(ents) == <span class="number">0</span> &amp;&amp; !sendIfEmpty &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">	&#125; <span class="comment">// sendIfEmpty 可以用作控制空消息是否可以被发送（消息过多时，肯定不建议发送）</span></span><br><span class="line">    <span class="comment">// 如果获取 term 或者 ents 失败，则发送 snap 消息</span></span><br><span class="line">	<span class="keyword">if</span> errt != <span class="literal">nil</span> || erre != <span class="literal">nil</span> &#123; <span class="comment">// 此处主要是构建 snap 消息的相关操作</span></span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		m.Type = pb.MsgSnap</span><br><span class="line">		snapshot, err := r.raftLog.snapshot()</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		m.Snapshot = snapshot</span><br><span class="line">		sindex, sterm := snapshot.Metadata.Index, snapshot.Metadata.Term</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">		pr.becomeSnapshot(sindex)</span><br><span class="line">		r.logger.Debugf(<span class="string">"%x paused sending replication messages to %x [%s]"</span>, r.id, to, pr)</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123; <span class="comment">// 先设置消息的相关属性</span></span><br><span class="line">		m.Type = pb.MsgApp</span><br><span class="line">		m.Index = pr.Next - <span class="number">1</span></span><br><span class="line">		m.LogTerm = term</span><br><span class="line">		m.Entries = ents</span><br><span class="line">		m.Commit = r.raftLog.committed</span><br><span class="line">        <span class="comment">// 此处针对节点不同的状态（定义在 progress.go 文件中），来控制一次性给节点发送的消息数量，是批量发送，还是一次只发一条，还是要先暂停探测一下</span></span><br><span class="line">		<span class="keyword">if</span> n := <span class="built_in">len</span>(m.Entries); n != <span class="number">0</span> &#123;</span><br><span class="line">			<span class="keyword">switch</span> pr.State &#123;</span><br><span class="line">			<span class="comment">// optimistically increase the next when in ProgressStateReplicate</span></span><br><span class="line">			<span class="keyword">case</span> ProgressStateReplicate:</span><br><span class="line">				last := m.Entries[n<span class="number">-1</span>].Index</span><br><span class="line">				pr.optimisticUpdate(last)</span><br><span class="line">				pr.ins.add(last)</span><br><span class="line">			<span class="keyword">case</span> ProgressStateProbe:</span><br><span class="line">				pr.pause()</span><br><span class="line">			<span class="keyword">default</span>:</span><br><span class="line">				r.logger.Panicf(<span class="string">"%x is sending append in unhandled state %s"</span>, r.id, pr.State)</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="comment">// send 函数会将消息保存到 raft.msgs 字段，最后用于构建 Ready 实例结构，以发送给应用程序，</span></span><br><span class="line">    <span class="comment">// 事实上，此步骤才是真正执行消息发送的步骤（raft 协议库向应用程序发送消息，然后应用程序来控制并执行具体的日志消息网络传输的操作）</span></span><br><span class="line">	r.send(m)</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125; <span class="comment">// /etcd/raft/raft.go</span></span><br></pre></td></tr></table></figure>

<p>简单而言，上述函数的逻辑为：首先根据该节点上一次已同步的日志位置<code>pr.Next-1</code>，从<code>raftLog</code>中获取该位置之后的日志项，并且日志同步的数量会受到<code>maxMsgSize</code>控制。并且若果无法从<code>raftLog</code>获取到想要的日志项，此时需要只能发送<code>snap</code>（即<code>MsgSnap</code>消息），因为对应日志项可能由于已经被<code>commit</code>而丢弃了。另外，真正的发送消息的操作其实是向<code>r.msgs</code>字段中追加实际需要发送的消息，后面会由<code>node</code>将其打包入<code>Ready</code>结构中，转而发送给应用程序，由应用程序执行真正消息的网络传输操作。</p>
<p>至此，<code>leader</code>节点广播日志项给<code>follower</code>相关流程已经分析完毕。</p>
<h5 id="follower-节点追加日志"><a href="#follower-节点追加日志" class="headerlink" title="follower 节点追加日志"></a>follower 节点追加日志</h5><p>在分析具体的<code>follower</code>节点追加<code>leader</code>节点给它发送的消息中的日志之前，我们把这个过程阐述得更完整一些。当应用程序调用<code>transport</code>网络传输组件将<code>MsgApp</code>类型的消息由传至<code>follower</code>节点时，更准确而言，<code>transport</code>组件的接收器在接收到消息后，会调用其<code>Raft</code>组件的<code>Process()</code>方法（此部分逻辑不再展示相关代码，在上上篇文章【<a href="https://qqzeng.top/2019/01/10/etcd-raft-%E7%BD%91%E7%BB%9C%E4%BC%A0%E8%BE%93%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/" target="_blank" rel="noopener">etcd-raft 网络传输源码简析</a>】中包含了此部分逻辑）。而应用程序会实现此<code>Process()</code>接口，在<code>raftexample</code>示例程序中，其实现逻辑也较为简单：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rc *raftNode)</span> <span class="title">Process</span><span class="params">(ctx context.Context, m raftpb.Message)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> rc.node.Step(ctx, m) <span class="comment">// 直接调用底层协议核心结构 node 的 Step 函数来处理消息</span></span><br><span class="line">&#125; <span class="comment">// /etcd/contrib/raftexample/raft.go</span></span><br></pre></td></tr></table></figure>

<p>调用<code>Step()</code>函数后，类似于<code>leader</code>节点，会进入到<code>node</code>实例的<code>Step()</code>函数中，它会调用<code>node</code>的一系列函数，包括<code>step()</code>、<code>stepWithWaitOption()</code>函数，然后将消息传入<code>recvc</code>通道，然后在<code>node</code>节点的主循环函数<code>run()</code>中，会一直监视着各通道，因此会从<code>recvc</code>通道中取出消息，最后调用<code>raft.Step()</code>，接下来经过一系列的检查，会调用<code>step()</code>函数即，同样，这里是<code>follower</code>节点，因此最后会调用<code>stepFollower()</code>函数（后面这一个阶段的函数调用栈同<code>leader</code>节点接收到应用程序的请求的流程是一样的）。下面简要贴出在<code>recv</code>通道放入消息之前流程的相关代码：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *node)</span> <span class="title">Step</span><span class="params">(ctx context.Context, m pb.Message)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="comment">// ignore unexpected local messages receiving over network</span></span><br><span class="line">	<span class="keyword">if</span> IsLocalMsg(m.Type) &#123;</span><br><span class="line">		<span class="comment">// <span class="doctag">TODO:</span> return an error?</span></span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> n.step(ctx, m)</span><br><span class="line">&#125; <span class="comment">// node.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *node)</span> <span class="title">step</span><span class="params">(ctx context.Context, m pb.Message)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> n.stepWithWaitOption(ctx, m, <span class="literal">false</span>)</span><br><span class="line">&#125; <span class="comment">// node.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *node)</span> <span class="title">stepWait</span><span class="params">(ctx context.Context, m pb.Message)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> n.stepWithWaitOption(ctx, m, <span class="literal">true</span>)</span><br><span class="line">&#125; <span class="comment">// node.go</span></span><br><span class="line"><span class="comment">// Step advances the state machine using msgs. The ctx.Err() will be returned,</span></span><br><span class="line"><span class="comment">// if any.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *node)</span> <span class="title">stepWithWaitOption</span><span class="params">(ctx context.Context, m pb.Message, wait <span class="keyword">bool</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> m.Type != pb.MsgProp &#123;</span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> n.recvc &lt;- m:</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-ctx.Done():</span><br><span class="line">			<span class="keyword">return</span> ctx.Err()</span><br><span class="line">		<span class="keyword">case</span> &lt;-n.done:</span><br><span class="line">			<span class="keyword">return</span> ErrStopped</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// node.go</span></span><br></pre></td></tr></table></figure>

<p>下面来重点看一下<code>stepFolower()</code>函数的逻辑，具体是接收到<code>MsgApp</code>类型的消息的处理逻辑。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">stepFollower</span><span class="params">(r *raft, m pb.Message)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">switch</span> m.Type &#123;</span><br><span class="line">	<span class="keyword">case</span> pb.MsgProp: <span class="comment">// 如果应用程序将请求直接发到了 follower 节点，则可能会将消息转发给 leader</span></span><br><span class="line">		<span class="keyword">if</span> r.lead == None &#123;</span><br><span class="line">			r.logger.Infof(<span class="string">"%x no leader at term %d; dropping proposal"</span>, r.id, r.Term)</span><br><span class="line">			<span class="keyword">return</span> ErrProposalDropped</span><br><span class="line">		&#125; <span class="keyword">else</span> <span class="keyword">if</span> r.disableProposalForwarding &#123;</span><br><span class="line">			r.logger.Infof(<span class="string">"%x not forwarding to leader %x at term %d; dropping proposal"</span>, r.id, r.lead, r.Term)</span><br><span class="line">			<span class="keyword">return</span> ErrProposalDropped</span><br><span class="line">		&#125;</span><br><span class="line">		m.To = r.lead</span><br><span class="line">		r.send(m) <span class="comment">// 转发给 leader</span></span><br><span class="line">	<span class="keyword">case</span> pb.MsgApp: <span class="comment">// 接收到 leader 发送的日志同步消息</span></span><br><span class="line">		r.electionElapsed = <span class="number">0</span></span><br><span class="line">		r.lead = m.From</span><br><span class="line">		r.handleAppendEntries(m) <span class="comment">// 追加日志操作</span></span><br><span class="line">	<span class="keyword">case</span> pb.MsgHeartbeat:</span><br><span class="line">		r.electionElapsed = <span class="number">0</span></span><br><span class="line">		r.lead = m.From</span><br><span class="line">		r.handleHeartbeat(m)</span><br><span class="line">	<span class="keyword">case</span> pb.MsgSnap:<span class="comment">// 接收到 leader 发送的 snap 同步消息</span></span><br><span class="line">		r.electionElapsed = <span class="number">0</span></span><br><span class="line">		r.lead = m.From</span><br><span class="line">		r.handleSnapshot(m) <span class="comment">// 处理快照同步的操作</span></span><br><span class="line">	<span class="keyword">case</span> pb.MsgTransferLeader:</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">case</span> pb.MsgTimeoutNow:</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">case</span> pb.MsgReadIndex:</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">case</span> pb.MsgReadIndexResp:</span><br><span class="line">		<span class="comment">// ..</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /etcd/raft/raft.go</span></span><br></pre></td></tr></table></figure>

<p>上面的逻辑很清晰。我们紧接着查看<code>handleAppendEntries()</code>函数：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *raft)</span> <span class="title">handleAppendEntries</span><span class="params">(m pb.Message)</span></span> &#123;</span><br><span class="line">	<span class="comment">// 消息中的索引不能小于节点已经提交的消息的索引，否则不追加消息，以已提交的索引作为参数直接回复</span></span><br><span class="line">	<span class="keyword">if</span> m.Index &lt; r.raftLog.committed &#123;</span><br><span class="line">		<span class="comment">// 此处的 send 函数同 前面 leader 节点在广播日志最终调用的 send 函数为同一个函数</span></span><br><span class="line">		<span class="comment">// 即将此消息放到 raft.msgs 结构中，此结构最后会作为 node 打包 Ready 结构的参数</span></span><br><span class="line">		<span class="comment">// 最后发送给应用程序，然后由应用程序通过网络转发给对应的节点（此处为 leader）</span></span><br><span class="line">		r.send(pb.Message&#123;To: m.From, Type: pb.MsgAppResp, Index: r.raftLog.committed&#125;)</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 调用 maybeAppend 函数进行日志追加，若追加成功，则以追加后的日志项集合作为参数回复</span></span><br><span class="line">	<span class="keyword">if</span> mlastIndex, ok := r.raftLog.maybeAppend(m.Index, m.LogTerm, m.Commit, m.Entries...); ok &#123;</span><br><span class="line">		r.send(pb.Message&#123;To: m.From, Type: pb.MsgAppResp, Index: mlastIndex&#125;)</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123; <span class="comment">// 否则表示日志追加失败，则是日志索引不匹配造成</span></span><br><span class="line">        <span class="comment">//（详情可查看 maybeAppedn函数，简而言之，最后会通过调用 append、truncateAndAppend函数以将消息追加到 raftLog 的 unstable 结构中。</span></span><br><span class="line">        <span class="comment">// 此函数在之前的 raftLog 接口实现分析中有涉及，因此不再阐述），</span></span><br><span class="line">			<span class="comment">// 则设置冲突的提示，以及本节点的最后的日志项索引作为参数进行回复</span></span><br><span class="line">		r.logger.Debugf(<span class="string">"%x [logterm: %d, index: %d] rejected msgApp [logterm: %d, index: %d] from %x"</span>,</span><br><span class="line">			r.id, r.raftLog.zeroTermOnErrCompacted(r.raftLog.term(m.Index)), m.Index, m.LogTerm, m.Index, m.From)</span><br><span class="line">		r.send(pb.Message&#123;To: m.From, Type: pb.MsgAppResp, Index: m.Index, Reject: <span class="literal">true</span>, RejectHint: r.raftLog.lastIndex()&#125;)</span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="comment">// /etcd/raft/raft.go</span></span><br></pre></td></tr></table></figure>

<p>作个简单小结，从上面分析的逻辑可以发现，同<code>leader</code>类似，<code>follower</code>节点的数据最终也是被写入了日志模块<code>raftLog</code>的<code>unstable</code>结构中，同样，<code>follower</code>节点的回复消息也是加入到<code>raft.msgs</code>结构中，最后会成为<code>Ready</code>的成员，以传递给应用程序，由应用程序进行实际的网络转发操作。</p>
<h5 id="leader-节点处理-follower-节点日志追加响应"><a href="#leader-节点处理-follower-节点日志追加响应" class="headerlink" title="leader 节点处理 follower 节点日志追加响应"></a>leader 节点处理 follower 节点日志追加响应</h5><p>最后，同样，当<code>follower</code>将回复消息发送之后，再由网络传输组件<code>transport</code>调用<code>node.Process()</code>函数以处理此消息（此逻辑已在上面的【<code>folower</code>节点追加日志】小节中最开始阐述）。因此，最后同样会进入<code>leader</code>的<code>stepLeader()</code>函数，而且会进入消息类型为<code>MsgAppResp</code>分支处理逻辑中，关键代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">stepLeader</span><span class="params">(r *raft, m pb.Message)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">switch</span> m.Type &#123;</span><br><span class="line">	<span class="keyword">case</span> pb.MsgAppResp:</span><br><span class="line">		pr.RecentActive = <span class="literal">true</span></span><br><span class="line">		<span class="keyword">if</span> m.Reject &#123; <span class="comment">// 若 follower回复拒绝消息</span></span><br><span class="line">			r.logger.Debugf(<span class="string">"%x received msgApp rejection(lastindex: %d) from %x for index %d"</span>,</span><br><span class="line">				r.id, m.RejectHint, m.From, m.Index)</span><br><span class="line">            <span class="comment">// 则需要减小消息的索引，即往前挑选消息（raft 论文中关于日志冲突已经详细介绍），</span></span><br><span class="line">            <span class="comment">// 即</span></span><br><span class="line">			<span class="keyword">if</span> pr.maybeDecrTo(m.Index, m.RejectHint) &#123;</span><br><span class="line">				r.logger.Debugf(<span class="string">"%x decreased progress of %x to [%s]"</span>, r.id, m.From, pr)</span><br><span class="line">				<span class="keyword">if</span> pr.State == ProgressStateReplicate &#123;</span><br><span class="line">					pr.becomeProbe()</span><br><span class="line">				&#125; <span class="comment">// 再次将消息发送给 follower</span></span><br><span class="line">				r.sendAppend(m.From)</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123; <span class="comment">// 否则 follower 回复成功追加日志</span></span><br><span class="line">			oldPaused := pr.IsPaused()</span><br><span class="line">            <span class="comment">// 此处为更新 leader 维护的对各 follower 节点的进度详情（具体在 progress.go中描述）</span></span><br><span class="line">            <span class="comment">// 比较简单，因此为了节约篇幅，此处不展开叙述。</span></span><br><span class="line">            <span class="comment">// 事实上，这也是 etcd-raft 针对 原始的 raft 论文作的一些优化。</span></span><br><span class="line">			<span class="keyword">if</span> pr.maybeUpdate(m.Index) &#123;</span><br><span class="line">				<span class="keyword">switch</span> &#123;</span><br><span class="line">				<span class="keyword">case</span> pr.State == ProgressStateProbe:</span><br><span class="line">					pr.becomeReplicate()</span><br><span class="line">				<span class="keyword">case</span> pr.State == ProgressStateSnapshot &amp;&amp; pr.needSnapshotAbort():</span><br><span class="line">					r.logger.Debugf(<span class="string">"%x snapshot aborted, resumed sending replication messages to %x [%s]"</span>, r.id, m.From, pr)</span><br><span class="line">					pr.becomeProbe()</span><br><span class="line">					pr.becomeReplicate()</span><br><span class="line">				<span class="keyword">case</span> pr.State == ProgressStateReplicate:</span><br><span class="line">					pr.ins.freeTo(m.Index)</span><br><span class="line">				&#125;</span><br><span class="line">				<span class="comment">// 检查是否需要提交，若的确可以提交，则同样将此消息进行广播</span></span><br><span class="line">				<span class="keyword">if</span> r.maybeCommit() &#123;</span><br><span class="line">					r.bcastAppend()</span><br><span class="line">				&#125; <span class="keyword">else</span> <span class="keyword">if</span> oldPaused &#123;</span><br><span class="line">					r.sendAppend(m.From)</span><br><span class="line">				&#125;</span><br><span class="line">				<span class="comment">// We've updated flow control information above, which may</span></span><br><span class="line">				<span class="comment">// allow us to send multiple (size-limited) in-flight messages</span></span><br><span class="line">				<span class="comment">// at once (such as when transitioning from probe to</span></span><br><span class="line">				<span class="comment">// replicate, or when freeTo() covers multiple messages). If</span></span><br><span class="line">				<span class="comment">// we have more entries to send, send as many messages as we</span></span><br><span class="line">				<span class="comment">// can (without sending empty messages for the commit index)</span></span><br><span class="line">				<span class="keyword">for</span> r.maybeSendAppend(m.From, <span class="literal">false</span>) &#123;</span><br><span class="line">				&#125;</span><br><span class="line">				<span class="comment">// Transfer leadership is in progress.</span></span><br><span class="line">				<span class="keyword">if</span> m.From == r.leadTransferee &amp;&amp; pr.Match == r.raftLog.lastIndex() &#123;</span><br><span class="line">					r.logger.Infof(<span class="string">"%x sent MsgTimeoutNow to %x after received MsgAppResp"</span>, r.id, m.From)</span><br><span class="line">					r.sendTimeoutNow(m.From)</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	<span class="keyword">case</span> pb.MsgHeartbeatResp:</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">case</span> pb.MsgSnapStatus:</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">case</span> pb.MsgTransferLeader:</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// /etcd/raft/raft.go</span></span><br></pre></td></tr></table></figure>

<p>至此，<code>leader</code>节点处理<code>follower</code>节点对日志追加消息的回复也已经分析完毕。</p>
<p>因此，整个完整的流程也已经结束。我们也对<code>unstabel</code>以及<code>raftLog</code>的流程，即<code>raft</code>协议库与<code>raftLog</code>的交互作一个简单小结：可以发现，<code>unstable</code>或者说<code>raftLog</code>只是协议存储管理日志的组件，没有其它作用，即它没有用作诸如节点宕机后重启、新节点加入过程的日志来源。<code>unstable</code>是未落盘的日志项集合，即可能会丢失，因此<code>unstable</code>日志最终会持久化到<code>storage</code>中，即持久化到<code>snap</code>以及<code>WAL</code>日志。</p>
<p>最后，需要提醒读者的是，文章比较长，若读者没有时间，也可以挑选部分小节进行参考（各小节是独立分析阐述的）。最重要的是，读者自己能够进入到源码文件进行查看，那比本文所贴出的代码逻辑会更容易理解，读者也会获取得更多。</p>
<p>参考文献</p>
<p>[1]. <a href="https://github.com/etcd-io/etcd/tree/master/raft" target="_blank" rel="noopener">https://github.com/etcd-io/etcd/tree/master/raft</a></p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>分布式协调服务</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>分布式协调服务</tag>
      </tags>
  </entry>
  <entry>
    <title>etcd-raft WAL日志管理源码简析</title>
    <url>/2019/01/11/etcd-raft-WAL%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/</url>
    <content><![CDATA[<p>上一篇文章简单分析了<code>etcd-raft</code> 网络传输组件相关的源码。本文会简要分析<code>etcd-raft WAL</code>日志管理部分的源码。<code>WAL</code>(<code>Write-Ahead Logging</code>)即为预写式日志，即在真正执行写操作之前先写日志，这在数据库系统和分布式系统领域很常见。它是为了保证数据的可靠写。日志对于利用一致性协议构建高可用的分布式系统而言至关重要，在<code>etcd raft</code>中，日志也会在各节点之间同步。并且<code>etcd</code>提供了一个<code>WAL</code>的日志库，它暴露日志管理相关的接口以方便应用程序具体操作日志的逻辑。本文从应用调用 <code>WAL</code>库执行日志追加逻辑切入，重点分析<code>etcd</code>提供的<code>WAL</code>日志库的相关接口实现逻辑细则，包括<code>WAL</code>日志的设计、日志创建追加等。</p>
<a id="more"></a>

<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>同之前的文章类似，希望读者能够主动查看源码（主要涉及目录<code>/etcd/wal</code>），文章作为参考。按惯例，先来观察与<code>WAL</code>相关的重要数据结构的设计。从最核心的数据结构切入<code>WAL</code>：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// WAL 是持久化存在的逻辑表示。并且要么处于读模式要么处于追加模式。</span></span><br><span class="line"><span class="comment">// 新创建的 WAL 处于追加模式，可用于记录追加。</span></span><br><span class="line"><span class="comment">// 刚打开的 WAL 处于读模式，可用于记录读取。</span></span><br><span class="line"><span class="comment">// 当读完之前所有的 WAL 记录后，WAL 才可用于记录追加。</span></span><br><span class="line"><span class="keyword">type</span> WAL <span class="keyword">struct</span> &#123;</span><br><span class="line">	lg *zap.Logger</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 日志存储目录</span></span><br><span class="line">	dir <span class="keyword">string</span> <span class="comment">// the living directory of the underlay files</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// dirFile is a fd for the wal directory for syncing on Rename</span></span><br><span class="line">	<span class="comment">// 文件描述符，用于 WAL 目录同步重命名操作</span></span><br><span class="line">	dirFile *os.File</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 元数据，在创建日志文件时，在写在文件头位置</span></span><br><span class="line">	metadata []<span class="keyword">byte</span>           <span class="comment">// metadata recorded at the head of each WAL</span></span><br><span class="line">	state    raftpb.HardState <span class="comment">// hardstate recorded at the head of WAL</span></span><br><span class="line"></span><br><span class="line">	start     walpb.Snapshot <span class="comment">// snapshot to start reading</span></span><br><span class="line">	decoder   *decoder       <span class="comment">// decoder to decode records</span></span><br><span class="line">	readClose <span class="function"><span class="keyword">func</span><span class="params">()</span> <span class="title">error</span>   // <span class="title">closer</span> <span class="title">for</span> <span class="title">decode</span> <span class="title">reader</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">	<span class="title">mu</span>      <span class="title">sync</span>.<span class="title">Mutex</span></span></span><br><span class="line"><span class="function">    // <span class="title">WAL</span> 中保存的最后一条日志的索引</span></span><br><span class="line"><span class="function">	<span class="title">enti</span>    <span class="title">uint64</span>   // <span class="title">index</span> <span class="title">of</span> <span class="title">the</span> <span class="title">last</span> <span class="title">entry</span> <span class="title">saved</span> <span class="title">to</span> <span class="title">the</span> <span class="title">wal</span></span></span><br><span class="line"><span class="function">	<span class="title">encoder</span> *<span class="title">encoder</span> // <span class="title">encoder</span> <span class="title">to</span> <span class="title">encode</span> <span class="title">records</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">	// <span class="title">LockedFile</span> 封装了 <span class="title">os</span>.<span class="title">File</span> 的结构，具备文件锁定功能</span></span><br><span class="line"><span class="function">	<span class="title">locks</span> []*<span class="title">fileutil</span>.<span class="title">LockedFile</span> // <span class="title">the</span> <span class="title">locked</span> <span class="title">files</span> <span class="title">the</span> <span class="title">WAL</span> <span class="title">holds</span> <span class="params">(the name is increasing)</span></span></span><br><span class="line"><span class="function">	<span class="title">fp</span>    *<span class="title">filePipeline</span></span></span><br><span class="line"><span class="function">&#125; // <span class="title">wal</span>.<span class="title">go</span></span></span><br></pre></td></tr></table></figure>

<p>简单的字段在代码中作了注释。下面了解下几个重点的结构：</p>
<ul>
<li><p><code>state</code>: <code>HardState{Term,Vote,Commit}</code>类型，它表示节点在回复消息时，必须先进行持久化保持的状态。</p>
</li>
<li><p><code>start</code>: <code>walpb.Snapshot{Index, Term}</code>类型，即表示<code>WAL</code>日志中的快照，当读<code>WAL</code>日志时需从此索引后一个开始，如应用在重放日志逻辑中，需要打开<code>WAL</code>日志，则其只需要对<code>Snapshot</code>索引后的日志作重放。</p>
</li>
<li><p><code>decoder</code>: <code>decoder</code>封装了<code>Reader</code>，并且使用<code>crc</code>来校验读取的记录，一个文件对应一个<code>decoder</code>。</p>
</li>
<li><p><code>encoder</code>: <code>encoder</code>封装了<code>PageWriter</code>，同样使用<code>crc</code>来检验写入记录，<code>encoder</code>实例同样对应一个文件。</p>
</li>
<li><p><code>fp</code>: <code>filePipeline</code>类型，它管理文件创建时的磁盘空间分配操作逻辑。若文件以写模式打开，它会开启一个单独的<code>go routine</code>为文件创建预分配空间，以提高文件创建的效率。此逻辑封装在<code>file_pipeline.go</code>。</p>
</li>
</ul>
<p>我们不妨简单看看<code>encoder</code>的结构（比<code>decoder</code>结构稍复杂），它包含了一个执行具体写操作的<code>PageWriter</code>，以及一个<code>crc</code>字段，另外，还包含两个预分配的缓冲区，其中<code>buf</code>(1MB)用于写入实际数据，而<code>uint64buf</code>(8B)用于写入长度相关字段。其代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> encoder <span class="keyword">struct</span> &#123;</span><br><span class="line">	mu sync.Mutex</span><br><span class="line">	bw *ioutil.PageWriter</span><br><span class="line"></span><br><span class="line">	crc       hash.Hash32</span><br><span class="line">	buf       []<span class="keyword">byte</span> <span class="comment">// 用于写入实际记录数据</span></span><br><span class="line">	uint64buf []<span class="keyword">byte</span> <span class="comment">// 用于写入长度相关字段</span></span><br><span class="line">&#125; <span class="comment">// encoder.go</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newEncoder</span><span class="params">(w io.Writer, prevCrc <span class="keyword">uint32</span>, pageOffset <span class="keyword">int</span>)</span> *<span class="title">encoder</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> &amp;encoder&#123;</span><br><span class="line">		bw:  ioutil.NewPageWriter(w, walPageBytes, pageOffset),</span><br><span class="line">		crc: crc.New(prevCrc, crcTable),</span><br><span class="line">		<span class="comment">// 1MB buffer</span></span><br><span class="line">		buf:       <span class="built_in">make</span>([]<span class="keyword">byte</span>, <span class="number">1024</span>*<span class="number">1024</span>),</span><br><span class="line">		uint64buf: <span class="built_in">make</span>([]<span class="keyword">byte</span>, <span class="number">8</span>),</span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="comment">// encoder.go</span></span><br></pre></td></tr></table></figure>

<p>另外，存储在<code>WAL</code>日志的记录包括两种，一种以<code>Record</code>形式保存，它是一种普通的记录格式，另一种以<code>Snapshot</code>形式保存，它专门用于快照记录的存储，但快照类型的记录最终还是作为<code>Record</code>类型记录存储：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Record <span class="keyword">struct</span> &#123;</span><br><span class="line">	Type             <span class="keyword">int64</span>  <span class="string">`protobuf:"varint,1,opt,name=type" json:"type"`</span></span><br><span class="line">	Crc              <span class="keyword">uint32</span> <span class="string">`protobuf:"varint,2,opt,name=crc" json:"crc"`</span></span><br><span class="line">	Data             []<span class="keyword">byte</span> <span class="string">`protobuf:"bytes,3,opt,name=data" json:"data,omitempty"`</span></span><br><span class="line">	XXX_unrecognized []<span class="keyword">byte</span> <span class="string">`json:"-"`</span></span><br><span class="line">&#125; <span class="comment">// record.pb.go</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Snapshot <span class="keyword">struct</span> &#123;</span><br><span class="line">	Index            <span class="keyword">uint64</span> <span class="string">`protobuf:"varint,1,opt,name=index" json:"index"`</span></span><br><span class="line">	Term             <span class="keyword">uint64</span> <span class="string">`protobuf:"varint,2,opt,name=term" json:"term"`</span></span><br><span class="line">	XXX_unrecognized []<span class="keyword">byte</span> <span class="string">`json:"-"`</span></span><br><span class="line">&#125; <span class="comment">// record.pb.go</span></span><br></pre></td></tr></table></figure>

<p>对于普通记录<code>Record</code>类型结构（即<code>WAL</code>日志类型），它的<code>Type</code>字段表示日志类型，包括如下几种日志类型：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> (</span><br><span class="line">    <span class="comment">// 元数据类型日志项，被写在每个日志文件的头部，具体内容可以任意，包括空值</span></span><br><span class="line">	metadataType <span class="keyword">int64</span> = <span class="literal">iota</span> + <span class="number">1</span></span><br><span class="line">    <span class="comment">// 实际的数据，即日志存储中的关键数据</span></span><br><span class="line">	entryType</span><br><span class="line">    <span class="comment">// 表示保存的为 HardState 类型的数据</span></span><br><span class="line">	stateType</span><br><span class="line">    <span class="comment">// 前一个 WAL 日志记录数据的 crc 值</span></span><br><span class="line">	crcType</span><br><span class="line">    <span class="comment">// 表示快照类型的日志记录，它表示当前 Snapshot 位于哪个日志记录，保存的是索引(Term,Index)数据</span></span><br><span class="line">	snapshotType</span><br><span class="line"></span><br><span class="line">	<span class="comment">// warnSyncDuration is the amount of time allotted to an fsync before</span></span><br><span class="line">	<span class="comment">// logging a warning</span></span><br><span class="line">	warnSyncDuration = time.Second</span><br><span class="line">) <span class="comment">// wal.go</span></span><br></pre></td></tr></table></figure>

<p>而它的<code>crc</code>字段表示校验和数据，需要注意的是它并非直接保存的是当前日志记录的校验数据，而保存的是当前文件该日志项之前的所有日志项的校验和，这似乎是采用类似一种<code>rolling crc</code>，以保证<code>WAL</code>日志的连续性，因为写日志的时候可能会涉及到<code>cut</code>操作，它会将日志内容存储到不止一个文件。<code>data</code>字段会根据不同的类型来具体确定，若为<code>stateType</code>，则存储<code>HardState</code>类型的数据，若为<code>entryType</code>，则存储<code>Entry</code>类型的数据，若为<code>snapshotType</code>，则存储<code>Snapshot</code>类型的数据（只是索引数据），若为<code>metadataType</code>，则似乎可以由应用决定（目前来看在<code>raftNode</code>结构中，使用了此类型的日志，但传过来的数据为空），若为<code>crcType</code>，则存储<code>Crc</code>类型(<code>unit32</code>)的数据。</p>
<p>最后的<code>padding</code>字段，则是为了保持日志项数据 8 字节对其的策略，而进行填充的内容。这个我们可以从任一一处编码<code>Record</code>记录的代码中观察得知，如从<code>wal.go</code>中<code>w.encoder.encode(...)</code>代码往下追溯具体的<code>encode()</code>的逻辑，在<code>encode()</code>函数中会调用<code>encodeFrameSize(len(data))</code>，其函数具体的代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">encodeFrameSize</span><span class="params">(dataBytes <span class="keyword">int</span>)</span> <span class="params">(lenField <span class="keyword">uint64</span>, padBytes <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">	lenField = <span class="keyword">uint64</span>(dataBytes)</span><br><span class="line">	<span class="comment">// force 8 byte alignment so length never gets a torn write</span></span><br><span class="line">	padBytes = (<span class="number">8</span> - (dataBytes % <span class="number">8</span>)) % <span class="number">8</span> <span class="comment">// 先得出 padding 的 bytes 的大小，一定小于 8</span></span><br><span class="line">	<span class="keyword">if</span> padBytes != <span class="number">0</span> &#123;</span><br><span class="line">		lenField |= <span class="keyword">uint64</span>(<span class="number">0x80</span>|padBytes) &lt;&lt; <span class="number">56</span> </span><br><span class="line">        <span class="comment">// 将 0x80 与 padBytes 进行或操作，得到 4 个二进制位的内容，然后再左移 56 位。最后得到的记录的存储二进制结构为：</span></span><br><span class="line">        <span class="comment">// &#123;|-(1位标记位)| |---(3位表示 Padding bytes Size)|&#125;&#123;...(56位于表示实际的 Record bytes Size)&#125;</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> lenField, padBytes</span><br><span class="line">&#125; <span class="comment">// encoder.go</span></span><br></pre></td></tr></table></figure>

<p>至此相关的重要的数据结构项已经查看完毕，主要是围绕<code>WAL</code>结构展开。文章为了节约篇幅并没有将所有的数据项结构的代码帖出，读者可以自己深入源码查看，较为简单。</p>
<h2 id="关键流程"><a href="#关键流程" class="headerlink" title="关键流程"></a>关键流程</h2><p>在此部分分析中，简要分析阐述<code>WAL</code>库提供的各个接口实现的逻辑，主要包括<code>WAL</code>创建、<code>WAL</code>初始化（打开）、<code>WAL</code>日志项读取及<code>WAL</code>追加日志项等流程。另外，关于<code>raft</code>协议核心库如何操作日志的逻辑暂不涉及。</p>
<h3 id="WAL-创建"><a href="#WAL-创建" class="headerlink" title="WAL 创建"></a>WAL 创建</h3><p>在<code>raftexample</code>示例代码中，应用在启动时，对<code>WAL</code>日志执行重放操作（<code>raft.go</code>，在<code>startRaft()</code>中的<code>rc.replayWAL()</code>），而在重放日志函数的逻辑中，它先加载<code>snapshot</code>数据，然后，将其作为参数传递给<code>rc.openWAL(snapshot)</code>函数，以对打开文件，如果文件不存在，则会先创建日志文件。关键代码如下所示：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// replayWAL replays WAL entries into the raft instance.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rc *raftNode)</span> <span class="title">replayWAL</span><span class="params">()</span> *<span class="title">wal</span>.<span class="title">WAL</span></span> &#123;</span><br><span class="line">	log.Printf(<span class="string">"replaying WAL of member %d"</span>, rc.id)</span><br><span class="line">	snapshot := rc.loadSnapshot() <span class="comment">// 加载 snapshot 数据</span></span><br><span class="line">	w := rc.openWAL(snapshot) <span class="comment">// 打开 WAL 日志文件，以读取 snaptshot 位置后的日志</span></span><br><span class="line">	_, st, ents, err := w.ReadAll() <span class="comment">// 读取 WAL 日志文件，相关逻辑后面详述</span></span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	<span class="keyword">return</span> w</span><br><span class="line">&#125; <span class="comment">// raft.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// openWAL returns a WAL ready for reading.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rc *raftNode)</span> <span class="title">openWAL</span><span class="params">(snapshot *raftpb.Snapshot)</span> *<span class="title">wal</span>.<span class="title">WAL</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> !wal.Exist(rc.waldir) &#123;</span><br><span class="line">		<span class="keyword">if</span> err := os.Mkdir(rc.waldir, <span class="number">0750</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line">			log.Fatalf(<span class="string">"raftexample: cannot create dir for wal (%v)"</span>, err)</span><br><span class="line">		&#125;</span><br><span class="line">        <span class="comment">// 1. 创建日志文件，注意在这里 metaData 参数为 nil</span></span><br><span class="line">		w, err := wal.Create(zap.NewExample(), rc.waldir, <span class="literal">nil</span>)</span><br><span class="line">		w.Close()</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="comment">// 2. 创建 snapshotType 类型的日志项，以用于记录当前快照的索引情况(Term, Index)</span></span><br><span class="line">	walsnap := walpb.Snapshot&#123;&#125;</span><br><span class="line">	<span class="keyword">if</span> snapshot != <span class="literal">nil</span> &#123;</span><br><span class="line">		walsnap.Index, walsnap.Term = snapshot.Metadata.Index, snapshot.Metadata.Term</span><br><span class="line">	&#125;</span><br><span class="line">	log.Printf(<span class="string">"loading WAL at term %d and index %d"</span>, walsnap.Term, walsnap.Index)</span><br><span class="line">    <span class="comment">// 3. 打开从 snapshot 位置打开日志，其相关的逻辑在后面详述</span></span><br><span class="line">	w, err := wal.Open(zap.NewExample(), rc.waldir, walsnap) </span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		log.Fatalf(<span class="string">"raftexample: error loading wal (%v)"</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> w</span><br><span class="line">&#125; <span class="comment">// raft.go</span></span><br></pre></td></tr></table></figure>

<p>阐明了应用<code>WAL</code>日志库的入口后，我们先来查看<code>WAL</code>创建函数相关的逻辑。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Create creates a WAL ready for appending records. The given metadata is</span></span><br><span class="line"><span class="comment">// recorded at the head of each WAL file, and can be retrieved with ReadAll.</span></span><br><span class="line"><span class="comment">// 创建一个 WAL 文件用于日志记录追加。元数据存放在文件头部，可以通过 ReadAll 检索到</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Create</span><span class="params">(lg *zap.Logger, dirpath <span class="keyword">string</span>, metadata []<span class="keyword">byte</span>)</span> <span class="params">(*WAL, error)</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> Exist(dirpath) &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, os.ErrExist</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// keep temporary wal directory so WAL initialization appears atomic</span></span><br><span class="line">	<span class="comment">// 1. 先创建一个临时文件，然后对此文件进行重命名，以使得文件被原子创建</span></span><br><span class="line">	tmpdirpath := filepath.Clean(dirpath) + <span class="string">".tmp"</span></span><br><span class="line">	<span class="keyword">if</span> fileutil.Exist(tmpdirpath) &#123;</span><br><span class="line">		<span class="keyword">if</span> err := os.RemoveAll(tmpdirpath); err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> err := fileutil.CreateDirAll(tmpdirpath); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 构造文件名，即构建 dir/filename, 其中 filename 伤脑筋 walName函数来获取，文件名构建规则为：seq-index.wal</span></span><br><span class="line">	p := filepath.Join(tmpdirpath, walName(<span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">	<span class="comment">// 3. WAL 对文件的操作都是通过 LockFile 来执行的</span></span><br><span class="line">	f, err := fileutil.LockFile(p, os.O_WRONLY|os.O_CREATE, fileutil.PrivateFileMode)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 4. 定位到文件末尾</span></span><br><span class="line">	<span class="keyword">if</span> _, err = f.Seek(<span class="number">0</span>, io.SeekEnd); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 5. 预分配文件，默认 SegmentSizeBytes 大小为 64MB</span></span><br><span class="line">	<span class="keyword">if</span> err = fileutil.Preallocate(f.File, SegmentSizeBytes, <span class="literal">true</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 6. 初始化 WAL 数据结构</span></span><br><span class="line">	w := &amp;WAL&#123;</span><br><span class="line">		lg:       lg,</span><br><span class="line">		dir:      dirpath,</span><br><span class="line">		metadata: metadata,</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 7. 针对此文件构建 WAL 结构的 encoder 字段，并且将 preCrc 字段赋值为0</span></span><br><span class="line">	w.encoder, err = newFileEncoder(f.File, <span class="number">0</span>)</span><br><span class="line">	<span class="comment">// 8. 将此（具备锁定性质的）文件添加到 WAL 结构的 locks 数组字段</span></span><br><span class="line">	w.locks = <span class="built_in">append</span>(w.locks, f)</span><br><span class="line">	<span class="comment">// 9. 保存类型为 crcType 的 crc 记录项，具体的 crc 数据为 preCrc=0</span></span><br><span class="line">	<span class="keyword">if</span> err = w.saveCrc(<span class="number">0</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 10. 利用 encoder 编码类型为 metadataType 的 metaData 记录项</span></span><br><span class="line">	<span class="keyword">if</span> err = w.encoder.encode(&amp;walpb.Record&#123;Type: metadataType, Data: metadata&#125;); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 11. 保存类型为 snapshotType 的空的 Snapshot 记录</span></span><br><span class="line">	<span class="keyword">if</span> err = w.SaveSnapshot(walpb.Snapshot&#123;&#125;); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 12. 重命名操作，之前以.tmp结尾的文件，初始化完成之后进行重命名，类似原子操作</span></span><br><span class="line">	<span class="keyword">if</span> w, err = w.renameWAL(tmpdirpath); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// directory was renamed; sync parent dir to persist rename</span></span><br><span class="line">	pdir, perr := fileutil.OpenDir(filepath.Dir(w.dir))</span><br><span class="line">	<span class="comment">// 13. 将上述涉及到对文件的操作进行同步处理</span></span><br><span class="line">	<span class="keyword">if</span> perr = fileutil.Fsync(pdir); perr != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, perr</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> perr = pdir.Close(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, perr</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> w, <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// wal.go</span></span><br></pre></td></tr></table></figure>

<p>上述代码片段中的注释对整个创建过程进行了详细阐述，这是总结一下，它主要涉及到几个操作：</p>
<ul>
<li>创建<code>WAL</code>目录，用于存储<code>WAL</code>日志文件及索引，同时使用临时文件及重命名的方式来原子操作。</li>
<li>对日志文件的创建，会预分配空间，以提高创建的效率。</li>
<li>在日志文件创建时，会初始化 <code>WAL</code>结构实例，同时写入<code>crcType</code>、<code>metadataType</code>记录项，并且保存一个空的<code>snapshotType</code>记录项。对于各种类型记录项，上文中数据结构小节已经详细阐述。</li>
</ul>
<p>我们来看下它是如何保存<code>snapshotType</code>类型的<code>Snapshot</code>数据的，相关逻辑在函数<code>SaveSnapShot(Snapshot)</code>:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 持久化 walpb.Snapshot 数据</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *WAL)</span> <span class="title">SaveSnapshot</span><span class="params">(e walpb.Snapshot)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	b := pbutil.MustMarshal(&amp;e) <span class="comment">// 1. 先执行序列化操作</span></span><br><span class="line">	w.mu.Lock()</span><br><span class="line">	<span class="keyword">defer</span> w.mu.Unlock()</span><br><span class="line">	<span class="comment">// 2. 构建 snaptshotType 类型的记录结构，并以序列化的数据作为参数</span></span><br><span class="line">	rec := &amp;walpb.Record&#123;Type: snapshotType, Data: b&#125;</span><br><span class="line">	<span class="comment">// 3. 利用 encoder 编码写入</span></span><br><span class="line">	<span class="keyword">if</span> err := w.encoder.encode(rec); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// update enti only when snapshot is ahead of last index</span></span><br><span class="line">	<span class="comment">// 4. w.enti 表示的是 WAL 中最后一条日志的索引，因此只有当其小于快照的索引时，才进行替换</span></span><br><span class="line">	<span class="keyword">if</span> w.enti &lt; e.Index &#123;</span><br><span class="line">		w.enti = e.Index</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> w.sync()</span><br><span class="line">&#125; <span class="comment">// wal.go</span></span><br></pre></td></tr></table></figure>

<p>我们不妨深入<code>encoder.encode()</code>函数中查看一下编码的细节：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 编码一条数据记录项</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e *encoder)</span> <span class="title">encode</span><span class="params">(rec *walpb.Record)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	e.mu.Lock()</span><br><span class="line">	<span class="keyword">defer</span> e.mu.Unlock()</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 1. 生成校验和数据</span></span><br><span class="line">	e.crc.Write(rec.Data)</span><br><span class="line">	rec.Crc = e.crc.Sum32()</span><br><span class="line">	<span class="keyword">var</span> (</span><br><span class="line">		data []<span class="keyword">byte</span></span><br><span class="line">		err  error</span><br><span class="line">		n    <span class="keyword">int</span></span><br><span class="line">	)</span><br><span class="line">	<span class="comment">// 2. 如果记录的大小超过预分配的 1MB 的 buffer（与文件的预分配可能类似），则重新分配空间</span></span><br><span class="line">	<span class="keyword">if</span> rec.Size() &gt; <span class="built_in">len</span>(e.buf) &#123;</span><br><span class="line">		data, err = rec.Marshal()</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> err</span><br><span class="line">		&#125;</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123; <span class="comment">// 否则直接使用预分配的空间</span></span><br><span class="line">		n, err = rec.MarshalTo(e.buf)</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> err</span><br><span class="line">		&#125;</span><br><span class="line">		data = e.buf[:n]</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 3. 调用 encodeFrameSize 函数来构建 lenField 以及判断对齐的位数</span></span><br><span class="line">	lenField, padBytes := encodeFrameSize(<span class="built_in">len</span>(data))</span><br><span class="line">	<span class="comment">// 4. 先写记录编码后的长度字段</span></span><br><span class="line">	<span class="keyword">if</span> err = writeUint64(e.bw, lenField, e.uint64buf); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 5. 然后，若需要对齐，则追加对齐填充数据</span></span><br><span class="line">	<span class="keyword">if</span> padBytes != <span class="number">0</span> &#123;</span><br><span class="line">		data = <span class="built_in">append</span>(data, <span class="built_in">make</span>([]<span class="keyword">byte</span>, padBytes)...)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 6. 最后正式写入记录的所包含的所有数据内容</span></span><br><span class="line">	_, err = e.bw.Write(data)</span><br><span class="line">	<span class="keyword">return</span> err</span><br><span class="line">&#125; <span class="comment">// encoder.go</span></span><br></pre></td></tr></table></figure>

<p>关于<code>WAL</code>文件创建相关逻辑已经阐述完毕，下一小节阐述与创建类似的操作即初始化操作。</p>
<h3 id="WAL-初始化"><a href="#WAL-初始化" class="headerlink" title="WAL 初始化"></a>WAL 初始化</h3><p><code>WAL</code>初始化，我将表示它表示为打开文件逻辑，即在应用程序里面中的代码<code>wal.Open()</code>函数中的流程。具体而言，打开<code>WAL</code>文件的目的是为了从里面读取日志文件（读取的目的一般是重放日志）。因此，更准确而言，是从指定索引处打开，此索引即表示之前的已经执行的快照的索引，从那之后开始进行读操作，而且只有当把快照索引之后的日志全部读取完毕才能进行追加操作。另外，打开操作必须保证快照之前已经被存储，否则读取操作<code>ReadlAll</code>会执行失败。打开操作的相关的代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Open</span><span class="params">(lg *zap.Logger, dirpath <span class="keyword">string</span>, snap walpb.Snapshot)</span> <span class="params">(*WAL, error)</span></span> &#123;</span><br><span class="line">	<span class="comment">// 只打开最后一个 seq 小于 snap 中的 index 之后的所有 wal 文件，并且以写的方式打开</span></span><br><span class="line">	w, err := openAtIndex(lg, dirpath, snap, <span class="literal">true</span>)</span><br><span class="line">	<span class="keyword">if</span> w.dirFile, err = fileutil.OpenDir(w.dir); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> w, <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// wal.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 打开指定索引后的日志文件</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">openAtIndex</span><span class="params">(lg *zap.Logger, dirpath <span class="keyword">string</span>, snap walpb.Snapshot, write <span class="keyword">bool</span>)</span> <span class="params">(*WAL, error)</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 读取所有 WAL 日志文件名称</span></span><br><span class="line">	names, err := readWALNames(lg, dirpath)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 返回名称集合中最后一个小于或者等于 snap.Index 的名称索引（在文件名称集合中的索引）</span></span><br><span class="line">	nameIndex, ok := searchIndex(lg, names, snap.Index)</span><br><span class="line">	<span class="comment">// 3. 检查 nameIndex 之后的文件名的 seq 是否有序递增的</span></span><br><span class="line">	<span class="keyword">if</span> !ok || !isValidSeq(lg, names[nameIndex:]) &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, ErrFileNotFound</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// open the wal files</span></span><br><span class="line">	rcs := <span class="built_in">make</span>([]io.ReadCloser, <span class="number">0</span>)</span><br><span class="line">	rs := <span class="built_in">make</span>([]io.Reader, <span class="number">0</span>)</span><br><span class="line">	ls := <span class="built_in">make</span>([]*fileutil.LockedFile, <span class="number">0</span>)</span><br><span class="line">	<span class="comment">// 3. 对返回的索引之后的文件进行遍历，同时构造 rcs、rs、ls 数组</span></span><br><span class="line">	<span class="keyword">for</span> _, name := <span class="keyword">range</span> names[nameIndex:] &#123;</span><br><span class="line">		<span class="comment">// 4. 构建文件路径</span></span><br><span class="line">		p := filepath.Join(dirpath, name)</span><br><span class="line">		<span class="comment">// 5. 如果是写模式打开，则进行如下操作</span></span><br><span class="line">		<span class="keyword">if</span> write &#123;</span><br><span class="line">			l, err := fileutil.TryLockFile(p, os.O_RDWR, fileutil.PrivateFileMode)</span><br><span class="line">			<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">				closeAll(rcs...)</span><br><span class="line">				<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">			&#125;</span><br><span class="line">			ls = <span class="built_in">append</span>(ls, l) <span class="comment">// 写模式似乎有锁定文件属性</span></span><br><span class="line">			rcs = <span class="built_in">append</span>(rcs, l) <span class="comment">// 追加文件读取与关闭接口</span></span><br><span class="line">		&#125; <span class="keyword">else</span> &#123; <span class="comment">// 6. 如果是读模式打开，则进行如下操作</span></span><br><span class="line">			rf, err := os.OpenFile(p, os.O_RDONLY, fileutil.PrivateFileMode)</span><br><span class="line">			<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">				closeAll(rcs...)</span><br><span class="line">				<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">			&#125;</span><br><span class="line">			ls = <span class="built_in">append</span>(ls, <span class="literal">nil</span>) <span class="comment">// 读模式并没有锁定文件属性</span></span><br><span class="line">			rcs = <span class="built_in">append</span>(rcs, rf) <span class="comment">// 同样追加文件读取与关闭接口</span></span><br><span class="line">		&#125;</span><br><span class="line">		rs = <span class="built_in">append</span>(rs, rcs[<span class="built_in">len</span>(rcs)<span class="number">-1</span>])</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 7. 构建用于文件读取与关闭的句柄集合</span></span><br><span class="line">	closer := <span class="function"><span class="keyword">func</span><span class="params">()</span> <span class="title">error</span></span> &#123; <span class="keyword">return</span> closeAll(rcs...) &#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// create a WAL ready for reading</span></span><br><span class="line">	<span class="comment">// 8. 利用以上信息构造 WAL 实例</span></span><br><span class="line">	w := &amp;WAL&#123;</span><br><span class="line">		lg:        lg,</span><br><span class="line">		dir:       dirpath,</span><br><span class="line">		start:     snap, <span class="comment">// 初始化快照数据，实际上表示可以从哪一个索引位置处开始读</span></span><br><span class="line">		decoder:   newDecoder(rs...), <span class="comment">// decoder 又以上述打开文件的句柄集合为参数</span></span><br><span class="line">		readClose: closer, <span class="comment">// 文件关闭句柄集合</span></span><br><span class="line">		locks:     ls, <span class="comment">// 具备锁定属性的文件集合</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 9. 若为写打开，则会重用读的文件描述符，因此不需要关闭 WAL 文件（需要释放锁）以直接执行追加操作</span></span><br><span class="line">	<span class="keyword">if</span> write &#123;</span><br><span class="line">		<span class="comment">// write reuses the file descriptors from read; don't close so</span></span><br><span class="line">		<span class="comment">// WAL can append without dropping the file lock</span></span><br><span class="line">		w.readClose = <span class="literal">nil</span></span><br><span class="line">		<span class="keyword">if</span> _, _, err := parseWALName(filepath.Base(w.tail().Name())); err != <span class="literal">nil</span> &#123;</span><br><span class="line">			closer()</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 10. 创建 FilePipeline 进行创建文件操作的空间预分配操作，具体是在 go routine 中循环执行空间分配操作，</span></span><br><span class="line">		<span class="comment">// 并将分配好的文件放到通道中，等待后面正式创建的时候使用</span></span><br><span class="line">		w.fp = newFilePipeline(w.lg, w.dir, SegmentSizeBytes)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> w, <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// wal.go</span></span><br></pre></td></tr></table></figure>

<p><code>WAL</code>文件打开以进行后续的读取与追加操作的相关逻辑已经阐述完毕。下面阐述日志项的读取相关逻辑。</p>
<h3 id="WAL-日志项读取"><a href="#WAL-日志项读取" class="headerlink" title="WAL 日志项读取"></a>WAL 日志项读取</h3><p>同样，在应用<code>raftexample</code>中启动初始化应用时(<code>startRaft()</code>)中可能会涉及到日志的读取操作(<code>w.ReadAll()</code>)。因此，我们来详细了解读取逻辑。大概地，它会读取<code>WAL</code>所有日志记录，当读取完毕后，就可以执行操作：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// ReadAll reads out records of the current WAL.</span></span><br><span class="line"><span class="comment">// If opened in write mode, it must read out all records until EOF. Or an error</span></span><br><span class="line"><span class="comment">// will be returned.</span></span><br><span class="line"><span class="comment">// If opened in read mode, it will try to read all records if possible.</span></span><br><span class="line"><span class="comment">// If it cannot read out the expected snap, it will return ErrSnapshotNotFound.</span></span><br><span class="line"><span class="comment">// If loaded snap doesn't match with the expected one, it will return</span></span><br><span class="line"><span class="comment">// all the records and error ErrSnapshotMismatch.</span></span><br><span class="line"><span class="comment">// <span class="doctag">TODO:</span> detect not-last-snap error.</span></span><br><span class="line"><span class="comment">// <span class="doctag">TODO:</span> maybe loose the checking of match.</span></span><br><span class="line"><span class="comment">// After ReadAll, the WAL will be ready for appending new records.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *WAL)</span> <span class="title">ReadAll</span><span class="params">()</span> <span class="params">(metadata []<span class="keyword">byte</span>, state raftpb.HardState, ents []raftpb.Entry, err error)</span></span> &#123;</span><br><span class="line">	w.mu.Lock()</span><br><span class="line">	<span class="keyword">defer</span> w.mu.Unlock()</span><br><span class="line">	<span class="comment">// 1. 初始化一个空的记录项</span></span><br><span class="line">	rec := &amp;walpb.Record&#123;&#125;</span><br><span class="line">	decoder := w.decoder</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 2. 根据记录不同的类型（在数据结构部分已经详述），来执行不同操作</span></span><br><span class="line">	<span class="keyword">var</span> match <span class="keyword">bool</span></span><br><span class="line">	<span class="keyword">for</span> err = decoder.decode(rec); err == <span class="literal">nil</span>; err = decoder.decode(rec) &#123;</span><br><span class="line">		<span class="keyword">switch</span> rec.Type &#123;</span><br><span class="line">		<span class="comment">// 2.1. 如果为 entryType 类型</span></span><br><span class="line">		<span class="keyword">case</span> entryType:</span><br><span class="line">			e := mustUnmarshalEntry(rec.Data)</span><br><span class="line">			<span class="comment">// 若读取到的日志的日志项的索引大于快照的索引，则将其追加到日志面集合，</span></span><br><span class="line">			<span class="comment">// 并且更新 WAL 的最后一条日志的日志索引</span></span><br><span class="line">			<span class="keyword">if</span> e.Index &gt; w.start.Index &#123;</span><br><span class="line">				ents = <span class="built_in">append</span>(ents[:e.Index-w.start.Index<span class="number">-1</span>], e)</span><br><span class="line">			&#125;</span><br><span class="line">			w.enti = e.Index</span><br><span class="line">		<span class="comment">// 2.2. 如果为 stateType 类型</span></span><br><span class="line">		<span class="keyword">case</span> stateType:</span><br><span class="line">			state = mustUnmarshalState(rec.Data)</span><br><span class="line">		<span class="comment">// 2.3 如果为 metadataType 类型，从此处来看 metadata 还可以用作检验</span></span><br><span class="line">		<span class="keyword">case</span> metadataType:</span><br><span class="line">			<span class="keyword">if</span> metadata != <span class="literal">nil</span> &amp;&amp; !bytes.Equal(metadata, rec.Data) &#123;</span><br><span class="line">				state.Reset()</span><br><span class="line">				<span class="keyword">return</span> <span class="literal">nil</span>, state, <span class="literal">nil</span>, ErrMetadataConflict</span><br><span class="line">			&#125;</span><br><span class="line">			metadata = rec.Data</span><br><span class="line">		<span class="comment">// 2.4 如果为 crcType 类型，则需要校验此 decoder 保存的 crc 检验和是否与记录的一致</span></span><br><span class="line">		<span class="keyword">case</span> crcType:</span><br><span class="line">			crc := decoder.crc.Sum32()</span><br><span class="line">			<span class="comment">// current crc of decoder must match the crc of the record.</span></span><br><span class="line">			<span class="comment">// do no need to match 0 crc, since the decoder is a new one at this case.</span></span><br><span class="line">			<span class="keyword">if</span> crc != <span class="number">0</span> &amp;&amp; rec.Validate(crc) != <span class="literal">nil</span> &#123;</span><br><span class="line">				state.Reset()</span><br><span class="line">				<span class="keyword">return</span> <span class="literal">nil</span>, state, <span class="literal">nil</span>, ErrCRCMismatch</span><br><span class="line">			&#125;</span><br><span class="line">			decoder.updateCRC(rec.Crc)</span><br><span class="line">		<span class="comment">// 2.5 如果为 snapshotType 类型</span></span><br><span class="line">		<span class="keyword">case</span> snapshotType:</span><br><span class="line">			<span class="keyword">var</span> snap walpb.Snapshot</span><br><span class="line">			pbutil.MustUnmarshal(&amp;snap, rec.Data)</span><br><span class="line">			<span class="comment">// 在反序列化之后，如果记录中的快照与 WAL 日志中快照不匹配，则报错</span></span><br><span class="line">			<span class="keyword">if</span> snap.Index == w.start.Index &#123;</span><br><span class="line">				<span class="keyword">if</span> snap.Term != w.start.Term &#123;</span><br><span class="line">					state.Reset()</span><br><span class="line">					<span class="keyword">return</span> <span class="literal">nil</span>, state, <span class="literal">nil</span>, ErrSnapshotMismatch</span><br><span class="line">				&#125;</span><br><span class="line">				match = <span class="literal">true</span></span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">default</span>:</span><br><span class="line">			state.Reset()</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span>, state, <span class="literal">nil</span>, fmt.Errorf(<span class="string">"unexpected block type %d"</span>, rec.Type)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 3. 通过 WAL 日志文件中最后一条记录来做不同的处理</span></span><br><span class="line">	<span class="keyword">switch</span> w.tail() &#123;</span><br><span class="line">	<span class="keyword">case</span> <span class="literal">nil</span>: <span class="comment">// 如果是读模式，则并不需要读取所有的记录，因为最后一条记录可能是部分写的</span></span><br><span class="line">		<span class="comment">// We do not have to read out all entries in read mode.</span></span><br><span class="line">		<span class="comment">// The last record maybe a partial written one, so</span></span><br><span class="line">		<span class="comment">// ErrunexpectedEOF might be returned.</span></span><br><span class="line">		<span class="keyword">if</span> err != io.EOF &amp;&amp; err != io.ErrUnexpectedEOF &#123;</span><br><span class="line">			state.Reset()</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span>, state, <span class="literal">nil</span>, err</span><br><span class="line">		&#125;</span><br><span class="line">	<span class="keyword">default</span>: <span class="comment">// 如果是写模式，则需要读取所有记录，直至返回 EOF</span></span><br><span class="line">		<span class="comment">// We must read all of the entries if WAL is opened in write mode.</span></span><br><span class="line">		<span class="keyword">if</span> err != io.EOF &#123;</span><br><span class="line">			state.Reset()</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span>, state, <span class="literal">nil</span>, err</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// decodeRecord() will return io.EOF if it detects a zero record,</span></span><br><span class="line">		<span class="comment">// but this zero record may be followed by non-zero records from</span></span><br><span class="line">		<span class="comment">// a torn write. Overwriting some of these non-zero records, but</span></span><br><span class="line">		<span class="comment">// not all, will cause CRC errors on WAL open. Since the records</span></span><br><span class="line">		<span class="comment">// were never fully synced to disk in the first place, it's safe</span></span><br><span class="line">		<span class="comment">// to zero them out to avoid any CRC errors from new writes.</span></span><br><span class="line">		<span class="keyword">if</span> _, err = w.tail().Seek(w.decoder.lastOffset(), io.SeekStart); err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span>, state, <span class="literal">nil</span>, err</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> err = fileutil.ZeroToEnd(w.tail().File); err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span>, state, <span class="literal">nil</span>, err</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	err = <span class="literal">nil</span></span><br><span class="line">	<span class="keyword">if</span> !match &#123;</span><br><span class="line">		err = ErrSnapshotNotFound</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 4. 读取完毕后，则关闭读操作</span></span><br><span class="line">	<span class="comment">// close decoder, disable reading</span></span><br><span class="line">	<span class="keyword">if</span> w.readClose != <span class="literal">nil</span> &#123;</span><br><span class="line">		w.readClose()</span><br><span class="line">		w.readClose = <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">	w.start = walpb.Snapshot&#123;&#125;</span><br><span class="line"></span><br><span class="line">	w.metadata = metadata</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 5. 如果最后一条记录不为空，则创建 encoder，准备追加操作</span></span><br><span class="line">	<span class="keyword">if</span> w.tail() != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="comment">// create encoder (chain crc with the decoder), enable appending</span></span><br><span class="line">		w.encoder, err = newFileEncoder(w.tail().File, w.decoder.lastCRC())</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	w.decoder = <span class="literal">nil</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> metadata, state, ents, err</span><br><span class="line">&#125; <span class="comment">// wal.go</span></span><br></pre></td></tr></table></figure>

<p>另外，关于记录的<code>decode</code>操作，下面帖出简要的注释过程，基本上是<code>encode</code>操作的逆操作，但是加了一个校验的过程。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// decode 日志记录项</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *decoder)</span> <span class="title">decode</span><span class="params">(rec *walpb.Record)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	rec.Reset()</span><br><span class="line">	d.mu.Lock()</span><br><span class="line">	<span class="keyword">defer</span> d.mu.Unlock()</span><br><span class="line">	<span class="keyword">return</span> d.decodeRecord(rec)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *decoder)</span> <span class="title">decodeRecord</span><span class="params">(rec *walpb.Record)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="comment">// 1. 需要读取器</span></span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(d.brs) == <span class="number">0</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> io.EOF</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 首先读与长度相关字段</span></span><br><span class="line">	l, err := readInt64(d.brs[<span class="number">0</span>])</span><br><span class="line">	<span class="comment">// 3. 解析出记录数据的字节大小以及对齐字节的大小</span></span><br><span class="line">	recBytes, padBytes := decodeFrameSize(l)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 4. 构建缓冲区用于存储具体读出的数据</span></span><br><span class="line">	data := <span class="built_in">make</span>([]<span class="keyword">byte</span>, recBytes+padBytes)</span><br><span class="line">	<span class="comment">// 5. 执行读实际数据的操作</span></span><br><span class="line">	<span class="keyword">if</span> _, err = io.ReadFull(d.brs[<span class="number">0</span>], data); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 6. 对数据执行反序列化操作</span></span><br><span class="line">	<span class="keyword">if</span> err := rec.Unmarshal(data[:recBytes]); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 7. 对非 crcType 类型的记录，需要校验 crc，即检测记录的 crc 数值与 decoder 的检验和是否一致</span></span><br><span class="line">	<span class="comment">// skip crc checking if the record type is crcType</span></span><br><span class="line">	<span class="keyword">if</span> rec.Type != crcType &#123;</span><br><span class="line">		d.crc.Write(rec.Data)</span><br><span class="line">		<span class="keyword">if</span> err := rec.Validate(d.crc.Sum32()); err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">if</span> d.isTornEntry(data) &#123;</span><br><span class="line">				<span class="keyword">return</span> io.ErrUnexpectedEOF</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">return</span> err</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 8. 更新目前已经检验的字节索引，下一次从此处开始检验</span></span><br><span class="line">	<span class="comment">// record decoded as valid; point last valid offset to end of record</span></span><br><span class="line">	d.lastValidOff += frameSizeBytes + recBytes + padBytes</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 为 encoder.encodeFrameSize() 函数的逆过程</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">decodeFrameSize</span><span class="params">(lenField <span class="keyword">int64</span>)</span> <span class="params">(recBytes <span class="keyword">int64</span>, padBytes <span class="keyword">int64</span>)</span></span> &#123;</span><br><span class="line">	<span class="comment">// the record size is stored in the lower 56 bits of the 64-bit length</span></span><br><span class="line">	recBytes = <span class="keyword">int64</span>(<span class="keyword">uint64</span>(lenField) &amp; ^(<span class="keyword">uint64</span>(<span class="number">0xff</span>) &lt;&lt; <span class="number">56</span>))</span><br><span class="line">	<span class="comment">// non-zero padding is indicated by set MSb / a negative length</span></span><br><span class="line">	<span class="keyword">if</span> lenField &lt; <span class="number">0</span> &#123;</span><br><span class="line">		<span class="comment">// padding is stored in lower 3 bits of length MSB</span></span><br><span class="line">		padBytes = <span class="keyword">int64</span>((<span class="keyword">uint64</span>(lenField) &gt;&gt; <span class="number">56</span>) &amp; <span class="number">0x7</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> recBytes, padBytes</span><br><span class="line">&#125; <span class="comment">// decoder.go</span></span><br></pre></td></tr></table></figure>

<p>最后一个部分来简要阐述日志项的追加逻辑。</p>
<h3 id="WAL-日志项追加"><a href="#WAL-日志项追加" class="headerlink" title="WAL 日志项追加"></a>WAL 日志项追加</h3><p>同样，在【<a href="https://qqzeng.top/2019/01/09/etcd-raftexample-%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/" target="_blank" rel="noopener">etcd raftexample 源码简析</a>】中，当应用收到底层<code>raft</code>协议的指令消息时，会先进行写日志(<code>rc.wal.Save(rd.HardState, rd.Entries)</code>)，也即此处的日志项追加操作。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 日志项追加操作</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *WAL)</span> <span class="title">Save</span><span class="params">(st raftpb.HardState, ents []raftpb.Entry)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	w.mu.Lock()</span><br><span class="line">	<span class="keyword">defer</span> w.mu.Unlock()</span><br><span class="line"></span><br><span class="line">	<span class="comment">// short cut, do not call sync</span></span><br><span class="line">	<span class="comment">// 1. 若无 需要持久化的字段 且无日志项数据，则返回</span></span><br><span class="line">	<span class="keyword">if</span> raft.IsEmptyHardState(st) &amp;&amp; <span class="built_in">len</span>(ents) == <span class="number">0</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. MustSync 会检查当前的 Save 操作是否需要同步存盘</span></span><br><span class="line">	<span class="comment">// 事实上，其逻辑大致为检查 log entries 是否为0，或者 candidate id 是否变化或者是 term 有变化，</span></span><br><span class="line">	<span class="comment">// 一旦这些条件中之一满足，则需要先执行存盘操作。</span></span><br><span class="line">	<span class="comment">// 这些字段为 raft 实例需要持久化的字段，以便重启的时候可以继续协议</span></span><br><span class="line">	mustSync := raft.MustSync(st, w.state, <span class="built_in">len</span>(ents))</span><br><span class="line"></span><br><span class="line">	<span class="comment">// TODO(xiangli): no more reference operator</span></span><br><span class="line">	<span class="comment">// 3. 遍历日志项，并保存，在 saveEntry 中，会构建 Entry 记录，并更新 WAL 的 enti 索引字段</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="keyword">range</span> ents &#123;</span><br><span class="line">		<span class="keyword">if</span> err := w.saveEntry(&amp;ents[i]); err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> err</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 4. 保存 HardState 字段，并保存，在 saveState 中，会构建 State 记录，但不会更新 enti 索引字段</span></span><br><span class="line">	<span class="keyword">if</span> err := w.saveState(&amp;st); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 5. 获取最后一个 LockedFile 的大小（已经使用的）</span></span><br><span class="line">	curOff, err := w.tail().Seek(<span class="number">0</span>, io.SeekCurrent)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 6. 若小于预分配空间大小 64MB，则直接返回即可</span></span><br><span class="line">	<span class="keyword">if</span> curOff &lt; SegmentSizeBytes &#123;</span><br><span class="line">		<span class="keyword">if</span> mustSync &#123; <span class="comment">// 若需同步刷盘操作，则要将已经 encode 的记录存盘</span></span><br><span class="line">			<span class="keyword">return</span> w.sync()</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 6. 若大于预分配空间，则需要另外创建一个文件</span></span><br><span class="line">	<span class="keyword">return</span> w.cut()</span><br><span class="line">&#125; <span class="comment">// wal.go</span></span><br></pre></td></tr></table></figure>

<p>其中涉及到的几个保存不同类型的记录的函数如下，比较简单：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">MustSync</span><span class="params">(st, prevst pb.HardState, entsnum <span class="keyword">int</span>)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">	<span class="comment">// Persistent state on all servers:</span></span><br><span class="line">	<span class="comment">// (Updated on stable storage before responding to RPCs)</span></span><br><span class="line">	<span class="comment">// currentTerm</span></span><br><span class="line">	<span class="comment">// votedFor</span></span><br><span class="line">	<span class="comment">// log entries[]</span></span><br><span class="line">	<span class="keyword">return</span> entsnum != <span class="number">0</span> || st.Vote != prevst.Vote || st.Term != prevst.Term</span><br><span class="line">&#125; <span class="comment">// node.go 由 raft 协议库核心提供</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *WAL)</span> <span class="title">saveEntry</span><span class="params">(e *raftpb.Entry)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="comment">// <span class="doctag">TODO:</span> add MustMarshalTo to reduce one allocation.</span></span><br><span class="line">	b := pbutil.MustMarshal(e)</span><br><span class="line">	<span class="comment">// 构建 entryType 类型的 Record，并对记录进行编码</span></span><br><span class="line">	rec := &amp;walpb.Record&#123;Type: entryType, Data: b&#125;</span><br><span class="line">	<span class="keyword">if</span> err := w.encoder.encode(rec); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 更新 WAL 日志项中最后一条日志的索引号</span></span><br><span class="line">	w.enti = e.Index</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// wal.go</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *WAL)</span> <span class="title">saveState</span><span class="params">(s *raftpb.HardState)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> raft.IsEmptyHardState(*s) &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">	w.state = *s</span><br><span class="line">	b := pbutil.MustMarshal(s)</span><br><span class="line">	rec := &amp;walpb.Record&#123;Type: stateType, Data: b&#125;</span><br><span class="line">	<span class="keyword">return</span> w.encoder.encode(rec)</span><br><span class="line">&#125; <span class="comment">// wal.go</span></span><br></pre></td></tr></table></figure>

<p>最后若当前的文件的预分配的空间不够，则需另外创建新的文件来进行保存日志项。<code>cut()</code>函数流程如下，它的流程同<code>Create()</code>函数非常类似：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// cut closes current file written and creates a new one ready to append.</span></span><br><span class="line"><span class="comment">// cut first creates a temp wal file and writes necessary headers into it.</span></span><br><span class="line"><span class="comment">// Then cut atomically rename temp wal file to a wal file.</span></span><br><span class="line"><span class="comment">// cut 函数实现了WAL文件切换的功能，即关闭当前WAL日志，创建新的WAL日志，继续用于日志追加。</span></span><br><span class="line"><span class="comment">// 每个 WAL 文件的预分配空间为 64MB，一旦超过该大小，便需要创建新的 WAL 文件</span></span><br><span class="line"><span class="comment">// 同样，cut 操作也会原子性的创建，能够创建临时文件来实现。</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *WAL)</span> <span class="title">cut</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="comment">// close old wal file; truncate to avoid wasting space if an early cut</span></span><br><span class="line">	<span class="comment">// 1. 关闭当前 WAL 文件，得到文件大小</span></span><br><span class="line">	off, serr := w.tail().Seek(<span class="number">0</span>, io.SeekCurrent)</span><br><span class="line">	<span class="keyword">if</span> serr != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> serr</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 2. 截断文件</span></span><br><span class="line">	<span class="keyword">if</span> err := w.tail().Truncate(off); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> err := w.sync(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 3. 构建新文件的路径（文件名），顺序递增 seq 及 enti</span></span><br><span class="line">	fpath := filepath.Join(w.dir, walName(w.seq()+<span class="number">1</span>, w.enti+<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">	<span class="comment">// create a temp wal file with name sequence + 1, or truncate the existing one</span></span><br><span class="line">	<span class="comment">// 4. 创建临时文件，其会使用先前 pipelinefile 预先分配的空间来执行此创建操作</span></span><br><span class="line">	newTail, err := w.fp.Open()</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// update writer and save the previous crc</span></span><br><span class="line">	<span class="comment">// 5. 同 Create 函数类似，将文件加入到 WAL 的 locks 数组集合</span></span><br><span class="line">	w.locks = <span class="built_in">append</span>(w.locks, newTail)</span><br><span class="line">	<span class="comment">// 6. 计算 crc 检验和，它是本文件之前的所有记录的检验和</span></span><br><span class="line">	prevCrc := w.encoder.crc.Sum32()</span><br><span class="line">	<span class="comment">// 7. 构建 WAL 实例的 encoder</span></span><br><span class="line">	w.encoder, err = newFileEncoder(w.tail().File, prevCrc)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 8. 先保存 检验和</span></span><br><span class="line">	<span class="keyword">if</span> err = w.saveCrc(prevCrc); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 9. 再保存 metadata</span></span><br><span class="line">	<span class="keyword">if</span> err = w.encoder.encode(&amp;walpb.Record&#123;Type: metadataType, Data: w.metadata&#125;); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 10. 接着保存 HardState</span></span><br><span class="line">	<span class="keyword">if</span> err = w.saveState(&amp;w.state); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// atomically move temp wal file to wal file</span></span><br><span class="line">	<span class="keyword">if</span> err = w.sync(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	off, err = w.tail().Seek(<span class="number">0</span>, io.SeekCurrent)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 11. 重命名</span></span><br><span class="line">	<span class="keyword">if</span> err = os.Rename(newTail.Name(), fpath); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> err = fileutil.Fsync(w.dirFile); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// reopen newTail with its new path so calls to Name() match the wal filename format</span></span><br><span class="line">	newTail.Close()</span><br><span class="line"></span><br><span class="line">	<span class="comment">//  12. 重新打开并上锁新的文件（重命名之后的）</span></span><br><span class="line">	<span class="keyword">if</span> newTail, err = fileutil.LockFile(fpath, os.O_WRONLY, fileutil.PrivateFileMode); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> _, err = newTail.Seek(off, io.SeekStart); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 13. 将新的文件加入数组</span></span><br><span class="line">	w.locks[<span class="built_in">len</span>(w.locks)<span class="number">-1</span>] = newTail</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 14. 重新计算检验和 以及 encoder</span></span><br><span class="line">	prevCrc = w.encoder.crc.Sum32()</span><br><span class="line">	w.encoder, err = newFileEncoder(w.tail().File, prevCrc)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// wal.go</span></span><br></pre></td></tr></table></figure>

<p>至此关于<code>WAL</code>库的日志管理相关的接口已经分析完毕。简单总结一下，本文是从【<a href="https://qqzeng.top/2019/01/09/etcd-raftexample-%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/" target="_blank" rel="noopener">etcd raftexample 源码简析</a>】中对<code>WAL</code>库接口的调用切入（日志重放的操作），然后简要分析了<code>WAL</code>日志文件创建、<code>WAL</code>初始化（打开）、<code>WAL</code>日志项读取及<code>WAL</code>追加日志项等流程。最后，关于<code>WAL</code>库与如何与<code>raft</code>核心协议交互的内容，后面再了解。</p>
<p>参考文献</p>
<p>[1]. <a href="https://zhuanlan.zhihu.com/p/29692778" target="_blank" rel="noopener">etcd-raft日志管理</a><br>[2]. <a href="https://github.com/etcd-io/etcd/tree/master/wal" target="_blank" rel="noopener">https://github.com/etcd-io/etcd/tree/master/wal</a></p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>分布式协调服务</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>WAL 日志</tag>
      </tags>
  </entry>
  <entry>
    <title>etcd-raft 网络传输源码简析</title>
    <url>/2019/01/10/etcd-raft-%E7%BD%91%E7%BB%9C%E4%BC%A0%E8%BE%93%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/</url>
    <content><![CDATA[<p>上一篇文章简单分析了<code>etcd raftexample</code>的源码。我们知道，<code>etcd raft</code>只实现了<code>raft</code>协议核心部分，而将诸如日志、快照及消息的网络传输交给应用来管理。本文会简单分析<code>raft</code>集群用来实现消息在节点之间传输部分的相关逻辑。因为<code>etcd raft</code>会在节点之间传递各种消息指令，包括日志复制、快照拷贝等，这都需要通过应用来将对应的消息转发到集群中其它节点。简单而言，<code>raft</code>实现的节点之间的网络传输将消息的读写进行分离，即每两个节点之间存在两条消息通道，分别用作消息的接收与发送，另外针对不同类型的消息的收发，其也提供了不同的组件。本文会对大致的消息传输的流程进行介绍。</p>
<a id="more"></a>

<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>同上一篇博文类似，希望读者能够主动查看源码（主要涉及目录<code>/etcd/etcdserver/api/rafthttp</code>），文章只作参考。我们先来观察一下与网络传输相关的重要的数据结构，一般而言，只要理解了核心的数据结构的功能，基本就能推断相关的功能与大致的流程。网络传输最核心的结构为<code>Transporter</code>：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Transporter <span class="keyword">interface</span> &#123;</span><br><span class="line">	<span class="comment">// Start starts the given Transporter.</span></span><br><span class="line">	<span class="comment">// Start MUST be called before calling other functions in the interface.</span></span><br><span class="line">    <span class="comment">// 在处理具体的消息收发之前，需要启动网络传输组件。它在应用初始化（如初始化 raftNode）时启动</span></span><br><span class="line">    <span class="comment">// 网络传输组件</span></span><br><span class="line">	Start() error</span><br><span class="line">	<span class="comment">// Handler returns the HTTP handler of the transporter.</span></span><br><span class="line">	<span class="comment">// A transporter HTTP handler handles the HTTP requests</span></span><br><span class="line">	<span class="comment">// from remote peers.</span></span><br><span class="line">	<span class="comment">// The handler MUST be used to handle RaftPrefix(/raft)</span></span><br><span class="line">	<span class="comment">// endpoint.</span></span><br><span class="line">    <span class="comment">// 消息传输组件的消息处理器，它对不同消息配置不同的消息处理器（如pipelineHandler、streamHandler）。</span></span><br><span class="line">	Handler() http.Handler</span><br><span class="line">	<span class="comment">// Send sends out the given messages to the remote peers.</span></span><br><span class="line">	<span class="comment">// Each message has a To field, which is an id that maps</span></span><br><span class="line">	<span class="comment">// to an existing peer in the transport.</span></span><br><span class="line">	<span class="comment">// If the id cannot be found in the transport, the message</span></span><br><span class="line">	<span class="comment">// will be ignored.</span></span><br><span class="line">    <span class="comment">// 消息发送接口，即将消息发送到指定 id 的节点</span></span><br><span class="line">	Send(m []raftpb.Message)</span><br><span class="line">	<span class="comment">// SendSnapshot sends out the given snapshot message to a remote peer.</span></span><br><span class="line">	<span class="comment">// The behavior of SendSnapshot is similar to Send.</span></span><br><span class="line">    <span class="comment">// 快照数据发送接口</span></span><br><span class="line">	SendSnapshot(m snap.Message)</span><br><span class="line">    <span class="comment">// 后面都是关于节点的管理的方法，不作重点阐述</span></span><br><span class="line">	<span class="comment">// AddRemote adds a remote with given peer urls into the transport.</span></span><br><span class="line">	<span class="comment">// A remote helps newly joined member to catch up the progress of cluster,</span></span><br><span class="line">	<span class="comment">// and will not be used after that.</span></span><br><span class="line">	<span class="comment">// It is the caller's responsibility to ensure the urls are all valid,</span></span><br><span class="line">	<span class="comment">// or it panics.</span></span><br><span class="line">	AddRemote(id types.ID, urls []<span class="keyword">string</span>)</span><br><span class="line">	<span class="comment">// AddPeer adds a peer with given peer urls into the transport.</span></span><br><span class="line">	<span class="comment">// It is the caller's responsibility to ensure the urls are all valid,</span></span><br><span class="line">	<span class="comment">// or it panics.</span></span><br><span class="line">	<span class="comment">// Peer urls are used to connect to the remote peer.</span></span><br><span class="line">	AddPeer(id types.ID, urls []<span class="keyword">string</span>)</span><br><span class="line">	<span class="comment">// RemovePeer removes the peer with given id.</span></span><br><span class="line">	RemovePeer(id types.ID)</span><br><span class="line">	<span class="comment">// RemoveAllPeers removes all the existing peers in the transport.</span></span><br><span class="line">	RemoveAllPeers()</span><br><span class="line">	<span class="comment">// UpdatePeer updates the peer urls of the peer with the given id.</span></span><br><span class="line">	<span class="comment">// It is the caller's responsibility to ensure the urls are all valid,</span></span><br><span class="line">	<span class="comment">// or it panics.</span></span><br><span class="line">	UpdatePeer(id types.ID, urls []<span class="keyword">string</span>)</span><br><span class="line">	<span class="comment">// ActiveSince returns the time that the connection with the peer</span></span><br><span class="line">	<span class="comment">// of the given id becomes active.</span></span><br><span class="line">	<span class="comment">// If the connection is active since peer was added, it returns the adding time.</span></span><br><span class="line">	<span class="comment">// If the connection is currently inactive, it returns zero time.</span></span><br><span class="line">	ActiveSince(id types.ID) time.Time</span><br><span class="line">	<span class="comment">// ActivePeers returns the number of active peers.</span></span><br><span class="line">	ActivePeers() <span class="keyword">int</span></span><br><span class="line">	<span class="comment">// Stop closes the connections and stops the transporter.</span></span><br><span class="line">	Stop()</span><br><span class="line">&#125; <span class="comment">// transport.go</span></span><br></pre></td></tr></table></figure>

<p>需要补充一点的是，在上面的函数声明中，我们可以推测，节点采用<code>peer</code>的实例来进行消息的收发，由<code>transport</code>只是对外提供统一的接口，并提供逻辑框架。那<code>remote</code>又作何用？查看源码注释可以知道，<code>remote</code>是帮助新加入到集群的节点”追赶”当前集群正常节点的组件，除那之后，它没有其它作用。而相比之下，<code>peer</code>则代表<code>raft</code>节点与其它节点通信的实体。后面会详细阐述<code>peer</code>组件。下面来了解下<code>Trasnporter</code>的具体实现<code>Transport</code>结构：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Transport 实现了 Transporter 接口，用户使用其提供的接口实现完成消息收发</span></span><br><span class="line"><span class="keyword">type</span> Transport <span class="keyword">struct</span> &#123;</span><br><span class="line">	Logger *zap.Logger</span><br><span class="line"></span><br><span class="line">	DialTimeout time.Duration <span class="comment">// maximum duration before timing out dial of the request</span></span><br><span class="line">	<span class="comment">// DialRetryFrequency defines the frequency of streamReader dial retrial attempts;</span></span><br><span class="line">	<span class="comment">// a distinct rate limiter is created per every peer (default value: 10 events/sec)</span></span><br><span class="line">	DialRetryFrequency rate.Limit</span><br><span class="line"></span><br><span class="line">	TLSInfo transport.TLSInfo <span class="comment">// TLS information used when creating connection</span></span><br><span class="line"></span><br><span class="line">	ID          types.ID   <span class="comment">// local member ID</span></span><br><span class="line">	URLs        types.URLs <span class="comment">// local peer URLs</span></span><br><span class="line">	ClusterID   types.ID   <span class="comment">// raft cluster ID for request validation</span></span><br><span class="line">	Raft        Raft       <span class="comment">// raft state machine, to which the Transport forwards received messages and reports status</span></span><br><span class="line">	Snapshotter *snap.Snapshotter</span><br><span class="line">	ServerStats *stats.ServerStats <span class="comment">// used to record general transportation statistics</span></span><br><span class="line">	<span class="comment">// used to record transportation statistics with followers when</span></span><br><span class="line">	<span class="comment">// performing as leader in raft protocol</span></span><br><span class="line">	LeaderStats *stats.LeaderStats  <span class="comment">// leader 节点用于记录传输消息到 follower 的相关数据统计</span></span><br><span class="line">	ErrorC <span class="keyword">chan</span> error</span><br><span class="line"></span><br><span class="line">	streamRt   http.RoundTripper <span class="comment">// roundTripper used by streams</span></span><br><span class="line">	pipelineRt http.RoundTripper <span class="comment">// roundTripper used by pipelines</span></span><br><span class="line"></span><br><span class="line">	mu      sync.RWMutex         <span class="comment">// protect the remote and peer map</span></span><br><span class="line">	remotes <span class="keyword">map</span>[types.ID]*remote <span class="comment">// remotes map that helps newly joined member to catch up</span></span><br><span class="line">	peers   <span class="keyword">map</span>[types.ID]Peer    <span class="comment">// peers map</span></span><br><span class="line"></span><br><span class="line">	pipelineProber probing.Prober</span><br><span class="line">	streamProber   probing.Prober</span><br><span class="line">&#125; <span class="comment">// transport.go</span></span><br></pre></td></tr></table></figure>

<p>可以发现，<code>Transport</code>里面包含了一个对<code>Raft</code>状态机接口，容易想到，因为，当网络传输组件接收到涎宾，需要对消息进行处理，具体即需要交给<code>Raft</code>来处理，因此它提供这样一个接口。应用可以实现此接口以实现对接收到的消息进行处理。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Raft <span class="keyword">interface</span> &#123;</span><br><span class="line">    <span class="comment">// 消息处理接口，raftNode 实现了此函数，并调用底层的 raft 协议库 node 的 Step 函数来处理消息</span></span><br><span class="line">	Process(ctx context.Context, m raftpb.Message) error </span><br><span class="line">	IsIDRemoved(id <span class="keyword">uint64</span>) <span class="keyword">bool</span></span><br><span class="line">	ReportUnreachable(id <span class="keyword">uint64</span>)</span><br><span class="line">	ReportSnapshot(id <span class="keyword">uint64</span>, status raft.SnapshotStatus)</span><br><span class="line">&#125; <span class="comment">// transport.go</span></span><br></pre></td></tr></table></figure>

<p>下面重点来查看一下<code>peer</code>数据结构（暂且忽略<code>remote</code>）。<code>Peer</code>接口定义如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Peer <span class="keyword">interface</span> &#123;</span><br><span class="line">	<span class="comment">// send sends the message to the remote peer. The function is non-blocking</span></span><br><span class="line">	<span class="comment">// and has no promise that the message will be received by the remote.</span></span><br><span class="line">	<span class="comment">// When it fails to send message out, it will report the status to underlying</span></span><br><span class="line">	<span class="comment">// raft.</span></span><br><span class="line">    <span class="comment">// 发送消息的接口，注意此接口是 non-blocking 的，但它不承诺可靠消息传输，但会报告出错信息</span></span><br><span class="line">	send(m raftpb.Message)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// sendSnap sends the merged snapshot message to the remote peer. Its behavior</span></span><br><span class="line">	<span class="comment">// is similar to send.</span></span><br><span class="line">    <span class="comment">// 传输快照数据</span></span><br><span class="line">	sendSnap(m snap.Message)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// update updates the urls of remote peer.</span></span><br><span class="line">	update(urls types.URLs)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// attachOutgoingConn attaches the outgoing connection to the peer for</span></span><br><span class="line">	<span class="comment">// stream usage. After the call, the ownership of the outgoing</span></span><br><span class="line">	<span class="comment">// connection hands over to the peer. The peer will close the connection</span></span><br><span class="line">	<span class="comment">// when it is no longer used.</span></span><br><span class="line">    <span class="comment">// 一旦接收到对端的连接，会把连接 attach 到节点 encoder 的 writer 中，以协同 encoder 和对端decoder的工作了</span></span><br><span class="line">	attachOutgoingConn(conn *outgoingConn)</span><br><span class="line">	activeSince() time.Time</span><br><span class="line">	stop()</span><br><span class="line">&#125; <span class="comment">// peer.go</span></span><br></pre></td></tr></table></figure>

<p>紧接着，我们了解下<code>Peer</code>接口的实现<code>peer</code>：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> peer <span class="keyword">struct</span> &#123;</span><br><span class="line">	lg *zap.Logger</span><br><span class="line"></span><br><span class="line">	localID types.ID</span><br><span class="line">	<span class="comment">// id of the remote raft peer node</span></span><br><span class="line">	id types.ID</span><br><span class="line"></span><br><span class="line">	r Raft</span><br><span class="line"></span><br><span class="line">	status *peerStatus</span><br><span class="line"></span><br><span class="line">	picker *urlPicker</span><br><span class="line"></span><br><span class="line">	msgAppV2Writer *streamWriter</span><br><span class="line">	writer         *streamWriter</span><br><span class="line">	pipeline       *pipeline</span><br><span class="line">	snapSender     *snapshotSender <span class="comment">// snapshot sender to send v3 snapshot messages</span></span><br><span class="line">	msgAppV2Reader *streamReader</span><br><span class="line">	msgAppReader   *streamReader</span><br><span class="line"></span><br><span class="line">	recvc <span class="keyword">chan</span> raftpb.Message</span><br><span class="line">	propc <span class="keyword">chan</span> raftpb.Message</span><br><span class="line"></span><br><span class="line">	mu     sync.Mutex</span><br><span class="line">	paused <span class="keyword">bool</span></span><br><span class="line"></span><br><span class="line">	cancel context.CancelFunc <span class="comment">// cancel pending works in go routine created by peer.</span></span><br><span class="line">	stopc  <span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line">&#125; <span class="comment">// peer.go</span></span><br></pre></td></tr></table></figure>

<p>首先，需要说明的是，<code>peer</code>包含两种机制来发送消息：<code>stream</code>及<code>pipeline</code>。其中<code>stream</code>被初始化为一个长轮询的连接，在消息传输过程中保持打开的状态。另外，<code>peer</code>也提供一种优化后的<code>stream</code>以用来发送<code>msgApp</code>类型的消息，这种消息由<code>leader</code>向<code>follower</code>节点发送，其占据一大部分的消息内容。而对比之下，<code>pipeline</code>则是为<code>http</code>请求提供的<code>http</code>客户端。它只在<code>stream</code>还没有被建立的时候使用。另外，从<code>peer</code>结构中发现还有一个专门用于发送<code>snap</code>的发送器。换言之，针对不同的类型的消息采用不同的传输方式应该可以提高效率。</p>
<h2 id="关键流程"><a href="#关键流程" class="headerlink" title="关键流程"></a>关键流程</h2><p>下面从组件启动开始监听、消息发送及消息接收三个方面来阐述相关的逻辑，这三个方面可能会相互穿插，但如果读者跟着代码来解读，相信也较容易理解。</p>
<h3 id="启动监听"><a href="#启动监听" class="headerlink" title="启动监听"></a>启动监听</h3><p>下面会从<code>raftNode</code>(<code>raft.go</code>)中初始化代码开始索引(<code>startRaft()</code>)，它使用<code>rc.transport.Start()</code>启动网络传输组件，并通过<code>t.peers[id] = startPeer(t, urls, id, fs)</code>启动各节点上的网络传输实体。在<code>startPeer</code>函数中，分别创建启动了<code>pipeline</code>以及<code>stream</code>，并提供了两个管道，一个作为消息的缓冲区，但因为消息会被阻塞处理（调用了<code>Process()</code>），可能花费较长时间，因此额外提供了一个<code>pending</code>的管理用于接收消息。</p>
<p>另外，我们接紧着先来查看一下，<code>stream</code>监听消息的逻辑（<code>pipeline</code>监听的逻辑更为简单，但流程类似，初始化，然后设置监听）。注意到在<code>startPeer</code>函数中有两行代码（针对不同的版本同时启动了相关的逻辑处理），启用了<code>stream</code>监听(<code>p.msgAppV2Reader.start()</code>)，在<code>start()</code>方法中，开启了一个 <code>go routine</code>，它这个协程中(<code>run()</code>方法)，它会先与对端建立连接，通过<code>dial()</code>来实现，然后调用<code>decodeLoope()</code>函数来循环读取远程的节点发来的消息，并调用<code>decode()</code>函数进行消息解码处理。</p>
<h3 id="消息发送"><a href="#消息发送" class="headerlink" title="消息发送"></a>消息发送</h3><p>下面梳理一下消息的发送的流程，即在<code>raft.serveChannels()</code>函数中，当<code>raft</code>应用层收到底层<code>raft</code>的消息指令时，需要把消息指令转发给其它<code>peer</code>（<code>rc.transport.Send(rd.Messages)</code>）。在<code>Send()</code>方法中，其大致逻辑为取出对端地址，然后对消息进行发送。在<code>peer.send()</code>函数中，它将消息发送到指定的<code>writerc</code>中，<code>writerc</code>是<code>pipeline</code>的一个结构<code>p.pipeline.msgc</code>，它在<code>pipeline.start()</code>中被初始化，并且在<code>handler()</code>方法中持续监听此通道的消息，一旦管道中有消息，则取出消息，并使用<code>post()</code>函数发送。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *peer)</span> <span class="title">send</span><span class="params">(m raftpb.Message)</span></span> &#123;</span><br><span class="line">	p.mu.Lock()</span><br><span class="line">	paused := p.paused</span><br><span class="line">	p.mu.Unlock()</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> paused &#123;</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 1. 根据消息的类型选择具体的传输方式</span></span><br><span class="line">	writec, name := p.pick(m)</span><br><span class="line">	<span class="keyword">select</span> &#123;</span><br><span class="line">    <span class="comment">// 2. 将消息放到管道中</span></span><br><span class="line">	<span class="keyword">case</span> writec &lt;- m:</span><br><span class="line">	<span class="keyword">default</span>:</span><br><span class="line">		p.r.ReportUnreachable(m.To)</span><br><span class="line">		<span class="keyword">if</span> isMsgSnap(m) &#123;</span><br><span class="line">			p.r.ReportSnapshot(m.To, raft.SnapshotFailure)</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="comment">// peer.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// pick picks a chan for sending the given message. The picked chan and the picked chan</span></span><br><span class="line"><span class="comment">// string name are returned.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *peer)</span> <span class="title">pick</span><span class="params">(m raftpb.Message)</span> <span class="params">(writec <span class="keyword">chan</span>&lt;- raftpb.Message, picked <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> ok <span class="keyword">bool</span></span><br><span class="line">	<span class="comment">// Considering MsgSnap may have a big size, e.g., 1G, and will block</span></span><br><span class="line">	<span class="comment">// stream for a long time, only use one of the N pipelines to send MsgSnap.</span></span><br><span class="line">	<span class="keyword">if</span> isMsgSnap(m) &#123;</span><br><span class="line">		<span class="keyword">return</span> p.pipeline.msgc, pipelineMsg</span><br><span class="line">	&#125; <span class="keyword">else</span> <span class="keyword">if</span> writec, ok = p.msgAppV2Writer.writec(); ok &amp;&amp; isMsgApp(m) &#123;</span><br><span class="line">		<span class="keyword">return</span> writec, streamAppV2</span><br><span class="line">	&#125; <span class="keyword">else</span> <span class="keyword">if</span> writec, ok = p.writer.writec(); ok &#123;</span><br><span class="line">		<span class="keyword">return</span> writec, streamMsg</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> p.pipeline.msgc, pipelineMsg</span><br><span class="line">&#125; <span class="comment">// peer.go</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *pipeline)</span> <span class="title">start</span><span class="params">()</span></span> &#123;</span><br><span class="line">    p.stopc = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;)</span><br><span class="line">    p.msgc = <span class="built_in">make</span>(<span class="keyword">chan</span> raftpb.Message, pipelineBufSize)</span><br><span class="line">    p.wg.Add(connPerPipeline)</span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; connPerPipeline; i++ &#123;</span><br><span class="line">        <span class="keyword">go</span> p.handle()</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125; <span class="comment">// pipeline.go</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *pipeline)</span> <span class="title">handle</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">defer</span> p.wg.Done()</span><br><span class="line">    <span class="keyword">for</span> &#123;</span><br><span class="line">        <span class="keyword">select</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> m := &lt;-p.msgc:</span><br><span class="line">            start := time.Now()</span><br><span class="line">            err := p.post(pbutil.MustMarshal(&amp;m)) <span class="comment">// 发送消息</span></span><br><span class="line">            end := time.Now()</span><br><span class="line">            <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">                <span class="comment">// ...</span></span><br><span class="line">            &#125;</span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="comment">// pipeline.go</span></span><br></pre></td></tr></table></figure>

<p>因此，整个消息发送的流程还是比较简单且清晰的。</p>
<h3 id="消息接收"><a href="#消息接收" class="headerlink" title="消息接收"></a>消息接收</h3><p>还记得在<code>raftNode</code>初始化的过程中，有一行这样的代码<code>go rc.serveRaft()</code>，没错，它是用于启动节点网络传输监听。它将监听的处理程序设置为<code>transport.Handler()</code>，相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rc *raftNode)</span> <span class="title">serveRaft</span><span class="params">()</span></span> &#123;</span><br><span class="line">	url, err := url.Parse(rc.peers[rc.id<span class="number">-1</span>])</span><br><span class="line">	ln, err := newStoppableListener(url.Host, rc.httpstopc)</span><br><span class="line">	err = (&amp;http.Server&#123;Handler: rc.transport.Handler()&#125;).Serve(ln) <span class="comment">// 开启监听，设置处理器</span></span><br><span class="line">	<span class="keyword">select</span> &#123;</span><br><span class="line">	<span class="keyword">case</span> &lt;-rc.httpstopc:</span><br><span class="line">	<span class="keyword">default</span>:</span><br><span class="line">		log.Fatalf(<span class="string">"raftexample: Failed to serve rafthttp (%v)"</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">close</span>(rc.httpdonec)</span><br><span class="line">&#125; <span class="comment">// raft.go</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 为不同的消息类型设置了不同类型的处理器程序</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *Transport)</span> <span class="title">Handler</span><span class="params">()</span> <span class="title">http</span>.<span class="title">Handler</span></span> &#123;</span><br><span class="line">	pipelineHandler := newPipelineHandler(t, t.Raft, t.ClusterID)</span><br><span class="line">	streamHandler := newStreamHandler(t, t, t.Raft, t.ID, t.ClusterID)</span><br><span class="line">	snapHandler := newSnapshotHandler(t, t.Raft, t.Snapshotter, t.ClusterID)</span><br><span class="line">	mux := http.NewServeMux()</span><br><span class="line">	mux.Handle(RaftPrefix, pipelineHandler)</span><br><span class="line">	mux.Handle(RaftStreamPrefix+<span class="string">"/"</span>, streamHandler)</span><br><span class="line">	mux.Handle(RaftSnapshotPrefix, snapHandler)</span><br><span class="line">	mux.Handle(ProbingPrefix, probing.NewHandler())</span><br><span class="line">	<span class="keyword">return</span> mux</span><br><span class="line">&#125; <span class="comment">// transport.go</span></span><br></pre></td></tr></table></figure>

<p>我们具体到其中一个处理器进行查看，比如<code>pipelineHandler</code>，其相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h *pipelineHandler)</span> <span class="title">ServeHTTP</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">    <span class="comment">// 1. 请求数据检查</span></span><br><span class="line">	<span class="keyword">if</span> r.Method != <span class="string">"POST"</span> &#123;</span><br><span class="line">		w.Header().Set(<span class="string">"Allow"</span>, <span class="string">"POST"</span>)</span><br><span class="line">		http.Error(w, <span class="string">"Method Not Allowed"</span>, http.StatusMethodNotAllowed)</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	w.Header().Set(<span class="string">"X-Etcd-Cluster-ID"</span>, h.cid.String())</span><br><span class="line">	limitedr := pioutil.NewLimitedBufferReader(r.Body, connReadLimitByte)</span><br><span class="line">	b, err := ioutil.ReadAll(limitedr)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	&#125;</span><br><span class="line">    <span class="comment">// 2. 消息解码</span></span><br><span class="line">	<span class="keyword">var</span> m raftpb.Message</span><br><span class="line">	<span class="keyword">if</span> err := m.Unmarshal(b); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">	&#125;</span><br><span class="line">	receivedBytes.WithLabelValues(types.ID(m.From).String()).Add(<span class="keyword">float64</span>(<span class="built_in">len</span>(b)))</span><br><span class="line">	<span class="comment">// 3. 调用 Raft 的 Process 函数进行消息处理</span></span><br><span class="line">	<span class="keyword">if</span> err := h.r.Process(context.TODO(), m); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">switch</span> v := err.(<span class="keyword">type</span>) &#123;</span><br><span class="line">		<span class="keyword">case</span> writerToResponse:</span><br><span class="line">			v.WriteTo(w)</span><br><span class="line">		<span class="keyword">default</span>:</span><br><span class="line">		<span class="comment">// ...</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="comment">// http.go</span></span><br></pre></td></tr></table></figure>

<p>同样，整个消息的接收的流程也较为简单，针对不同类型的消息采用不同的接收及发送处理器，并将接收到的消息直接交给由应用定义的消息处理接口。至此，整个关于<code>etcd-raft</code>的网络传输相关逻辑的大致流程已经梳理完毕，介绍得比较浅显，只大概梳理了整个流程，如果读者想要深入了解，可以具体到每一个环节的代码深入分析。</p>
<p>参考文献</p>
<p>[1]. <a href="https://zhuanlan.zhihu.com/p/29207055" target="_blank" rel="noopener">etcd-raft网络传输组件实现分析</a><br>[2]. <a href="https://github.com/etcd-io/etcd/blob/master/etcdserver/api/rafthttp" target="_blank" rel="noopener">https://github.com/etcd-io/etcd/blob/master/etcdserver/api/rafthttp</a></p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>分布式协调服务</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>网络传输</tag>
      </tags>
  </entry>
  <entry>
    <title>etcd raftexample 源码简析</title>
    <url>/2019/01/09/etcd-raftexample-%E6%BA%90%E7%A0%81%E7%AE%80%E6%9E%90/</url>
    <content><![CDATA[<p>最近集中了解了<code>ZAB</code>、<code>Raft</code>及<code>Paxos</code>协议的基本理论，因此想进一步深入到源代码仔细体验一致性协议如何在分布式系统中发挥作用。虽然在 MIT 6.824 课程中有简单实现<code>Raft</code>协议，并基于<code>Raft</code>构建了一个粗糙的 kv 存储系统。但还是想了解下工业生产级别的<code>Raft</code>协议的实现内幕，故选择<code>etcd</code>进行解读。<code>etcd</code>是 CoreOS 基于<code>Raft</code>协议使用 go 开发的分布式 kv 存储系统，可用于服务发现、共享配置及其它利用一致性保障的功能（如<code>leader</code>选举及分布式锁、队列等）。这些功能<code>ZooKeeper</code>不也有提供？没错。它们都可以作为其它分布式应用的独立协调服务，这通过通用的一致性元信息存储来实现。但在易用性上，<code>etcd</code>可谓略胜一筹。因此，后续的一系列博客会简单对<code>etcd</code>各重要组成部分的源码进行简要分析（重点在<code>Raft</code>实现）。本文主要是分析<code>etcd</code>的<code>raftexample</code>的代码。它是<code>etcd</code>官方提供的如何使用<code>etcd</code>内部的<code>Raft</code>协议组件来构建分布式应用的一个简单示例。</p>
<a id="more"></a>

<p>（阐述<code>etcd-raft</code>的系列文章对应的<code>etcd-raft</code>的版本为 3.3.11，但遗憾实际上看的<code>master unstable</code>版本）<code>etcd</code>内部使用<code>Raft</code>协议对集群各节点的状态（数据、日志及快照等）进行同步。类似于<code>ZooKeeper</code>利用<code>ZAB</code>协议作为底层的可靠的事务广播协议。但<code>etcd</code>对<code>Raft</code>的实现有点特殊，它底层的<code>Raft</code>组件库只实现了<code>Raft</code>协议最核心的部分，这主要包括选主逻辑、一致性具体实现以及成员关系变化。而将诸如<code>WAL</code>、<code>snapshot</code>以及网络传输等模块让用户来实现，这明显增加了使用的难度，但对于应用本质上也更灵活。</p>
<p>本文会简单分析<code>etcd</code>提供的如何其核心的<code>Raft</code>协议组件来构建一个简单的高可用内存 kv 存储（其本质是一个状态机），用户可以通过 http 协议来访问应用（kv 存储系统），以对数据进行读写操作，在对日志进行读写过程中，<code>Raft</code>组件库能够保证各节点数据的一致性。其对应的源码目录为<code>/etcd-io/etcd/tree/master/contrib/raftexample</code>。另外，需要强调的是，本文的主题是利用<code>Raft</code>协议库来构建一个简单的 kv 存储，关于<code>Raft</code>协议库实现的细节不会过多阐述。若读者想继续了解此文，个人建议<code>clone</code>源代码，在阅读源代码的过程中，参考本文效果可能会更好，如果有理解错误的地方，欢迎指正！</p>
<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>在按<code>raftexample/main</code>的示例完整解读整个流程之前，先熟悉几个重要的数据结构会有好处。此示例构建的应用为 kv 存储系统，因此，先来了解 <code>kvstore</code>定义的相关字段：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// a key-value store backed by raft</span></span><br><span class="line"><span class="keyword">type</span> kvstore <span class="keyword">struct</span> &#123;</span><br><span class="line">	proposeC    <span class="keyword">chan</span>&lt;- <span class="keyword">string</span> <span class="comment">// channel for proposing updates</span></span><br><span class="line">	mu          sync.RWMutex</span><br><span class="line">	kvStore     <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span> <span class="comment">// current committed key-value pairs</span></span><br><span class="line">	snapshotter *snap.Snapshotter</span><br><span class="line">&#125; <span class="comment">// kvstore.go</span></span><br></pre></td></tr></table></figure>

<p>关键结构成员解释如下：</p>
<ul>
<li><code>proposeC</code>: 应用与底层<code>Raft</code>核心库之间的通信<code>channel</code>，当用户向应用通过 http 发送更新请求时，应用会将此请求通过<code>channel</code>传递给底层的<code>Raft</code>库。</li>
<li><code>kvStore</code>:  kv 结构的内存存储，即对应应用的状态机。</li>
<li><code>snapshotter</code>: 由应用管理的快照<code>snapshot</code>接口。</li>
</ul>
<p>接下来分析一下应用封装底层<code>Raft</code>核心库的结构<code>raftNode</code>，应用通过与<code>raftNode</code>结构进行交互来使用底层的<code>Raft</code>核心协议，它封装完整的<code>Raft</code>协议相关的逻辑（如<code>WAL</code>及<code>snapshot</code>等）。我们先列举它的相关处理逻辑，然后展示其结构内容。具体地逻辑如下：</p>
<ul>
<li>将应用的更新请求传递给<code>Raft</code>核心来执行。</li>
<li>同时，将<code>Raft</code>协议已提交的日志传回给应用，以指示应用来将日志请求应用到状态机。</li>
<li>另外，它也处理由<code>Raft</code>协议相关的指令，包括选举、成员变化等。</li>
<li>处理<code>WAL</code>日志相关逻辑。</li>
<li>处理快照相关的逻辑。</li>
<li>将底层<code>Raft</code>协议的指令消息传输到集群其它节点。</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// A key-value stream backed by raft</span></span><br><span class="line"><span class="keyword">type</span> raftNode <span class="keyword">struct</span> &#123;</span><br><span class="line">	proposeC    &lt;-<span class="keyword">chan</span> <span class="keyword">string</span>            <span class="comment">// proposed messages (k,v)</span></span><br><span class="line">	confChangeC &lt;-<span class="keyword">chan</span> raftpb.ConfChange <span class="comment">// proposed cluster config changes</span></span><br><span class="line">	commitC     <span class="keyword">chan</span>&lt;- *<span class="keyword">string</span>           <span class="comment">// entries committed to log (k,v)</span></span><br><span class="line">	errorC      <span class="keyword">chan</span>&lt;- error             <span class="comment">// errors from raft session</span></span><br><span class="line"></span><br><span class="line">	id          <span class="keyword">int</span>      <span class="comment">// client ID for raft session</span></span><br><span class="line">	peers       []<span class="keyword">string</span> <span class="comment">// raft peer URLs</span></span><br><span class="line">	join        <span class="keyword">bool</span>     <span class="comment">// node is joining an existing cluster</span></span><br><span class="line">	waldir      <span class="keyword">string</span>   <span class="comment">// path to WAL directory</span></span><br><span class="line">	snapdir     <span class="keyword">string</span>   <span class="comment">// path to snapshot directory</span></span><br><span class="line">	getSnapshot <span class="function"><span class="keyword">func</span><span class="params">()</span> <span class="params">([]<span class="keyword">byte</span>, error)</span></span></span><br><span class="line"><span class="function">	<span class="title">lastIndex</span>   <span class="title">uint64</span> // <span class="title">index</span> <span class="title">of</span> <span class="title">log</span> <span class="title">at</span> <span class="title">start</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">	<span class="title">confState</span>     <span class="title">raftpb</span>.<span class="title">ConfState</span></span></span><br><span class="line"><span class="function">	<span class="title">snapshotIndex</span> <span class="title">uint64</span></span></span><br><span class="line"><span class="function">	<span class="title">appliedIndex</span>  <span class="title">uint64</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">	// <span class="title">raft</span> <span class="title">backing</span> <span class="title">for</span> <span class="title">the</span> <span class="title">commit</span>/<span class="title">error</span> <span class="title">channel</span></span></span><br><span class="line"><span class="function">	<span class="title">node</span>        <span class="title">raft</span>.<span class="title">Node</span></span></span><br><span class="line"><span class="function">	<span class="title">raftStorage</span> *<span class="title">raft</span>.<span class="title">MemoryStorage</span></span></span><br><span class="line"><span class="function">	<span class="title">wal</span>         *<span class="title">wal</span>.<span class="title">WAL</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">	<span class="title">snapshotter</span>      *<span class="title">snap</span>.<span class="title">Snapshotter</span></span></span><br><span class="line"><span class="function">	<span class="title">snapshotterReady</span> <span class="title">chan</span> *<span class="title">snap</span>.<span class="title">Snapshotter</span> // <span class="title">signals</span> <span class="title">when</span> <span class="title">snapshotter</span> <span class="title">is</span> <span class="title">ready</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">	<span class="title">snapCount</span> <span class="title">uint64</span></span></span><br><span class="line"><span class="function">	<span class="title">transport</span> *<span class="title">rafthttp</span>.<span class="title">Transport</span></span></span><br><span class="line"><span class="function">	<span class="title">stopc</span>     <span class="title">chan</span> <span class="title">struct</span></span>&#123;&#125; <span class="comment">// signals proposal channel closed</span></span><br><span class="line">	httpstopc <span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125; <span class="comment">// signals http server to shutdown</span></span><br><span class="line">	httpdonec <span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125; <span class="comment">// signals http server shutdown complete</span></span><br><span class="line">&#125; <span class="comment">// raft.go</span></span><br></pre></td></tr></table></figure>

<p>关键结构成员解释如下：</p>
<ul>
<li><code>proposeC</code>: 同<code>kvStore.proposeC</code>通道类似，事实上，<code>kvStore</code>会将用户的更新请求传递给<code>raftNode</code>以使得其最终能传递给底层的<code>Raft</code>协议库。</li>
<li><code>confChangeC</code>: <code>Raft</code>协议通过此<code>channel</code>来传递集群配置变更的请求给应用。</li>
<li><code>commitC</code>: 底层<code>Raft</code>协议通过此<code>channel</code>可以向应用传递准备提交或应用的<code>channel</code>，最终<code>kvStore</code>会反复从此通道中读取可以提交的日志<code>entry</code>，然后正式应用到状态机。</li>
<li><code>node</code>: 即底层<code>Raft</code>协议组件，<code>raftNode</code>可以通过<code>node</code>提供的接口来与<code>Raft</code>组件进行交互。</li>
<li><code>raftStorage</code>: <code>Raft</code>协议的状态存储组件，应用在更新<code>kvStore</code>状态机时，也会更新此组件，并且通过<code>raft.Config</code>传给<code>Raft</code>协议。</li>
<li><code>wal</code>: 管理<code>WAL</code>日志，前文提过<code>etcd</code>将日志的相关逻辑交由应用来管理。</li>
<li><code>snapshotter</code>: 管理 <code>snapshot</code>文件，快照文件也是由应用来管理。</li>
<li><code>transport</code>: 应用通过此接口与集群中其它的节点(<code>peer</code>)通信，比如传输日志同步消息、快照同步消息等。网络传输也是由应用来处理。</li>
</ul>
<p>其它的相关的数据结构不再展开，具体可以查看源代码，辅助注释理解。</p>
<h2 id="关键流程"><a href="#关键流程" class="headerlink" title="关键流程"></a>关键流程</h2><p>我们从<code>main.go</code>中开始通过梳理一个典型的由客户端发起的状态更新请求的完整流程来理解如何利用<code>Raft</code>协议库来构建应用状态机。<code>main.go</code>的主要逻辑如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="comment">// 解析客户端请求参数信息</span></span><br><span class="line">    ...</span><br><span class="line">	proposeC := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">string</span>)</span><br><span class="line">	<span class="keyword">defer</span> <span class="built_in">close</span>(proposeC)</span><br><span class="line">	confChangeC := <span class="built_in">make</span>(<span class="keyword">chan</span> raftpb.ConfChange)</span><br><span class="line">	<span class="keyword">defer</span> <span class="built_in">close</span>(confChangeC)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// raft provides a commit stream for the proposals from the http api</span></span><br><span class="line">	<span class="keyword">var</span> kvs *kvstore</span><br><span class="line">	getSnapshot := <span class="function"><span class="keyword">func</span><span class="params">()</span> <span class="params">([]<span class="keyword">byte</span>, error)</span></span> &#123; <span class="keyword">return</span> kvs.getSnapshot() &#125;</span><br><span class="line">	commitC, errorC, snapshotterReady := newRaftNode(*id, strings.Split(*cluster, <span class="string">","</span>), *join, getSnapshot, proposeC, confChangeC)</span><br><span class="line"></span><br><span class="line">	kvs = newKVStore(&lt;-snapshotterReady, proposeC, commitC, errorC)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// the key-value http handler will propose updates to raft</span></span><br><span class="line">	serveHttpKVAPI(kvs, *kvport, confChangeC, errorC)</span><br><span class="line">&#125; <span class="comment">// main.go</span></span><br></pre></td></tr></table></figure>

<p>显然，此示例的步骤较为清晰。主要包括三方面逻辑：其一，初始化<code>raftNode</code>，并通过 go routine 来启动相关的逻辑，实际上，这也是初始化并启动<code>Raft</code>协议组件，后面会详细相关流程。其二，初始化应用状态机，它会反复从<code>commitC</code>通道中读取<code>raftNode/Raft</code>传递给它的准备提交应用的日志。最后，启动 http 服务以接收客户端读写请求，并设置监听。下面会围绕这三个功能相关的逻辑进行阐述。</p>
<h3 id="Raft-初始化"><a href="#Raft-初始化" class="headerlink" title="Raft 初始化"></a>Raft 初始化</h3><p>首先我们来理顺<code>Raft</code>初始化的逻辑，这部分相对简单。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newRaftNode</span><span class="params">(id <span class="keyword">int</span>, peers []<span class="keyword">string</span>, join <span class="keyword">bool</span>, getSnapshot <span class="keyword">func</span>()</span> <span class="params">([]<span class="keyword">byte</span>, error)</span>, <span class="title">proposeC</span> &lt;-<span class="title">chan</span> <span class="title">string</span>,</span></span><br><span class="line"><span class="function">	<span class="title">confChangeC</span> &lt;-<span class="title">chan</span> <span class="title">raftpb</span>.<span class="title">ConfChange</span>) <span class="params">(&lt;-<span class="keyword">chan</span> *<span class="keyword">string</span>, &lt;-<span class="keyword">chan</span> error, &lt;-<span class="keyword">chan</span> *snap.Snapshotter)</span></span> &#123;</span><br><span class="line"></span><br><span class="line">	commitC := <span class="built_in">make</span>(<span class="keyword">chan</span> *<span class="keyword">string</span>)</span><br><span class="line">	errorC := <span class="built_in">make</span>(<span class="keyword">chan</span> error)</span><br><span class="line"></span><br><span class="line">	rc := &amp;raftNode&#123;</span><br><span class="line">		proposeC:    proposeC,</span><br><span class="line">		confChangeC: confChangeC,</span><br><span class="line">		commitC:     commitC,</span><br><span class="line">		errorC:      errorC,</span><br><span class="line">		id:          id,</span><br><span class="line">		peers:       peers,</span><br><span class="line">		join:        join,</span><br><span class="line">		waldir:      fmt.Sprintf(<span class="string">"raftexample-%d"</span>, id),</span><br><span class="line">		snapdir:     fmt.Sprintf(<span class="string">"raftexample-%d-snap"</span>, id),</span><br><span class="line">		getSnapshot: getSnapshot,</span><br><span class="line">		snapCount:   defaultSnapshotCount, <span class="comment">// 只有当日志数量达到此阈值时才执行快照</span></span><br><span class="line">		stopc:       <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;),</span><br><span class="line">		httpstopc:   <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;),</span><br><span class="line">		httpdonec:   <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;),</span><br><span class="line"></span><br><span class="line">		snapshotterReady: <span class="built_in">make</span>(<span class="keyword">chan</span> *snap.Snapshotter, <span class="number">1</span>),</span><br><span class="line">		<span class="comment">// rest of structure populated after WAL replay</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">go</span> rc.startRaft() <span class="comment">// 通过 go routine 来启动 raftNode 的相关处理逻辑</span></span><br><span class="line">	<span class="keyword">return</span> commitC, errorC, rc.snapshotterReady</span><br><span class="line">&#125; <span class="comment">// raft.go</span></span><br></pre></td></tr></table></figure>

<p><code>newRaftNode</code>初始化一个<code>Raft</code>实例，并且将<code>commitC</code>、<code>errorC</code>及<code>snapshotterReady</code>三个通道返回给<code>raftNode</code>。<code>raftNode</code>初始化所需要的信息包括集群中其它<code>peer</code>的地址、<code>WAL</code>管理日志以及<code>snapshot</code>管理快照的目录等。接下来，分析稍为复杂的<code>startRaft</code>的逻辑：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rc *raftNode)</span> <span class="title">startRaft</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> !fileutil.Exist(rc.snapdir) &#123; <span class="comment">// 若快照目录不存在，则创建</span></span><br><span class="line">		<span class="keyword">if</span> err := os.Mkdir(rc.snapdir, <span class="number">0750</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line">			log.Fatalf(<span class="string">"raftexample: cannot create dir for snapshot (%v)"</span>, err)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	rc.snapshotter = snap.New(zap.NewExample(), rc.snapdir)</span><br><span class="line">	rc.snapshotterReady &lt;- rc.snapshotter</span><br><span class="line"></span><br><span class="line">	oldwal := wal.Exist(rc.waldir) <span class="comment">//判断是否已存在 WAL 日志（在节点宕机重启时会执行）</span></span><br><span class="line">	rc.wal = rc.replayWAL() <span class="comment">// 重放 WAL 日志以应用到 raft 实例中</span></span><br><span class="line"></span><br><span class="line">	rpeers := <span class="built_in">make</span>([]raft.Peer, <span class="built_in">len</span>(rc.peers))</span><br><span class="line">	<span class="keyword">for</span> i := <span class="keyword">range</span> rpeers &#123; <span class="comment">// 创建集群节点标识</span></span><br><span class="line">		rpeers[i] = raft.Peer&#123;ID: <span class="keyword">uint64</span>(i + <span class="number">1</span>)&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	c := &amp;raft.Config&#123; <span class="comment">// 初始化底层 raft 协议实例的配置结构</span></span><br><span class="line">		ID:                        <span class="keyword">uint64</span>(rc.id),</span><br><span class="line">		ElectionTick:              <span class="number">10</span>,</span><br><span class="line">		HeartbeatTick:             <span class="number">1</span>,</span><br><span class="line">		Storage:                   rc.raftStorage,</span><br><span class="line">		MaxSizePerMsg:             <span class="number">1024</span> * <span class="number">1024</span>,</span><br><span class="line">		MaxInflightMsgs:           <span class="number">256</span>,</span><br><span class="line">		MaxUncommittedEntriesSize: <span class="number">1</span> &lt;&lt; <span class="number">30</span>,</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> oldwal &#123; <span class="comment">// 若已存在 WAL 日志，则重启节点（并非第一次启动）</span></span><br><span class="line">		rc.node = raft.RestartNode(c)</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		startPeers := rpeers</span><br><span class="line">		<span class="keyword">if</span> rc.join &#123; <span class="comment">// 节点可以通过两种不同的方式来加入集群，应用以 join 字段来区分</span></span><br><span class="line">			startPeers = <span class="literal">nil</span></span><br><span class="line">		&#125; <span class="comment">// 启动底层 raft 的协议实体 node</span></span><br><span class="line">		rc.node = raft.StartNode(c, startPeers)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 初始化集群网格传输组件</span></span><br><span class="line">	rc.transport = &amp;rafthttp.Transport&#123;</span><br><span class="line">		Logger:      zap.NewExample(),</span><br><span class="line">		ID:          types.ID(rc.id),</span><br><span class="line">		ClusterID:   <span class="number">0x1000</span>,</span><br><span class="line">		Raft:        rc,</span><br><span class="line">		ServerStats: stats.NewServerStats(<span class="string">""</span>, <span class="string">""</span>),</span><br><span class="line">		LeaderStats: stats.NewLeaderStats(strconv.Itoa(rc.id)),</span><br><span class="line">		ErrorC:      <span class="built_in">make</span>(<span class="keyword">chan</span> error),</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 启动（初始化）transport 的相关内容</span></span><br><span class="line">	rc.transport.Start()</span><br><span class="line">	<span class="keyword">for</span> i := <span class="keyword">range</span> rc.peers &#123; <span class="comment">// 为每一个节点添加集群中其它的 peer，并且会启动数据传输通道</span></span><br><span class="line">		<span class="keyword">if</span> i+<span class="number">1</span> != rc.id &#123;</span><br><span class="line">			rc.transport.AddPeer(types.ID(i+<span class="number">1</span>), []<span class="keyword">string</span>&#123;rc.peers[i]&#125;)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 启动 go routine 来处理本节点与其它节点通信的 http 服务监听</span></span><br><span class="line">	<span class="keyword">go</span> rc.serveRaft()</span><br><span class="line">    <span class="comment">// 启动 go routine 来处理 raftNode 与 底层 raft 通过通道来进行通信</span></span><br><span class="line">	<span class="keyword">go</span> rc.serveChannels()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="应用初始化"><a href="#应用初始化" class="headerlink" title="应用初始化"></a>应用初始化</h3><p>应用初始化相关代码较为简单，它只需要初始化内存状态机，并且监听从<code>raftNode</code>传来的准备提交的日志的<code>channel</code>即可，以将<code>commitC</code>读到的日志应用到内存状态机。应用初始化相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newKVStore</span><span class="params">(snapshotter *snap.Snapshotter, proposeC <span class="keyword">chan</span>&lt;- <span class="keyword">string</span>, commitC &lt;-<span class="keyword">chan</span> *<span class="keyword">string</span>, errorC &lt;-<span class="keyword">chan</span> error)</span> *<span class="title">kvstore</span></span> &#123;</span><br><span class="line">	s := &amp;kvstore&#123;proposeC: proposeC, kvStore: <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span>), snapshotter: snapshotter&#125;</span><br><span class="line">	<span class="comment">// replay log into key-value map</span></span><br><span class="line">	s.readCommits(commitC, errorC)</span><br><span class="line">	<span class="comment">// read commits from raft into kvStore map until error</span></span><br><span class="line">	<span class="keyword">go</span> s.readCommits(commitC, errorC)</span><br><span class="line">	<span class="keyword">return</span> s</span><br><span class="line">&#125; <span class="comment">// kvstore.go</span></span><br></pre></td></tr></table></figure>

<p>其中<code>readComits</code>即循环监听通道，并从其中取出日志的函数。并且如果本地存在<code>snapshot</code>，则先将日志重放到内存状态机中。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *kvstore)</span> <span class="title">readCommits</span><span class="params">(commitC &lt;-<span class="keyword">chan</span> *<span class="keyword">string</span>, errorC &lt;-<span class="keyword">chan</span> error)</span></span> &#123;</span><br><span class="line">	<span class="keyword">for</span> data := <span class="keyword">range</span> commitC &#123;</span><br><span class="line">		<span class="keyword">if</span> data == <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="comment">// done replaying log; new data incoming</span></span><br><span class="line">			<span class="comment">// OR signaled to load snapshot</span></span><br><span class="line">			snapshot, err := s.snapshotter.Load()</span><br><span class="line">			<span class="keyword">if</span> err == snap.ErrNoSnapshot &#123;</span><br><span class="line">				<span class="keyword">return</span></span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">				log.Panic(err)</span><br><span class="line">			&#125;</span><br><span class="line">			log.Printf(<span class="string">"loading snapshot at term %d and index %d"</span>, snapshot.Metadata.Term, snapshot.Metadata.Index)</span><br><span class="line">            <span class="comment">// 将之前某时刻快照重新设置为状态机目前的状态</span></span><br><span class="line">			<span class="keyword">if</span> err := s.recoverFromSnapshot(snapshot.Data); err != <span class="literal">nil</span> &#123;</span><br><span class="line">				log.Panic(err)</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">continue</span></span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">        <span class="comment">// 先对数据解码</span></span><br><span class="line">		<span class="keyword">var</span> dataKv kv</span><br><span class="line">		dec := gob.NewDecoder(bytes.NewBufferString(*data))</span><br><span class="line">		<span class="keyword">if</span> err := dec.Decode(&amp;dataKv); err != <span class="literal">nil</span> &#123;</span><br><span class="line">			log.Fatalf(<span class="string">"raftexample: could not decode message (%v)"</span>, err)</span><br><span class="line">		&#125;</span><br><span class="line">		s.mu.Lock()</span><br><span class="line">		s.kvStore[dataKv.Key] = dataKv.Val</span><br><span class="line">		s.mu.Unlock()</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> err, ok := &lt;-errorC; ok &#123;</span><br><span class="line">		log.Fatal(err)</span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="comment">// kvstore.go</span></span><br></pre></td></tr></table></figure>

<h3 id="开启-http-服务监听"><a href="#开启-http-服务监听" class="headerlink" title="开启 http 服务监听"></a>开启 http 服务监听</h3><p>此应用对用户（客户端）提供 http 接口服务。用户可以通过此 http 接口来提交对应用的数据更新请求，应用启动对外服务及设置监听相关逻辑如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// serveHttpKVAPI starts a key-value server with a GET/PUT API and listens.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">serveHttpKVAPI</span><span class="params">(kv *kvstore, port <span class="keyword">int</span>, confChangeC <span class="keyword">chan</span>&lt;- raftpb.ConfChange, errorC &lt;-<span class="keyword">chan</span> error)</span></span> &#123;</span><br><span class="line">	srv := http.Server&#123;</span><br><span class="line">		Addr: <span class="string">":"</span> + strconv.Itoa(port),</span><br><span class="line">		Handler: &amp;httpKVAPI&#123;</span><br><span class="line">			store:       kv,</span><br><span class="line">			confChangeC: confChangeC,</span><br><span class="line">		&#125;,</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		<span class="keyword">if</span> err := srv.ListenAndServe(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">			log.Fatal(err)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;()</span><br><span class="line"></span><br><span class="line">	<span class="comment">// exit when raft goes down</span></span><br><span class="line">	<span class="keyword">if</span> err, ok := &lt;-errorC; ok &#123;</span><br><span class="line">		log.Fatal(err)</span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="comment">// httpapi.go</span></span><br></pre></td></tr></table></figure>

<p>而接收并解析用户的请求相关逻辑如下所示，它将从用户接收到的对应用的读写请求，传递给<code>raftNode</code>，由<code>raftNode</code>传递至底层的<code>raft</code>协议核心组件来处理。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h *httpKVAPI)</span> <span class="title">ServeHTTP</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">	key := r.RequestURI</span><br><span class="line">	<span class="keyword">switch</span> &#123;</span><br><span class="line">	<span class="keyword">case</span> r.Method == <span class="string">"PUT"</span>:</span><br><span class="line">		v, err := ioutil.ReadAll(r.Body)</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			log.Printf(<span class="string">"Failed to read on PUT (%v)\n"</span>, err)</span><br><span class="line">			http.Error(w, <span class="string">"Failed on PUT"</span>, http.StatusBadRequest)</span><br><span class="line">			<span class="keyword">return</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 将请求传递至 raftNode 组件，最终会传递到底层的 raft 核心协议模块</span></span><br><span class="line">		h.store.Propose(key, <span class="keyword">string</span>(v))</span><br><span class="line"></span><br><span class="line">		<span class="comment">// Optimistic-- no waiting for ack from raft. Value is not yet</span></span><br><span class="line">		<span class="comment">// committed so a subsequent GET on the key may return old value</span></span><br><span class="line">		w.WriteHeader(http.StatusNoContent)</span><br><span class="line">	<span class="keyword">case</span> r.Method == <span class="string">"GET"</span>:</span><br><span class="line">		<span class="keyword">if</span> v, ok := h.store.Lookup(key); ok &#123;</span><br><span class="line">			w.Write([]<span class="keyword">byte</span>(v))</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			http.Error(w, <span class="string">"Failed to GET"</span>, http.StatusNotFound)</span><br><span class="line">		&#125;</span><br><span class="line">	<span class="keyword">case</span> r.Method == <span class="string">"POST"</span>:</span><br><span class="line">		url, err := ioutil.ReadAll(r.Body)</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			log.Printf(<span class="string">"Failed to read on POST (%v)\n"</span>, err)</span><br><span class="line">			http.Error(w, <span class="string">"Failed on POST"</span>, http.StatusBadRequest)</span><br><span class="line">			<span class="keyword">return</span></span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		nodeId, err := strconv.ParseUint(key[<span class="number">1</span>:], <span class="number">0</span>, <span class="number">64</span>)</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			log.Printf(<span class="string">"Failed to convert ID for conf change (%v)\n"</span>, err)</span><br><span class="line">			http.Error(w, <span class="string">"Failed on POST"</span>, http.StatusBadRequest)</span><br><span class="line">			<span class="keyword">return</span></span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		cc := raftpb.ConfChange&#123;</span><br><span class="line">			Type:    raftpb.ConfChangeAddNode,</span><br><span class="line">			NodeID:  nodeId,</span><br><span class="line">			Context: url,</span><br><span class="line">		&#125;</span><br><span class="line">		h.confChangeC &lt;- cc</span><br><span class="line"></span><br><span class="line">		<span class="comment">// As above, optimistic that raft will apply the conf change</span></span><br><span class="line">		w.WriteHeader(http.StatusNoContent)</span><br><span class="line">	<span class="keyword">case</span> r.Method == <span class="string">"DELETE"</span>:</span><br><span class="line">		nodeId, err := strconv.ParseUint(key[<span class="number">1</span>:], <span class="number">0</span>, <span class="number">64</span>)</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			log.Printf(<span class="string">"Failed to convert ID for conf change (%v)\n"</span>, err)</span><br><span class="line">			http.Error(w, <span class="string">"Failed on DELETE"</span>, http.StatusBadRequest)</span><br><span class="line">			<span class="keyword">return</span></span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		cc := raftpb.ConfChange&#123;</span><br><span class="line">			Type:   raftpb.ConfChangeRemoveNode,</span><br><span class="line">			NodeID: nodeId,</span><br><span class="line">		&#125;</span><br><span class="line">		h.confChangeC &lt;- cc</span><br><span class="line">		<span class="comment">// ..</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="comment">// httpapi.go</span></span><br></pre></td></tr></table></figure>

<h3 id="状态机更新请求"><a href="#状态机更新请求" class="headerlink" title="状态机更新请求"></a>状态机更新请求</h3><p>在 <code>httpapi.go</code> 的逻辑中，我们选择 PUT 请求分支来进行分析。当它接收到用户发送的更新请求时。它会调用 <code>kvstore</code>的<code>Propose</code>函数，并将更新请求相关参数传递过去：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *kvstore)</span> <span class="title">Propose</span><span class="params">(k <span class="keyword">string</span>, v <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> buf bytes.Buffer</span><br><span class="line">    <span class="comment">// 编码后，传递至 raftNode</span></span><br><span class="line">	<span class="keyword">if</span> err := gob.NewEncoder(&amp;buf).Encode(kv&#123;k, v&#125;); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		log.Fatal(err)</span><br><span class="line">	&#125;</span><br><span class="line">	s.proposeC &lt;- buf.String()</span><br><span class="line">&#125; <span class="comment">// kvstore.go</span></span><br></pre></td></tr></table></figure>

<p>在<code>kvstore</code>将请求 buf 压到管道后，<code>raftNode</code>可以在管道的另一端取出，即在<code>serverChannel</code>函数取出请求，并交由底层 <code>raft</code>协议核心库来保证此次集群状态的更新。相关代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rc *raftNode)</span> <span class="title">serveChannels</span><span class="params">()</span></span> &#123;</span><br><span class="line">	snap, err := rc.raftStorage.Snapshot()</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="built_in">panic</span>(err)</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="comment">// 利用 raft 实例的内存状态机初始化 snapshot 相关属性</span></span><br><span class="line">	rc.confState = snap.Metadata.ConfState</span><br><span class="line">	rc.snapshotIndex = snap.Metadata.Index</span><br><span class="line">	rc.appliedIndex = snap.Metadata.Index</span><br><span class="line"></span><br><span class="line">	<span class="keyword">defer</span> rc.wal.Close()</span><br><span class="line">    <span class="comment">// 初始化一个定时器，每次触发 tick 都会调用底层 node.Tick()函数，以表示一次心跳事件，</span></span><br><span class="line">    <span class="comment">// 不同角色的事件处理函数不同。</span></span><br><span class="line">	ticker := time.NewTicker(<span class="number">100</span> * time.Millisecond)</span><br><span class="line">	<span class="keyword">defer</span> ticker.Stop()</span><br><span class="line"></span><br><span class="line">	<span class="comment">// send proposals over raft</span></span><br><span class="line">    <span class="comment">// 开启 go routine 以接收应用层(kvstore)的请求（包括正常的日志请求及集群配置变更请求）</span></span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		confChangeCount := <span class="keyword">uint64</span>(<span class="number">0</span>)</span><br><span class="line">		<span class="comment">// 循环监听来自 kvstore 的请求消息</span></span><br><span class="line">		<span class="keyword">for</span> rc.proposeC != <span class="literal">nil</span> &amp;&amp; rc.confChangeC != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">select</span> &#123;</span><br><span class="line">             <span class="comment">// 1. 正常的日志请求</span></span><br><span class="line">			<span class="keyword">case</span> prop, ok := &lt;-rc.proposeC:</span><br><span class="line">				<span class="keyword">if</span> !ok &#123;</span><br><span class="line">					rc.proposeC = <span class="literal">nil</span></span><br><span class="line">				&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">					<span class="comment">// blocks until accepted by raft state machine</span></span><br><span class="line">                      <span class="comment">// 调用底层的 raft 核心库的 node 的 Propose 接口来处理请求</span></span><br><span class="line">					rc.node.Propose(context.TODO(), []<span class="keyword">byte</span>(prop))</span><br><span class="line">				&#125;</span><br><span class="line">			<span class="comment">// 2. 配置变更请求类似处理</span></span><br><span class="line">			<span class="keyword">case</span> cc, ok := &lt;-rc.confChangeC:</span><br><span class="line">				<span class="keyword">if</span> !ok &#123;</span><br><span class="line">					rc.confChangeC = <span class="literal">nil</span></span><br><span class="line">				&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">					confChangeCount++</span><br><span class="line">					cc.ID = confChangeCount</span><br><span class="line">					rc.node.ProposeConfChange(context.TODO(), cc)</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// client closed channel; shutdown raft if not already</span></span><br><span class="line">		<span class="built_in">close</span>(rc.stopc)</span><br><span class="line">	&#125;()</span><br><span class="line"></span><br><span class="line">	<span class="comment">// event loop on raft state machine updates</span></span><br><span class="line">    <span class="comment">// 开启 go routine 以循环处理底层 raft 核心库通过 Ready 通道发送给 raftNode 的指令</span></span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">            <span class="comment">// 触发定时器事件</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-ticker.C:</span><br><span class="line">			rc.node.Tick()</span><br><span class="line"></span><br><span class="line">		<span class="comment">// store raft entries to wal, then publish over commit channel</span></span><br><span class="line">         <span class="comment">// 1.通过 Ready 获取 raft 核心库传递的指令</span></span><br><span class="line">		<span class="keyword">case</span> rd := &lt;-rc.node.Ready():</span><br><span class="line">            <span class="comment">// 2. 先写 WAL 日志</span></span><br><span class="line">			rc.wal.Save(rd.HardState, rd.Entries)</span><br><span class="line">			<span class="keyword">if</span> !raft.IsEmptySnap(rd.Snapshot) &#123;</span><br><span class="line">				rc.saveSnap(rd.Snapshot)</span><br><span class="line">				rc.raftStorage.ApplySnapshot(rd.Snapshot)</span><br><span class="line">				rc.publishSnapshot(rd.Snapshot)</span><br><span class="line">			&#125;</span><br><span class="line">            <span class="comment">// 3. 更新 raft 实例的内存状态</span></span><br><span class="line">			rc.raftStorage.Append(rd.Entries)</span><br><span class="line">            <span class="comment">// 4. 将接收到消息传递通过 transport 组件传递给集群其它 peer</span></span><br><span class="line">			rc.transport.Send(rd.Messages)</span><br><span class="line">            <span class="comment">// 5. 将已经提交的请求日志应用到状态机</span></span><br><span class="line">			<span class="keyword">if</span> ok := rc.publishEntries(rc.entriesToApply(rd.CommittedEntries)); !ok &#123;</span><br><span class="line">				rc.stop()</span><br><span class="line">				<span class="keyword">return</span></span><br><span class="line">			&#125;</span><br><span class="line">            <span class="comment">// 6. 如果有必要，则会触发一次快照</span></span><br><span class="line">			rc.maybeTriggerSnapshot()</span><br><span class="line">            <span class="comment">// 7. 通知底层 raft 核心库，当前的指令已经提交应用完成，这使得 raft 核心库可以发送下一个 Ready 指令了。</span></span><br><span class="line">			rc.node.Advance()</span><br><span class="line"></span><br><span class="line">		<span class="keyword">case</span> err := &lt;-rc.transport.ErrorC:</span><br><span class="line">			rc.writeError(err)</span><br><span class="line">			<span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">		<span class="keyword">case</span> &lt;-rc.stopc:</span><br><span class="line">			rc.stop()</span><br><span class="line">			<span class="keyword">return</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125; <span class="comment">// raft.go</span></span><br></pre></td></tr></table></figure>

<p>上述关于 <code>raftNode</code>与底层<code>Raft</code>核心库交互的相关逻辑大致已经清楚。大概地，<code>raftNode</code>会将从<code>kvstore</code>接收到的用户对状态机的更新请求传递给底层<code>raft</code>核心库来处理。此后，<code>raftNode</code>会阻塞直至收到由<code>raft</code>组件传回的<code>Ready</code>指令。根据指令的内容，先写<code>WAL</code>日志，更新内存状态存储，并分发至其它节点。最后如果指令已经可以提交，即底层<code>raft</code>组件判定请求在集群多数节点已经完成状态复制后，则应用到状态机，具体由<code>kvstore</code>来执行。并且若触发了快照的条件，则执行快照操作，最后才通知<code>raft</code>核心库可以准备下一个<code>Ready</code>指令。关于 <code>Ready</code>结构具体内容，我们可以大致看一下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Ready encapsulates the entries and messages that are ready to read,</span></span><br><span class="line"><span class="comment">// be saved to stable storage, committed or sent to other peers.</span></span><br><span class="line"><span class="comment">// All fields in Ready are read-only.</span></span><br><span class="line"><span class="comment">// Ready 结构包装了事务日志，以及需要发送给其它 peer 的消息指令，这些字段都是只读的，且有些必须进行持久化，或者已经可以提交应用。</span></span><br><span class="line"><span class="keyword">type</span> Ready <span class="keyword">struct</span> &#123;</span><br><span class="line">	<span class="comment">// The current volatile state of a Node.</span></span><br><span class="line">	<span class="comment">// SoftState will be nil if there is no update.</span></span><br><span class="line">	<span class="comment">// It is not required to consume or store SoftState.</span></span><br><span class="line">    <span class="comment">// 包含了内存中的状态，即瞬时状态数据</span></span><br><span class="line">	*SoftState</span><br><span class="line"></span><br><span class="line">	<span class="comment">// The current state of a Node to be saved to stable storage BEFORE</span></span><br><span class="line">	<span class="comment">// Messages are sent.</span></span><br><span class="line">	<span class="comment">// HardState will be equal to empty state if there is no update.</span></span><br><span class="line">    <span class="comment">// 包含了持久化的状态，即在消息发送给其它节点前需要保存到磁盘</span></span><br><span class="line">	pb.HardState</span><br><span class="line"></span><br><span class="line">	<span class="comment">// ReadStates can be used for node to serve linearizable read requests locally</span></span><br><span class="line">	<span class="comment">// when its applied index is greater than the index in ReadState.</span></span><br><span class="line">	<span class="comment">// Note that the readState will be returned when raft receives msgReadIndex.</span></span><br><span class="line">	<span class="comment">// The returned is only valid for the request that requested to read.</span></span><br><span class="line">    <span class="comment">// 用于节点提供本地的线性化读请求，但其条件是节点的 appliedIndex 必须要大于 ReadState 中的 index，这容易理解，否则会造成客户端的读的数据的不一致</span></span><br><span class="line">	ReadStates []ReadState</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Entries specifies entries to be saved to stable storage BEFORE</span></span><br><span class="line">	<span class="comment">// Messages are sent.</span></span><br><span class="line">    <span class="comment">// 表示在发送其它节点之前需要被持久化的状态数据</span></span><br><span class="line">	Entries []pb.Entry</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Snapshot specifies the snapshot to be saved to stable storage.</span></span><br><span class="line">    <span class="comment">// 与快照相关，指定了可以持久化的 snapshot 数据</span></span><br><span class="line">	Snapshot pb.Snapshot</span><br><span class="line"></span><br><span class="line">	<span class="comment">// CommittedEntries specifies entries to be committed to a</span></span><br><span class="line">	<span class="comment">// store/state-machine. These have previously been committed to stable</span></span><br><span class="line">	<span class="comment">// store.</span></span><br><span class="line">    <span class="comment">// 可以被提交应用到状态机的状态数据</span></span><br><span class="line">	CommittedEntries []pb.Entry</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Messages specifies outbound messages to be sent AFTER Entries are</span></span><br><span class="line">	<span class="comment">// committed to stable storage.</span></span><br><span class="line">	<span class="comment">// If it contains a MsgSnap message, the application MUST report back to raft</span></span><br><span class="line">	<span class="comment">// when the snapshot has been received or has failed by calling ReportSnapshot.</span></span><br><span class="line">    <span class="comment">// 当 Entries 被持久化后，需要转发到其它节点的消息</span></span><br><span class="line">	Messages []pb.Message</span><br><span class="line"></span><br><span class="line">	<span class="comment">// MustSync indicates whether the HardState and Entries must be synchronously</span></span><br><span class="line">	<span class="comment">// written to disk or if an asynchronous write is permissible.</span></span><br><span class="line">	MustSync <span class="keyword">bool</span></span><br><span class="line">&#125; <span class="comment">// /etcd/raft/node.go</span></span><br></pre></td></tr></table></figure>

<h3 id="日志管理"><a href="#日志管理" class="headerlink" title="日志管理"></a>日志管理</h3><p><code>raftexample</code>中使用了<code>etcd</code>提供的通用日志库来管理<code>WAL</code>日志，我们下面来分析下应用管理日志的相关逻辑。在上面的状态机更新请求中，注意到当<code>raftNode</code>接收到<code>raft</code>核心传递的<code>Ready</code>指令，第一步就进行写<code>WAL</code>日志操作，这种操作较为常见，以避免更新丢失。值得一提的的，<code>WAL</code>日志也会在各节点进行同步。另外在<code>startRaft</code>函数中，即启动<code>raftNode</code>相关逻辑时，便进行了<code>WAL</code>日志重放<code>rc.wal = rc.replayWAL()</code>，我们详细看一下日志重放的流程：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// replayWAL replays WAL entries into the raft instance.</span></span><br><span class="line"><span class="comment">// 重放节点 WAL 日志，以将重新初始化 raft 实例的内存状态</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rc *raftNode)</span> <span class="title">replayWAL</span><span class="params">()</span> *<span class="title">wal</span>.<span class="title">WAL</span></span> &#123;</span><br><span class="line">	log.Printf(<span class="string">"replaying WAL of member %d"</span>, rc.id)</span><br><span class="line">    <span class="comment">// 1. 加载快照数据</span></span><br><span class="line">	snapshot := rc.loadSnapshot()</span><br><span class="line">    <span class="comment">// 2. 借助快照数据（的相关属性）来打开 WAL 日志。应用只会重放快照时间点（索引）之后的日志，因为快照数据直接记录着状态机的状态数据（这等同于将快照数据所对应的 WAL 日志重放），因此可以直接应用到内存状态结构。换言之，不需要重放 WAL 包含的所有的日志项，这明显可以加快日志重放的速度。结合 openWAL 函数可以得出结论。</span></span><br><span class="line">	w := rc.openWAL(snapshot)</span><br><span class="line">    <span class="comment">// 3. 从 WAL 日志中读取事务日志</span></span><br><span class="line">	_, st, ents, err := w.ReadAll()</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		log.Fatalf(<span class="string">"raftexample: failed to read WAL (%v)"</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="comment">// 4. 构建 raft 实例的内存状态结构</span></span><br><span class="line">	rc.raftStorage = raft.NewMemoryStorage()</span><br><span class="line">	<span class="keyword">if</span> snapshot != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="comment">// 5. 将快照数据直接加载应用到内存结构</span></span><br><span class="line">		rc.raftStorage.ApplySnapshot(*snapshot)</span><br><span class="line">	&#125;</span><br><span class="line">	rc.raftStorage.SetHardState(st)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// append to storage so raft starts at the right place in log</span></span><br><span class="line">    <span class="comment">// 6. 将 WAL 记录的日志项更新到内存状态结构</span></span><br><span class="line">	rc.raftStorage.Append(ents)</span><br><span class="line">	<span class="comment">// send nil once lastIndex is published so client knows commit channel is current</span></span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(ents) &gt; <span class="number">0</span> &#123;</span><br><span class="line">        <span class="comment">// 更新最后一条日志索引的记录</span></span><br><span class="line">		rc.lastIndex = ents[<span class="built_in">len</span>(ents)<span class="number">-1</span>].Index</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		rc.commitC &lt;- <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> w</span><br><span class="line">&#125; <span class="comment">// raft.go</span></span><br></pre></td></tr></table></figure>

<p>通过查看上述的流程，关于 <code>WAL</code>日志重放的流程也很清晰。</p>
<h3 id="快照管理"><a href="#快照管理" class="headerlink" title="快照管理"></a>快照管理</h3><p>快照(<code>snapshot</code>)本质是对日志进行压缩，它是对状态机某一时刻（或者日志的某一索引）的状态的保存。快照操作可以缓解日志文件无限制增长的问题，一旦达日志项达到某一临界值，可以将内存的状态数据进行压缩成为<code>snapshot</code>文件并存储在快照目录，这使得快照之前的日志项都可以被舍弃，节约了磁盘空间。我们在上文的状态机更新请求相关逻辑中，发现程序有可能会对日志项进行快照操作即这一行代码逻辑<code>rc.maybeTriggerSnapshot()</code>，那我们来具体了解快照是如何创建的：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rc *raftNode)</span> <span class="title">maybeTriggerSnapshot</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="comment">// 1. 只有当前已经提交应用的日志的数据达到 rc.snapCount 才会触发快照操作</span></span><br><span class="line">	<span class="keyword">if</span> rc.appliedIndex-rc.snapshotIndex &lt;= rc.snapCount &#123;</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	log.Printf(<span class="string">"start snapshot [applied index: %d | last snapshot index: %d]"</span>, rc.appliedIndex, rc.snapshotIndex)</span><br><span class="line">    <span class="comment">// 2. 生成此时应用的状态机的状态数据，此函数由应用提供，可以在 kvstore.go 找到它的定义</span></span><br><span class="line">	data, err := rc.getSnapshot()</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		log.Panic(err)</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="comment">// 2. 结合已经提交的日志以及配置状态数据正式生成快照</span></span><br><span class="line">	snap, err := rc.raftStorage.CreateSnapshot(rc.appliedIndex, &amp;rc.confState, data)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="built_in">panic</span>(err)</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="comment">// 4. 快照存盘</span></span><br><span class="line">	<span class="keyword">if</span> err := rc.saveSnap(snap); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="built_in">panic</span>(err)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	compactIndex := <span class="keyword">uint64</span>(<span class="number">1</span>)</span><br><span class="line">    <span class="comment">// 5. 判断是否达到阶段性整理内存日志的条件，若达到，则将内存中的数据进行阶段性整理标记</span></span><br><span class="line">	<span class="keyword">if</span> rc.appliedIndex &gt; snapshotCatchUpEntriesN &#123;</span><br><span class="line">		compactIndex = rc.appliedIndex - snapshotCatchUpEntriesN</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> err := rc.raftStorage.Compact(compactIndex); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="built_in">panic</span>(err)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	log.Printf(<span class="string">"compacted log at index %d"</span>, compactIndex)</span><br><span class="line">    <span class="comment">// 6. 最后更新当前已快照的日志索引</span></span><br><span class="line">	rc.snapshotIndex = rc.appliedIndex</span><br><span class="line">&#125; <span class="comment">// raft.go</span></span><br></pre></td></tr></table></figure>

<p>需要注意的是，每次生成的快照实体包含两个方面的数据：一个显然是实际的内存状态机中的数据，一般将它存储到当前的快照目录中。另外一个为快照的索引数据，即当前快照的索引信息，换言之，即记录下当前已经被执行快照的日志的索引编号，因为在此索引之前的日志不需要执行重放操作，因此也不需要被<code>WAL</code>日志管理。快照的索引数据一般存储在日志目录下。</p>
<p>另外关于快照的操作还有利用快照进行恢复操作。这段逻辑较为简单，因为快照就代表内存状态机的瞬时的状态数据，因此，将此数据执行反序列化，并加载到内存状态机即可：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *kvstore)</span> <span class="title">recoverFromSnapshot</span><span class="params">(snapshot []<span class="keyword">byte</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> store <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span></span><br><span class="line">	<span class="keyword">if</span> err := json.Unmarshal(snapshot, &amp;store); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	s.mu.Lock()</span><br><span class="line">	s.kvStore = store</span><br><span class="line">	s.mu.Unlock()</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="comment">// kvstore.go</span></span><br></pre></td></tr></table></figure>

<p>至此，<code>raftexmaple</code>主要流程已经简单分析完毕。这是一个简单的应用<code>etcd</code>提供的<code>raft</code>核心库来构建一个 kv 存储的示例，虽然示例的逻辑较为简单，但它却符合前面提到的一点：<code>raft</code>核心库只实现了<code>raft</code>协议的核心部分（包括集群选举、成员变更等），而将日志管理、快照管理、应用状态机实现以及消息转发传输相关逻辑交给应用来处理。这使得底层的<code>raft</code>核心库的逻辑简单化，只要实现协议的核心功能（一致性主义的保证），然后提供与上层应用的接口，并通过<code>channel</code>与上层应用组件交互，如此来构建基于<code>Raft</code>协议的分布式高可靠应用。</p>
<p>参考文献</p>
<p>[1]. <a href="https://github.com/etcd-io/etcd/tree/master/contrib/raftexample" target="_blank" rel="noopener">etcd-raftexample </a><br>[2]. <a href="https://zhuanlan.zhihu.com/p/29180575" target="_blank" rel="noopener">etcd-raft示例分析</a></p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>分布式协调服务</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>分布式协调服务</tag>
        <tag>分布式存储</tag>
        <tag>分布式缓存</tag>
        <tag>一致性协议</tag>
      </tags>
  </entry>
  <entry>
    <title>简单对比 Raft 及 ZAB 协议</title>
    <url>/2019/01/08/%E7%AE%80%E5%8D%95%E5%AF%B9%E6%AF%94-Raft-%E5%8F%8A-ZAB-%E5%8D%8F%E8%AE%AE/</url>
    <content><![CDATA[<p>如果你了解过<code>Raft</code>协议、<code>ZAB</code>(<code>ZooKeeper&#39;s Atomic Broadcast</code>)协议及<code>Paxos</code>算法，你会发现它们本质上都是为了解决共识问题，即属于一种一致性算法（原子广播协议通常意义上可以等同于一致性协议）。但你可能会觉得相比于<code>Paxos</code>，<code>ZAB</code>与<code>Raft</code>可能更相似。从直观感受上，<code>Paxos</code>协议（<code>Basic Paxos</code>）更像是一种广义上的一致性算法的理论版本，它泛化了很多问题，并且没有基于特定场景的（工程）设计，因此相对而言也更难理解。而<code>ZAB</code>及<code>Raft</code>则像是具化的一致性化算法，并且简化了一些问题的前提设定，这也使得它们更易理解，也更易实现。本文对<code>Raft</code>协议及<code>ZAB</code>协议进行简单理解对比，主要讨论它们的不同之处。考虑到<code>Raft</code>论文给出了关于实现的详细细节，但官方提供的<code>ZAB</code>论文并没有涉及太多实现细节（Andr´e Medeiros 于 2012 年发表了一篇理论结合实践的论文），因此关于<code>ZAB</code>的细节是针对<code>ZooKeeper</code>的实现而言的。</p>
<a id="more"></a>

<p>首先，考虑一个问题，为什么需要选举出一个<code>leader</code>？我们知道，在<code>Basic Paxos</code>中并没有强调一定需要一个<code>leader</code>。但在<code>Raft</code>中包含了<code>leader</code>的强领导原则，而<code>ZAB</code>协议，正常的<code>Broadcast</code>阶段也需要一个<code>leader</code>。很自然地，若能够选举出一个<code>leader</code>节点，由其来统筹所有的客户端请求，可以方便并发控制，而且，因为<code>leader</code>是具备最新日志的节点，这使得日志同步过程也变得更简单，单向地由<code>leader</code>流向<code>follower</code>。另外，其实在日志恢复过程中，需要挑选出包含最新日志的节点，如果将它作为<code>leader</code>，那将使得失败恢复过程加快。最后，根本上而言，<code>Raft</code>及<code>ZAB</code>的对日志的应用都差不多归纳为一个二阶段过程，先收集<code>follower</code>反馈，然后，根据特定规则决定是否提交。那么收集反馈的工作若交由<code>leader</code>来处理，明显简化了协议流程。</p>
<p>接下来，我们简述<code>Raft</code>协议与<code>ZAB</code>协议中选举流程的对比情况。明显地，二者都是先选投票给自己，然后广播投票信息，另外它们都包含了选举轮次的概念（在<code>Raft</code>中为任期<code>term</code>，在<code>ZAB</code>中为<code>round</code>，两者的选举过程可能会涉及多轮），这确实比较类似，但需要注意的是，选举完成后，对于<code>Raft</code>而言，<code>term</code>即为<code>leader</code>所在的任期，而<code>ZAB</code>协议却额外使用了一个任期概念(<code>epoch</code>)。在具体的选举过程中，<code>Raft</code>协议规定一旦节点认为它能够为候选者投票，则在此轮投票过程中，都不会改变。而在<code>ZAB</code>协议中，集群中各节点反复交换选票信息（里面包含各自已提交的历史事务日志），以更新选票信息。二者都有<code>quorum</code>选票成功的概念。</p>
<p>与选举流程相关的另一个问题就是如何定义节点包含更新的事务日志。在<code>Raft</code>中，是通过依次比较<code>term</code>及<code>index</code>来确定。而<code>ZAB</code>协议是依次比较<code>epoch</code>及<code>counter</code>来决定（即通过比较<code>zxid</code>），值得注意的是选举轮次<code>round</code>也会作为比较因素。另外，在<code>Raft</code>中有一个很重要的一点为，被选举出来的<code>leader</code>只能提交本<code>term</code>的事务日志（不能显式提交之前<code>term</code>的未提交的事务日志，论文中详细阐述了原因），即在提交当前<code>term</code>的事务日志时，隐式（顺便）提交了之前<code>term</code>的未提交的（但已被复制到<code>quorum</code>节点）事务日志。在<code>ZAB</code>协议中，当<code>leader</code>选举未完成后，不会存在这样的情况，因为在<code>Broadcast</code>阶段之前，<code>Synchronization</code>阶段（<code>Raft</code>协议并未提供此阶段）会保证各节点的日志处于完全一致的状态。</p>
<p>另外，<code>ZAB</code>与<code>Raft</code>协议在选举阶段都使用了超时机制，以保证节点在超时时间内未收到投票信息，会自动转入下一轮的选举。具体而言，<code>Raft</code>的选举流程还可能会出现瓜分选票的情况(<code>split vote)</code>，因此，<code>Raft</code>通过随机化超时(<code>randomized timeout</code>)时间来缓解这个问题（不是解决）。而<code>ZAB</code>协议不会存在瓜分选票的情况，唯一依据是节点的选票的新旧程度。因此，理论上<code>Raft</code>可能存在活性的问题，即不会选举过程不会终止。而<code>ZAB</code>的选举时间应该会比<code>Raft</code>的选举时间更长（更频繁的交换选票信息）。</p>
<p>其次，在<code>ZAB</code>论文中有提到过，<code>follower</code>及<code>leader</code>由<code>Broadcast</code>阶段进入选举阶段，有各自判定依据，或者，这可以表述为，各节点如何触发<code>leader</code>选举过程。明显，在集群刚启动时，节点会先进行选举。另外，<code>Raft</code>协议通过周期性地由<code>leader</code>向<code>follower</code>发送心跳，心巩固<code>leader</code>的领导地位，一旦超时时间内，<code>follower</code>未收到心跳信息，则转为<code>candidate</code>状态、递增<code>term</code>，并触发选举流程（当<code>leader</code>发现消息回复中包含更高<code>term</code>时，便转为<code>follower</code>状态）。而在<code>ZAB</code>协议中，也是通过<code>leader</code>周期性向<code>follower</code>发送心跳，一旦<code>leader</code>未检测到<code>quorum</code>个回复，则会转为<code>election</code>状态，并进入选举流程（它会断开与<code>follower</code>的连接）。而此时<code>follower</code>一旦检测到<code>leader</code>已经卸任，同样会进入<code>election</code>状态，进入选举流程。</p>
<p>如果不幸<code>leader</code>发生了宕机，集群因此重新进行了选举，并生成了新的<code>leader</code>，上一个<code>term</code>并不会影响到当前的<code>leader</code>的工作。这在<code>Raft</code>及<code>ZAB</code>协议中分别可以通过<code>term</code>及<code>epoch</code>来判定决定。那上一任期遗留的事务日志如何处理？典型地，这包含是否已被<code>quorum</code>节点复制的日志。而对于之前<code>term</code>的事务日志，<code>Raft</code>的策略在前文已经叙述，不会主动提交，若已经被过半复制，则会隐式提交。而那些未过半复制的，可能会被删除。而<code>ZAB</code>协议则采取更激进的策略，对于所有过半还是未过半的日志都判定为提交，都将其应用到状态机。</p>
<p>最后，是关于如何让一个新的节点加入协议流程的问题。在<code>Raft</code>中，<code>leader</code>会周期性地向<code>follower</code>发送心跳信息，里面包含了<code>leader</code>信息，因此，此节点可以重构其需要的信息。在<code>ZAB</code>中会有所不同，刚启动后，它会向转入<code>election</code>状态，并向所有节点发送投票信息，因此，正常情况下它会收到集群中其它的<code>follower</code>节点发送的关于<code>leader</code>的投票信息，当然也会收到<code>leader</code>的消息，然后从这些回复中判断当前的<code>leader</code>节点的信息，然后转入<code>following</code>状态，会周期性收到<code>leader</code>的心跳消息。需要注意的一点是，对于<code>Raft</code>而言，一个节点加入协议（不是新机器）不会阻塞整个协议的运行，因为<code>leader</code>保存有节点目前已同步的信息，或者说下一个需要同步的日志的索引，因此它只需要将后续的日志通过心跳发送给<code>follower</code>即可。而<code>ZAB</code>协议中是会阻塞<code>leader</code>收到客户端的写请求。因此，<code>leader</code>向<code>follower</code>同步日志的过程，需要获取<code>leader</code>数据的读锁，然后，确定需要同步给<code>follower</code>的事务日志，确定之后才能释放锁。值得注意的是，<code>Raft</code>的日志被设计成是连续的。而<code>ZAB</code>的日志被设计成允许存在空洞。具体而言，<code>leader</code>为每个<code>follower</code>保存了一个队列，用于存放所有变更。当<code>follower</code>在与<code>leader</code>进行同步时，需要阻塞<code>leader</code>的写请求，只有等到将<code>follower</code>和<code>leader</code>之间的差异数据先放入队列完成之后，才能解除阻塞。这是为了保证所有请求的顺序性，因为在同步期间的数据需要被添加在了上述队列末尾，从而保证了队列中的数据是有序的，从而进一步保证<code>leader</code>发给<code>follower</code>的数据与其接受到客户端的请求的顺序相同，而<code>follower</code>也是一个个进行确认请求（这不同于<code>Raft</code>，后者可以批量同步事务日志），所以对于<code>leader</code>的请求回复也是严格有序的。</p>
<p>最后，从论文来看，二者的快照也略有不同。<code>Raft</code>的快照机制对应了某一个时刻状态机数据（即采取的是准确式快照）。而<code>ZooKeeper为</code>了保证快照的高性能，采用一种<code>fuzzy snapshot</code>机制（这在<code>ZooKeeper</code>博文中有介绍），大概地，它会记录从快照开始的事务标识，并且此时不会阻塞写请求（不锁定内存），因此，它会对部分新的事务日志应用多次（事务日志的幂等特性保证了这种做法的正确性）。</p>
<p>顺便提一下，<code>ZooKeepr</code>为保证读性能的线性扩展，让任何节点都能处理读请求。但这带来的代价是过期数据。（虽然可通过<code>sync read</code>来强制读取最新数据）。而<code>Raft</code>不会出现过期数据的情况（具体如何保证取决于实现，如将读请求转发到<code>leader</code>）。</p>
<p>本文是从协议流程的各个阶段来对比<code>Raft</code>及<code>ZAB</code>协议。<a href="https://blog.acolyer.org/2015/03/11/vive-la-difference-paxos-vs-viewstamped-replication-vs-zab/" target="_blank" rel="noopener">这里</a>也提供更系统、更理论、更深入的对比（加入了<code>Viewstamped Replication</code>和<code>Paxos</code>一致性协议），它简要概括了<a href="https://arxiv.org/pdf/1309.5671.pdf" target="_blank" rel="noopener">论文</a>。</p>
<p>关于<code>ZAB</code>协议与<code>Paxos</code>的区别，这里便不多阐述了。在<code>ZAB</code>文章中有简略介绍。另外，也可以在<a href="https://cwiki.apache.org/confluence/display/ZOOKEEPER/Zab+vs.+Paxos" target="_blank" rel="noopener">这里</a>进行了解。这篇博文主要参考了文献[1]。</p>
<p>参考文献</p>
<p>[1]. <a href="https://my.oschina.net/pingpangkuangmo/blog/782702" target="_blank" rel="noopener">Raft对比ZAB协议</a><br>[2]. <a href="https://blog.acolyer.org/2015/03/11/vive-la-difference-paxos-vs-viewstamped-replication-vs-zab/" target="_blank" rel="noopener">Vive La Différence: Paxos vs Viewstamped Replication vs Zab</a><br>[3]. Van Renesse R, Schiper N, Schneider F B. Vive la différence: Paxos vs. viewstamped replication vs. zab[J]. IEEE Transactions on Dependable and Secure Computing, 2015, 12(4): 472-484.</p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>一致性算法</category>
      </categories>
      <tags>
        <tag>一致性算法</tag>
        <tag>原子广播协议</tag>
      </tags>
  </entry>
  <entry>
    <title>理解 ZAB 协议</title>
    <url>/2019/01/05/%E7%90%86%E8%A7%A3-ZAB-%E5%8D%8F%E8%AE%AE/</url>
    <content><![CDATA[<p><code>ZAB</code> 协议是应用于 <code>ZooKeeper</code> 分布式协调框架中的可靠原子广播协议(<code>atomic broadcast protocol</code>)（或者称之为全局有序的广播协议<code>totaly ordered broadcast protocol</code>，二者基本等价），这使得<code>ZooKeeper</code>实现了一个主从(<code>primary-backup</code>)模式的架构以通过主服务器接受客户端的数据变更请求，并使用<code>ZAB</code>协议将数据变更请求增量的传播(<code>progpagate</code>)到集群副本节点。在一定程度上，原子广播协议等价于一致性算法(<code>consensus algorithm</code>)，但它们的侧重点有所不同。本质上而言，<code>ZooKeeper</code>依赖于<code>ZAB</code>协议为其它分布式应用提供诸如配置管理、分布式互斥锁以及<code>leader</code>选举等协调原语服务。另一方面，<code>ZooKeeper</code>之所以能提供高可用(<code>highly-available</code>)（比如支持支持崩溃恢复<code>efﬁcient crash-recovery</code>）及高性能(<code>highly-performance</code>)（包括低延迟<code>low latency</code>、高吞吐量<code>good throughput</code>）的协调服务，部分原因是<code>ZAB</code>协议的核心设计（区别于<code>paxos</code>）及工程实现上的优化。大致地，<code>ZAB</code>协议可以分为四个阶段：leader 选举(<code>leader election</code>)、发现(<code>Discovery</code>)、同步(<code>Synchronization</code>)以及广播(<code>Broadcast</code>)，论文中将阶段一与二合并了，<code>ZAB</code>的实际工程实现耦合了阶段二与三（与论文论述并发完全一致），因此也可以称之为三个阶段。</p>
<a id="more"></a>

<p>本文主要阐述自己对<code>ZAB</code>协议的理解，这源自于<code>ZAB</code>相关的三篇论文的总结，但并非对原论文的完整翻译，因此更准确、更完整且更正式的内容可以参考原论文。值得注意的是，本论文并非如原论文那般详细、正式且全面地阐述<code>ZAB</code>协议，因此读者最好先阅读原论文，可以参考本文的协议解读。另外，本文不会过多阐述<code>ZooKeeper</code>的关键原理及系统架构，读者有兴趣可以参考<a href="https://qqzeng.top/2018/12/04/%E7%90%86%E8%A7%A3%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E6%9C%8D%E5%8A%A1-ZooKeeper/" target="_blank" rel="noopener">文章</a>，以大致了解<code>ZooKeeper</code>协调服务，并从应用层面整体把握<code>ZAB</code>协议。本文先介绍<code>ZAB</code>协议与二阶段提交的关系及与<code>paxos</code>作简单地对比论述。然后按照<code>ZAB</code>协议的四个阶段展开论述。因为本人暂未详细阅读过 Apache <code>ZooKeeper/ZAB</code>的实现源码，因此本文基本不会涉及与实现相关的细节，最后，考虑到本人知识的局限性，如有论述不当之处，谢谢指正！</p>
<p>在阅读<code>ZAB</code>相关之前，本人已初步了解过<code>raft</code>和<code>paxos</code>这两个一致性算法，如果你有了解过<code>raft</code>或者<code>paxos</code>，那么<code>ZAB</code>也较容易理解。直观上理解，<code>paxos</code>和<code>ZAB</code>都可以视作改进的二阶段提交的协议，因为原始的二阶段（包括三阶段）提交协议因为至少受到网络分区影响而不能称被直接应用于分布式系统构建。实际上，<code>ZAB</code>协议本质上是一个简化的二阶段协议，从协议构成的阶段形式上看，<code>leader</code>首先提出一个请求(称之为<code>request</code>或者<code>proposal</code>)，等待<code>follower</code>对请求的投票结果返回，最后综合投票结果以提交请求。但相比原始的二阶段提交，<code>ZAB</code>中<code>follower</code>（或者称<code>backup</code>，协议不同阶段的不同称呼）不会<code>abort</code>来自<code>leader</code>的请求，具体地，它只要么接受(<code>acknowledge</code>)<code>leader</code>的<code>proposal</code>，要么放弃此<code>leader</code>，重新进入新的一轮选举。另外，避免<code>abort</code>操作也意味着在<code>ZAB</code>协议中，<code>leader</code>提交请求并不需要经集群中所有的<code>follower</code>的同意，即只要<code>quorum</code>个<code>follower</code>给<code>leader</code>返回了<code>ACK</code>，则<code>leader</code>即请求已经在集群中达成一致。简化的二阶段提交也使得<code>ZAB</code>不得不面临<code>leader</code>失败的情况，因此，<code>ZAB</code>整个协议流程中必须考虑如何从<code>leader</code>失败中恢复的问题。在二阶段提交中，如果协调者失败，可以选择<code>abort</code>事务（准确而言是三阶段，在这里我们并不作严格区分）。</p>
<p>那么对比于<code>paxos</code>算法，<code>ZAB</code>协议有什么优势（即利用<code>ZAB</code>可以方便、正确且高效实现或满足，但<code>paxos</code>则不能达到此要求）？这包括两个方面：其一，<code>ZAB</code>协议允许客户端并发地发送请求消息，换言之，<code>ZAB</code>（<code>ZAB</code>的<code>primary</code>）能够同时处理若干个消息请求，并能保证请求消息以客户端提出的顺序（请求消息的<code>FIFO</code>顺序）被广播到<code>backup</code>节点。事实上，<code>ZAB</code>的能够提供这样的保证的原因是，<code>ZAB</code>中所有的请求消息 （准确而言，所有的写请求消息，因为只有写请求消息才需要被广播，以保持数据的一致性）都由<code>ZAB</code>中的（唯一一个）<code>primary</code>进行广播。因此，<code>ZAB</code>需要保证协议的始终只存在一个<code>primary</code>节点。然而，<code>paxos</code>协议却不能简单直接地保证此属性。简单而言，在<code>paxos</code>协议中，若各<code>primary</code>并发地提出请求（请求之间遵循一定的依赖关系，即只能按照其提出的顺序应用到集群），那么<code>learner</code>并不能保证按照<code>primary</code>提出事务请求的顺序来学习（应用）消息请求。虽然可以一次性将多个<code>proposal</code>进行打包形成一个单独的<code>proposal</code>，即对这些请求进行批处理，但这会影响到整个算法的性能，而且单个打包的<code>proposal</code>数量也不能简单求得。</p>
<p>其二，<code>ZAB</code>协议被设计成能够迅速从失败（可能是由于<code>leader</code>或<code>follower</code>崩溃或者网络故障而断连）中恢复，即<code>efficient recovery</code>。<code>ZAB</code>使用事务标识机制(<code>trasaction identification scheme</code>)来全局排序事务日志，并保证准<code>leader</code>(<code>prospective leader</code>)能够容易获知需要同步或截断的日志项。详细而言，<code>ZAB</code>采用<code>&lt;value, (epoch|counter)&gt;</code>来唯一标识一条事务日志，其中<code>value</code>为事务日志的内容。<code>epoch</code>（也被称为是<code>instance</code>）为<code>leader</code>的任期，每一个任期内保证只存在一个<code>leader</code>，每当重新进入<code>leader</code>选举时，需要递增此任期，事实上，任期可用于保证当上一任的<code>leader</code>失败重启后不会干扰到当前任期的<code>leader</code>的广播操作（这同<code>raft</code>类似，都采用了<code>epoch</code>以在一段逻辑时间内唯一标识<code>leader</code>）。<code>counter</code>为事务消息计数器，每次重新选举时，需要清空<code>counter</code>，此值随着客户端发送的请求消息而递增。<code>epoch</code>与<code>counter</code>各占 32 位以构成事务的<code>zxid</code>，即作为事务日志的标识。这提供了一种简单且方便的方式来比较事务日志的新旧：先比较<code>epoch</code>，<code>epoch</code>越大，日志越新，当<code>epoch</code>相等时，比较<code>counter</code>，<code>counter</code>越大，日志越新。在此种事务日志标识机制下，只有具备了最新的事务日志的节点才允许将其日志项拷贝到准<code>leader</code>。换言之，准<code>leader</code>只需从各节点返回的所有的日志中选择包含最新的日志的节点，以从此节点拷贝其缺失的事务日志（若需要的话）（需要注意的是，事实上这属于<code>Discover</code>阶段中的协议内容，若把此阶段的协议归并到<code>leader</code>选举中，则选举算法阶段会直接选择包含最新的事务日志的节点作为准<code>leader</code>，因此避免了准<code>leader</code>去包含最新的日志项的节点去拷贝操作）。而<code>paxos</code>协议并未要求失败恢复的高效执行。详细地，在其恢复阶段，只凭借拥有最大的日志编号（在<code>paxos</code>中<code>proposer</code>提出的每一条日志都有一个全局唯一的编号）并不能要求其对应的值被新的<code>leader</code>接受(<code>accpet</code>)（更多可以参考<code>paxos</code>论文或者<a href="https://qqzeng.top/2018/12/20/%E7%90%86%E8%A7%A3-Paxos-Made-Simple/" target="_blank" rel="noopener">这里</a> ），因此，新的<code>leader</code>必须为其缺少的日志编号所对应的日志项重新执行<code>paxos</code>协议阶段一的协议内容。</p>
<p>另外值得注意的是，<code>ZAB</code>采用了<code>TCP</code>（可靠的）作为节点之间的通信协议，因此避免了部分网络故障问题（如消息乱序、重复及丢失），<code>TCP</code>协议能够保证消息能够按照其发出的顺序(<code>FIFO</code>)达到目标节点。但<code>paxos</code>和<code>raft</code>协议并不依赖此条件。</p>
<p>在介绍<code>ZAB</code>协议的各阶段前，先简要声明一些术语。在<code>ZAB</code>协议中，每个节点可能处于三种状态中的一种：<code>following</code>、<code>leading</code>及<code>election</code>。所有的<code>leader</code>和<code>follower</code>都会依次循环执行前述的三个阶段：<code>Discover</code>（发现集群中全局最新的事务）、<code>Synchronization</code>（由<code>leader</code>向<code>follower</code>同步其缺失的事务日志）及<code>Broadcast</code>（由<code>leader</code>向<code>follower</code>广播复制客户端的事务日志），且在阶段一之前，节点处于<code>election</code>状态，当它通过执行<code>leader</code>选举流程后，它会判断自己是否有资格成为<code>leader</code>（收到<code>quorum</code>张选票），否则成为<code>follower</code>，我们暂且将<code>leader</code>选举作为协议的第零个阶段。显然，正常情况下，协议只循环在<code>Broadcast</code>阶段中执行，一旦发生<code>follower</code>与<code>leader</code>断连，则节点自动切换到选举阶段。在节点进入<code>Broadcast</code>前，必须保证集群的数据处于一致的状态。另外，在本文中节点、机器或者<code>server</code>同义；请求日志、事务日志、提案及日志命令等也作同义处理（不严谨，但读者需明白它们的细微区别）。下面各阶段涉及的术语：</p>
<blockquote>
<p>− <code>history</code>: 已被节点所接收的提案日志信息<br>− <code>acceptedEpoch</code>: 接收到的最后一个<code>NEWEPOCH</code>消息的<code>epoch</code>（由准<code>leader</code>生成的<code>epoch</code>）<br>− <code>currentEpoch</code>: 接收到的最后一个<code>NEWLEADER</code>消息的<code>epoch</code>（旧的<code>leader</code>的<code>epoch</code>）<br>− <code>lastZxid</code>: <code>history</code>中最后一个（最新的）事务提案的<code>Zxid</code>编号</p>
</blockquote>
<h2 id="Leader-Election"><a href="#Leader-Election" class="headerlink" title="Leader Election"></a>Leader Election</h2><p>在<code>leader</code>选举阶段，所有节点的初始状态为<code>election</code>，当选举结束后，节点将选举的结果持久化。在此阶段，若节点<code>p</code>给节点<code>q</code>投票，则节点<code>q</code>称节点<code>p</code>的准<code>leader</code>(<code>prospective leader</code>)，直至进入阶段三<code>Broadcast</code>，准<code>leader</code>才能被称为正式的<code>leader</code>(<code>estabilshed leader</code>)，同时它也会担任<code>primary</code>的角色（这样设计有许多优点）。<code>ZAB</code>协议中，<code>leader</code>与<code>primary</code>的称呼基本表示同一个节点，只不过它们是作为同一节点不同阶段（承担不同功能）的称呼。在<code>leader</code>选举过程中，所有的节点最开始都会为自己投票，若经过若干轮的投票广播后，发现自己不够”资格”成为<code>leader</code>时，就会转入<code>following</code>的状态，否则转为<code>leadering</code>状态。<code>leader</code>选举阶段需要为后面的阶段(<code>Broadcast</code>)提供一个后置条件(<code>postcondition</code>)，以保证在进入<code>Broadcast</code>阶段前，各节点的数据处于一致的状态，所谓的<code>postcondition</code>可以表述为<code>leader</code>必须包含所有已提交(<code>commit</code>)的事务日志。</p>
<p>前文提到，部分<code>leader</code>选举实现会直接选择包含最新的日志的节点作为准<code>leader</code>，<code>FLP</code>(<code>Fast Leader Election</code>)正是这样一种选举算法的实现。它通过选择包含有最大的<code>lastZxid</code>（历史日志中最后一条日志记录的<code>zxid</code>）值的节点作为准<code>leader</code>（因为具有最大<code>lastZxid</code>日志的节点必定具有最全的历史日志提交记录），这可以为后阶段的事务广播提供<code>postcondition</code>保证，<code>FLE</code>由若干轮(<code>round</code>)选举组成，在每一轮选举中，状态为<code>election</code>节点之间互相交换投票信息，并根据自己获得的选票信息(发现更好的候选者)不断地更新自己手中的选票。注意，在<code>FLE</code>执行过程中，节点并不会持久化相关状态属性（因此<code>round</code>的值不会被存盘）。</p>
<blockquote>
<p>− <code>recvSet</code>: 用于收集状态为<code>election</code>、<code>following</code>及<code>leading</code>的节点的投票信息<br>− <code>outOfElection</code>:  用于收集状态为<code>following</code>及<code>leading</code>的节点的投票信息（说明选举过程已完成）</p>
</blockquote>
<p>具体的选举的流程大致如下（更详细的流程可以参考论文)：</p>
<p>一旦开始选举，节点的初始状态为<code>election</code>，初始化选举超时时间，初始化<code>recvSet</code>及<code>outOfElection</code>。每个节点先为自己投票，递增<code>round</code>值，并把投票(<code>vote</code>包含节点的<code>lastZxid及id</code>)的消息（<code>notification</code>包含<code>vote, id, state及round</code>）广播给其它节点，即将投票信息发送到各节点的消息队列，并等待节点的回复，此后节点循环从其消息队列中取出其它节点发送给它的消息：</p>
<ul>
<li>若接收到的消息中的<code>round</code>小于其当前的<code>round</code>，则忽略此消息。</li>
<li>若接收到的消息中的<code>round</code>大于节点当前的<code>round</code>，则更新自己的 <code>round</code>，并清空上一轮自己获得的选票的信息集合<code>recvSet</code>。此时，如果消息中的选票的<code>lastZxid</code>比自己的要新，则在本地记录自己为此节点投票，即更新<code>recvSet</code>，否则在本地记录为自己投票。最后将投票信息广播到其它节点的消息队列中。</li>
<li>如果收到的消息的<code>round</code>与节点本地的<code>round</code>相等，即表示两个节点在进行同一轮选举。并且若此消息的<code>state</code>为<code>election</code>并且选票的<code>lastZxid</code>比自己的要新，则在本地记录自己为此节点投票，并广播记录的投票结果。若消息的提案号比自己旧或者跟自己一样，则记录这张选票。</li>
<li>整个选举过程中（节点的状态保持为<code>election</code>，即节点消息队列中的消息包含的状态），若节点检测到自己或其它某个节点得到超过集群半数的选票，自己切换为<code>leading/following</code>状态，随即进入阶段二(<code>Recovery</code>)（<code>FLE</code>选举后，<code>leader</code>具备最新的历史日志，因此，跳过了<code>Discovery</code>阶段，直接进入<code>Synchronization</code>阶段。否则进入<code>Discovery</code>阶段）。</li>
<li>另外，如果在选举过程中，从消息队列中检索出的消息的状态为<code>following</code>或者<code>leading</code>，说明此时选举过程已经完成，因此，消息中的<code>vote</code>即为<code>leader</code>的相关的信息。<ul>
<li>具体而言，如果此时消息中的<code>round</code>与节点相同，先在本地记录选票信息，然后若同时检测到消息中的状态为<code>leading</code>，则节点转为<code>following</code>状态，进入下一阶段，否则若非<code>leading</code>状态，则需检查<code>recvSet</code>来判断消息中的节点是否有资格成为<code>leader</code>。</li>
<li>否则，如果<code>round</code>不同，此时很有可能是选举已经完成。此时节点需要判断消息被投票的节点（有可能为<code>leader</code>）是否在<code>recvSet</code>或<code>outOfElection</code>字典中具备<code>quorum</code>张选票，同时，还要检查此节点是否给自己发送给投票信息，而正式确认此节点的<code>leading</code>状态。这个额外的检查的目的是为了避免这种情况：当协议非正常运行时，如<code>leader</code>检测到与<code>follower</code>失去了心跳连接，则其会自动转入<code>election</code>状态，但此时<code>follower</code>可能并没有意识到<code>leader</code>已经失效（这需要一定的时间，因为不同于<code>raft</code>，在<code>ZAB</code>协议中，<code>leader</code>及<code>follower</code>是通过各自的方式来检测到需要重新进行选举过程）。如果在<code>follower</code>还未检测到的期间内，恰好有新的节点加入到集群，则新加入的节点可能会收到集群中<code>quorum</code>个当前处于<code>following</code>状态的节点对先前的<code>leader</code>的投票（此时它已转入<code>election</code>状态），因此，此时仍需要此新加入的节点进行额外的判断，即检查它是否会收到<code>leader</code>发给它的投票消息（如果确实存在）。</li>
</ul>
</li>
<li>最后，补充一点，<code>ZAB</code>的选举过程同样加入了超时机制（且很可能并非线性超时），以应对当节点超时时间内未收到任何消息时，重新进入下一轮选举。</li>
</ul>
<h2 id="Discovery"><a href="#Discovery" class="headerlink" title="Discovery"></a>Discovery</h2><p><code>Discovery</code>阶段的目的是发现全局（<code>quorum</code>个也符合条件）最新的事务日志，并从此事务日志中获取<code>epoch</code>以构建新的<code>epoch</code>，这可以使历史<code>epoch</code>的<code>leader</code>失效，即不再能提交事务日志。另外，一旦一个处于非<code>leadering</code>状态节点收到其它节点的<code>FOLLOWERINFO</code>消息时，它将拒绝此消息，并重新发起选举。简而言之，此阶段中每一个节点会与它的准<code>leader</code>进行通信，以保证准<code>leader</code>能够获取当前集群中所包含的被提交的最新的事务日志。更详细的流程阐述如下：</p>
<p> 首先，由<code>follower</code>向其准<code>leader</code>发送<code>FOLLOWERINFO</code>（包含节点的<code>accpetedEpoch</code>）消息。当<code>leader</code>收到<code>quorum</code>个<code>FOLLOWERINFO</code>消息后，从这些消息中选择出最大的<code>epoch</code>值，并向此<code>quorum</code>个<code>follower</code>回复<code>NEWEPOCH</code>（包含最大的<code>epoch</code>）消息。接下来，当<code>follower</code>收到<code>leader</code>的回复后，将<code>NEWEPOCH</code>中的<code>epoch</code>与其本地的<code>epoch</code>进行对比，若回复消息中的<code>epoch</code>更大，则将自己本地的<code>accpetedEpoch</code>设置为<code>NEWEPOCH</code>消息中的<code>epoch</code>值，并向<code>leader</code>回复<code>ACKEPOCH</code>（包含节点的<code>currentEpoch</code>，<code>history</code>及<code>lastZxid</code>）消息。反之，重新进入选举阶段，即进入阶段零。当<code>leader</code>从<code>quorum</code>个节点收到<code>follower</code>的<code>ACKEPOCH</code>消息后，从这些<code>ACKEPOCH</code>消息中(<code>history</code>)查找出最新的（先比较<code>currentEpoch</code>，再比较<code>lastZxid</code>）历史日志信息，并用它覆盖<code>leader</code>本地的<code>history</code>事务日志。随即进入阶段二。</p>
<h2 id="Synchronization"><a href="#Synchronization" class="headerlink" title="Synchronization"></a>Synchronization</h2><p><code>Synchronization</code>阶段包含了失败恢复的过程，在这个阶段中，<code>leaer</code>向<code>follower</code>同步其最新的历史事务日志。简而言之，<code>leader</code>向<code>follower</code>发送其在阶段一中更新的历史事务日志，而<code>follower</code>将其与自己本地的历史事务日志进行对比，如果<code>follower</code>发现本地的日志集更旧，则会将这些日志应用追加到其本地历史日志集合中，并应答<code>leader</code>。而当<code>leader</code>收到<code>quorum</code>个回复消息后，立即发送<code>commit</code>消息，此时准<code>leader</code>(<code>prospective leader</code>)变成了正式<code>leader</code>(<code>established leader</code>)。更详细的流程阐述如下：</p>
<p>首先由准<code>leader</code>向<code>quorum</code>发送<code>NEWLEADER</code>（包含阶段一中的最大<code>epoch</code>及<code>history</code>），当<code>follower</code>收到<code>NEWLEADER</code>消息后，其对比消息中的<code>epoch</code>与其本地的<code>acceptedEpoch</code>，若二者相等，则更新自己的<code>currentEpoch</code>并且接收那些比自己新的事务日志，最后，将本地的<code>history</code>设置为消息中的<code>history</code>集合。之后向<code>leader</code>回复<code>ACKNEWLEADER</code>消息。若<code>leader</code>消息中的<code>epoch</code>与本地的不相等，则转为<code>election</code>状态，并进入选举阶段。当<code>leader</code>收到<code>quorum</code>个<code>ACKNEWLEADER</code>消息后，接着向它们发送<code>COMMIT</code>消息，并进入阶段三。而<code>follower</code>收到<code>COMMIT</code>消息后，将上一阶段接收的事务日志进行正式提交，同样进入阶段三。</p>
<p>事实上，在有些实现中，会对同步阶段进行优化，以提高效率。具体而言，<code>leader</code>实际上拥有两个与日志相关的属性（在前述中，我们只用了<code>history</code>来描述已提交的事务日志），其一为<code>outstandingProposals</code>：每当<code>leader</code>提出一个事务日志，都会将该日志存放至<code>outstandingProposals</code>字典中，一旦议案被过半认同了，就要提交该议案，则从<code>outstandingProposals</code>中删除该议案；其二为<code>toBeApplied</code>：每当准备提交一个议案，就会将该议案存放至<code>toBeApplied</code>中，一旦议案应用到<code>ZooKeeper</code>的内存树中了，就可以将该议案从<code>toBeApplied</code>集合中删除。因此，这将日志同步大致分为两个方面：</p>
<ul>
<li>一方面，对于那些已应用的日志（已经从<code>toBeApplied</code>集合中移除）可以通过不同的方式来进行同步：若<code>follower</code>消息中的<code>lastZxid</code>要小于<code>leader</code>设定的某一个事务日志索引(<code>minCommittedLog</code>)，则此时采用快照会更高效。也存在这样一种情况，<code>follower</code>中包含多余的事务日志，此时其<code>lastZxid</code>会大于<code>leader</code>的最新的已提交的事务日志索引(<code>maxCommittedLog</code>)，因此，会把多余的部分删除。最后一种情况是，消息中的<code>lastZxid</code>位于二个索引之间，因此，<code>leader</code>需要把<code>follower</code>缺失的事务日志发送给<code>follower</code>。当然，也会存在二者存在日志冲突的情况，即<code>leader</code>并没有找到<code>lastZxid</code>对应的事务日志，此时需要删除掉<code>follower</code>与<code>leader</code>冲突的部分，然后再进行同步。</li>
<li>另一方面，对于那些未应用的日志的同步方式为：对于<code>toBeApplied</code>集合中的日志（已提交，但未应用到内存），则直接将大于<code>follower</code>的<code>lastZxid</code>的索引日志发送给<code>follower</code>，同时发送提交命令。对于<code>outstandingProposals</code>的事务日志，则同样依据同样的规则发送给<code>follower</code>，但不会发送提交命令。</li>
</ul>
<p>需要注意的的，在进行日志同步时，需要先获取<code>leader</code>的内存数据的读锁（因此在释放读锁之前不能对<code>leader</code>的内存数据进行写操作）。但此同步过程仅涉及到确认需要同步的议案，即将需要被同步的议案放置到对应<code>follower</code>的队列中即可，后续会通过异步方式进行发送。但快照同步则是同步写入阻塞。</p>
<p>当同步完成后，<code>leader</code>会几<code>follower</code>发送<code>UPTODATE</code>命令，以表示同步完成。此时，<code>leader</code>开始进入心跳检测过程，周期性地向<code>follower</code>发送心跳，并检查是否有<code>quorum</code>节点回复心跳，一旦出现心跳断连，则转为<code>election</code>状态，进入leader选举阶段。</p>
<h2 id="Broadcast"><a href="#Broadcast" class="headerlink" title="Broadcast"></a>Broadcast</h2><p><code>Broadcast</code>为<code>ZAB</code>正常工作所处的阶段。当进入此阶段，<code>leader</code>会调用<code>ready(epoch)，</code>以使得<code>ZooKeeper</code>应用层能够开始广播事务日志到<code>ZAB</code>协议。同时，此阶段允许动态的加入新节点(<code>follower</code>)，因此，<code>leader</code>必须在新节点加入的时候，与这些节点建立通信连接，并将最新日志同步到这些节点。更详细的流程阐述如下：</p>
<p>当<code>leader</code>(<code>primary</code>)收到客户端发送的消息（写）请求<code>value</code>，它将消息请求转化为事务日志<code>(epoch, &lt;value,zxid&gt;), zxid=(epoch|counter)</code>，广播出去。当<code>follower</code>从<code>leader</code>收到事务请求时，将此事务日志追加到本地的历史日志<code>history</code>，并向<code>leader</code>回复<code>ACK</code>。而一旦<code>leader</code>收到<code>quorum</code>个<code>ACK</code>后，随即向<code>quorum</code>节点发送<code>COMMIT</code>日志，当<code>follower</code>收到此命令后，会将未提交的日志正式进行提交。需要注意的是，当有新的节点加入时，即在<code>Broadcast</code>阶段，若<code>leader</code>收到<code>FOLLOWINFO</code>消息，则它会依次发送<code>NEWEPOCH</code>和<code>NEWLEADER</code>消息，并带上<code>epoch</code>及<code>history</code>。收到此消息的节点会将设置节点本地的<code>epoch</code>并更新本地历史日志。</p>
<p>根据在<code>Synchronization</code>提到的两个数据结构<code>outstandingProposals</code>及<code>toBeApplied</code>。因此，事实上，<code>leader</code>会将其提出的事务日志放至<code>outstandingProposals</code>，如果获得了<code>quorum</code>节点的回复，则会将其从<code>outstandingProposals</code>中移除，并将事务日志放入<code>toBeApplied</code>集合，然后开始提交议案，即将事务日志应用到内存中，同时更新<code>lastZxid</code>，并将事务日志保存作缓存，同时更新<code>maxCommittedLog</code>和<code>minCommittedLog</code>。</p>
<p>最后，讨论<code>ZAB</code>协议中两个额外的细节：</p>
<ul>
<li>若<code>leader</code>宕机，<code>outstandingProposals</code>字典及<code>toBeApplied</code>集合便失效（并没有持久化），因此它们对于<code>leader</code>的恢复并不起作用，而只是在<code>Synchronization</code>阶段（该阶段实际上是<code>leader</code>向<code>follower</code>同步日志，即也可以看成是<code>follower</code>挂了，重启后的日志同步过程），且同步过程包含快照同步及日志恢复。</li>
<li>另外，在日志恢复阶段，协议会将所有最新的事务日志作为已经提交的事务来处理的，换言之，这里面可能会有部分事务日志还未真正提交，而这里全部当做已提交来处理。（这与<code>raft</code>不同，个人认为，这并不会产生太大影响，因为在日志恢复过程中，并不会恢复那些未被<code>quorum</code>节点通过的事务日志，只是在<code>ZAB</code>在提交历史任期的日志的时机与<code>raft</code>不同，<code>rfat</code>不会主动提交历史任期未提交的日志，只在新的<code>leader</code>提交当前任期内的日志时顺便提交历史的未提交但已经复制到<code>quorum</code>节点的日志项）。</li>
</ul>
<p>需要注意的是，本文使用的一些术语与<code>Yahoo!</code>官方发表的论文[2]可能不一样（个人参照另外一篇论文[4]阐述），但它们的问题意义相同。而且，对于每个阶段，本文先是大概阐述其流程，然后从实际实现的角度进行拓展，希望不要造成读者的困扰。另外，实际工程实现可能并不完全符合这些阶段，而且<code>ZooKeeper</code>各版本的实现也可能会包含不同的工程优化细节。具体参考论文，当然，查看<code>ZooKeeper</code>源码实现可能更清晰。</p>
<p>参考文献</p>
<p>[1] Gray J N. Notes on data base operating systems[M]//Operating Systems. Springer, Berlin, Heidelberg, 1978: 393-481.<br>[2] Junqueira F P, Reed B C, Serafini M. Zab: High-performance broadcast for primary-backup systems[C]//Dependable Systems &amp; Networks (DSN), 2011 IEEE/IFIP 41st International Conference on. IEEE, 2011: 245-256.<br>[3] Reed B, Junqueira F P. A simple totally ordered broadcast protocol[C]//proceedings of the 2nd Workshop on Large-Scale Distributed Systems and Middleware. ACM, 2008: 2.<br>[4] Medeiros A. ZooKeeper’s atomic broadcast protocol: Theory and practice[J]. Aalto University School of Science, 2012, 20.<br>[5] 倪超. 从 Paxos 到 Zookeeper: 分布式一致性原理与实践[J]. 2015.<br>[6]. <a href="https://my.oschina.net/pingpangkuangmo/blog/778927" target="_blank" rel="noopener">ZooKeeper的一致性算法赏析</a></p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>一致性算法</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>一致性协议</tag>
        <tag>原子广播协议</tag>
        <tag>选举算法</tag>
      </tags>
  </entry>
  <entry>
    <title>MyBatis注解概览</title>
    <url>/2018/12/30/2018-12-30-MyBatis%E6%B3%A8%E8%A7%A3%E6%A6%82%E8%A7%88/</url>
    <content><![CDATA[<h1 id="映射器注解"><a href="#映射器注解" class="headerlink" title="映射器注解"></a>映射器注解</h1><p>&emsp;&emsp;因为最初设计时，MyBatis 是一个 XML 驱动的框架。配置信息是基于 XML 的，而且映射语句也是定义在 XML 中的。而到了 MyBatis 3，就有新选择了。MyBatis 3 构建在全面且强大的基于 Java 语言的配置 API 之上。这个配置 API 是基于 XML 的 MyBatis 配置的基础，也是新的基于注解配置的基础。注解提供了一种简单的方式来实现简单映射语句，而不会引入大量的开销。</p>
<a id="more"></a>

<h1 id="注解说明"><a href="#注解说明" class="headerlink" title="注解说明"></a>注解说明</h1><table>
<thead>
<tr>
<th align="left">注解</th>
<th align="left">对象</th>
<th align="left">XML标签</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>@CacheNamespace</code></td>
<td align="left"><code>类</code></td>
<td align="left"><code>&lt;cache&gt;</code></td>
<td align="left">为给定的命名空间（比如类）配置缓存。属性有：<code>implemetation</code>, <code>eviction</code>, <code>flushInterval</code>, <code>size</code>, <code>readWrite</code>, <code>blocking</code> 和<code>properties</code>。</td>
</tr>
<tr>
<td align="left"><code>@Property</code></td>
<td align="left">N/A</td>
<td align="left"><code>&lt;property&gt;</code></td>
<td align="left">指定参数值或占位值（placeholder）（能被 <code>mybatis-config.xml</code>内的配置属性覆盖）。属性有：<code>name</code>, <code>value</code>。（仅在MyBatis 3.4.2以上版本生效）</td>
</tr>
<tr>
<td align="left"><code>@CacheNamespaceRef</code></td>
<td align="left"><code>类</code></td>
<td align="left"><code>&lt;cacheRef&gt;</code></td>
<td align="left">参照另外一个命名空间的缓存来使用。属性有：<code>value</code>, <code>name</code>。如果你使用了这个注解，你应设置 <code>value</code> 或者 <code>name</code>属性的其中一个。<code>value</code> 属性用于指定 Java 类型而指定命名空间（命名空间名就是指定的 Java 类型的全限定名），<code>name</code> 属性（这个属性仅在MyBatis 3.4.2以上版本生效）直接指定了命名空间的名字。</td>
</tr>
<tr>
<td align="left"><code>@ConstructorArgs</code></td>
<td align="left"><code>方法</code></td>
<td align="left"><code>&lt;constructor&gt;</code></td>
<td align="left">收集一组结果传递给一个结果对象的构造方法。属性有：<code>value</code>，它是形式参数数组。</td>
</tr>
<tr>
<td align="left"><code>@Arg</code></td>
<td align="left">N/A</td>
<td align="left"><code>&lt;arg&gt;``&lt;idArg&gt;</code></td>
<td align="left">单参数构造方法，是 ConstructorArgs 集合的一部分。属性有：<code>id</code>, <code>column</code>, <code>javaType</code>, <code>jdbcType</code>, <code>typeHandler</code>, <code>select</code> 和 <code>resultMap</code>。id 属性是布尔值，来标识用于比较的属性，和<code>&lt;idArg&gt;</code> XML 元素相似。</td>
</tr>
<tr>
<td align="left"><code>@TypeDiscriminator</code></td>
<td align="left"><code>方法</code></td>
<td align="left"><code>&lt;discriminator&gt;</code></td>
<td align="left">一组实例值被用来决定结果映射的表现。属性有：<code>column</code>, <code>javaType</code>, <code>jdbcType</code>, <code>typeHandler</code> 和 <code>cases</code>。cases 属性是实例数组。</td>
</tr>
<tr>
<td align="left"><code>@Case</code></td>
<td align="left">N/A</td>
<td align="left"><code>&lt;case&gt;</code></td>
<td align="left">单独实例的值和它对应的映射。属性有：<code>value</code>, <code>type</code>, <code>results</code>。results 属性是结果数组，因此这个注解和实际的 <code>ResultMap</code> 很相似，由下面的 <code>Results</code> 注解指定。</td>
</tr>
<tr>
<td align="left"><code>@Results</code></td>
<td align="left"><code>方法</code></td>
<td align="left"><code>&lt;resultMap&gt;</code></td>
<td align="left">结果映射的列表，包含了一个特别结果列如何被映射到属性或字段的详情。属性有：<code>value</code>, <code>id</code>。value 属性是 <code>Result</code> 注解的数组。这个 id 的属性是结果映射的名称。</td>
</tr>
<tr>
<td align="left"><code>@Result</code></td>
<td align="left">N/A</td>
<td align="left"><code>&lt;result&gt;``&lt;id&gt;</code></td>
<td align="left">在列和属性或字段之间的单独结果映射。属性有：<code>id</code>, <code>column</code>, <code>javaType</code>, <code>jdbcType</code>, <code>typeHandler</code>, <code>one</code>, <code>many</code>。id 属性是一个布尔值，来标识应该被用于比较（和在 XML 映射中的<code>&lt;id&gt;</code>相似）的属性。one 属性是单独的联系，和 <code>&lt;association&gt;</code> 相似，而 many 属性是对集合而言的，和<code>&lt;collection&gt;</code>相似。它们这样命名是为了避免名称冲突。</td>
</tr>
<tr>
<td align="left"><code>@One</code></td>
<td align="left">N/A</td>
<td align="left"><code>&lt;association&gt;</code></td>
<td align="left">复杂类型的单独属性值映射。属性有：<code>select</code>，已映射语句（也就是映射器方法）的全限定名，它可以加载合适类型的实例。<code>fetchType</code>会覆盖全局的配置参数 <code>lazyLoadingEnabled</code>。注意 联合映射在注解 API中是不支持的。这是因为 Java 注解的限制,不允许循环引用。</td>
</tr>
<tr>
<td align="left"><code>@Many</code></td>
<td align="left">N/A</td>
<td align="left"><code>&lt;collection&gt;</code></td>
<td align="left">映射到复杂类型的集合属性。属性有：<code>select</code>，已映射语句（也就是映射器方法）的全限定名，它可以加载合适类型的实例的集合，<code>fetchType</code> 会覆盖全局的配置参数 <code>lazyLoadingEnabled</code>。注意 联合映射在注解 API中是不支持的。这是因为 Java 注解的限制，不允许循环引用</td>
</tr>
<tr>
<td align="left"><code>@MapKey</code></td>
<td align="left"><code>方法</code></td>
<td align="left"></td>
<td align="left">这是一个用在返回值为 Map 的方法上的注解。它能够将存放对象的 List 转化为 key 值为对象的某一属性的 Map。属性有： <code>value</code>，填入的是对象的属性名，作为 Map 的 key 值。</td>
</tr>
<tr>
<td align="left"><code>@Options</code></td>
<td align="left"><code>方法</code></td>
<td align="left">映射语句的属性</td>
<td align="left">这个注解提供访问大范围的交换和配置选项的入口，它们通常在映射语句上作为属性出现。<code>Options</code> 注解提供了通俗易懂的方式来访问它们，而不是让每条语句注解变复杂。属性有：<code>useCache=true</code>, <code>flushCache=FlushCachePolicy.DEFAULT</code>, <code>resultSetType=FORWARD_ONLY</code>, <code>statementType=PREPARED</code>, <code>fetchSize=-1</code>, <code>timeout=-1</code>, <code>useGeneratedKeys=false</code>, <code>keyProperty=&quot;id&quot;</code>, <code>keyColumn=&quot;&quot;</code>, <code>resultSets=&quot;&quot;</code>。值得一提的是， Java 注解无法指定 <code>null</code> 值。因此，一旦你使用了 <code>Options</code> 注解，你的语句就会被上述属性的默认值所影响。要注意避免默认值带来的预期以外的行为。    注意： <code>keyColumn</code> 属性只在某些数据库中有效（如 Oracle、PostgreSQL等）。请在插入语句一节查看更多关于 <code>keyColumn</code> 和 <code>keyProperty</code> 两者的有效值详情。</td>
</tr>
<tr>
<td align="left"><code>@Insert</code></td>
<td align="left"><code>方法</code></td>
<td align="left"><code>&lt;insert&gt;</code></td>
<td align="left">这四个注解分别代表将会被执行的 SQL 语句。它们用字符串数组（或单个字符串）作为参数。如果传递的是字符串数组，字符串之间先会被填充一个空格再连接成单个完整的字符串。这有效避免了以 Java 代码构建 SQL 语句时的“丢失空格”的问题。然而，你也可以提前手动连接好字符串。属性有：<code>value</code>，填入的值是用来组成单个 SQL 语句的字符串数组。</td>
</tr>
<tr>
<td align="left"><code>@Update</code></td>
<td align="left"><code>方法</code></td>
<td align="left"><code>&lt;update&gt;</code></td>
<td align="left">同上</td>
</tr>
<tr>
<td align="left"><code>@Delete</code></td>
<td align="left"><code>方法</code></td>
<td align="left"><code>&lt;delete&gt;</code></td>
<td align="left">同上</td>
</tr>
<tr>
<td align="left"><code>@Select</code></td>
<td align="left"><code>方法</code></td>
<td align="left"><code>&lt;select&gt;</code></td>
<td align="left">同上</td>
</tr>
<tr>
<td align="left"><code>@InsertProvider</code></td>
<td align="left"><code>方法</code></td>
<td align="left"><code>&lt;insert&gt;</code></td>
<td align="left">允许构建动态 SQL。这些备选的 SQL 注解允许你指定类名和返回在运行时执行的 SQL 语句的方法。（自从MyBatis 3.4.6开始，你可以用 <code>CharSequence</code> 代替 <code>String</code> 来返回类型返回值了。）当执行映射语句的时候，MyBatis 会实例化类并执行方法，类和方法就是填入了注解的值。你可以把已经传递给映射方法了的对象作为参数，”Mapper interface type” 和 “Mapper method” 会经过 <code>ProviderContext</code> （仅在MyBatis 3.4.5及以上支持）作为参数值。（MyBatis 3.4及以上的版本，支持多参数传入）属性有： <code>type</code>, <code>method</code>。<code>type</code> 属性需填入类。<code>method</code> 需填入该类定义了的方法名。注意 接下来的小节将会讨论类，能帮助你更轻松地构建动态 SQL。</td>
</tr>
<tr>
<td align="left"><code>@UpdateProvider</code></td>
<td align="left"><code>方法</code></td>
<td align="left"><code>&lt;update&gt;</code></td>
<td align="left">同上</td>
</tr>
<tr>
<td align="left"><code>@DeleteProvider</code></td>
<td align="left"><code>方法</code></td>
<td align="left"><code>&lt;delete&gt;</code></td>
<td align="left">同上</td>
</tr>
<tr>
<td align="left"><code>@SelectProvider</code></td>
<td align="left"><code>方法</code></td>
<td align="left"><code>&lt;select&gt;</code></td>
<td align="left">同上</td>
</tr>
<tr>
<td align="left"><code>@Param</code></td>
<td align="left"><code>参数</code></td>
<td align="left">N/A</td>
<td align="left">如果你的映射方法的形参有多个，这个注解使用在映射方法的参数上就能为它们取自定义名字。若不给出自定义名字，多参数（不包括 <code>RowBounds</code> 参数）则先以 “param” 作前缀，再加上它们的参数位置作为参数别名。例如 <code>#{param1}</code>, <code>#{param2}</code>，这个是默认值。如果注解是 <code>@Param(&quot;person&quot;)</code>，那么参数就会被命名为 <code>#{person}</code>。</td>
</tr>
<tr>
<td align="left"><code>@SelectKey</code></td>
<td align="left"><code>方法</code></td>
<td align="left"><code>&lt;selectKey&gt;</code></td>
<td align="left">这个注解的功能与 <code>&lt;selectKey&gt;</code> 标签完全一致，用在已经被 <code>@Insert</code> 或 <code>@InsertProvider</code> 或 <code>@Update</code> 或 <code>@UpdateProvider</code> 注解了的方法上。若在未被上述四个注解的方法上作 <code>@SelectKey</code> 注解则视为无效。如果你指定了 <code>@SelectKey</code> 注解，那么 MyBatis 就会忽略掉由 <code>@Options</code> 注解所设置的生成主键或设置（configuration）属性。属性有：<code>statement</code> 填入将会被执行的 SQL 字符串数组，<code>keyProperty</code> 填入将会被更新的参数对象的属性的值，<code>before</code> 填入 <code>true</code> 或 <code>false</code> 以指明 SQL 语句应被在插入语句的之前还是之后执行。<code>resultType</code> 填入 <code>keyProperty</code> 的 Java 类型和用 <code>Statement</code>、 <code>PreparedStatement</code> 和 <code>CallableStatement</code> 中的 <code>STATEMENT</code>、 <code>PREPARED</code> 或 <code>CALLABLE</code> 中任一值填入 <code>statementType</code>。默认值是 <code>PREPARED</code>。</td>
</tr>
<tr>
<td align="left"><code>@ResultMap</code></td>
<td align="left"><code>方法</code></td>
<td align="left">N/A</td>
<td align="left">这个注解给 <code>@Select</code> 或者 <code>@SelectProvider</code> 提供在 XML 映射中的 <code>&lt;resultMap&gt;</code> 的id。这使得注解的 select 可以复用那些定义在 XML 中的 ResultMap。如果同一 select 注解中还存在 <code>@Results</code> 或者 <code>@ConstructorArgs</code>，那么这两个注解将被此注解覆盖。</td>
</tr>
<tr>
<td align="left"><code>@ResultType</code></td>
<td align="left"><code>方法</code></td>
<td align="left">N/A</td>
<td align="left">此注解在使用了结果处理器的情况下使用。在这种情况下，返回类型为 void，所以 Mybatis 必须有一种方式决定对象的类型，用于构造每行数据。如果有 XML 的结果映射，请使用 <code>@ResultMap</code> 注解。如果结果类型在 XML 的 <code>&lt;select&gt;</code>节点中指定了，就不需要其他的注解了。其他情况下则使用此注解。比如，如果 @Select 注解在一个将使用结果处理器的方法上，那么返回类型必须是 void 并且这个注解（或者@ResultMap）必选。这个注解仅在方法返回类型是 void 的情况下生效。</td>
</tr>
<tr>
<td align="left"><code>@Flush</code></td>
<td align="left"><code>方法</code></td>
<td align="left">N/A</td>
<td align="left">如果使用了这个注解，定义在 Mapper 接口中的方法能够调用 <code>SqlSession#flushStatements()</code> 方法。（Mybatis 3.3及以上）</td>
</tr>
</tbody></table>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="http://www.mybatis.org/mybatis-3/zh/java-api.html" target="_blank" rel="noopener">MyBatis 官方文档</a>    </p>
]]></content>
      <categories>
        <category>后端开发</category>
      </categories>
      <tags>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title>理解 Paxos Made Simple</title>
    <url>/2018/12/20/%E7%90%86%E8%A7%A3-Paxos-Made-Simple/</url>
    <content><![CDATA[<p>Paxos 算法在分布式系统领域早已是如雷贯耳般的存在，基本成为了分布式一致性协议的代名词，想必对于任何一个从事分布式领域的人来说都充满敬畏——即感叹算法的精巧，也畏惧算法的晦涩。Leslie Lamport 早在 1980s 就写作了描述 <code>Paxos</code>最原始的论文 《The Part-Time Parliament》，但因其难以理解（与论述方式相关?）而没有得到过多的关注（相反，Lamport 本人却坚持认为自己采用了一种更加形象恰当且容易理解的方式阐述，摈弃了传统学术论文的”死板“风格）。在 2001年，Lamport 对 <code>Paxos</code> 论文进行整理简化并发表了《Paxos Made Simple》，引起了广泛关注。论文的第一句话 The Paxos algorithm, when presented in plain English, is very simple 可以体会到 Leslie Lamport 似乎仍旧对众人对 <code>Paxos</code> 冠以难理解性的言行的”不屑“。</p>
<a id="more"></a>

<p>最近重新阅读了《Paxo Made Simple》论文，想从论文本身出发，阐述自己对论文的一些（浅显，且可能有误）的理解，因为还未了解<code>Paoxs</code>系列其它论文（如 Fast Paxos），因此个人的理解可能存在一定的局限性。同时，个人坚持认为，反复读原始论文是理解算法的最根本途径，最好结合开源实现进行理解（开源实现一般都会对算法进行工程上的优化与”妥协”）。当然读完原论文可能会有困惑，因此，也可以尝试参考别人的理解（从不同的角度思考问题，或许会有收获），但最终还是要回归论文。如果你对本文有兴趣，你需要先阅读论文。另外，你需要先了解其应用场景。本文先简述其应用场景，然后按照原论文推理的逻辑和步骤来逐步阐述自己对这些步骤的理解。</p>
<h2 id="Paxos-应用场景"><a href="#Paxos-应用场景" class="headerlink" title="Paxos 应用场景"></a>Paxos 应用场景</h2><p><code>Paxos</code>用于解决分布式场景的一致性问题。换言之，<code>Paxos</code>是一个一致性（共识）算法。这个说法可能比较笼统宽泛，因为你可能在很多领域了解过一致性问题（虽然这些解释背后的含义可能也存在共性）。比如对于分布式存储，典型的<code>Nosql</code>数据库领域，所谓的一致性可能是要求客户端能够读取其最新写入的数据。换言之，最近写入的数据需要对所后续的客户端的读都可见，强调的是可见性。这可以用线性一致性(<code>Linearizability</code>)来描述；再者，在数据库领域，顺序一致性(<code>serializability</code>)是事务正确性的保证，即强调正确性；而复制状态机(<code>replicated state machine</code>)是很多一致性算法的典型应用场景（包括<code>Paxos</code>），其强调的是让一组互为备份的节点执行一系列相同的命令日志来保证存储在此节点集合中的数据的一致，以达到容错目的。另外，从一致性算法的强弱角度来考虑，一致性算法包括强一致性，弱一致性以及最终一致性。而<code>Paxos</code>则属于强一致性算法。另外，我们再简单了共识算法的正确性的保证：</p>
<blockquote>
<ol>
<li><em>Agreement</em> - all N (or a majority) nodes decide on the same value</li>
<li><em>Validity</em> - the value that is decided upon must have been proposed by some node in N</li>
<li><em>Termination</em> - all nodes eventually decide</li>
</ol>
</blockquote>
<p>这些都容易理解，比如，对于<code>Agreement</code>而言，若某个算法都不难最后表决出来的值是同一个，那就不能称之为共识算法，而<code>Validity</code>可能觉得是很显然的事情，可以从这样一个角度思考，如果所有节点始终回复相同的值，而不管实际提出的值是什么，那么<code>Agreement</code>能够得到保证，但却违反了<code>Validity</code>条件。最后的<code>Termination</code>保证了算法最终能够停止，即我们不仅希望你们能够做表决，也希望能够最终表决出一个结果，否则此表决过程没有意义。而<code>Paxos</code>论文提到的<code>safty requirement</code> 如下：</p>
<blockquote>
<ol>
<li>Only a value that has been proposed may be chosen,</li>
<li>Only a single value is chosen, and</li>
<li>A process never learns that a value has been chosen unless it actually has been.</li>
</ol>
</blockquote>
<p>明确提出了，只保证了前面两点(<code>Agreement</code>及<code>Validity</code>，只是换了一种说法，并颠倒1与2的顺序)，换言之，理论上而言，<code>Paxos</code>是存在活锁的问题，后面会详细阐述。当然<code>Paxos</code>算法只考虑节点存在<code>non-Byzantine</code>及<code>asynchronous</code>网络的条件下。</p>
<p>那么<code>Paxos</code>如何应用于复制状态机呢？简单而言，<code>Paxos</code>试图通过对所有的（客户端发送的）命令日志（如<code>SET X=1</code>）进行全局编号，如果能够全局编号成功，那么互为备份的节点按照此全局编号顺序来执行对应的命令日志，即能够保证数据的一致性。在一个分布式系统中，若执行命令日志序列前，系统处于一致的状态，且节点都执行了相同的命令日志序列，那么最终整个系统也处于一个一致的状态。因此为了保证每个节点都能够以相同的顺序执行命令日志，所有节点必须对于每一条命令日志达成共识（比如，有两个节点尝试提交命令日志，节点<code>a</code>尝试让<code>v=i</code>，而节点<code>b</code>尝试让<code>v=j</code>，明显这会产生冲突，因此需要协调以达成共识，即最终<code>v</code>的值要么是<code>i</code>，那么所有节点都会认为<code>v=a</code>），即每个节点看到的指令顺序是一致的。显然，问题在于不同的节点可能接收到的日志的编号的顺序是不同的，因此不能按照单个节点的意愿进行命令日志的执行（否则会出现数据一致的情况），换言之，所有节点需要相互通信协调，每个节点都对全局编号的排序进行表决。每一次表决，只能对一条命令日志（数据）进行编号，这样才能保证确定的日志执行，这也正是<code>Paxos</code>所做的，即<code>Paxos</code>的核心在于确保每次表决只产生一条命令日志（一个<code>value</code>，这里的命令日志可以表示一个操作，也可以表示一个值）。当然某一次表决成功（达成一致）并不意味着此时所有节点的本地的<code>value</code>都相同，因为可能有节点宕机，即通常而言，只要保证大多数(<code>quorum</code>)个节点存储相同的<code>value</code>即可。</p>
<h2 id="论文理解"><a href="#论文理解" class="headerlink" title="论文理解"></a>论文理解</h2><p>这里省略了协议的一些基本术语及概念。但还是再强调一下，协议对某个数据达成一致的真正含义提什么，其表示<code>proposer</code>、<code>acceptor</code>及<code>learner</code>都要认为同一个值被选定。详细而言，对于<code>acceptor</code>而言，只要其接受了某个<code>proposal</code>，则其就认定该<code>proposal</code>的<code>value</code>被选定了。而对于<code>proposer</code>而言，只要其<code>issue</code>的<code>proposal</code>被<code>quorum</code>个<code>acceptor</code>接受了，则其就认定该<code>proposal</code>对应的<code>value</code>就被选定了。最后对于<code>learner</code>而言，需要<code>acceptor</code>将最终决定的<code>value</code>发送给它，则其就认定该<code>value</code>被选定了。另外，<code>acceptor</code>是可能有多个的，因为单个<code>acceptor</code>很明显存在单点故障的问题。</p>
<p>我们直接一步步来观察 Lamport 论文中的推导，以达到最终只有一个值被选中的目的（确定一个值），即<code>Only a single value is chosen</code>。这句话很重要，它暗示了不能存在这样的情形，某个时刻<code>v</code>被决定为了<code>i</code>，而在另一时刻<code>v</code>又被决定成了<code>j</code>。</p>
<blockquote>
<p>P1. An acceptor must accept the ﬁrst proposal that it receives.</p>
</blockquote>
<p>乍一看此条件，让人有点不知所措。论文前一句提到，在没有故障的情况，我们希望当只有一个<code>proposer</code>的时候，并且其只提出一个<code>value</code>时，能够有一个<code>value</code>被选中，然后就引出了<code>P1</code>。这是理所当然的，因为此<code>acceptor</code>之前没有收到任何的<code>value</code>，或许后面也不会收到了，那它选择此<code>value</code>就无可厚非。换言之，此时<code>acceptor</code>并没有一个合适的拒绝策略，只能先选择这个值。但很明显，这个条件远不能达到我们的目的（比如，多个<code>acceptor</code>可能会接受到不同的<code>proposer</code>提出的不同的<code>value</code>，直接导致不同的<code>value</code>被选定，因此不可能只决定一个值）。而且仔细想想，作者提出的这个条件确实比较奇怪，因为你不知道此条件与最终协议的充要条件有什么联系，而且，你可能会想，既然已经选择了第一个值，若后面又有第二个<code>proposal</code>来了应该如何处理（才能保证最终只选择一个值）。直观上我们可能会推断出，每个<code>acceptor</code>只接受一个<code>proposal</code>是行不通的，即它可能会接受多个<code>proposal</code>，那既然会接受多个<code>proposal</code>，这些<code>proposal</code>肯定是不同的（至少是不同时间点收到的），因此需要进行区分衡量，这也正是提案编号<code>proposal id</code>的作用。另外还暗示了一点，正常情况下，对于<code>proposer</code>而言，一个<code>proposal</code>不能由只被一个<code>acceptor</code>接受了就认定其<code>value</code>被选定，必须要由大多数的（即法定集合<code>quorum</code>）选定才能说这个值被选定了。</p>
<p>直观上理解，虽然我们允许了一个<code>acceptor</code>可以<code>accept</code>多个<code>proposal</code>，但为了保证最终只能决定一个<code>value</code>，因此很容易想到的办法是保证<code>acceptor</code>接受的多个<code>proposal</code>的<code>value</code>相同。这便引出了<code>P2</code>：</p>
<blockquote>
<p>P2. If a proposal with value v is chosen, then every higher-numbered proposal that is chosen has value v.</p>
</blockquote>
<p>为了保证每次只选定一个值，<code>P2</code>规定了如果在一个<code>value</code>已经被选定的情况下，若还有的<code>proposer</code>提交<code>value</code>，那么之后（拥有更高编号<code>higher-numbered</code>）被<code>accept</code>的<code>value</code>应该与之前已经被<code>accept</code>的保持一致。这是一个比较强的约束条件。显然，如果能够保证<code>P2</code>，那么也能够够保证<code>Paxos</code>算法的正确性。</p>
<p>但从另一方面考虑，对比<code>P1</code>与<code>P2</code>，感觉它们有很大的不同，它们阐述的不是同一个问题。<code>P1</code>讨论的是如何选择<code>proposal</code>的问题，而<code>P2</code>则直接跳到了选出来后的问题：一旦<code>value</code>被选定了，后面的被选出来的<code>value</code>应该保持不变。从论文中后面的推断不断增强可以分析出，<code>P2</code>其实包含了<code>P1</code>，两个条件并不是相互独立的，因为<code>P2</code>其实也是一个如何选的过程，只不过它表示了一般情况下应该如何选的问题，而<code>P1</code>是针对第一个<code>proposal</code>应该如何选的问题。换言之，<code>P1</code>是任何后续的推论都需要保证的，后续作出的任何推断都不能与<code>P1</code>矛盾。</p>
<p>注意到，后续若有其它的<code>proposal</code>被选定，前提肯定是有<code>acceptor</code>接受了这个<code>proposal</code>。自然而然，可以转换<code>P2</code>的论述方式，于是就有了<code>P2a</code>：</p>
<blockquote>
<p>P2a . If a proposal with value v is chosen, then every higher-numbered proposal accepted by any acceptor has value v.</p>
</blockquote>
<p><code>P2a</code>其实是在对<code>acceptor</code>做限制。事实上，<code>P2</code>与<code>P2a</code>是一致的，只要满足了<code>P2a</code>就能满足<code>P2</code>。但前面提到过<code>P1</code>是后续推断所必须满足的，而仔细考量<code>P2a</code>，它似乎违反了<code>P1</code>这个约束底线。可以考虑这样一个场景：若有 2 个<code>proposer</code>和 5 个<code>acceptor</code>。首先由<code>proposer-1</code>提出了<code>[id1, v1]</code>的提案，恰好<code>acceptor1~3</code>都顺利接受了此提案，即<code>quorum</code>个节点选定了该值<code>v1</code>，于是对于<code>proposer-1</code>及<code>acceptor1~3</code>而言，它们都选定了<code>v1</code>。而<code>acceptor4</code>在<code>proposer-1</code>提出提案的时候，刚好宕机了（事实上，只要其先接受<code>proposer-2</code>的提案即可，且<code>proposer-2</code>的编号大于<code>proposer-1</code>的编号）而后有<code>proposer-2</code>提出了提案<code>[id2, v2]</code>且<code>id2&gt;id1 &amp; v1!=v2</code>。那么由<code>P1</code>知，<code>acceptor-4</code>在宕机恢复后，必须接受提案<code>[id2, v2]</code>，即选定<code>v2</code>。很明显这不符合<code>P2a</code>的条件。因此，我们只有对<code>P2a</code>进行加强，才能让它继续满足<code>P1</code>所设定的底线。</p>
<p>我们自己可以先直观思考，为了保证<code>acceptor</code>后续通过的<code>proposal</code>的值与之前已经认定的值是相同的。如果直接依据之前的简单流程：<code>proposer</code>直接将其提案发送给<code>acceptor</code>，这可能会产生冲突。所以，我们可以尝试限制后续的<code>proposer</code>发送的提案的<code>value</code>，以保证<code>proposer</code>发送的提案的``value<code>与之前已经通过的提案的value</code>相同，于是引出了<code>P2b</code>：</p>
<blockquote>
<p>P2b. If a proposal with value v is chosen, then every higher-numbered proposal issued by any proposer has value v.</p>
</blockquote>
<p><code>P2b</code>的叙述同<code>P2a</code>类似，但它强调（约束）的是<code>proposer</code>的<code>issue</code>提案的过程。因为，<code>issue</code>是发生在<code>accept</code>之前，那么<code>accept</code>的<code>proposal</code>一定已经被<code>issue</code>过的。因此，<code>P2a</code>可以由<code>P2b</code>来保证，而且，<code>P2b</code>的限制似乎更强。另外，<code>P1</code>也同时得到满足。</p>
<p>对于<code>P2b</code>这个条件，其实是难以实现。因为直观上，你不能限定各个<code>proposer</code>该<code>issue</code>什么样的<code>proposal</code>，不能<code>issue</code>什么样的<code>proposal</code>。那么又该如何保证<code>P2b</code>呢？我们同样可以先自己主观思考，为了让<code>proposer</code>之后<code>issue</code>的<code>proposal</code>的<code>value</code>与之前已经被通过的<code>proposal</code>的<code>value</code>的值保持一致，我们是不是可以尝试让<code>proposer</code>提前与<code>acceptor</code>进行沟通，以获取之前已经通过的<code>proposal</code>的<code>value</code>呢？具体如何沟通，无非是相互通信，接收消息或者主动询问，接收消息未免显得过于消极，而主动询问显然是更好的策略。如果的确存在这样的<code>value</code>，那为了保证一致，我就不再指定新的<code>value</code>了，与先前的<code>value</code>保持一致即可。而原论文给出了<code>P2c</code>:</p>
<blockquote>
<p>P2c. For any v and n, if a proposal with value v and number n is issued, then there is a set S consisting of a majority of acceptors such that either </p>
<p>(a) no acceptor in S has accepted any proposal numbered less than n, or </p>
<p>(b) v is the value of the highest-numbered proposal among all proposals numbered less than n accepted by the acceptors in S.</p>
</blockquote>
<p>作者认为，<code>P2c</code>里面包含了<code>P2b</code>。<code>P2c</code>中的<code>(a)</code>容易理解，因为如果从来没有<code>accept</code>过编号小于<code>n</code>的提案，那由<code>P1</code>自然而然就可以接受。而对于<code>(b)</code>可以用法定集合的性质简单证明，即两个法定集合(<code>quorum</code>)必定存在一个公共元素。我们可以采用反证法结合归纳法来简单证明。假定编号为<code>m</code>且值为<code>v</code>的提案已经被选定，那么，存在一个法定集合<code>C</code>，<code>C</code>中每一个<code>acceptor</code>都选定了<code>v</code>。然后有编号为<code>n</code>的<code>proposal</code>被提出 ：那么，</p>
<p>① 当<code>n=m+1</code> 时，假设编号为<code>n</code>的提案的<code>value</code>不为<code>v</code>而为<code>w</code>。则根据<code>P2c</code>，存在一个法定集合<code>S</code>，要么<code>S</code>中的<code>acceptor</code>从来没有批准过小于<code>n</code>的提案；要么在批准的所有编号小于<code>n</code>的提案中，编号最大的提案的值为<code>w</code>。但因为<code>S</code>和<code>C</code>至少存在一个公共<code>acceptor</code>，明显两个条件都不满足。所以假设不成立。因此<code>n</code>的值为<code>v</code>。② 当编号<code>m</code>属于<code>m ... (n-1)</code>，同样假设编号为<code>n</code>的提案的<code>value</code>不为<code>v</code>，而为<code>w’</code> 。则存在一个法定集合<code>S’</code>，要么在<code>S’</code>中没有一个<code>acceptor</code>批准过编号小于<code>n</code>的提案；要么在<code>S’</code>中批准过的所有的编号小于<code>n</code>的提案中，编号最大的提案的值为<code>w’</code>。根据假设条件，编号属于<code>m...(n-1)</code>的提案的值都为<code>v</code>，并且<code>S’</code>和<code>C</code>至少有一个公共<code>acceptor</code>，所以由<code>S’</code>中的<code>acceptor</code>批准的小于<code>n</code>的提案中编号最大的那个提案也属于<code>m...(n-1)</code>。从而必然有<code>w’=v</code>。</p>
<p>若要满足<code>P2c</code>，其实也从侧面反映出若要使得<code>proposer</code>提交一个正确的<code>value</code>，必须同时对<code>proposer</code>和<code>acceptor</code>作出限制。我们现在回顾一下先前的推断的递推关系：<code>P2c=&gt;P2b=&gt;P2a=&gt;P2</code>。因此，<code>P2c</code>最终确保了<code>P2</code>，即当一个<code>value</code>被选定之后，后续的编号更大的被选定的<code>proposal</code>都具有先前已经被选定的<code>value</code>。整个过程，先是对整个结果提出要求形成<code>P2</code>，然后转为对<code>acceptor</code>提出要求<code>P2a</code>，进行转为对<code>proposer</code>提出要求<code>P2b</code>，最后，同时对<code>acceptor</code>及<code>proposer</code>作出要求<code>P2c</code>。</p>
<h2 id="Paxos-算法步骤"><a href="#Paxos-算法步骤" class="headerlink" title="Paxos 算法步骤"></a>Paxos 算法步骤</h2><p>最后，我们简单阐述一下<code>Paxos</code>算法的步骤。其大致可以分为两个阶段。</p>
<ol>
<li>阶段一，<code>prepare</code>阶段。<ul>
<li><code>proposer</code>选择一个新的编号<code>n</code>发送给<code>quorum</code>个<code>acceptor</code>，并等待回应。</li>
<li>如果<code>acceptor</code>收到一个针对编号为<code>n</code>的<code>prepare</code>请求，则若此<code>prepare</code>请求的编号<code>n</code>大于它之前已经回复过的<code>proposal</code>的所有编号的值，那么它会 (1) 承诺不再接受编号小于<code>n</code>的<code>proposal</code>。(b) 向<code>proposer</code>回复之前已经接受过的<code>proposal</code>中编号最大的<code>proposal</code>（如果有的话）。否则，不予回应。或者，回复一个<code>error</code>给<code>proposer</code>以让<code>proposer</code>终止此轮决议，并重新生成编号。</li>
</ul>
</li>
<li>阶段二，<code>accept</code>阶段。<ul>
<li>如果<code>proposer</code>收到了<code>quorum</code>个<code>acceptor</code>对其编号为<code>n</code>的<code>prepare</code>请求的回复，那么它就发送一个针对<code>[n, v]</code>的<code>proposal</code>给<code>quorum</code>个<code>acceptor</code>（此<code>quorum</code>与<code>prepare</code>阶段的<code>quorum</code>不必相同）。其中，<code>v</code>是收到的<code>prepare</code>请求的响应的<code>proposal</code>集合中具有最大编号的<code>proposal</code>的<code>value</code>。如果收到的响应集合中不包含任何<code>proposal</code>，则由此<code>proposer</code>自己决定<code>v</code>的值。</li>
<li>如果<code>acceptor</code>收到一个针对编号为<code>n</code>的<code>accept</code>请求，则若其没有对编号大于<code>n</code>的<code>prepare</code>请求做出过响应，就接受该<code>proposal</code>。</li>
</ul>
</li>
</ol>
<h2 id="Paxos-算法活性"><a href="#Paxos-算法活性" class="headerlink" title="Paxos 算法活性"></a>Paxos 算法活性</h2><p>前面提到，理论上<code>Paxos</code>可能永远不会终止（即永远无法达成一致），即使是在没有故障发生的情况。考虑这样一个场景，<code>proposer-1</code>发起了<code>prepare</code>阶段并获得了大多数<code>acceptor</code>的支持，然后<code>proposer-2</code>立刻带着更高的编号来了，发起了<code>prepare</code>阶段，同样获得了大多数的<code>acceptor</code>的支持（因为<code>proposer-2</code>的编号更高，<code>acceptor</code>只能对<code>prepare</code>请求回复成功）。紧接着<code>proposer-a</code>进入了<code>accept</code>阶段，从<code>acceptor</code>的回复中得知大家又都接受了一个更高的编程，因此不得不选择更大的编号并重新发起一轮<code>prepare</code>阶段。同样，<code>proposer-2</code>也会面临<code>proposer-1</code>同样的问题。于是，它们轮流更新编号，始终无法通过。这也就是所谓的活锁问题。<code>FLP</code>定理早就证明过即使允许一个进程失败，在异步环境下任何一致性算法都存在永不终止的可能性。论文后面提出为了避免活锁的问题，可以引入了一个<code>proposer leader</code>，由此<code>leader</code>来提出<code>proposal</code>。但事实上，<code>leader</code>的选举本身也是一个共识问题。而在工程实现上，存在一些手段可以用来减少两个提案冲突的概率（在<code>raft</code>中采用了随机定时器超时的方式来减小选票瓜分的可能性）。</p>
<p>最后，为了更好地理解<code>Paxos</code>算法时，补充（明确）以下几点。</p>
<ul>
<li><p><code>Paxos</code>算法的目的是确定一个值，一轮完整的<code>paxos</code>交互过程值用于确定一个值。且为了确定一个值，各节点需要协同互助，不能”各自为政”。且一旦接受提案，提案的<code>value</code>就被选定。</p>
</li>
<li><p><code>Paxos</code>算法的强调的是值<code>value</code>，而不是提案<code>proposal</code>，更加不是编号。提案和编号都是为了确定一个值所采用的辅助手段。显然，当一个值被确定时，<code>acceptor</code>接受的提案可能是多个，编号当然也就不同，但是这些提案所对应的值一定是一样的。</p>
</li>
<li><p><code>Paxos</code>流程保证最终对选定的值达到一致，这需要一个投票决议过程，需要一定时间。</p>
</li>
<li><p>上面描述的大多流程都是正常情况，但毫无疑问，<code>acceptor</code>收到的消息有可能错位，比如 (1) <code>acceptor</code>还没收到<code>prepare</code>请求就直接收到了<code>accept</code>请求，此时要直接写入日志。(2) <code>acceptor</code>还未返回对<code>prepare</code>请求的确认，就收到了<code>accept</code>请求，此时直接写入日志，并拒绝后续的<code>prepare</code>请求。</p>
</li>
<li><p>因为节点任何时候都可能宕机，因此必须保证节点具备可靠的存储。具体而言，(1) 对于<code>proposer</code>需要持久化已提交的最大<code>proposal</code>编号、决议编号(<code>instance id</code>)（表示一轮<code>Paxos</code>的选举过程）。(2) 对于<code>acceptor</code>需要持久化已经<code>promise</code>的最大编号、已<code>accept</code>的最大编号和<code>value</code>以及决议编号。</p>
</li>
</ul>
<p>参考资料</p>
<p>[1]. Lamport L. Paxos made simple[J]. ACM Sigact News, 2001, 32(4): 18-25.<br>[2]. <a href="https://blog.csdn.net/chen77716/article/details/6166675" target="_blank" rel="noopener">https://blog.csdn.net/chen77716/article/details/6166675</a><br>[3]. <a href="https://www.zhihu.com/question/19787937" target="_blank" rel="noopener">如何浅显易懂地解说 Paxos 的算法</a></p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>一致性算法</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>一致性算法</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringBoot之Starter组件概览</title>
    <url>/2018/12/16/2018-12-16-SpringBoot%E4%B9%8BStarter%E7%BB%84%E4%BB%B6%E6%A6%82%E8%A7%88/</url>
    <content><![CDATA[<h1 id="应用类-Starter"><a href="#应用类-Starter" class="headerlink" title="应用类 Starter"></a>应用类 Starter</h1><table>
<thead>
<tr>
<th>名称</th>
<th>描述</th>
<th>POM</th>
</tr>
</thead>
<tbody><tr>
<td><code>spring-boot-starter</code></td>
<td>核心 starter，包含自动配置支持、日志和 YAML</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-activemq</code></td>
<td>提供 JMS 消息支持，使用 Apache ActiveMQ</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-activemq/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-amqp</code></td>
<td>提供 Spring AMQP 与 Rabbit MQ 支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-amqp/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-aop</code></td>
<td>提供 Spring AOP 与 AspectJ 面向切面编程支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-aop/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-artemis</code></td>
<td>提供 JMS 消息服务支持，使用 Apache Artemis</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-artemis/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-batch</code></td>
<td>提供 Spring Batch 支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-batch/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-cache</code></td>
<td>提供 Spring Framework 缓存支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-cache/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-cloud-connectors</code></td>
<td>使用 Spring Cloud Connectors 简单连接到类似 Cloud Foundry 和 Heroku 等云平台</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-cloud-connectors/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-data-cassandra</code></td>
<td>提供对 Cassandra 分布式数据库和 Spring Data Cassandra 的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-cassandra/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-data-cassandra-reactive</code></td>
<td>提供对 Cassandra 分布式数据库和 Spring Data Cassandra Reactive 的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-cassandra-reactive/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-data-couchbase</code></td>
<td>提供对 Couchbase 面向文档数据库和 Spring Data Couchbase 的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-couchbase/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-data-couchbase-reactive</code></td>
<td>提供对 Couchbase 面向文档数据库和 Spring Data Couchbase Reactive 的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-couchbase-reactive/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-data-elasticsearch</code></td>
<td>提供对 Elasticseach 搜索与分析引擎和 Spring Data Elasticsearch 的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-elasticsearch/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-data-jpa</code></td>
<td>提供 Spring Data JPA 与 Hibernate 的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-jpa/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-data-ldap</code></td>
<td>提供对 Spring Data LDAP 的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-ldap/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-data-mongodb</code></td>
<td>提供对 MongoDB 面向文档数据库和 Spring Data MongoDB 的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-mongodb/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-data-mongodb-reactive</code></td>
<td>提供对 MongoDB 面向文档数据库和 Spring Data MongoDB Reactive 的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-mongodb-reactive/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-data-neo4j</code></td>
<td>提供对 Neo4j 图数据库与 SPring Data Neo4j 的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-neo4j/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-data-redis</code></td>
<td>提供对 Redis 键值数据存储、Spring Data Redis 和 Lettuce 客户端的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-redis/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-data-redis-reactive</code></td>
<td>提供对 Redis 键值数据存储、Spring Data Redis Reactive 和 Lettuce 客户端的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-redis-reactive/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-data-rest</code></td>
<td>提供使用 Spring Data REST 通过 REST 暴露 Spring Data 资源库的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-rest/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-data-solr</code></td>
<td>提供对 Apache Solr 搜索平台与 Spring Data Solr 的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-solr/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-freemarker</code></td>
<td>提供使用 Freemakrer 视图构建 MVC web 应用的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-freemarker/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-groovy-templates</code></td>
<td>提供使用 Groovy 模板视图构建 MVC web 应用的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-groovy-templates/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-hateoas</code></td>
<td>提供使用 Spring MVC 与Spring HATEOAS 构建基于超媒体的 RESTful web 应用的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-hateoas/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-integration</code></td>
<td>提供对 Spring Integration 的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-integration/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-jdbc</code></td>
<td>提供 JDBC 与 Tomcat JDBC 连接池的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-jdbc/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-jersey</code></td>
<td>提供对使用 JAX-RS 与 Jersey 构建 RESTful web 应用的支持。<a href="https://docs.spring.io/spring-boot/docs/2.0.0.RELEASE/reference/htmlsingle/#spring-boot-starter-web" target="_blank" rel="noopener"><code>spring-boot-starter-web</code></a> 的替代方案</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-jersey/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-jooq</code></td>
<td>提供对使用 JOOQ 访问 SQL 数据库的支持。<a href="https://docs.spring.io/spring-boot/docs/2.0.0.RELEASE/reference/htmlsingle/#spring-boot-starter-data-jpa" target="_blank" rel="noopener"><code>spring-boot-starter-data-jpa</code></a> 或 <a href="https://docs.spring.io/spring-boot/docs/2.0.0.RELEASE/reference/htmlsingle/#spring-boot-starter-jdbc" target="_blank" rel="noopener"><code>spring-boot-starter-jdbc</code></a> 的替代方案</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-jooq/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-json</code></td>
<td>提供了读写 json 的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-json/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-jta-atomikos</code></td>
<td>提供 Atomikos JTA 事务支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-jta-atomikos/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-jta-bitronix</code></td>
<td>提供 Bitronix JTA 事务支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-jta-bitronix/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-jta-narayana</code></td>
<td>提供 Narayana JTA 支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-jta-narayana/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-mail</code></td>
<td>提供使用　Java Mail 与 Spring Framework 的邮件发送支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-mail/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-mustache</code></td>
<td>提供使用 Mustache 视图构建 web 应用的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-mustache/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-quartz</code></td>
<td>Quartz 支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-quartz/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-security</code></td>
<td>Spring Security 支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-security/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-test</code></td>
<td>提供包含了 JUnit、Hamcrest 与 Mockito 类库的 Spring Boot 单元测试支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-test/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-thymeleaf</code></td>
<td>提供使用 Thymeleaf 视图构建 MVC web 应用的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-thymeleaf/pom.xml" target="_blank" rel="noopener">pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-validation</code></td>
<td>提供 Hibernate Validator 与 Java Bean Validation 的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-validation/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-web</code></td>
<td>提供使用 Spring MVC 构建 web（包含 RESTful）应用的支持，使用 Tomcat 作为默认嵌入式容器</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-web/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-web-services</code></td>
<td>Spring Web Services 支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-web-services/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-webflux</code></td>
<td>提供使用 Spring Framework 的 Reactive Web 支持构建 WebFlux 应用的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-webflux/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-websocket</code></td>
<td>提供使用 Spring Framework 的 WebSocket 支持构建 WebSocket 应用的支持</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-websocket/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
</tbody></table><a id="more"></a>
<h1 id="生产类-starter"><a href="#生产类-starter" class="headerlink" title="生产类 starter"></a>生产类 starter</h1><table>
<thead>
<tr>
<th>名称</th>
<th>描述</th>
<th>POM</th>
</tr>
</thead>
<tbody><tr>
<td><code>spring-boot-starter-actuator</code></td>
<td>Spring Boot 的 Actuator 支持，其提供了生产就绪功能，帮助您监控和管理应用</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-actuator/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
</tbody></table>
<h1 id="技术类-starter"><a href="#技术类-starter" class="headerlink" title="技术类 starter"></a>技术类 starter</h1><table>
<thead>
<tr>
<th>名称</th>
<th>描述</th>
<th>POM</th>
</tr>
</thead>
<tbody><tr>
<td><code>spring-boot-starter-jetty</code></td>
<td>使用 Jetty 作为嵌入式 servlet 容器。可代替 <a href="https://docs.spring.io/spring-boot/docs/2.0.0.RELEASE/reference/htmlsingle/#spring-boot-starter-tomcat" target="_blank" rel="noopener"><code>spring-boot-starter-tomcat</code></a></td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-jetty/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-log4j2</code></td>
<td>使用 Log4j2 作为日志组件。可代替 <a href="https://docs.spring.io/spring-boot/docs/2.0.0.RELEASE/reference/htmlsingle/#spring-boot-starter-logging" target="_blank" rel="noopener"><code>spring-boot-starter-logging</code></a></td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-log4j2/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-logging</code></td>
<td>使用 Logback 作为日志组件，此 starter 为默认的日志 starter</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-logging/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-reactor-netty</code></td>
<td>使用 Reactor Netty 作为内嵌响应式 HTTP 服务器</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-reactor-netty/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-tomcat</code></td>
<td>使用 Tomcat 作为嵌入式 servlet 容器，此为 <a href="https://docs.spring.io/spring-boot/docs/2.0.0.RELEASE/reference/htmlsingle/#spring-boot-starter-web" target="_blank" rel="noopener"><code>spring-boot-starter-web</code></a> 默认的 servlet 容器 starter</td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-tomcat/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
<tr>
<td><code>spring-boot-starter-undertow</code></td>
<td>使用 Undertow 作为嵌入式 servlet 容器，可代替 <a href="https://docs.spring.io/spring-boot/docs/2.0.0.RELEASE/reference/htmlsingle/#spring-boot-starter-tomcat" target="_blank" rel="noopener"><code>spring-boot-starter-tomcat</code></a></td>
<td><a href="https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-undertow/pom.xml" target="_blank" rel="noopener">Pom</a></td>
</tr>
</tbody></table>
<p><strong>提示</strong></p>
<blockquote>
<p>有关其它社区贡献的 starter 列表，请参阅 GitHub 上的 <code>spring-boot-starters</code> 模块中的 <a href="https://github.com/spring-projects/spring-boot/tree/master/spring-boot-project/spring-boot-starters/README.adoc" target="_blank" rel="noopener">README 文件</a>。</p>
</blockquote>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://docs.spring.io/spring-boot/docs/2.1.1.RELEASE/reference/htmlsingle/#using-boot-starter" target="_blank" rel="noopener">SpringBoot官方文档</a><br><a href="https://docshome.gitbooks.io/springboot/content/pages/using-spring-boot.html#using-boot-starter" target="_blank" rel="noopener">SpringBoot官方文档中文翻译</a><br><a href="https://blog.csdn.net/cxd275050943/article/details/74452102" target="_blank" rel="noopener">SpringBoot组件说明</a>  </p>
]]></content>
      <categories>
        <category>后端开发</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis学习笔记</title>
    <url>/2018/12/15/2018-12-15-Redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><h2 id="命令安装"><a href="#命令安装" class="headerlink" title="命令安装"></a>命令安装</h2><h3 id="Ubuntu"><a href="#Ubuntu" class="headerlink" title="Ubuntu"></a>Ubuntu</h3><h4 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt install redis-server</span><br></pre></td></tr></table></figure>

<h3 id="CentOS"><a href="#CentOS" class="headerlink" title="CentOS"></a>CentOS</h3><h4 id="安装-2"><a href="#安装-2" class="headerlink" title="安装"></a>安装</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install epel-release</span><br><span class="line">yum install redis</span><br><span class="line">sudo service redis start</span><br></pre></td></tr></table></figure>

<a id="more"></a>

<h2 id="安装包安装"><a href="#安装包安装" class="headerlink" title="安装包安装"></a>安装包安装</h2><h3 id="Ubuntu-1"><a href="#Ubuntu-1" class="headerlink" title="Ubuntu"></a>Ubuntu</h3><h4 id="安装-3"><a href="#安装-3" class="headerlink" title="安装"></a>安装</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget http://download.redis.io/releases/redis-4.0.11.tar.gz</span><br><span class="line">tar -zxvf redis-4.0.0.tar.gz</span><br><span class="line">cd redis-4.0.0/</span><br><span class="line">sudo make</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure>

<h3 id="CentOS-1"><a href="#CentOS-1" class="headerlink" title="CentOS"></a>CentOS</h3><h4 id="安装-4"><a href="#安装-4" class="headerlink" title="安装"></a>安装</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget http://download.redis.io/releases/redis-2.8.17.tar.gz</span><br><span class="line">tar xzf redis-2.8.17.tar.gz</span><br><span class="line">cd /usr/local/src/redis-2.8.17/</span><br><span class="line">make</span><br><span class="line">make install</span><br><span class="line">vim redis.conf </span><br><span class="line">./src/redis-server redis.conf </span><br><span class="line">sudo netstat -plutn | grep 6379</span><br><span class="line">redis-cli</span><br></pre></td></tr></table></figure>

<h1 id="管理"><a href="#管理" class="headerlink" title="管理"></a>管理</h1><h2 id="服务管理"><a href="#服务管理" class="headerlink" title="服务管理"></a>服务管理</h2><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo systemctl start redis-server</span><br></pre></td></tr></table></figure>
<h3 id="重启"><a href="#重启" class="headerlink" title="重启"></a>重启</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo systemctl restart redis-server</span><br></pre></td></tr></table></figure>
<h3 id="停止"><a href="#停止" class="headerlink" title="停止"></a>停止</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo systemctl stop redis-server</span><br></pre></td></tr></table></figure>
<h3 id="查看状态"><a href="#查看状态" class="headerlink" title="查看状态"></a>查看状态</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo systemctl status redis-server</span><br></pre></td></tr></table></figure>

<h2 id="启动-1"><a href="#启动-1" class="headerlink" title="启动"></a>启动</h2><p>后台运行  </p>
<p>首次  </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/usr/local/src/redis/redis-4.0.11/src/redis-server ../redis.conf&amp;</span><br></pre></td></tr></table></figure>

<p>非首次  </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/usr/local/src/redis/redis-4.0.11/src/redis-server&amp;</span><br></pre></td></tr></table></figure>

<h2 id="进入"><a href="#进入" class="headerlink" title="进入"></a>进入</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/usr/local/src/redis/redis-4.0.11/src/redis-cli</span><br><span class="line"><span class="meta">#</span><span class="bash"> 需要密码</span></span><br><span class="line">/usr/local/src/redis/redis-4.0.11/src/redis-cli -p 6379 -a redisPassword!</span><br></pre></td></tr></table></figure>

<h2 id="命令设置密码"><a href="#命令设置密码" class="headerlink" title="命令设置密码"></a>命令设置密码</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt;config set requirepass redisPassword!</span><br></pre></td></tr></table></figure>

<h2 id="配置文件设置密码"><a href="#配置文件设置密码" class="headerlink" title="配置文件设置密码"></a>配置文件设置密码</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim redis.conf</span><br><span class="line">:348 #348行</span><br><span class="line">requirepass redisPassword! #修改保存重启</span><br></pre></td></tr></table></figure>

<h2 id="查询密码"><a href="#查询密码" class="headerlink" title="查询密码"></a>查询密码</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt;config get requirepass</span><br></pre></td></tr></table></figure>

<h2 id="认证密码"><a href="#认证密码" class="headerlink" title="认证密码"></a>认证密码</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; auth redisPassword!</span><br></pre></td></tr></table></figure>

<h2 id="登录"><a href="#登录" class="headerlink" title="登录"></a>登录</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">redis-cli -p 6379 -a redisPassword!</span><br></pre></td></tr></table></figure>

<h2 id="查看"><a href="#查看" class="headerlink" title="查看"></a>查看</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 查看是否已经自动启动</span></span></span><br><span class="line">ps -aux | grep redis</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 查看是否已经监听端口</span></span></span><br><span class="line">netstat -nlt | grep 6379</span><br></pre></td></tr></table></figure>

<h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/redis/redis.conf</span><br></pre></td></tr></table></figure>

<h2 id="无密码登录"><a href="#无密码登录" class="headerlink" title="无密码登录"></a>无密码登录</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">redis-cli</span><br></pre></td></tr></table></figure>

<h2 id="有密码登录"><a href="#有密码登录" class="headerlink" title="有密码登录"></a>有密码登录</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">redis-cli -a root -h yibuwulianwang.com</span><br></pre></td></tr></table></figure>

<h1 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h1><h2 id="查看所有的key列表"><a href="#查看所有的key列表" class="headerlink" title="查看所有的key列表"></a>查看所有的key列表</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt;keys *</span><br></pre></td></tr></table></figure>

<h2 id="增加一条记录key1"><a href="#增加一条记录key1" class="headerlink" title="增加一条记录key1"></a>增加一条记录key1</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt;set key1 "hello"</span><br></pre></td></tr></table></figure>

<h2 id="打印记录"><a href="#打印记录" class="headerlink" title="打印记录"></a>打印记录</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt;get key1</span><br></pre></td></tr></table></figure>

<h2 id="增加一条数字记录key2"><a href="#增加一条数字记录key2" class="headerlink" title="增加一条数字记录key2"></a>增加一条数字记录key2</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt;set key2 1</span><br></pre></td></tr></table></figure>

<h2 id="让值（数字）自增"><a href="#让值（数字）自增" class="headerlink" title="让值（数字）自增"></a>让值（数字）自增</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt;INCR key2</span><br></pre></td></tr></table></figure>

<h2 id="增加一个列表记录key3"><a href="#增加一个列表记录key3" class="headerlink" title="增加一个列表记录key3"></a>增加一个列表记录key3</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt;LPUSH key3 a</span><br></pre></td></tr></table></figure>

<h2 id="从左边插入列表"><a href="#从左边插入列表" class="headerlink" title="从左边插入列表"></a>从左边插入列表</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt;LPUSH key3 b</span><br></pre></td></tr></table></figure>

<h2 id="从右边插入列表"><a href="#从右边插入列表" class="headerlink" title="从右边插入列表"></a>从右边插入列表</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt;RPUSH key3 c</span><br></pre></td></tr></table></figure>
<h2 id="打印列表记录，按从左到右的顺序"><a href="#打印列表记录，按从左到右的顺序" class="headerlink" title="打印列表记录，按从左到右的顺序"></a>打印列表记录，按从左到右的顺序</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt;LRANGE key3 0 3</span><br></pre></td></tr></table></figure>

<h2 id="增加一个哈希记表录key4"><a href="#增加一个哈希记表录key4" class="headerlink" title="增加一个哈希记表录key4"></a>增加一个哈希记表录key4</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt;HSET key4 name "John Smith"</span><br></pre></td></tr></table></figure>

<h2 id="在哈希表中插入，email的Key和Value的值"><a href="#在哈希表中插入，email的Key和Value的值" class="headerlink" title="在哈希表中插入，email的Key和Value的值"></a>在哈希表中插入，email的Key和Value的值</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt;HSET key4 email "abc@gmail.com"</span><br></pre></td></tr></table></figure>

<h2 id="打印哈希表中，name为key的值"><a href="#打印哈希表中，name为key的值" class="headerlink" title="打印哈希表中，name为key的值"></a>打印哈希表中，name为key的值</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt;HGET key4 name</span><br></pre></td></tr></table></figure>

<h2 id="打印整个哈希表"><a href="#打印整个哈希表" class="headerlink" title="打印整个哈希表"></a>打印整个哈希表</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt;HGETALL key4</span><br></pre></td></tr></table></figure>

<h2 id="增加一条哈希表记录key5，一次插入多个Key和value的值"><a href="#增加一条哈希表记录key5，一次插入多个Key和value的值" class="headerlink" title="增加一条哈希表记录key5，一次插入多个Key和value的值"></a>增加一条哈希表记录key5，一次插入多个Key和value的值</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt;HMSET key5 username antirez password P1pp0 age 3</span><br></pre></td></tr></table></figure>

<h2 id="打印哈希表中，username和age为key的值"><a href="#打印哈希表中，username和age为key的值" class="headerlink" title="打印哈希表中，username和age为key的值"></a>打印哈希表中，username和age为key的值</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt;HMGET key5 username age</span><br></pre></td></tr></table></figure>

<h2 id="打印完整的哈希表记录"><a href="#打印完整的哈希表记录" class="headerlink" title="打印完整的哈希表记录"></a>打印完整的哈希表记录</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt;HGETALL key5</span><br></pre></td></tr></table></figure>

<h2 id="查看所有的key列表-1"><a href="#查看所有的key列表-1" class="headerlink" title="查看所有的key列表"></a>查看所有的key列表</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt;127.0.0.1:6379&gt;keys *</span><br></pre></td></tr></table></figure>

<h2 id="删除key1-key5"><a href="#删除key1-key5" class="headerlink" title="删除key1,key5"></a>删除key1,key5</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt;del key1</span><br></pre></td></tr></table></figure>

<h1 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h1><table>
<thead>
<tr>
<th align="left">类型</th>
<th align="left">简介</th>
<th align="left">特性</th>
<th align="left">可存储的值</th>
<th align="left">操作</th>
<th align="left">场景</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>String</strong></td>
<td align="left">字符串，二进制安全</td>
<td align="left">可以包含任何数据,比如jpg图片或者序列化的对象,一个键最大能存储512M</td>
<td align="left">字符串，整，浮点数</td>
<td align="left">1. 对整个字符串或者字符串中的一部分执行操作，2. 对整数或浮点数执行自增或自减操作</td>
<td align="left">缓存、限流、计算器、分布式锁、分布式session</td>
</tr>
<tr>
<td align="left"><strong>Hash</strong></td>
<td align="left">字典，键值对集合,即编程语言中的Map类型</td>
<td align="left">适合存储对象,并且可以像数据库中update一个属性一样只修改某一项属性值(Memcached中需要取出整个字符串反序列化成对象修改完再序列化存回去)</td>
<td align="left">包含键对值的无序散列表</td>
<td align="left">1. 添加，获取，移除单个键对值；2. 获取所有键对值；3. 检查某个键对值是否存在</td>
<td align="left">存储、读取、修改用户信息、用户主页访问量、组合查询</td>
</tr>
<tr>
<td align="left"><strong>List</strong></td>
<td align="left">列表，链表(双向链表)</td>
<td align="left">增删快,提供了操作某一段元素的API</td>
<td align="left">链表</td>
<td align="left">1. 从两端压入或者弹出元素；2. 读取多个或者单个元素进行修剪；3. 只保留一个范围内的元素</td>
<td align="left">最新消息排行等功能(比如朋友圈的时间线) 、消息队列、时间轴</td>
</tr>
<tr>
<td align="left"><strong>Set</strong></td>
<td align="left">集合，哈希表实现,元素不重复</td>
<td align="left">1、添加、删除,查找的复杂度都是O(1) 2、为集合提供了求交集、并集、差集等操作</td>
<td align="left">无序集合</td>
<td align="left">1. 添加，获取，移除单个元素；2. 检查一个元素是否存在与集合中；3.计算交集，并集，差集；4. 从集合里面随机获取元素</td>
<td align="left">共同好友 、利用唯一性,统计访问网站的所有独立ip 、好友推荐时,根据tag求交集,大于某个阈值就可以推荐，赞，踩，标签，好友关系</td>
</tr>
<tr>
<td align="left"><strong>ZSet</strong></td>
<td align="left">Sorted Set(有序集合)，将Set中的元素增加一个权重参数score,元素按score有序排列</td>
<td align="left">数据插入集合时,已经进行天然排序</td>
<td align="left">有序集合</td>
<td align="left">1. 添加，获取，移除单个元素；2. 根据分值范围或成员来获取元素；3. 计算一个键的排名</td>
<td align="left">排行榜 、带权重的消息队列</td>
</tr>
</tbody></table>
<h1 id="监控中心"><a href="#监控中心" class="headerlink" title="监控中心"></a>监控中心</h1><p><code>redis-monitor</code>:使用<code>Python2</code>开发，默认端口是<code>9527</code></p>
<h2 id="安装-5"><a href="#安装-5" class="headerlink" title="安装"></a>安装</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install redis-monitor</span><br></pre></td></tr></table></figure>

<h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">redis-monitor init</span><br></pre></td></tr></table></figure>

<h2 id="后台运行"><a href="#后台运行" class="headerlink" title="后台运行"></a>后台运行</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nohup redis-monitor start &gt; redis-monitor-2018-12-15.log &amp;</span><br></pre></td></tr></table></figure>

<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="http://blog.fens.me/linux-redis-install/" target="_blank" rel="noopener">在Ubuntu中安装Redis</a>  </p>
]]></content>
      <categories>
        <category>后端开发</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Http之转发与重定向</title>
    <url>/2018/12/14/2018-12-14-Http%E4%B9%8B%E8%BD%AC%E5%8F%91%E4%B8%8E%E9%87%8D%E5%AE%9A%E5%90%91/</url>
    <content><![CDATA[<h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><h2 id="redirect"><a href="#redirect" class="headerlink" title="redirect"></a>redirect</h2><p><strong>透明式间接转发，两次请求，两次处理，两次响应 。</strong>  </p>
<h2 id="forward"><a href="#forward" class="headerlink" title="forward"></a>forward</h2><p><strong>隐身式直接转发，一次请求，两次处理，一次响应。</strong>  </p>
<a id="more"></a>

<h1 id="重定向示例"><a href="#重定向示例" class="headerlink" title="重定向示例"></a>重定向示例</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// URLDecoder.decode 解码url</span></span><br><span class="line"><span class="comment">// URLEncoder.encode 编码url</span></span><br><span class="line">String reUrl = URLDecoder.decode(redirect_uri, <span class="string">"utf-8"</span>) + (redirect_uri.contains(<span class="string">"?"</span>) ? <span class="string">"&amp;"</span> : <span class="string">"?"</span>) + <span class="string">"code="</span> + code + <span class="string">"&amp;state="</span> + state;</span><br></pre></td></tr></table></figure>

<h2 id="示例一"><a href="#示例一" class="headerlink" title="示例一"></a>示例一</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">return</span> <span class="string">"redirect:"</span> + reUrl;</span><br></pre></td></tr></table></figure>

<h2 id="示例二（推荐）"><a href="#示例二（推荐）" class="headerlink" title="示例二（推荐）"></a>示例二（推荐）</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">red</span><span class="params">()</span></span>&#123;</span><br><span class="line">	ModelAndView modelAndView = <span class="keyword">new</span> ModelAndView(<span class="string">"redirect:"</span>+URLDecoder.decode(redirect_uri, <span class="string">"utf-8"</span>));</span><br><span class="line">	modelAndView.addObject(<span class="string">"code"</span>, code);<span class="comment">//追加参数（有效）</span></span><br><span class="line">	modelAndView.addObject(<span class="string">"state"</span>, state);</span><br><span class="line">	<span class="keyword">return</span> modelAndView;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="示例三（推荐）"><a href="#示例三（推荐）" class="headerlink" title="示例三（推荐）"></a>示例三（推荐）</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">red</span><span class="params">()</span></span>&#123;</span><br><span class="line">	RedirectView redirectView = <span class="keyword">new</span> RedirectView(URLDecoder.decode(redirect_uri, <span class="string">"utf-8"</span>));		</span><br><span class="line">	redirectView.addStaticAttribute(<span class="string">"code"</span>, code);<span class="comment">//追加参数（有效）</span></span><br><span class="line">	redirectView.addStaticAttribute(<span class="string">"state"</span>, state);</span><br><span class="line">	redirectView.addStaticAttribute(<span class="string">"type"</span>, state);</span><br><span class="line">	<span class="keyword">return</span> redirectView;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="示例四"><a href="#示例四" class="headerlink" title="示例四"></a>示例四</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">red</span><span class="params">(HttpServletRequest request)</span></span>&#123;</span><br><span class="line">	HttpHeaders httpHeaders = <span class="keyword">new</span> HttpHeaders();</span><br><span class="line">	httpHeaders.setLocation(<span class="keyword">new</span> URI(reUrl));</span><br><span class="line">	request.setAttribute(<span class="string">"code"</span>, code);<span class="comment">//追加参数(无效)</span></span><br><span class="line">	request.setAttribute(<span class="string">"state"</span>, state);</span><br><span class="line">	<span class="keyword">return</span> <span class="keyword">new</span> ResponseEntity&lt;Object&gt;(httpHeaders, HttpStatus.FOUND);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="示例五"><a href="#示例五" class="headerlink" title="示例五"></a>示例五</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">red</span><span class="params">(RedirectAttributes redirectAttributes)</span></span>&#123;</span><br><span class="line">	HttpHeaders httpHeaders = <span class="keyword">new</span> HttpHeaders();</span><br><span class="line">	httpHeaders.setLocation(<span class="keyword">new</span> URI(reUrl));</span><br><span class="line">	redirectAttributes.addAttribute(<span class="string">"code"</span>, code);<span class="comment">//追加参数（无效）</span></span><br><span class="line">	redirectAttributes.addAttribute(<span class="string">"state"</span>, state);</span><br><span class="line">	<span class="keyword">return</span> <span class="keyword">new</span> ResponseEntity&lt;Object&gt;(httpHeaders, HttpStatus.FOUND);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="示例六"><a href="#示例六" class="headerlink" title="示例六"></a>示例六</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">response.sendRedirect(reUrl);</span><br></pre></td></tr></table></figure>

<h2 id="示例七"><a href="#示例七" class="headerlink" title="示例七"></a>示例七</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">red</span><span class="params">(RedirectAttributes redirectAttributes)</span></span>&#123;</span><br><span class="line">	redirectAttributes.addAttribute(<span class="string">"code"</span>, code);<span class="comment">//追加参数（有效）</span></span><br><span class="line">	redirectAttributes.addAttribute(<span class="string">"state"</span>, state);</span><br><span class="line">	<span class="keyword">return</span> <span class="keyword">new</span> ModelAndView(<span class="string">"redirect:"</span>+reUrl);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="示例八"><a href="#示例八" class="headerlink" title="示例八"></a>示例八</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">red</span><span class="params">(Model model)</span></span>&#123;</span><br><span class="line">	model.addAttribute(<span class="string">"code"</span>, code);<span class="comment">//追加参数(无效)</span></span><br><span class="line">	model.addAttribute(<span class="string">"state"</span>, state);</span><br><span class="line">	model.addAttribute(<span class="string">"type"</span>, state);</span><br><span class="line">	<span class="keyword">return</span> <span class="string">"redirect:"</span>+URLDecoder.decode(redirect_uri, <span class="string">"utf-8"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="示例九（推荐）"><a href="#示例九（推荐）" class="headerlink" title="示例九（推荐）"></a>示例九（推荐）</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">red</span><span class="params">(Model model)</span></span>&#123;</span><br><span class="line">	RedirectView redirectView = <span class="keyword">new</span> RedirectView();</span><br><span class="line">	redirectView.setUrl(URLDecoder.decode(codeUrl, <span class="string">"utf-8"</span>));</span><br><span class="line">	redirectView.setContentType(MediaType.APPLICATION_FORM_URLENCODED_VALUE);</span><br><span class="line">	redirectView.setStatusCode(HttpStatus.FOUND);</span><br><span class="line">	redirectView.addStaticAttribute(<span class="string">"client_id"</span>, clientId1);</span><br><span class="line">	redirectView.addStaticAttribute(<span class="string">"response_type"</span>, <span class="string">"code"</span>);</span><br><span class="line">	redirectView.addStaticAttribute(<span class="string">"redirect_uri"</span>, redirectUri);</span><br><span class="line">	redirectView.addStaticAttribute(<span class="string">"scope"</span>, scope);</span><br><span class="line">	redirectView.addStaticAttribute(<span class="string">"state"</span>, state);</span><br><span class="line">	<span class="keyword">return</span> redirectView;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="示例十（推荐）"><a href="#示例十（推荐）" class="headerlink" title="示例十（推荐）"></a>示例十（推荐）</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">red</span><span class="params">(Model model)</span></span>&#123;</span><br><span class="line">	Map&lt;String, Object&gt; clientMap = <span class="keyword">new</span> HashMap&lt;String, Object&gt;();</span><br><span class="line">	clientMap.put(<span class="string">"client_id"</span>, clientId1);</span><br><span class="line">	clientMap.put(<span class="string">"response_type"</span>, <span class="string">"code"</span>);</span><br><span class="line">	clientMap.put(<span class="string">"redirect_uri"</span>, redirectUri);</span><br><span class="line">	clientMap.put(<span class="string">"scope"</span>, scope);</span><br><span class="line">	clientMap.put(<span class="string">"state"</span>, state);</span><br><span class="line">	String reUrl = URLDecoder.decode(redirectUri, <span class="string">"utf-8"</span>);</span><br><span class="line">	<span class="keyword">if</span> (MapUtil.isNotEmpty(clientMap)) &#123;</span><br><span class="line">		<span class="keyword">for</span> (Map.Entry&lt;String, Object&gt; entry : clientMap.entrySet()) &#123;</span><br><span class="line">			reUrl = reUrl + (reUrl.contains(<span class="string">"?"</span>) ? <span class="string">"&amp;"</span> : <span class="string">"?"</span>) + entry.getKey() + <span class="string">"="</span> + entry.getValue();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	HttpHeaders httpHeaders = <span class="keyword">new</span> HttpHeaders();</span><br><span class="line">	httpHeaders.setContentType(MediaType.APPLICATION_FORM_URLENCODED);</span><br><span class="line">	httpHeaders.setLocation(<span class="keyword">new</span> URI(reUrl));</span><br><span class="line">	<span class="keyword">return</span> <span class="keyword">new</span> ResponseEntity&lt;Object&gt;(httpHeaders, HttpStatus.FOUND);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="转发示例"><a href="#转发示例" class="headerlink" title="转发示例"></a>转发示例</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String foUrl = <span class="string">"/oauth.html"</span>;</span><br></pre></td></tr></table></figure>

<h2 id="示例一-1"><a href="#示例一-1" class="headerlink" title="示例一"></a>示例一</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">return</span> <span class="string">"forward:"</span>+foUrl;</span><br></pre></td></tr></table></figure>

<h2 id="示例二（推荐）-1"><a href="#示例二（推荐）-1" class="headerlink" title="示例二（推荐）"></a>示例二（推荐）</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> ModelAndView(<span class="string">"forward:"</span>+foUrl);</span><br></pre></td></tr></table></figure>

<h2 id="示例三"><a href="#示例三" class="headerlink" title="示例三"></a>示例三</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">RequestDispatcher requestDispatcher = request.getRequestDispatcher(forUrl);</span><br><span class="line">requestDispatcher.forward(request, response);</span><br></pre></td></tr></table></figure>

<h2 id="示例四-1"><a href="#示例四-1" class="headerlink" title="示例四"></a>示例四</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">servletContext.getRequestDispatcher(foUrl).forward(request,response);</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>后端开发</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title>浅析分布式事务</title>
    <url>/2018/12/11/%E6%B5%85%E6%9E%90%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</url>
    <content><![CDATA[<p>分布式系统中，将数据块冗余到不同节点使得系统具备容错能力，但其代价是必须要保证各数据副本间的一致性。同样，我们可以将计算（执行）分发到不同节点，以更有效地利用节点并行处理能力，但其代价是必须要对各节点的执行进行协调，以产生应用程序期望的结果。换言之，我们需要推断出节点内部执行的正确性，以保证应用程序可见的语义。而数据库通常能提供涉及事务(<code>transaction</code>)和可序列化(<code>serializability</code>)的相对较强的语义。因此，对于分布式系统而言，此种语义的正确性可以通过分布式事务(<code>distributed transaction</code>)来保证，其通常涉及两个或多个在物理上分离且通过网络连接的主机的数据库事务。</p>
<a id="more"></a>

<p>正式而言，分布式事务包含两个方面：并发控制(<code>concurrency control</code>)及原子提交(<code>atomic commit</code>)。并发控制描述事务并发执行的正确性，而原子提交表示事务包含的一组操作要么全部执行，要么全部不执行，这通常与失败(<code>failure</code>)相关。本文会依次阐述分布式事务的并发控制、原子提交相关内容。</p>
<h2 id="并发控制"><a href="#并发控制" class="headerlink" title="并发控制"></a>并发控制</h2><p>我们以一个例子来展开对并发控制的讨论。考虑一个银行转账的场景：有两个银行账户<code>x</code>和<code>y</code>，且<code>x</code>与<code>y</code>仅次于不同的服务器上，<code>x</code>与<code>y</code>账户初始数目都是 10 。客户端<code>c1</code>将从<code>x</code>账户转账1到<code>y</code>账户，同时，<code>c2</code>是一个审计者以检查银行各账户的钱是否有丢失。因此，抽象化<code>c1</code>及<code>c2</code>的操作为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">c1:             c2:</span><br><span class="line">add(x, 1)       tmp1 = get(x)</span><br><span class="line">add(y, -1)      tmp2 = get(y)</span><br><span class="line">                print tmp1, tmp2</span><br></pre></td></tr></table></figure>

<p>我们（应用程序）期待最终的结果为：<code>x=11, y=9</code>，同时<code>c2</code>打印 <code>10, 10</code>或者<code>11, 9</code>。但并发执行的操作可能并不会按照应用期待的结果输出。比如，若<code>c2</code>的两个操作完全运行在<code>c1</code>的两个操作之间，导致最终的结果为：<code>x=11, y=9</code>，同时打印<code>11, 10</code>。显然，对于此应用场景而言，我们并不希望出现后者。因此我们需要对并发执行的操作进行协调，以保证其操作结果的语义能够符合应用程序。</p>
<p>先引出一个概念<code>before-or-after atomicity</code>，其定义如下。</p>
<blockquote>
<p>Concurrent actions have the before-or-after property if their effect from the point of view of their invokers is the same as if the actions occurred either completely before or completely after one another. </p>
</blockquote>
<p>显然，若并发操作能<code>before-or-after atomicity</code>属性，则此转账应用产生的结果是正确的。基于此，我们尝试给出一个能够保证应用程序的正确性的论断。</p>
<blockquote>
<p>Coordination among concurrent actions can be considered to be correct if every result is guaranteed to be one that could have been obtained by some purely serial application of those same actions. </p>
</blockquote>
<p>可以通过如下几个步骤来认证此观点的正确性：考虑一个系统被应用（可能是并发执行的）操作之后从一个状态转换到另一个状态，如果系统的初始状态是正确的（由具体应用程序确定），并且操作正确地被执行应用到系统，则系统新的状态也是正确的。并且此论述独立于应用程序。同样，如果如果是多个操作并发执行，则上述的论断变更为，若系统最终所处的状态是应用到系统的并发操作集的某个顺序执行后系统的状态，那么此时系统的新的状态也是正确的。换言之，结合<code>before-or-after atomicity</code>属性，可以得出这样的结论：若协调并发操作的规则遵循<code>before-or-after atomicity</code>，则这些并发操作是可序列化的，即存在某些并发事务构成的串行执行顺序，若遵循这些顺序，将导致系统处于相同的终止状态，此时并发操作的结果是正确的。这同样是传统数据事务正确性定义——<code>serializability</code>所要求的。</p>
<p>理论上而言，并发操作的中间过程是不重要的，因为只要保证并发操作所产生的系统新的状态与按照某一个顺序顺序执行所有的“单个”的原子操作所产生的系统新的状态相同，我们并不关心具体与哪一个操作顺序相同，甚至，我们都不要求所谓的顺序操作的中间状态是否真实存在（如图所示，即若操作执行的中间状态的路径是按照虚线进行的），只要此中间状态不会被外部应用程序所观察到，那么我们同样认为这样的操作具备<code>before-or-after atomicity</code>属性，即符合<code>serializability</code>的要求。值得注意的是，对系统应用并发操作的目的是提高性能，但具备<code>before-or-after atomicity</code>属性，或满足<code>serializability</code>的并发操作并不保证系统具备最佳的执行性能。另外，满足<code>serializability</code>特性的并发操作，对编程人员是友好的，因为，我们不必关心并发操作细节。</p>
<h2 id="基于锁的-before-or-after-atomicity-属性的实现"><a href="#基于锁的-before-or-after-atomicity-属性的实现" class="headerlink" title="基于锁的 before-or-after atomicity 属性的实现"></a>基于锁的 before-or-after atomicity 属性的实现</h2><p>基于锁来实现事务的并发控制可以分为两个类别：悲观锁(<code>pessimistic</code>)及乐观锁(<code>optimistic</code>)。前者会在操作共享对象之前获取锁，如果在获取锁时，锁已经被其它事务占用了，则必须等待。而后者并不要求在操作共享对象之前获取锁，它会先将对象进行拷贝，然后操作对象，在提交事务的时候检查原始对象是否有被更改过，若没有，则提交事务，否则中止事务，换言之，在获取锁失败时，乐观并发控制(<code>optimistic cocurrency controll</code>)采用的是<code>abort+retry</code>的模式来操作共享对象，因为它没有直接给对象加锁，因此若对象访问没有冲突时，它比悲观锁要快，反之，若在一个充满锁竞争的事务环境下，乐观锁的效果一种会比悲观锁要差。而本节下面提到的基于锁的<code>before-or-after atomicity</code>属性（或<code>serializability</code>）的实现都属于悲观锁的实现。</p>
<p><code>system-wide lock</code>，即系统级锁。这是基于锁实现的<code>before-or-after atomicity</code>属性最简单的版本。顾名思义，它在系统开始运行时便在内存中创建一个（唯一一个）锁对象，并且必须在事务执行的开始与结束位置插入获取锁与释放锁的代码。显然，<code>system-wide lock</code>一次只允许运行单个事务，它会将所有的事务按照其获取锁的顺序依次执行，不支持事务的并发执行。因为<code>system-wide lock</code>锁住孙事务涉及的所有对象，因此在某些场合其是不必根据，换言之，其锁的粒度（范围）过大。</p>
<p><code>simple locking</code>，即简单锁。它满足两个规则：其一，每个事务在对某一对象执行实际的读写操作时，必须提前获取此对象的锁。其二，当事务所有操作完成后被提交或者事务被中断时才释放锁。其中，<code>lock point</code>被定义为事务获取其范围内操作所有对象的锁的时刻。而<code>lock set</code>被定义为截止<code>lock point</code>时间点，其所获取的锁的集合。因此，为了保证能正确地协调事务的并发执行，应用程序在执行其每个事务前必须获取事务所对应的<code>lock set</code>，同样，在事务执行完成时释放<code>lock set</code>中的锁。下面简单证明<code>simple locking</code>的策略能够保证<code>before-or-after atomicity</code>。</p>
<blockquote>
<p>假定有一个外部观察者维护一个事务标识符的列表，并且一旦某个事务到达其<code>lock point</code>，其标识符就会被添加到此列表，并在事务执行完毕即将释放锁时将其从列表中移除。<code>simple locking</code>能够保证：每个事务都不会在其被添加到列表之前读或写任何对象，并且列表中此事务前面的所有事务都已经通过其对应的<code>lock point</code>。由于任意两个事务<code>lock set</code>不会出现相同的数据对象，因此任何事务的<code>lock set</code>中的数据对象都不会出现在列表中它前面的事务的<code>lock set</code>中，所以也不会出现在列表中更早的事务的<code>lock set</code>中。因此，此事务的输入所涉及的对象内容与列表中的其前一个事务<code>commit</code>（事务顺利完成）或<code>abort</code>（事务中止）后的输出的对象的内容相同。因此，<code>simple locking</code>规则保证此事务<code>before-or-after atomicity</code>属性。</p>
</blockquote>
<p>显然，<code>simple locking</code> 所提供的并发粒度也过大，因为，它必须对事务可能涉及到的每一个共享对象加锁，因此它有可能锁住那些原本并不需要的对象。</p>
<p><code>two-phase locking</code>(<code>2PL</code>)，即两阶段锁。相比于<code>simple locking</code>，它并不要求事务在操作共享对象之前获取其所涉及到的所有对象的锁（准确而言，对于<code>simple locking</code>，一旦事务操作任一共享对象，都需要获取所有对象的锁，而<code>two-phase locking</code>只有等到事务真正操作某一对象时，才去尝试获取此对象对应的锁，因此其锁的粒度要比<code>simple locking</code>要小）。典型地，<code>2PL</code>包括两个过程：1. 扩展锁阶段(<code>expanding phase</code>)，根据操作共享对象的顺序依次获取锁，在此过程中不会有锁被释放。2. 收缩锁阶段(<code>shrinking phase</code>)，锁逐渐被释放，并且在此过程不会尝试获取锁（如果阶段一没有明确的完成标志，那么为了保证事务安全，会等到事务提交或者事务中止时，才会一次性释放所有锁）。但同<code>simple locking</code>类似的是，<code>2PL</code>也允许应用程序并发执行事务，其也会保证所有事务的执行所产生的结果同它们以某一个顺序（到达<code>lock point</code>的顺序）执行所产生的结果相同（因此，<code>2PL</code>有可能导致死锁）。虽然，同<code>simple locking</code>相比，<code>2PL</code>提供更强的事务并发执行能力，但其同样会导致原本允许并发执行的事务的串行顺序执行。参考文献[1]还讨论了当事务执行失败时，锁与日志的交互如何保证事务的顺序执行。</p>
<h2 id="原子提交"><a href="#原子提交" class="headerlink" title="原子提交"></a>原子提交</h2><p>若构成事务的操作分布在不同机器上，为了确保事务被正确执行，则必须保证事务原子性提交，即分布在不同机器上的事务要么全部执行，要么都不执行。</p>
<p><code>Two-phase commit</code>(<code>2PC</code>)，两阶段提交。它被用于解决分布式事务原子提交问题（但并没有完全解决）。先简要阐述经典的<code>2PC</code>协议，整个事务由一个事务协调者(<code>transaction coordinator</code>及若干事务参与者(<code>participant</code>)构成，协议的执行大致可以分为如下两个阶段：</p>
<ul>
<li><code>prepare</code>阶段：客户端向<code>TC</code>发送事务提交请求，<code>TC</code>开始执行两阶段提交。它首先通过<code>RPC</code>向所有的<code>participant</code>发送<code>prepare</code>消息，若<code>participant</code>当前能够执行事务，则向<code>TC</code>回复<code>prepare</code>成功(<code>YES</code>)，并且锁定事务执行所需要的锁与资源，否则回复<code>NO</code>。</li>
<li><code>commit</code>阶段：若<code>TC</code>收到所有<code>participant</code>回复的<code>YES</code>消息，则开始正式<code>commit</code>事务。它会给所有的<code>participant</code>发送<code>commit</code>消息。<code>participant</code>收到<code>commit</code>消息后，释放事务过程中持有的锁和其他资源，并将事务在本地提交，然后向<code>TC</code>回复<code>commit</code>成功，即<code>YES</code>，否则回复<code>NO</code>。<code>TC</code>收到所有<code>participant</code>回复的<code>commit</code>成功的消息后，向客户端返回成功。反之，一旦<code>TC</code>收到某个<code>participant</code>对<code>preapre</code>消息回复了<code>NO</code>消息，则向所有的<code>participant</code>回复<code>abort</code>消息。</li>
</ul>
<p>显然，若整个过程无任何故障发生，<code>2PC</code>能够保证分布式事务提交的原子性，因为所有事务参与者对事务的提交都是经由事务协调者来协调决定，因此它们要么全部提交事务要么都不会提交事务。</p>
<p>上述为正常条件下协议执行流程，即没有节点宕机，也没有网络故障。下面讨论若发生失败，会有怎样的情况：</p>
<ul>
<li>事务参与者宕机，然后重启。若此<code>participant</code>在宕机前对<code>TC</code>的<code>prepare</code>消息回复了<code>YES</code>，那么它必须在宕机前对日志记录。因为其它的<code>participant</code>也有可能同意了<code>prepare</code>消息。具体而言，如果<code>participant</code>重启后，其日志文件记录了<code>prepare</code>的<code>YES</code>消息，但其并没有<code>commit</code>事务，此时它必须主动发消息给<code>TC</code>，或者等待<code>TC</code>重新向它发送<code>commit</code>消息。且在整个过程中，<code>participant</code>必须一直保持对资源及锁的占用。</li>
<li>事务协调者宕机，然后重启。因为<code>TC</code>可能在宕机前对所有协调者发送了<code>commit</code>消息，因此它也必须对此作日志记录。因为或许某个<code>participant</code>已经执行了事务的<code>commit</code>。如果其在重启后，收到了<code>participant</code>的询问消息，必须重新发送<code>commit</code>消息（或者等待一段超时时间后，重新发送<code>commit</code>消息）。</li>
<li>事务协调者一直未收到事务参与者的对<code>prepare</code>消息的回复。可能此时<code>participant</code>已经宕机并且没有重启，也有可能网络发生了故障。因此<code>TC</code>必须设置超时机制，一旦超时未收到回复，则中止事务的提交（因为此时并没有发送<code>commit</code>消息，所有<code>participant</code>都不会提交，保证了事务提交的原子性）。</li>
<li>事务参与者在收到<code>prepare</code>消息前宕机，或超时（一直未收到）。此时，因为<code>participant</code>并没有回复<code>prepare</code>消息（即未对<code>TC</code>作出事务执行的任何承诺），因此其允许单方面中止事务，释放锁及其它资源，此时可能是协议还未开始执行（自然而然，<code>participant</code>的宕机对协议是没有任何影响，直到下一次协议开始执行了，若此<code>participant</code>仍旧处于宕机状态，则将导致<code>abort</code>事务）。</li>
<li>事务协调者在未发送<code>prepare</code>消息前宕机。此时，同上一种情况类似，协议很可能还未开始执行，因此<code>TC</code>的宕机并不影响事务正确性。</li>
<li>事务参与者对<code>prepare</code>消息回复了<code>YES</code>，但是一直未收到<code>commit/abort</code>消息。此时，<code>participant</code>不能单方面中止事务，因为其已经向<code>TC</code>的<code>prepare</code>消息回复了<code>YES</code>，且其它<code>participant</code>也有可能向<code>TC</code>回复了<code>YES</code>，因此<code>TC</code>可能已经向除此<code>participant</code>之外的所有<code>participant</code>发送了<code>commit</code>消息，然后<code>TC</code>发生了宕机。但收到<code>commit</code>消息的<code>participant</code>可能已经<code>commit</code>本地事务。因此，此<code>participant</code>不能单方面<code>abort</code>事务（否则造成事务不一致）。同时，此<code>participant</code>也不能单方面的<code>commit</code>本地事务，因为同样，其它的<code>participant</code>也有可能对<code>TC</code>的<code>prepare</code>消息回复了<code>NO</code>，因此<code>TC</code>在收到所有的<code>prepare</code>消息的回复后，中止了事务的提交。总而言之，若<code>participant</code>对<code>TC</code>的<code>prepare</code>消息回复了<code>YES</code>，则它不能单方面作出任何决定，只能一直阻塞等待<code>TC</code>对事务的决定。</li>
</ul>
<p>因此，通过上述分述，经典的<code>2PC</code>协议存在明显的局限性：</p>
<ul>
<li>事务协调者宕机：<code>2PC</code>为一个阻塞式协议，一旦事务协调者宕机，则若有参与者处于执行<code>commit/abort</code>之前的任何阶段，事务进程都将会被阻塞，必须等待事务协调者重启后，事务才能继续执行。</li>
<li>交互延迟：事务协调者必须将事务的<code>commit/abort</code>写日志后才能发送<code>commit/abort</code>‘消息。因此整个过程至少包含2次<code>RPC</code>(<code>prepare+commit</code>)，以及3次日志记录的延迟（<code>prepare</code>写日志+事务协调者状态持久化+<code>commit</code>写日志）。</li>
</ul>
<p>参考文献</p>
<p>[1] <a href="https://en.wikipedia.org/wiki/Two-phase_locking" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Two-phase_locking</a><br>[2] Saltzer J H, Kaashoek M F. Principles of computer system design: an introduction[M]. Morgan Kaufmann, 2009.<br>[3]. <a href="https://zhuanlan.zhihu.com/p/22594180" target="_blank" rel="noopener">两阶段提交的工程实践</a></p>
]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>分布式事务</tag>
        <tag>并发控制</tag>
        <tag>原子提交</tag>
        <tag>二阶段提交</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring全家桶注解概览</title>
    <url>/2018/12/07/2018-12-07-Spring%E5%85%A8%E5%AE%B6%E6%A1%B6%E6%B3%A8%E8%A7%A3%E6%A6%82%E8%A7%88/</url>
    <content><![CDATA[<h1 id="Java元注解"><a href="#Java元注解" class="headerlink" title="Java元注解"></a>Java元注解</h1><table>
<thead>
<tr>
<th align="left">注解</th>
<th align="left">解释</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>@Documented</strong></td>
<td align="left">javadoc文档中列出被此注解注解的元素</td>
</tr>
<tr>
<td align="left"><strong>@Target</strong></td>
<td align="left">注解能被应用的目标元素，比如类、方法、属性、参数等等</td>
</tr>
<tr>
<td align="left"><strong>@Retention</strong></td>
<td align="left">仅在源码保留，还是保留到编译后的字节码，还是到运行时也去加载</td>
</tr>
<tr>
<td align="left"><strong>@Inherited</strong></td>
<td align="left">如果子类没有定义注解的话，能自动从父类获取定义了继承属性的注解</td>
</tr>
<tr>
<td align="left"><strong>@Repeatable</strong></td>
<td align="left">通过关联注解容器定义可重复注解</td>
</tr>
<tr>
<td align="left"><strong>@Native</strong></td>
<td align="left">是否在.h头文件中生成被标记的字段，原生程序需要和Java程序交互</td>
</tr>
</tbody></table>
<a id="more"></a>

<h1 id="SpringCore-注解"><a href="#SpringCore-注解" class="headerlink" title="SpringCore 注解"></a>SpringCore 注解</h1><table>
<thead>
<tr>
<th align="left">注解</th>
<th align="left">解释</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>@Controller</strong></td>
<td align="left">定义表现层组件</td>
</tr>
<tr>
<td align="left"><strong>@Service</strong></td>
<td align="left">定义业务逻辑层组件</td>
</tr>
<tr>
<td align="left"><strong>@Repository</strong></td>
<td align="left">定义数据访问层资源库组件</td>
</tr>
<tr>
<td align="left"><strong>@Component</strong></td>
<td align="left">定义其它组件（比如访问外部服务的组件）</td>
</tr>
<tr>
<td align="left"><strong>@Autowired</strong></td>
<td align="left">自动装配<code>Bean</code>（默认按类型装配<code>byType</code>）</td>
</tr>
<tr>
<td align="left"><strong>@Required</strong></td>
<td align="left">用于在<code>setter</code>方法标记属性值需要由<code>Spring</code>进行装配</td>
</tr>
<tr>
<td align="left"><strong>@Qualifier</strong></td>
<td align="left">用于通过给<code>Bean</code>定义修饰语来注入相应的Bean</td>
</tr>
<tr>
<td align="left"><strong>@Resource</strong></td>
<td align="left">自动装配<code>Bean</code>（默认按照名称进行装配<code>byName</code>）</td>
</tr>
<tr>
<td align="left"><strong>@Value</strong></td>
<td align="left">用于注入属性配置或SpEL表达式</td>
</tr>
<tr>
<td align="left"><strong>@Lookup</strong></td>
<td align="left">可以实现方法注入(注入的对象是<code>Prototype</code>生命周期,每次<code>new</code>一个出来）</td>
</tr>
<tr>
<td align="left"><strong>@EnableTransactionManagement</strong></td>
<td align="left">用于开启事务管理</td>
</tr>
<tr>
<td align="left"><strong>@Transactional</strong></td>
<td align="left">用于开启事务以及设置传播性、隔离性、回滚条件等</td>
</tr>
<tr>
<td align="left"><strong>@TransactionalEventListener</strong></td>
<td align="left">用于配置事务的回调方法(事务提交前、提交后、完成后,回滚后)</td>
</tr>
<tr>
<td align="left"><strong>@Order</strong></td>
<td align="left">注解可以设置<code>Spring</code>管理对象的加载顺序</td>
</tr>
<tr>
<td align="left"><strong>@AliasFor</strong></td>
<td align="left">注解可以设置一组注解属性相互作为别名</td>
</tr>
</tbody></table>
<h1 id="SpringContext-注解"><a href="#SpringContext-注解" class="headerlink" title="SpringContext 注解"></a>SpringContext 注解</h1><table>
<thead>
<tr>
<th align="left">注解</th>
<th align="left">解释</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>@Configuration</strong></td>
<td align="left">用于标注配置类，启用Java配置方式的Bean配置</td>
</tr>
<tr>
<td align="left"><strong>@Bean</strong></td>
<td align="left">用于配置一个<code>Bean</code></td>
</tr>
<tr>
<td align="left"><strong>@ComponentScan</strong></td>
<td align="left">用于扫描包方式配置<code>Bean</code></td>
</tr>
<tr>
<td align="left"><strong>@ComponentScans</strong></td>
<td align="left">用于配置一组<code>@ComponentScan</code></td>
</tr>
<tr>
<td align="left"><strong>@PropertySource</strong></td>
<td align="left">用于导入配置文件</td>
</tr>
<tr>
<td align="left"><strong>@PropertySources</strong></td>
<td align="left">用于配置一组<code>@PropertySource</code></td>
</tr>
<tr>
<td align="left"><strong>@Conditional</strong></td>
<td align="left">用于设置关联的条件类，在合适的时候启用<code>Bean</code>的配置</td>
</tr>
<tr>
<td align="left"><strong>@Import</strong></td>
<td align="left">用于导入其它配置类</td>
</tr>
<tr>
<td align="left"><strong>@ImportResource</strong></td>
<td align="left">用于导入非Java配置方式的<code>XML</code>配置</td>
</tr>
<tr>
<td align="left"><strong>@Profile</strong></td>
<td align="left">用于指定在合适的<code>Profile</code>下启用配置</td>
</tr>
<tr>
<td align="left"><strong>@Lazy</strong></td>
<td align="left">用于告知容器延迟到使用的时候实例化<code>Bean</code>（默认情况下容器启动的时候实例化Bean来检查所有的问题）</td>
</tr>
<tr>
<td align="left"><strong>@Description</strong></td>
<td align="left">用于给Bean设置描述</td>
</tr>
<tr>
<td align="left"><strong>@Scope</strong></td>
<td align="left">用于设置Bean的生命周期</td>
</tr>
<tr>
<td align="left"><strong>@Primary</strong></td>
<td align="left">用于在定义了多个Bean的时候指定首选的Bean</td>
</tr>
<tr>
<td align="left"><strong>@EventListener</strong></td>
<td align="left">用于设置回调方法监听Spring制定的以及自定义的各种事件</td>
</tr>
<tr>
<td align="left"><strong>@EnableAspectJAutoProxy</strong></td>
<td align="left">用于开启支持<code>AspectJ</code>的<code>@Aspect</code>切面配置支持</td>
</tr>
</tbody></table>
<h1 id="SpringMVC-注解"><a href="#SpringMVC-注解" class="headerlink" title="SpringMVC 注解"></a>SpringMVC 注解</h1><table>
<thead>
<tr>
<th align="left">注解</th>
<th align="left">解释</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>@RequestScope</strong></td>
<td align="left"><code>Bean</code>特殊生命周期的复合注解（需要<code>Bean</code>跟随<strong>请求</strong>声明周期）</td>
</tr>
<tr>
<td align="left"><strong>@SessionScope</strong></td>
<td align="left"><code>Bean</code>特殊生命周期的复合注解（需要<code>Bean</code>跟随<strong>会话</strong>声明周期）</td>
</tr>
<tr>
<td align="left"><strong>@ApplicationScope</strong></td>
<td align="left"><code>Bean</code>特殊生命周期的复合注解（需要<code>Bean</code>跟随<strong>应用程序</strong>的声明周期）</td>
</tr>
<tr>
<td align="left"><strong>@RequestMapping</strong></td>
<td align="left">用于配置<code>Http</code>请求路径参数等，手动配置<code>HttpMethod</code></td>
</tr>
<tr>
<td align="left"><strong>@PostMapping</strong></td>
<td align="left">基于<code>@RequestMapping</code>的复核注解，<code>HTTPPOST</code>请求</td>
</tr>
<tr>
<td align="left"><strong>@GetMapping</strong></td>
<td align="left">基于<code>@RequestMapping</code>的复核注解，<code>HTTPGET</code>请求</td>
</tr>
<tr>
<td align="left"><strong>@DeleteMapping</strong></td>
<td align="left">基于<code>@RequestMapping</code>的复核注解，<code>HTTPDELETE</code>请求</td>
</tr>
<tr>
<td align="left"><strong>@PutMapping</strong></td>
<td align="left">基于<code>@RequestMapping</code>的复核注解，<code>HTTPPUT</code>请求</td>
</tr>
<tr>
<td align="left"><strong>@ResponseStatus</strong></td>
<td align="left">可用到方法或异常上，请求得到响应代码</td>
</tr>
<tr>
<td align="left"><strong>@ExceptionHandle</strong></td>
<td align="left">可用到方法或异常上，请求得到异常原因,可以进行统一的全局异常处理</td>
</tr>
<tr>
<td align="left"><strong>@ResponseBody</strong></td>
<td align="left">把返回内容（序列化后）输出到请求体，<code>@RestController</code>常用</td>
</tr>
<tr>
<td align="left"><strong>@RequestBody</strong></td>
<td align="left">从请求体获取参数（处理复杂数据，比如<code>JSON</code>）</td>
</tr>
<tr>
<td align="left"><strong>@RequestHeader</strong></td>
<td align="left">从请求头获取参数获取参数</td>
</tr>
<tr>
<td align="left"><strong>@CookieValue</strong></td>
<td align="left">从<code>cookie</code>中获取参数</td>
</tr>
<tr>
<td align="left"><strong>@SessionAttribute</strong></td>
<td align="left">从会话中获取参数</td>
</tr>
<tr>
<td align="left"><strong>@RequestAttribute</strong></td>
<td align="left">从请求的<code>Attribute</code>中（过滤器和拦截器手动设置的一些临时数据）</td>
</tr>
<tr>
<td align="left"><strong>@RequestParam</strong></td>
<td align="left">从请求参数（处理简单数据，键值对）</td>
</tr>
<tr>
<td align="left"><strong>@PathVariable</strong></td>
<td align="left">从路径片段中获取参数</td>
</tr>
<tr>
<td align="left"><strong>@MatrixAttribute</strong></td>
<td align="left">矩阵变量允许我们采用特殊的规则在<code>URL</code>路径后加参数（分号区分不同参数，逗号为参数增加多个值）</td>
</tr>
<tr>
<td align="left"><strong>@ControllerAdvice</strong></td>
<td align="left">允许我们在集中的地方配置控制器，相当于为<code>@ExceptionHandler</code>加上了<code>@ResponseBody</code></td>
</tr>
<tr>
<td align="left"><strong>@RestControllerAdvice</strong></td>
<td align="left">和<code>@ControllerAdvice</code>类似</td>
</tr>
<tr>
<td align="left"><strong>@InitBinder</strong></td>
<td align="left">用来设置<code>WebDataBinder</code>，<code>WebDataBinder</code>用来自动绑定前台请求参数到<code>Model</code>中</td>
</tr>
<tr>
<td align="left"><strong>@ModelAttribute</strong></td>
<td align="left">让全局的<code>@RequestMapping</code>都能获得在此处设置的键值对</td>
</tr>
<tr>
<td align="left"><strong>@CrossOrigin</strong></td>
<td align="left">用到<code>@Controller</code>或<code>Method</code>上（需要配合<code>@RequestMapping</code>）设置细粒度的跨域行为</td>
</tr>
</tbody></table>
<h1 id="SpringBoot-注解"><a href="#SpringBoot-注解" class="headerlink" title="SpringBoot 注解"></a>SpringBoot 注解</h1><table>
<thead>
<tr>
<th align="left">注解</th>
<th align="left">解释</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>@ConfigurationProperties</strong></td>
<td align="left">配合<code>@EnableConfigurationProperties</code>注解来设置需要启用的配置类,用来自定义配置类和配置文件进行关联</td>
</tr>
<tr>
<td align="left"><strong>@EnableConfigurationProperties</strong></td>
<td align="left">启动自定义配置</td>
</tr>
<tr>
<td align="left"><strong>@DeprecatedConfigurationProperty</strong></td>
<td align="left">用于标记废弃的配置以及设置替代配置和告知废弃原因</td>
</tr>
<tr>
<td align="left"><strong>@ConfigurationPropertiesBinding</strong></td>
<td align="left">用于指定自定义的转换器用于配置解析的时的类型转换</td>
</tr>
<tr>
<td align="left"><strong>@NestedConfigurationProperty</strong></td>
<td align="left">用于关联外部的类型作为嵌套配置类</td>
</tr>
<tr>
<td align="left"><strong>@EnableAutoConfiguration</strong></td>
<td align="left">可以启用自动配置</td>
</tr>
<tr>
<td align="left"><strong>@SpringBootApplication</strong></td>
<td align="left">复合注解，<code>SpringBoot</code>启动注解</td>
</tr>
<tr>
<td align="left"><strong>@AutoConfigureOrder</strong></td>
<td align="left">用于设置自动配置类加载顺序，以及精确控制加载依赖关系（值越小优先级越高）</td>
</tr>
<tr>
<td align="left"><strong>@AutoConfigureAfter</strong></td>
<td align="left">在指定的配置类初始化后再加载</td>
</tr>
<tr>
<td align="left"><strong>@AutoConfigureBefore</strong></td>
<td align="left">在指定的配置类初始化前加载</td>
</tr>
<tr>
<td align="left"><strong>@ConditionalOnBean</strong></td>
<td align="left">用于仅当容器中已经包含指定的Bean类型或名称时才匹配条件</td>
</tr>
<tr>
<td align="left"><strong>@ConditionalOnClass</strong></td>
<td align="left">仅当<code>classpath</code>上存在指定类时条件匹配</td>
</tr>
<tr>
<td align="left"><strong>@ConditionalOnCloudPlatform</strong></td>
<td align="left">仅当指定的云平台处于活动状态时条件匹配</td>
</tr>
<tr>
<td align="left"><strong>@ConditionalOnExpression</strong></td>
<td align="left">依赖于<code>SpEL</code>表达式的值的条件元素的配置注解</td>
</tr>
<tr>
<td align="left"><strong>@ConditionalOnJava</strong></td>
<td align="left">基于应用运行的JVM版本的条件匹配</td>
</tr>
<tr>
<td align="left"><strong>@ConditionalOnJndi</strong></td>
<td align="left">基于<code>JNDI</code>可用和可以查找指定位置的条件匹配</td>
</tr>
<tr>
<td align="left"><strong>@ConditionalOnMissingBean</strong></td>
<td align="left">仅当容器中不包含指定的Bean类型或名称时条件匹配</td>
</tr>
<tr>
<td align="left"><strong>@ConditionalOnMissingClass</strong></td>
<td align="left">仅当<code>classpath</code>上不存在指定类时条件匹配</td>
</tr>
<tr>
<td align="left"><strong>@ConditionalOnNotWebApplication</strong></td>
<td align="left">仅当不是<code>WebApplicationContext</code>（非<code>Web</code>项目）时条件匹配</td>
</tr>
<tr>
<td align="left"><strong>@ConditionalOnWebApplication</strong></td>
<td align="left">仅当是<code>WebApplicationContext</code>（<code>Web</code>项目）时条件匹配</td>
</tr>
<tr>
<td align="left"><strong>@ConditionalOnProperty</strong></td>
<td align="left">是检查指定的属性是否具有指定的值</td>
</tr>
<tr>
<td align="left"><strong>@ConditionalOnResource</strong></td>
<td align="left">示仅当<code>classpath</code>上存在指定资源时条件匹配</td>
</tr>
<tr>
<td align="left"><strong>@ConditionalOnSingleCandidate</strong></td>
<td align="left">仅当容器中包含指定的Bean类并且可以判断只有单个候选者时条件匹配</td>
</tr>
<tr>
<td align="left"><strong>@Conditional</strong></td>
<td align="left">关联到自己实现的<code>SpringBootCondition</code></td>
</tr>
</tbody></table>
<h1 id="SpringCloud-注解"><a href="#SpringCloud-注解" class="headerlink" title="SpringCloud 注解"></a>SpringCloud 注解</h1><table>
<thead>
<tr>
<th align="left">注解</th>
<th align="left">解释</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>@EnableXXX</strong></td>
<td align="left">开启某个功能</td>
</tr>
<tr>
<td align="left"><strong>@RibbonClient</strong></td>
<td align="left">这个注解用来为负载均衡客户端做一些自定义的配置</td>
</tr>
<tr>
<td align="left"><strong>@SpringCloudApplication</strong></td>
<td align="left">复合注解，<code>SpringCloud</code>启动注解</td>
</tr>
<tr>
<td align="left"><strong>@LoadBalanced</strong></td>
<td align="left">用于和<code>RestTemplate</code>配合使用构成一个负载均衡的<code>Http</code>客户端，实现原理上其实这个注解是一个<code>@Qualifier</code>注解</td>
</tr>
<tr>
<td align="left"><strong>@SpanName</strong></td>
<td align="left">手动设置span的名称</td>
</tr>
</tbody></table>
<h1 id="注"><a href="#注" class="headerlink" title="注"></a>注</h1><ol>
<li>元注解，也就是注解的注解  </li>
<li><code>Spring</code>容器相关的一些注解，包括<code>@Qualifier</code>、<code>@AliasFor</code>、<code>@Order</code>等看似不重要但其实很重要的注解  </li>
<li><code>Spring</code>、<code>Java</code>配置相关的一些注解，包括条件注解  </li>
<li><code>SpringBoo</code>t自动配置相关的一些注解  </li>
<li>很多注解可以同时应用到类型、方法、参数上，有的时候应用到不同的地方作用会略微不一样，这个需要重点关注  </li>
</ol>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://mp.weixin.qq.com/s/ZDqDvG5Soy_gucYrvMi6fg" target="_blank" rel="noopener">朱晔和你聊Spring系列S1E9：聊聊Spring的那些注解</a>  </p>
]]></content>
      <categories>
        <category>后端开发</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>理解分布式协调服务 zookeeper</title>
    <url>/2018/12/04/%E7%90%86%E8%A7%A3%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E6%9C%8D%E5%8A%A1-ZooKeeper/</url>
    <content><![CDATA[<p><code>ZooKeeper</code>是 Yahoo! 于 2010 年在 USENIX 会议上发表的一篇论文中提出的，被用作分布式应用程序的协调服务(<code>coordination service</code>)。虽然<code>ZooKeeper</code>被认为是 Google <code>Chubby</code>的开源实现，但其设计理念却存在较大差异：<code>ZooKeeper</code>致力于提供一个简单且高性能(<code>high performance</code>)的内核(<code>kernel</code>)以为客户端（应用程序）构建更复杂、更高层(<code>high level</code>)的协调原语(<code>coordination primitives</code>)。换言之，<code>ZooKeeper</code>并不针对特定应用或者具体某一协调服务而设计实现，它只提供构建应用协调原语的内核，而将具体协调原语的构建逻辑放权给客户端，并且，它确保了客户端在不需要更改内核服务的前提下，能够灵活构建出新的、更高级的且更强大的协调原语，比如分布式互斥锁、分布式队列等。<code>ZooKeeper</code>为每个客户端操作提供<code>FIFO</code>顺序保证，并且为所有写操作提供<code>linearlizablity</code>保证。<code>ZooKeeper</code>的实现原理为构建在其之上的服务提供高性能保证。</p>
<a id="more"></a>

<p><a href="https://scholar.google.com/scholar_url?url=https://www.usenix.org/event/usenix10/tech/full_papers/Hunt.pdf&hl=zh-CN&sa=T&oi=gsb-ggp&ct=res&cd=0&d=16979330189653726967&ei=n4kGXN6bNYSwyQTtrY2YBw&scisig=AAGBfm3u4LNga1CwiXqT9W5TbZFnKyv21Q" target="_blank" rel="noopener">Zookeeper</a> 为分布式应用提供诸如配置管理(<code>configuration managation</code>)、leader 选举等协调服务，这通过为应用程序提供构建协调原语的 <code>API</code>来实现。并且，与那些提供阻塞原语的服务不同，<code>ZooKeeper</code>实现的 <a href="https://en.wikipedia.org/wiki/Non-blocking_algorithm" target="_blank" rel="noopener">wait-free</a> 数据对象确保其容错和高性能特性，因为若利用阻塞原语来构建协调服务，可能会导致那些慢的(<code>slow</code>)或者有错误的(<code>faulty</code>)的客户端影响正常的客户端的服务性能。此博客阐述个人对<code>ZooKeeper</code>的理解，并从一个<code>ZooKeeper</code>的应用实例开始讨论，分别阐述<code>ZooKeeper</code>两个<code>ordering guarantees</code>、。因为本文并非对原论文的完整翻译，因此你需要提前阅读原论文，确保熟知<code>ZooKeeper</code>数据模型以及客户端<code>API</code>等内容，而且，博客也会省略论文所阐述的利用<code>ZooKeeper</code>来实现部分协调服务部分，具体内容可以参考原论文。</p>
<h2 id="一个应用实例阐述"><a href="#一个应用实例阐述" class="headerlink" title="一个应用实例阐述"></a>一个应用实例阐述</h2><p>我们知道<code>MapReduce</code>需要知道集群<code>master</code>的<code>ip:port</code>以使得其它节点能够与<code>master</code>建立连接通信，为此，<code>MapReduce</code>可以利用<code>ZooKeeper</code>作为动态配置服务，让<code>master candidate</code>在<code>ZooKeeper</code>上并发注册（创建）各自<code>ephemeral</code>类型的<code>ip:port</code>节点，并让<code>slave</code>监听对应节点的<code>watch event</code>，因此一旦有<code>master candidate</code>注册成功（且只能有一个创建成功），则其它节点将能获取到<code>master</code>的<code>ip:port</code>。</p>
<p>若使用基于<code>raft</code>构建的复制状态机实现，比如在<code>raft</code>集群上构建一个<code>key/value</code>存储系统来存放<code>GFS master</code>的元信息。则整个过程大致如下：首先，<code>master candidate</code>向<code>raft</code>发送<code>Put(&quot;gfs-master&quot;, &quot;ip:port&quot;)</code>命令日志，当<code>raft</code>集群<code>apply</code>此命令日志后，其它节点可通过向<code>raft</code>发送<code>Get(&quot;gfs-master&quot;)</code>命令来获取<code>master</code>的<code>ip:port</code>。但此过程存在几个问题：其一，若多个<code>master candidate</code>同时向<code>raft</code>发送节点地址的注册命令日志，此时将产生<code>race condition</code>，其会导致后发送的命令被应用到状态机，因此<code>master candidate</code>需要进一步判断自己是否成为真正的<code>master</code>（不能仅通过发送了节点地址命令日志来确定）；其二，若<code>master</code>失效，其地址项日志必须要从存储中移除，那么谁来执行此操作？因此，必须对<code>master</code>的元数据信息设置<code>timeout timestamp</code>，并且让<code>master</code>通过定期向<code>raft</code>发送<code>Put(ip:port, timestamp)</code>日志来更新<code>timeout</code>的<code>timestamp</code>，而集群其它节点通过向<code>raft</code>轮询(<code>poll</code>)此<code>timestamp</code>来确保<code>master</code>正常工作，毫无疑问，这将产生大量不必要的<code>poll cost</code>。对比使用<code>ZooKeeper</code>来提供此协调服务（上一段），问题是如何被<code>ZooKeeper</code>高效便捷地解决呢？首先它会确保在多个<code>master candidate</code>同时注册地址信息时，只会有一个操作成功；其次，<code>ZooKeeper</code>的<code>session</code>机制简化了<code>timestamp timeout</code>设置，一旦<code>master</code>宕机，其在<code>ZooKeeper</code>上注册的元信息节点将会自动清除。而且，对应的节点移除消息也会通知到其它节点，避免了<code>slave</code>的大量的轮询消耗。由此可见，使用<code>ZooKeeper</code>来进行集群配置信息的管理，有利于简化服务实现的逻辑。</p>
<h2 id="ZooKeeper-两个-ordering-guarantees"><a href="#ZooKeeper-两个-ordering-guarantees" class="headerlink" title="ZooKeeper 两个 ordering guarantees"></a>ZooKeeper 两个 ordering guarantees</h2><p>在讨论<code>ZooKeeper</code>两个基本的<code>ordering guarantees</code>之前，先了解什么是 <code>wait-free</code>，你可以从<a href="https://en.wikipedia.org/wiki/Non-blocking_algorithm" target="_blank" rel="noopener">维基</a>或者 <a href="https://cs.brown.edu/~mph/Herlihy91/p124-herlihy.pdf" target="_blank" rel="noopener">Herlihy的论文</a> 上找到其明确定义：</p>
<blockquote>
<p>A wait-free implementation of a concurrent data object is one that guarantees that any process can complete any operation in a finite number of steps, regardless of the execution speeds of the other processes.</p>
</blockquote>
<blockquote>
<p>Wait-freedom is the strongest non-blocking guarantee of progress, combining guaranteed system-wide throughput with starvation-freedom. An algorithm is wait-free if every operation has a bound on the number of steps the algorithm will take before the operation completes</p>
</blockquote>
<p>而对于<code>ZooKeeper</code>而言，其提供的<code>API</code>被称为是<code>wait-free</code>的，因为<code>ZooKeeper</code>直接响应客户端请求，即此请求的返回并不会受到其它客户端操作的影响（通常是<code>slow</code>或者<code>faulty</code>）。换言之，若此客户端请求为写节点数据操作，只要<code>ZooKeeper</code>收到状态变更，则会立即响应此客户端。如果在这之前某一客户端监听了此节点的数据变更事件，则一旦此节点的数据发生变化，则<code>ZooKeeper</code>会推送变更事件给监听的客户端，然后立即返回给写数据的客户端，并不会等待此监听客户端确认此事件。相比于同步阻塞的调用，<code>wait-free</code>明显提供更好的性能，因为客户端不用同步等待每次调用的返回，且其可以进行异步的批量调用<code>batch call</code>操作，以均摊(<code>amortize</code>)网络传输和IO开销。<code>wait-free</code>的<code>API</code>是<code>ZooKeeper</code>具备高性能的基础，因此也是<code>ZooKeeper</code>的设计核心。</p>
<p><code>ZooKeeper</code>提供了两个基本的<code>ordering guarantees</code>：<code>Linearizable writes</code>及<code>FIFO client order</code>。<code>Linearizable write</code>表示对<code>ZooKeeper</code>的节点状态更新的请求都是线性化的(<code>serializable</code>)，而<code>FIFO client order</code>则表示对于同一个客户端而言，<code>ZooKeeper</code>会保证其操作的执行顺序与客户端发送此操作的顺序一致。毫无疑问，这是两个很强的保证。</p>
<p><code>ZooKeeper</code>提供了<code>Linearizable write</code>，那什么是<code>Linearizablility</code>？<a href="https://cs.brown.edu/~mph/Herlihy91/p124-herlihy.pdf" target="_blank" rel="noopener">Herlihy的论文</a>同样给出了其定义，为了方便，你也可以参考<a href="https://medium.com/databasss/on-ways-to-agree-part-2-path-to-atomic-broadcast-662cc86a4e5f" target="_blank" rel="noopener">这里</a>或者<a href="http://www.bailis.org/blog/linearizability-versus-serializability/" target="_blank" rel="noopener">这里</a>。</p>
<blockquote>
<p>Linearizability is a correctness condition for concurrent objects that provides the illusion that each operation applied by concurrent processes takes effect instantaneously at some point between its invocation and its response, implying that the meaning of a concurrent object’s operations can be given by pre- and post-conditions.</p>
</blockquote>
<p>简单而言，<code>Linearizability</code>是分布式系统领域的概念（区别于数据库领域与事务相关的概念<code>Serializability</code>），一个分布式系统若实现了<code>linearizability</code>，它必须能够保证系统中存在一个时间点，在此时间点之后，整个系统会提交到新的状态，且绝不会返回到旧的状态，此过程是即时的(<code>instantaneous</code>)，一旦这个值被提交，其它所有的进程都会看到，系统的写操作会保证是全局有序(<code>totally ordered</code>)。</p>
<p>而<code>ZooKeeper</code>论文提到其<code>write</code>具备<code>Linearizability</code>，确切而言是<code>A-linearizability</code>(<code>asynchronous linearizability</code>)。简而言之，<code>Linearizability</code>原本（原论文）是针对单个对象，单个操作(<code>single object, single operation</code>)而言的，但<code>ZooKeeper</code>扩大其应用范围，它允许客户端同时执行多个操作（读写），并且保证每个操作同样会遵循<code>Linearizability</code>。</p>
<p>值得注意的是，<code>ZooKeeper</code>对其操作（<code>create</code>,<code>delete</code>等）提供<code>pipelining</code>特性，即<code>ZooKeeper</code>允许客户端批量地执行异步操作（比如发送了<code>setData</code>操作后可以立即调用<code>geData</code>），而不需要等到上一个操作的结果返回。毫无疑问，这降低了操作的延迟(<code>lantency</code>)，增加了客户端服务的吞吐量(<code>throughtout</code>)，也是<code>ZooKeeper</code>高性能的保证。但通常情况下，这会带来一个问题，因为所有操作都是异步的，因此这些操作可能会被重排序(<code>re-order</code>)，这肯定不是客户端希望发生的（比如对于两个写操作而言，<code>re-order</code>后会产生奇怪的行为）。因此，对于特定客户端，<code>ZooKeeper</code>还提供<code>client FIFO order</code>的保证。</p>
<h2 id="ZooKeeper-实现原理"><a href="#ZooKeeper-实现原理" class="headerlink" title="ZooKeeper 实现原理"></a>ZooKeeper 实现原理</h2><p>同分布式存储系统类似，<code>ZooKeeper</code>也会对数据进行冗余备份。在客户端发送请求之前，它会连接到一个<code>ZooKeeper server</code>，并将后续的请求提交给对应的<code>server</code>，当<code>server</code>收到请求后，有做如下三个保证：其一，若请求所操作的节点被某些客户端注册了监听事件，它会向对应的客户端推送事件通知。其二，若此请求为写操作，则<code>server</code>一次性只会对一个请求做处理（不会同时处理其它的读或者写请求）。其三，写操作最终是交由<code>leader</code>来处理（若接收请求的<code>server</code>并非<code>leader</code>，其主动会对请求进行转发），<code>leader</code>会利用<code>Zab</code>（原子广播协议，<code>ZooKeper atomic broadcast</code>）对此请求进行协调，最终各节点会对请求的执行结果达成一致，并将结果 <code>replica</code>到<code>ensemble servers</code>。<code>ZooKeeper</code>将数据存储到内存中（更快），但为了保证数据存储的可靠性，在将数据写到内存数据库前，也会将数据写到磁盘等外部存储。同时，对操作做好相应的<code>replay log</code>，并且其定期会对数据库进行<code>snapshot</code>。</p>
<p>若请求为读操作，则接收请求的<code>server</code>直接在本地对请求进行处理（因此读操作仅仅是在<code>server</code>的本地内存数据库进行检索处理，这也是<code>ZooKeeper</code>高性能的保证）。正因为如此，同<code>GFS</code>可能向客户端返回过期数据的特点类似，<code>ZooKeeper</code>也有此问题。如果应用程序不希望得到过期数据（即只允许得到最近一次写入的数据），则可以采用<code>sync</code>操作进行读操作前的写操作同步，即如果在读操作之前集群还有<code>pending</code>的写操作，会阻塞直至写操作完成。值得注意的是，每一次的读操作都会携带一个<code>zxid</code>，它表示<code>ZooKeeper</code>最近一次执行事务的编号（关于事务，后面会介绍），因此<code>zxid</code>定义了读操作与写操作之间的偏序关系。同时，当客户端连接到<code>server</code>时，如果此<code>server</code>发现其本地存储的当前<code>zxid</code>小于客户端提供的<code>zxid</code>的大小，其会拒绝客户端的连接请求，直至其将本地数据库同步至全局最新的状态。</p>
<p>在<code>ZooKeeper</code>内部，它会将接收到的写操作转换为事务(<code>transaction</code>)操作。因为<code>ZooKeeper</code>可能需要同时处理若干个操作，因此其会提前计算好操作被提交后数据库所处的状态。这里给出论文中提到的一个事务转换的示例：如果客户端发送一个条件更新的命令<code>setData</code>并附带上目标节点的<code>version number</code>及数据内容，当<code>ZooKeeper server</code>收到请求后，会根据更新后的数据，版本号以及更新的时间戳，为此请求生成一个<code>setDataTXN</code>事务。当事务执行出错时（比如版本号不对应），则会产生一个<code>errorTXN</code>的事务。</p>
<p>值得注意的是，<code>ZooKeeper</code>内部所构建的事务操作是幂等的(<code>idempotent</code>)。这有利于<code>ZooKeeper</code>执行失效恢复过程。具体而言，为了应对节点宕机等故障，<code>ZooKeeper</code>会定期进行<code>snapshot</code>操作，<code>ZooKeeper</code>称其为<code>fuzzy snapshot</code>。但与普通的分布式系统不同的是，它在进行快照时，并不会锁定当前<code>ZooKeeper</code>集群（一旦锁定，便不能处理客户端的写操作，且快照的时间一般也相对较长，因此会降低客户端的服务性能），它会对其树形存储进行深度优先搜索，并将搜索过程中所遍历的每一个节点的元信息及数据写到磁盘。因为<code>ZooKeeper</code>快照期间并没有锁定<code>ZooKeeper</code>的状态，因此在此过程中，若有<code>server</code>在同步写操作，则写操作可能只被<code>replica</code>到部分节点，最终使得<code>snapshot</code>的结果处于不一致的状态。但正是由于<code>ZooKeeper</code>的事务操作是<code>idempontent</code>，因此，在<code>recover</code>过程应用<code>snapshot</code>时，还会重新按顺序提交从快照启动开始到结束所涉及到的事务操作。原论文给出了一个快照恢复过程示例。因此我们会发现，<code>fuzzy snapshot</code>同样是<code>ZooKeeper</code> 高性能的体现。另外，事务幂等的特性也使得<code>ZooKeeper</code>不需要保存请求消息的ID（保存的目的是为了防止对重复执行同一请求消息），因为事务的重复执行并不会导致节点数据的不一致性。由此可见，事务幂等性的大大设计简化了<code>ZooKeeper</code>的请求处理过程及日志恢复的过程。</p>
<p>最后，关于原论文所阐述的基于<code>ZooKeeper</code>内核来构建协调服务的相关实例部分，<a href="https://github.com/qqzeng/zkprimitives" target="_blank" rel="noopener">参考实现代码在这里</a>。</p>
<p>参考文献</p>
<p>[1] Hunt P, Konar M, Junqueira F P, et al. ZooKeeper: Wait-free Coordination for Internet-scale Systems[C]//USENIX annual technical conference. 2010, 8(9).<br>[2] Herlihy M P, Wing J M. Linearizability: A correctness condition for concurrent objects[J]. ACM Transactions on Programming Languages and Systems (TOPLAS), 1990, 12(3): 463-492.<br>[3] <a href="https://medium.com/databasss/on-ways-to-agree-part-2-path-to-atomic-broadcast-662cc86a4e5f" target="_blank" rel="noopener">https://medium.com/databasss/on-ways-to-agree-part-2-path-to-atomic-broadcast-662cc86a4e5f</a><br>[4] <a href="https://en.wikipedia.org/wiki/Non-blocking_algorithm" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Non-blocking_algorithm</a><br>[5] <a href="http://www.bailis.org/blog/linearizability-versus-serializability/" target="_blank" rel="noopener">http://www.bailis.org/blog/linearizability-versus-serializability/</a></p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>分布式协调服务</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>分布式协调服务</tag>
        <tag>原子广播协议</tag>
        <tag>分布式锁</tag>
      </tags>
  </entry>
  <entry>
    <title>Http之消息头</title>
    <url>/2018/11/17/2018-11-17-Http%E4%B9%8B%E6%B6%88%E6%81%AF%E5%A4%B4/</url>
    <content><![CDATA[<p>Http Request  </p><hr><style>
table th:nth-of-type(3) {
    width: 400px;
}
</style><table>
<thead>
<tr>
<th align="center">Header</th>
<th align="center">解释</th>
<th align="center">示例</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Accept</td>
<td align="center">指定客户端能够接收的内容类型</td>
<td align="center">Accept:text/plain,text/html</td>
</tr>
<tr>
<td align="center">Accept-Charset</td>
<td align="center">浏览器可以接受的字符编码集。</td>
<td align="center">Accept-Charset:iso-8859-5</td>
</tr>
<tr>
<td align="center">Accept-Encoding</td>
<td align="center">指定浏览器可以支持的web服务器返回内容压缩编码类型。</td>
<td align="center">Accept-Encoding:compress,gzip</td>
</tr>
<tr>
<td align="center">Accept-Language</td>
<td align="center">浏览器可接受的语言</td>
<td align="center">Accept-Language:en,zh</td>
</tr>
<tr>
<td align="center">Accept-Ranges</td>
<td align="center">可以请求网页实体的一个或者多个子范围字段</td>
<td align="center">Accept-Ranges:bytes</td>
</tr>
<tr>
<td align="center">Authorization</td>
<td align="center">HTTP授权的授权证书</td>
<td align="center">Authorization:BasicQWxhZGRpbjpvcGVuIHNlc2FtZQ==</td>
</tr>
<tr>
<td align="center">Cache-Control</td>
<td align="center">指定请求和响应遵循的缓存机制</td>
<td align="center">Cache-Control:no-cache</td>
</tr>
<tr>
<td align="center">Connection</td>
<td align="center">表示是否需要持久连接。（HTTP1.1默认进行持久连接）</td>
<td align="center">Connection:close</td>
</tr>
<tr>
<td align="center">Cookie</td>
<td align="center">HTTP请求发送时，会把保存在该请求域名下的所有cookie值一起发送给web服务器。</td>
<td align="center">Cookie:$Version=1;Skin=new;</td>
</tr>
<tr>
<td align="center">Content-Length</td>
<td align="center">请求的内容长度</td>
<td align="center">Content-Length:348</td>
</tr>
<tr>
<td align="center">Content-Type</td>
<td align="center">请求的与实体对应的MIME信息</td>
<td align="center">Content-Type:application/x-www-form-urlencoded</td>
</tr>
<tr>
<td align="center">Date</td>
<td align="center">请求发送的日期和时间</td>
<td align="center">Date:Tue,15Nov201008:12:31GMT</td>
</tr>
<tr>
<td align="center">Expect</td>
<td align="center">请求的特定的服务器行为</td>
<td align="center">Expect:100-continue</td>
</tr>
<tr>
<td align="center">From</td>
<td align="center">发出请求的用户的Email</td>
<td align="center">From:<a href="mailto:user@email.com" target="_blank" rel="noopener">user@email.com</a></td>
</tr>
<tr>
<td align="center">Host</td>
<td align="center">指定请求的服务器的域名和端口号</td>
<td align="center">Host:<a href="http://www.google.cn" target="_blank" rel="noopener">www.google.cn</a></td>
</tr>
<tr>
<td align="center">If-Match</td>
<td align="center">只有请求内容与实体相匹配才有效</td>
<td align="center">If-Match:“737060cd8c284d8af7ad3082f209582d”</td>
</tr>
<tr>
<td align="center">If-Modified-Since</td>
<td align="center">如果请求的部分在指定时间之后被修改则请求成功，未被修改则返回304代码</td>
<td align="center">If-Modified-Since:Sat,29Oct201019:43:31GMT</td>
</tr>
<tr>
<td align="center">If-None-Match</td>
<td align="center">如果内容未改变返回304代码，参数为服务器先前发送的Etag，与服务器回应的Etag比较判断是否改变</td>
<td align="center">If-None-Match:“737060cd8c284d8af7ad3082f209582d”</td>
</tr>
<tr>
<td align="center">If-Range</td>
<td align="center">如果实体未改变，服务器发送客户端丢失的部分，否则发送整个实体。参数也为Etag</td>
<td align="center">If-Range:“737060cd8c284d8af7ad3082f209582d”</td>
</tr>
<tr>
<td align="center">If-Unmodified-Since</td>
<td align="center">只在实体在指定时间之后未被修改才请求成功</td>
<td align="center">If-Unmodified-Since:Sat,29Oct201019:43:31GMT</td>
</tr>
<tr>
<td align="center">Max-Forwards</td>
<td align="center">限制信息通过代理和网关传送的时间</td>
<td align="center">Max-Forwards:10</td>
</tr>
<tr>
<td align="center">Pragma</td>
<td align="center">用来包含实现特定的指令</td>
<td align="center">Pragma:no-cache</td>
</tr>
<tr>
<td align="center">Proxy-Authorization</td>
<td align="center">连接到代理的授权证书</td>
<td align="center">Proxy-Authorization:BasicQWxhZGRpbjpvcGVuIHNlc2FtZQ==</td>
</tr>
<tr>
<td align="center">Range</td>
<td align="center">只请求实体的一部分，指定范围</td>
<td align="center">Range:bytes=500-999</td>
</tr>
<tr>
<td align="center">Referer</td>
<td align="center">先前网页的地址，当前请求网页紧随其后,即来路</td>
<td align="center">Referer:<a href="https://www.google.cn/" target="_blank" rel="noopener">https://www.google.cn/</a></td>
</tr>
<tr>
<td align="center">TE</td>
<td align="center">客户端愿意接受的传输编码，并通知服务器接受接受尾加头信息</td>
<td align="center">TE:trailers,deflate;q=0.5</td>
</tr>
<tr>
<td align="center">Upgrade</td>
<td align="center">向服务器指定某种传输协议以便服务器进行转换（如果支持）</td>
<td align="center">Upgrade:HTTP/2.0,SHTTP/1.3,IRC/6.9,RTA/x11</td>
</tr>
<tr>
<td align="center">User-Agent</td>
<td align="center">User-Agent的内容包含发出请求的用户信息</td>
<td align="center">User-Agent:Mozilla/5.0(Linux;X11)</td>
</tr>
<tr>
<td align="center">Via</td>
<td align="center">通知中间网关或代理服务器地址，通信协议</td>
<td align="center">Via:1.0fred,1.1nowhere.com(Apache/1.1)</td>
</tr>
<tr>
<td align="center">Warning</td>
<td align="center">关于消息实体的警告信息</td>
<td align="center">Warn:199Miscellaneouswarning</td>
</tr>
</tbody></table><a id="more"></a>




<p>Http Response  </p>
<hr>
<table>
<thead>
<tr>
<th align="center">Header</th>
<th align="left">解释</th>
<th align="center">示例</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Accept-Ranges</td>
<td align="left">表明服务器是否支持指定范围请求及哪种类型的分段请求</td>
<td align="center">Accept-Ranges:bytes</td>
</tr>
<tr>
<td align="center">Age</td>
<td align="left">从原始服务器到代理缓存形成的估算时间（以秒计，非负）</td>
<td align="center">Age:12</td>
</tr>
<tr>
<td align="center">Allow</td>
<td align="left">对某网络资源的有效的请求行为，不允许则返回405</td>
<td align="center">Allow:GET,HEAD</td>
</tr>
<tr>
<td align="center">Cache-Control</td>
<td align="left">告诉所有的缓存机制是否可以缓存及哪种类型</td>
<td align="center">Cache-Control:no-cache</td>
</tr>
<tr>
<td align="center">Content-Encoding</td>
<td align="left">web服务器支持的返回内容压缩编码类型。</td>
<td align="center">Content-Encoding:gzip</td>
</tr>
<tr>
<td align="center">Content-Language</td>
<td align="left">响应体的语言</td>
<td align="center">Content-Language:en,zh</td>
</tr>
<tr>
<td align="center">Content-Length</td>
<td align="left">响应体的长度</td>
<td align="center">Content-Length:348</td>
</tr>
<tr>
<td align="center">Content-Location</td>
<td align="left">请求资源可替代的备用的另一地址</td>
<td align="center">Content-Location:/index.htm</td>
</tr>
<tr>
<td align="center">Content-MD5</td>
<td align="left">返回资源的MD5校验值</td>
<td align="center">Content-MD5:Q2hlY2sgSW50ZWdyaXR5IQ==</td>
</tr>
<tr>
<td align="center">Content-Range</td>
<td align="left">在整个返回体中本部分的字节位置</td>
<td align="center">Content-Range:bytes21010-47021/47022</td>
</tr>
<tr>
<td align="center">Content-Type</td>
<td align="left">返回内容的MIME类型</td>
<td align="center">Content-Type:text/html;charset=utf-8</td>
</tr>
<tr>
<td align="center">Date</td>
<td align="left">原始服务器消息发出的时间</td>
<td align="center">Date:Tue,15Nov201008:12:31GMT</td>
</tr>
<tr>
<td align="center">ETag</td>
<td align="left">请求变量的实体标签的当前值</td>
<td align="center">ETag:“737060cd8c284d8af7ad3082f209582d”</td>
</tr>
<tr>
<td align="center">Expires</td>
<td align="left">响应过期的日期和时间</td>
<td align="center">Expires:Thu,01Dec201016:00:00GMT</td>
</tr>
<tr>
<td align="center">Last-Modified</td>
<td align="left">请求资源的最后修改时间</td>
<td align="center">Last-Modified:Tue,15Nov201012:45:26GMT</td>
</tr>
<tr>
<td align="center">Location</td>
<td align="left">用来重定向接收方到非请求URL的位置来完成请求或标识新的资源</td>
<td align="center">Location:<a href="https://www.google.cn" target="_blank" rel="noopener">https://www.google.cn</a></td>
</tr>
<tr>
<td align="center">Pragma</td>
<td align="left">包括实现特定的指令，它可应用到响应链上的任何接收方</td>
<td align="center">Pragma:no-cache</td>
</tr>
<tr>
<td align="center">Proxy-Authenticate</td>
<td align="left">它指出认证方案和可应用到代理的该URL上的参数</td>
<td align="center">Proxy-Authenticate:Basic</td>
</tr>
<tr>
<td align="center">refresh</td>
<td align="left">应用于重定向或一个新的资源被创造，在5秒之后重定向（由网景提出，被大部分浏览器支持）</td>
<td align="center">Refresh:5;url=<a href="https://www.google.cn" target="_blank" rel="noopener">https://www.google.cn</a></td>
</tr>
<tr>
<td align="center">Retry-After</td>
<td align="left">如果实体暂时不可取，通知客户端在指定时间之后再次尝试</td>
<td align="center">Retry-After:120</td>
</tr>
<tr>
<td align="center">Server</td>
<td align="left">web服务器软件名称</td>
<td align="center">Server:Apache/1.3.27(Unix)(Red-Hat/Linux)</td>
</tr>
<tr>
<td align="center">Set-Cookie</td>
<td align="left">设置HttpCookie</td>
<td align="center">Set-Cookie:UserID=JohnDoe;Max-Age=3600;Version=1</td>
</tr>
<tr>
<td align="center">Trailer</td>
<td align="left">指出头域在分块传输编码的尾部存在</td>
<td align="center">Trailer:Max-Forwards</td>
</tr>
<tr>
<td align="center">Transfer-Encoding</td>
<td align="left">文件传输编码</td>
<td align="center">Transfer-Encoding:chunked</td>
</tr>
<tr>
<td align="center">Vary</td>
<td align="left">告诉下游代理是使用缓存响应还是从原始服务器请求</td>
<td align="center">Vary:*</td>
</tr>
<tr>
<td align="center">Via</td>
<td align="left">告知代理客户端响应是通过哪里发送的</td>
<td align="center">Via:1.0fred,1.1nowhere.com(Apache/1.1)</td>
</tr>
<tr>
<td align="center">Warning</td>
<td align="left">警告实体可能存在的问题</td>
<td align="center">Warning:199Miscellaneouswarning</td>
</tr>
<tr>
<td align="center">WWW-Authenticate</td>
<td align="left">表明客户端请求实体应该使用的授权方案</td>
<td align="center">WWW-Authenticate:Basic</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>后端开发</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title>MapReduce 原型实现</title>
    <url>/2018/11/16/MapReduce-%E5%8E%9F%E5%9E%8B%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<p><code>MapReduce</code> 最早是由谷歌于 2004 年在操作系统顶会 OSDI 上发表的一篇面向大规模数据处理的分布式计算框架（并行计算模型）论文中提出。<code>MapReduce</code>使用 <code>Google File System</code> 作为数据存储，支撑起了谷歌全网搜索等大规模数据存储与处理业务。<code>MapReduce</code> 对于大规模数据的高效处理体现在三个方面：其一，大规模数据并行处理，分而治之；其二，<code>MapReduce</code>编程模型；最后，<code>MapReduce</code>运行时环境（失败恢复、任务调度以及负载均衡等）。它简化了并行编程，使得开发人员很容易编写出高效且具备容错能力的并行化程序。</p>
<a id="more"></a>

<p>博客基于 MIT 6.824 (2018) 的课程 Lab1。整个实验实现了<code>MapReduce</code>原型，并且对其关键特性进行测试，主要包括<code>MapReduce</code>编程模型，集中在 <code>Map</code>与<code>Reduce</code>两个阶段，以及任务失败处理。在阅读原论文 <a href="https://pdos.csail.mit.edu/6.824/papers/mapreduce.pdf" target="_blank" rel="noopener">MapReduce</a> 的基础，Lab1 能够让我们对 <code>MapReduce</code>原理有更为深刻的理解，也能够提高我们实现分布式系统的实践能力，这包括节点通信模型、系统构建框架以及诸如失败恢复机制等。而且，仔细阅读整个 Lab 的代码可以学习到很多原理及设计知识，而不仅仅是完成其 Lab 任务。下文会简单介绍整个 Lab1 框架，然后阐述几个关键点（模块）。</p>
<h2 id="Sequential-及-Distributed-运行模式"><a href="#Sequential-及-Distributed-运行模式" class="headerlink" title="Sequential 及 Distributed 运行模式"></a>Sequential 及 Distributed 运行模式</h2><p>Lab1 实现了两种不同运行模式的<code>MapReduce</code>原型框架：一种是<code>Sequential</code>运行模式，它顺序编程实现<code>MapReduce</code>过程，也不具备容错功能，因此并非真正意义上的实现。具体地，基于此种运行模式，所有<code>task</code>串行执行且<code>Map</code>与<code>Reduce</code>两个阶段也是串行执行，且未提供任务执行失败的恢复机制。大概地，它首先创建输入文件并读取<code>Map</code>输入，同时创建对应数量的<code>Map task</code>（即循环调用<code>Map</code>函数来处理输入文件），并顺序调度执行，将中间结果写到磁盘上，当所有<code>Map task</code>执行完成后，启动一定数量的<code>Reduce task</code>，并让<code>Reduce task</code>从本地磁盘相应位置读取<code>Map task</code>输出，同样被顺序调度执行，最后，将<code>Reduce task</code>输出写到本地磁盘，最终<code>merge</code>所有输出文件，以合并写到本地输出文件。</p>
<p>另一种是 <code>Distributed</code>运行模式，它更接近真实的<code>MapReduce</code>原型框架实现。客户端会依次启动一个<code>master</code>节点及多个<code>slave</code>节点(go 的<code>goroutine</code>)，并将输入文件信息传给<code>master</code>节点，此后客户端会阻塞等待<code>master</code>返回 。<code>master</code>启动后开始监听<code>slave</code>的连接(<code>one client one goroutine</code>），<code>slave</code>启动后会主动往<code>master</code>节点注册，并等待<code>master</code>分配任务。所有节点通过<code>go rpc</code>实现对等通信。一旦有<code>slave/worker</code>注册成功，<code>master</code>开始实施任务调度，通过<code>rpc</code>将任务信息（任务类型、任务输入文件位置等）发送给<code>worker</code>，而<code>worker</code>在注册成功后，就不断监听<code>master</code>的连接并调用<code>worker</code>的任务执行<code>handler</code>(<code>doTask</code>)， <code>doTask</code>会调用应用程序的<code>Map</code>或<code>Reduce</code>执行<code>MapReduce</code>任务，所有的<code>worker</code>在本节点执行任务的过程同<code>Sequential</code>运行模式下类似，只是各个<code>worker</code>并行执行，互不干扰。值得注意的是，在整个<code>MapReduce Job</code>调度执行过程中，<code>worker</code>允许动态加入，<code>master</code>一旦发现<code>worker</code>注册加入，若此时有未完成的任务等待调度，就会将此任务让新加入的<code>worker</code>调度执行。只有所有的<code>Map task</code>调度完成后，<code>Reduce task</code>才会被调度。当所有<code>Reduce task</code>执行完成后，同样会进行<code>merge</code>的过程，然后从<code>MapReduce</code>框架返回。</p>
<h2 id="Map-及-Reduce-工作流程"><a href="#Map-及-Reduce-工作流程" class="headerlink" title="Map 及 Reduce 工作流程"></a>Map 及 Reduce 工作流程</h2><p>这里简要阐述 <code>Map &amp; Reduce</code>阶段执行流程。当<code>worker</code>执行<code>map task</code>时，包括以下几个步骤：首先从本地磁盘读取其负责处理的原始输入文件；然后，通过将文件名及文件内容作为参数传递给<code>MapFun</code>来执行用户自定义逻辑；最后，对于每一个<code>Reduce task</code>，通过迭代<code>MapFunc</code>返回的执行结果，并按记录(<code>record</code>)的<code>key</code>进行<code>partition</code>以将分配给对应的<code>Reducer</code>的中间输出结果写到本地磁盘对应文件。</p>
<p><code>Reduce task</code>的执行过程大致如下：首先读取本<code>Reduce task</code>负责的输入文件，并使用<code>JSON</code>来<code>decode</code>文件内容，并将<code>decode</code>后的<code>kev/value</code>存储到<code>map</code>中，同一个<code>key</code>对应一个<code>value list</code>，然后将整个<code>map</code>的<code>key</code>进行排序，并对每一个<code>key/value list</code>通过调用<code>ReduceFunc</code>来执行用户名自定义逻辑，同时，将其返回的结果，经<code>JSON encode</code>后写入输出文件。这些由<code>Reduce task</code>输出的文件内容，会被<code>merge</code>到最终的输出文件。</p>
<h2 id="再谈失败恢复"><a href="#再谈失败恢复" class="headerlink" title="再谈失败恢复"></a>再谈失败恢复</h2><p>容错（失败恢复）是<code>MapReduce</code>运行时的一个关键特性。且 Lab1 也模拟实现了任务执行失败后所采取的措施。任务执行失败，典型的包括两种情况：网络分区（网络故障）及节点宕机，且事实上无法很好地区分这两种情形（在两种情形下，<code>master</code>都会发现不能成功<code>ping</code>通 <code>worker</code>）。而实验则是采用阻止<code>worker</code>与<code>master</code>的<code>rpc</code>连接来模拟实现。具体地，所有<code>worker</code>在执行若干个<code>rpc</code>连接请求后（一个<code>rpc</code>连接请相当于一次任务分配），关闭其<code>rpc</code>连接，如此<code>master</code>不能连接<code>worker</code>而导致任务分配执行失败。个人认为，一般情况下会让    <code>master</code>缓存<code>worker</code>的连接<code>handler</code>，并不会在每次发送<code>rpc</code>请求时，都需要执行<code>Dial/DialHttp</code>，若是如此，便不能以原实验的方式来模拟任务执行失败（虽然这可能并不影响）。另外 Lab1 显式禁止了<code>worker</code>同时被分配两个任务的情况，这是显而易见的。</p>
<p>关于失败恢复（节点容错），下面讨论更多细节。容错是<code>MapReduce</code>的一个重要特性，因为节点失效在大数据处理工作中过于频繁，而且当发生节点宕机或者网络不可达时，整个<code>MapReduce job</code>会执行失败，此时<code>MapReduce</code>并不是重启整个<code>job</code>，那样会导致重新提交执行一个庞大的<code>job</code>而耗时（资源）过多，因此它只会重启对应<code>worker</code>所负责执行的<code>task</code>。值得注意的是，正是因为<code>worker</code>并不维护<code>task</code>相关信息，它们只是从磁盘读取输入文件或者将输出写到磁盘，也不存在与其它<code>worker</code>进行通信协调，因此<code>task</code>的执行是幂等的，两次执行会产生相同的执行结果，这也可以说是<code>MapReduce</code>并行执行任务的约束条件之一，也是<code>MapReduce</code>同其它的并行执行框架的不同之处，但无论如何，这样设计使得<code>MapReduce</code>执行任务更为简单。因为<code>Map task</code>会为<code>Reduce task</code>产生输入文件，因此若<code>Reduce task</code>已经从<code>Map task</code>获得了其所需要的所有输入，此时<code>Map</code>的失败，并不会导致其被重新执行。另外关键的是，<code>GFS</code>的<code>atomic rename</code>机制确保即使<code>Map/Reduce task</code>在已经溢写了部分内容到磁盘后失败了，此时重新执行也是安全的，因为<code>GFS</code>会保证直到所有输出写磁盘完成，才使得其输出文件可见，这种情况也会发生在两个<code>Reduce task</code>执行同一个任务，<code>GFS atomic rename</code>机制同样会保证其安全性。那么，若两个<code>Map</code>执行同一个<code>task</code>结果会如何？这种情况发生在，<code>master</code>错误地认为<code>Map task</code>宕机（可能只是发生了网络拥塞或者磁IO过慢，事实上，<code>MapReduce</code>的<code>stragger worker</code>正描述的是磁盘IO过慢的情况），此时即便两个<code>Map task</code>都执行成功（它们不会输出到相同的中间文件，因此不会有写冲突），<code>MapReduce</code>运行时也保证只告诉<code>Reduce task</code>从其中之一获取其输入。最后，注意<code>MapReduce</code>的失败恢复机制所针对的错误是<code>fail-stop</code>故障类型，即要么正常运行，要么宕机，不会产生不正确的输出。</p>
<p>参考文献</p>
<p>[1] Dean J, Ghemawat S. MapReduce: simplified data processing on large clusters[J]. Communications of the ACM, 2008, 51(1): 107-113.<br>[2].<a href="https://pdos.csail.mit.edu/6.824/index.html" target="_blank" rel="noopener">MIT 6.824</a></p>
]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>分布式计算框架</tag>
        <tag>MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title>解决Hexo首页阅读次数样式诡异的问题</title>
    <url>/2018/11/16/%E8%A7%A3%E5%86%B3Hexo%E9%A6%96%E9%A1%B5%E9%98%85%E8%AF%BB%E6%AC%A1%E6%95%B0%E6%A0%B7%E5%BC%8F%E8%AF%A1%E5%BC%82%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>  今晚在完善阅读统计的功能是时候发现一个很诡异的问题，我们一起来探讨一下。上一篇文章大概有阐述阅读统计功能的搭建，所有这里我就不多说了。<br>  利用leancloud接完统计功能后，当前这个hexo版本我会发现首页的阅读数量的样式有点诡异，大致如下：<br>  两种情况： 1：<em>阅读次数::9:9</em>   :2：<em>阅读次数::99</em><br>  实际上这个时候我们的阅读量只有9而已，正常来说应该这样显示：  <em>阅读次数：9</em><br>  于是我忍不住摁住F12一探究竟,大致可以知道阅读次数那一块的元素是js直接赋值的，所以我就去找了一下阅读统计的部分的相关js，我比较粗暴，直接定位全局搜索一波 <em>leancloud_visitors</em>  相关的文件<br>  这是我们可以找到一个路径为 <em>themes\next\layout_third-party\analytics\lean-analytics.swig</em> 的文件，打开发现就是这部分js处理leancloud的阅读数量统计。</p>
 <a id="more"></a>

<h3 id="贴一波阅读次数统计的代码-LeanCloud提供支持"><a href="#贴一波阅读次数统计的代码-LeanCloud提供支持" class="headerlink" title="贴一波阅读次数统计的代码(LeanCloud提供支持)"></a>贴一波阅读次数统计的代码(LeanCloud提供支持)</h3>  <figure class="highlight javascript"><figcaption><span>看到function showTime 我相信你已经很明白了</span></figcaption><table><tr><td class="code"><pre><span class="line">&#123;% <span class="keyword">if</span> theme.leancloud_visitors.enable %&#125;</span><br><span class="line"></span><br><span class="line">  &#123;# custom analytics part create by xiamo #&#125;</span><br><span class="line"> &lt;script src=<span class="string">"https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"</span>&gt;<span class="xml"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br><span class="line"> &lt;script&gt;AV.initialize(<span class="string">"&#123;&#123;theme.leancloud_visitors.app_id&#125;&#125;"</span>, <span class="string">"&#123;&#123;theme.leancloud_visitors.app_key&#125;&#125;"</span>);<span class="xml"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br><span class="line"> &lt;script&gt;</span><br><span class="line"> <span class="function"><span class="keyword">function</span> <span class="title">showTime</span>(<span class="params">Counter</span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.warn(<span class="string">'~欢迎光临我的博客 Email:binzhizhu@gmail.com '</span>)</span><br><span class="line"> 	<span class="keyword">var</span> query = <span class="keyword">new</span> AV.Query(Counter);</span><br><span class="line"> 	$(<span class="string">".leancloud_visitors"</span>).each(<span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line"> 		<span class="keyword">var</span> url = $(<span class="keyword">this</span>).attr(<span class="string">"id"</span>).trim();</span><br><span class="line"> 		query.equalTo(<span class="string">"url"</span>, url);</span><br><span class="line"> 		query.find(&#123;</span><br><span class="line"> 			success: <span class="function"><span class="keyword">function</span>(<span class="params">results</span>) </span>&#123;</span><br><span class="line">                <span class="built_in">console</span>.warn(<span class="string">'--这里是阅读统计代码-- by --leancloud--'</span>)</span><br><span class="line"> 				<span class="keyword">if</span> (results.length == <span class="number">0</span>) &#123;</span><br><span class="line"> 					<span class="keyword">var</span> content = $(<span class="built_in">document</span>.getElementById(url)).text() + <span class="string">': 0'</span>;</span><br><span class="line"> 					$(<span class="built_in">document</span>.getElementById(url)).text(content);</span><br><span class="line"> 					<span class="keyword">return</span>;</span><br><span class="line"> 				&#125;</span><br><span class="line"> 				<span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; results.length; i++) &#123;</span><br><span class="line"> 					<span class="keyword">var</span> object = results[i];</span><br><span class="line"> 					<span class="keyword">var</span> content = $(<span class="built_in">document</span>.getElementById(url)).text() + object.attributes.time;</span><br><span class="line"> 					$(<span class="built_in">document</span>.getElementById(url)).text(content);</span><br><span class="line"> 				&#125;</span><br><span class="line"> 			&#125;,</span><br><span class="line"> 			error: <span class="function"><span class="keyword">function</span>(<span class="params">object, error</span>) </span>&#123;</span><br><span class="line"> 				<span class="built_in">console</span>.log(<span class="string">"Error: "</span> + error.code + <span class="string">" "</span> + error.message);</span><br><span class="line"> 			&#125;</span><br><span class="line"> 		&#125;);</span><br><span class="line"></span><br><span class="line"> 	&#125;);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<p>  上述代码中的 for循环，看起来是没任何问题。但我hexo g -d 到GitHubPage 的时候，我再for循环里面console.log(‘obj’,object),打印了一下当前文章的所有属性，发现同一篇文章会打印两次，所有才会出现上面所说的 <em>阅读次数::99<em>的情况。相当于第一次循环time是9，循环了两次拼接了起来于是变成</em>阅读次数::99</em><br>  所有我 直接在for循环的最后加了一句  </p>
 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">return;</span><br></pre></td></tr></table></figure>

<h3 id="真-阅读统计代码段"><a href="#真-阅读统计代码段" class="headerlink" title="真.阅读统计代码段"></a>真.阅读统计代码段</h3><p>  这么做实际上很简单，类似于做一层兼容了，确保不会重复循环，修复了之后发现真的没有问题了，阅读次数显示正常了，美滋滋，这也是一种收获。顺便也贴一下其他阅读统计事件的代码片段吧：<br>   <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> function addCount(Counter) &#123;</span><br><span class="line"> 	var Counter = AV.Object.extend(&quot;Counter&quot;);</span><br><span class="line"> 	url = $(&quot;.leancloud_visitors&quot;).attr(&apos;id&apos;).trim();</span><br><span class="line"> 	title = $(&quot;.leancloud_visitors&quot;).attr(&apos;data-flag-title&apos;).trim();</span><br><span class="line"> 	var query = new AV.Query(Counter);</span><br><span class="line"> 	query.equalTo(&quot;url&quot;, url);</span><br><span class="line"> 	query.find(&#123;</span><br><span class="line"> 		success: function(results) &#123;</span><br><span class="line"> 			if (results.length &gt; 0) &#123;</span><br><span class="line"> 				var counter = results[0];</span><br><span class="line"> 				counter.fetchWhenSave(true);</span><br><span class="line"> 				counter.increment(&quot;time&quot;);</span><br><span class="line"> 				counter.save(null, &#123;</span><br><span class="line"> 					success: function(counter) &#123;</span><br><span class="line"> 						var content = $(document.getElementById(url)).text() + &apos;: &apos; + counter.get(&apos;time&apos;);</span><br><span class="line"> 						$(document.getElementById(url)).text(content);</span><br><span class="line"> 					&#125;,</span><br><span class="line"> 					error: function(counter, error) &#123;</span><br><span class="line"> 						console.log(&apos;Failed to save Visitor num, with error message: &apos; + error.message);</span><br><span class="line"> 					&#125;</span><br><span class="line"> 				&#125;);</span><br><span class="line"> 			&#125; else &#123;</span><br><span class="line"> 				var newcounter = new Counter();</span><br><span class="line"> 				newcounter.set(&quot;title&quot;, title);</span><br><span class="line"> 				newcounter.set(&quot;url&quot;, url);</span><br><span class="line"> 				newcounter.set(&quot;time&quot;, 1);</span><br><span class="line"> 				newcounter.save(null, &#123;</span><br><span class="line"> 					success: function(newcounter) &#123;</span><br><span class="line"> 					    console.log(&quot;newcounter.get(&apos;time&apos;)=&quot;+newcounter.get(&apos;time&apos;));</span><br><span class="line"> 						var content = $(document.getElementById(url)).text() + &apos;: &apos; + newcounter.get(&apos;time&apos;);</span><br><span class="line"> 						$(document.getElementById(url)).text(content);</span><br><span class="line"> 					&#125;,</span><br><span class="line"> 					error: function(newcounter, error) &#123;</span><br><span class="line"> 						console.log(&apos;Failed to create&apos;);</span><br><span class="line"> 					&#125;</span><br><span class="line"> 				&#125;);</span><br><span class="line"> 			&#125;</span><br><span class="line"> 		&#125;,</span><br><span class="line"> 		error: function(error) &#123;</span><br><span class="line"> 			console.log(&apos;Error:&apos; + error.code + &quot; &quot; + error.message);</span><br><span class="line"> 		&#125;</span><br><span class="line"> 	&#125;);</span><br><span class="line"> &#125;</span><br><span class="line"> $(function() &#123;</span><br><span class="line"> 	var Counter = AV.Object.extend(&quot;Counter&quot;);</span><br><span class="line"> 	if ($(&apos;.leancloud_visitors&apos;).length == 1) &#123;</span><br><span class="line"> 		addCount(Counter);</span><br><span class="line"> 	&#125; else if ($(&apos;.post-title-link&apos;).length &gt; 1) &#123;</span><br><span class="line"> 		showTime(Counter);</span><br><span class="line"> 	&#125;</span><br><span class="line"> &#125;);</span><br><span class="line"> &lt;/script&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure></p>
<p> 这篇博客写得我有点疲惫了，已经深夜十分了，准备入睡啦，明天还要起来搬砖呢，晚安各位，希望能够帮助到大家吧，我也是刚学习Hexo自己搭建博客。<br> 但有趣的一点是我们可以在这些开源的框架或者资源里面肆意的玩弄代码，hexo其实就是提供给大家开源开发的，看着文档接服务就好了，一大推的第三方服务已经Api。</p>
]]></content>
      <categories>
        <category>博客</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>服务架构之演变与进化</title>
    <url>/2018/11/13/2018-11-13-%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%B9%8B%E6%BC%94%E5%8F%98%E4%B8%8E%E8%BF%9B%E5%8C%96/</url>
    <content><![CDATA[<h1 id="为何架构演进"><a href="#为何架构演进" class="headerlink" title="为何架构演进"></a>为何架构演进</h1><ul>
<li>业务功能越来越多，越来越复杂</li>
<li>物联网时代数据量越来越大</li>
<li>请求量越来越大</li>
<li>更高的用户体验要求</li>
<li>业务快速迭代</li>
<li>持续交付的能力</li>
</ul>
<h1 id="架构如何演进"><a href="#架构如何演进" class="headerlink" title="架构如何演进"></a>架构如何演进</h1><ol>
<li>单体架构（Monoliths）</li>
<li>水平分层架构（Horizontal layered）</li>
<li>面向服务架构 (SOA)（垂直分层架构）</li>
<li>微服务架构（MicroServices）</li>
<li>服务网格架构（Service Mesh）</li>
</ol>
<a id="more"></a>

<h1 id="体系架构设计原则"><a href="#体系架构设计原则" class="headerlink" title="体系架构设计原则"></a>体系架构设计原则</h1><ul>
<li>服务封装</li>
<li>服务松耦合(Loosely coupled) - 服务之间的关系最小化，只是互相知道。</li>
<li>服务契约 - 服务按照服务描述文档所定义的服务契约行事。</li>
<li>服务抽象 - 除了服务契约中所描述的内容，服务将对外部隐藏逻辑。</li>
<li>服务的重用性 - 将逻辑分布在不同的服务中，以提高服务的重用性。</li>
<li>服务的可组合性 - 一组服务可以协调工作并组合起来形成一个组合服务。</li>
<li>服务自治 – 服务对所封装的逻辑具有控制权</li>
<li>服务无状态 – 服务将一个活动所需保存的信息最小化。</li>
<li>服务的可被发现性 – 服务需要对外部提供描述信息，这样可以通过现有的发现机制发现并访问这些服务。</li>
</ul>
<h1 id="架构模式"><a href="#架构模式" class="headerlink" title="架构模式"></a>架构模式</h1><ul>
<li>分层</li>
<li>冗余</li>
<li>分隔</li>
<li>异步</li>
<li>分布式</li>
<li>安全</li>
<li>自动化</li>
<li>集群</li>
<li>缓存</li>
</ul>
<h1 id="单体架构"><a href="#单体架构" class="headerlink" title="单体架构"></a>单体架构</h1><h2 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h2><p><img src="https://www.google.cn/assets/private/images/image-67.png" alt="单体架构"></p>
<h2 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h2><ul>
<li>业务场景简单</li>
<li>功能不复杂</li>
<li>开发人员较少</li>
<li>创业公司初期</li>
<li>性能要求极其苛刻</li>
</ul>
<h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><ul>
<li>一个进程完成业务</li>
<li>打包成war包</li>
<li>依赖Servlet容器</li>
</ul>
<h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ul>
<li>避免多次网络交互</li>
<li>请求响应延迟低</li>
<li>部署和运维成本低</li>
</ul>
<h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><ul>
<li>系统耦合性高</li>
<li>可扩展性差</li>
<li>技术选型单一</li>
<li>架构粒度过粗</li>
</ul>
<h1 id="水平划分架构"><a href="#水平划分架构" class="headerlink" title="水平划分架构"></a>水平划分架构</h1><h2 id="架构图-1"><a href="#架构图-1" class="headerlink" title="架构图"></a>架构图</h2><h3 id="同步架构"><a href="#同步架构" class="headerlink" title="同步架构"></a>同步架构</h3><p><img src="https://www.google.cn/assets/private/images/image-68.png" alt="水平划分之同步架构"></p>
<h3 id="异步架构"><a href="#异步架构" class="headerlink" title="异步架构"></a>异步架构</h3><p><img src="https://www.google.cn/assets/private/images/image-69.png" alt="水平划分之异步架构"></p>
<h2 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h2><ul>
<li>高耦合问题</li>
<li>低扩展问题</li>
</ul>
<h2 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h2><ul>
<li>一个进程或多个进程</li>
<li>分层思想明确</li>
<li>MVC架构（Model层、View层、Control层）</li>
</ul>
<h2 id="网关层"><a href="#网关层" class="headerlink" title="网关层"></a>网关层</h2><ul>
<li>请求鉴权</li>
<li>数据完整性检查</li>
<li>协议转换</li>
<li>路由转发</li>
<li>服务治理（限流，熔断等）</li>
</ul>
<h2 id="业务逻辑层"><a href="#业务逻辑层" class="headerlink" title="业务逻辑层"></a>业务逻辑层</h2><ul>
<li>业务逻辑判断和处理</li>
</ul>
<h2 id="数据访问层"><a href="#数据访问层" class="headerlink" title="数据访问层"></a>数据访问层</h2><ul>
<li>CRUD（增删改查）</li>
<li>ORM（对象关系映射 如MyBatis）</li>
<li>Sharding（分库分表）</li>
<li>屏蔽底层存储差异性</li>
</ul>
<h2 id="异步架构优点"><a href="#异步架构优点" class="headerlink" title="异步架构优点"></a>异步架构优点</h2><ul>
<li>提高系统吞吐量</li>
</ul>
<h2 id="异步架构缺点"><a href="#异步架构缺点" class="headerlink" title="异步架构缺点"></a>异步架构缺点</h2><ul>
<li>数据处理延迟</li>
</ul>
<h2 id="异步架构适合的场景"><a href="#异步架构适合的场景" class="headerlink" title="异步架构适合的场景"></a>异步架构适合的场景</h2><ul>
<li>适合高并发场景</li>
<li>对数据一致性要求不高</li>
</ul>
<h2 id="水平划分的优点"><a href="#水平划分的优点" class="headerlink" title="水平划分的优点"></a>水平划分的优点</h2><ul>
<li>低耦合</li>
<li>可扩展</li>
</ul>
<h2 id="水平划分的缺点"><a href="#水平划分的缺点" class="headerlink" title="水平划分的缺点"></a>水平划分的缺点</h2><ul>
<li>请求路径变长</li>
<li>响应延迟变高</li>
<li>定位问题变得复杂化</li>
<li>运维成本增加</li>
</ul>
<h1 id="面向服务架构"><a href="#面向服务架构" class="headerlink" title="面向服务架构"></a>面向服务架构</h1><h2 id="架构图-2"><a href="#架构图-2" class="headerlink" title="架构图"></a>架构图</h2><p><img src="https://www.google.cn/assets/private/images/image-70.png" alt="面向服务架构"></p>
<h2 id="SOA的设计原则"><a href="#SOA的设计原则" class="headerlink" title="SOA的设计原则"></a>SOA的设计原则</h2><ul>
<li>可重复使用, 粒度, 模块性, 可组合型, 对象化原件, 构件化以及具交互操作性</li>
<li>匹配开放标准(通用的或行业的)</li>
<li>服务的识别和分类，提供和发布，监控和跟踪。</li>
</ul>
<h2 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h2><ul>
<li>简单化系统的开发</li>
<li>面向企业商业流程</li>
<li>更好的适应性和扩展性</li>
<li>互用性</li>
<li>对系统的升级，分布，和维护有个更多的优化</li>
<li>简化了提供，寻找和使用服务的过程</li>
<li>通过共同资源的利用，减少了开支</li>
</ul>
<h2 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h2><ul>
<li>每一个服务依然是单体架构</li>
<li>对ESB严重依赖</li>
<li>减低了系统的性能</li>
<li>在向标准化过度的转换过程，增加了简介费用</li>
<li>很多没有太多意义的文件型信息</li>
<li>对商业流程的计划要求甚高</li>
</ul>
<h1 id="微服务架构"><a href="#微服务架构" class="headerlink" title="微服务架构"></a>微服务架构</h1><h2 id="架构图-3"><a href="#架构图-3" class="headerlink" title="架构图"></a>架构图</h2><p><img src="https://www.google.cn/assets/private/images/image-71.png" alt="微服务架构图"></p>
<h2 id="定义-2"><a href="#定义-2" class="headerlink" title="定义"></a>定义</h2><ul>
<li>小型服务套件</li>
<li>在自己的进程中运行</li>
<li>围绕业务能力</li>
<li>独立展开</li>
<li>集中管理</li>
<li>面向业务架构</li>
<li>水平分层架构和面向服务架构的整合</li>
</ul>
<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><ul>
<li>项目快速迭代</li>
<li>项目持续交付</li>
</ul>
<h2 id="服务组件"><a href="#服务组件" class="headerlink" title="服务组件"></a>服务组件</h2><ul>
<li>服务注册中心</li>
<li>服务调用方式</li>
<li>服务网关</li>
<li>断路器</li>
<li>分布式链路监控</li>
<li>分布式配置</li>
<li>分布式锁</li>
<li>分布式消息</li>
<li>消息队列</li>
<li>服务跟踪</li>
<li>消息总线</li>
<li>集群选主</li>
<li>数据流</li>
<li>批量任务</li>
<li>服务发现</li>
<li>服务通讯</li>
<li>负载均衡</li>
<li>服务熔断</li>
<li>请求超时重试</li>
<li>服务容错</li>
<li>异步处理</li>
<li>安全控制</li>
<li>命令行工具</li>
</ul>
<h2 id="优点-2"><a href="#优点-2" class="headerlink" title="优点"></a>优点</h2><ul>
<li>逻辑清晰</li>
<li>简化部署</li>
<li>可扩展</li>
<li>灵活组合</li>
<li>技术异构</li>
<li>高可靠</li>
</ul>
<h2 id="缺点-2"><a href="#缺点-2" class="headerlink" title="缺点"></a>缺点</h2><ul>
<li>复杂度高</li>
<li>运维复杂</li>
<li>影响性能</li>
</ul>
<h1 id="服务网格架构"><a href="#服务网格架构" class="headerlink" title="服务网格架构"></a>服务网格架构</h1><h2 id="定义-3"><a href="#定义-3" class="headerlink" title="定义"></a>定义</h2><p>服务网格（Service Mesh）这个术语通常用于描述构成这些应用程序的微服务网络以及应用之间的交互。也就是解决系统架构微服务化后的服务间通信和治理问题。   </p>
<ul>
<li>是一个基础设施</li>
<li>轻量级网络代理，应用程序间通讯的中间层</li>
<li>应用程序无感知，对应用程序透明无侵入</li>
<li>解耦应用程序的重试/超时、监控、追踪和服务发现等控制层面的东西</li>
</ul>
<h2 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h2><ul>
<li>流量管理</li>
<li>安全</li>
<li>可观察性</li>
<li>平台支持</li>
<li>集成和定制</li>
<li>健康检查</li>
<li>负载均衡</li>
<li>追踪</li>
<li>访问日志</li>
<li>熔断</li>
<li>重试策略</li>
<li>超时配置</li>
<li>限速</li>
<li>流量迁移</li>
<li>通过发现服务来动态调整配置（XDS）</li>
</ul>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://mp.weixin.qq.com/s/lGRadMbSebo3AJzWkjMqYg" target="_blank" rel="noopener">互联网架构究竟如何演进？</a><br><a href="https://zh.wikipedia.org/wiki/%E9%9D%A2%E5%90%91%E6%9C%8D%E5%8A%A1%E7%9A%84%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84" target="_blank" rel="noopener">面向服务的体系结构</a><br><a href="http://dubbo.apache.org/zh-cn/docs/user/preface/background.html" target="_blank" rel="noopener">Dubbo官方文档</a><br><a href="http://www.voidcn.com/article/p-ojmvdtsw-bc.html" target="_blank" rel="noopener">论SOA架构的几种主要开发方式</a><br><a href="https://zhuanlan.zhihu.com/p/42115757" target="_blank" rel="noopener">互联网架构演进之路</a><br><a href="http://www.ruanyifeng.com/blog/2016/09/software-architecture.html" target="_blank" rel="noopener">软件架构入门</a><br><a href="http://www.ruanyifeng.com/blog/2016/09/how_amazon_take_soa.html" target="_blank" rel="noopener">亚马逊如何变成 SOA（面向服务的架构）？</a><br><a href="https://www.jianshu.com/p/6fe0795c782d" target="_blank" rel="noopener">架构设计漫步：从单体架构、SOA到微服务</a><br><a href="http://dockone.io/article/1646" target="_blank" rel="noopener">微服务与SOA架构</a><br><a href="http://www.servicemesher.com/blog/why-is-service-mesh/" target="_blank" rel="noopener">为什么要选择Service Mesh？</a><br><a href="https://istio.io/zh/docs/concepts/what-is-istio/" target="_blank" rel="noopener">Istio 官方文档</a><br><a href="http://www.servicemesher.com" target="_blank" rel="noopener">Service Mesh 社区</a><br><a href="https://github.com/servicemesher" target="_blank" rel="noopener">servicemesher</a><br><a href="https://jimmysong.io/" target="_blank" rel="noopener">jimmysong.io</a><br><a href="http://www.importnew.com/28798.html" target="_blank" rel="noopener">Service Mesh 及其主流开源实现解析</a><br><a href="https://conduit.io/" target="_blank" rel="noopener">conduit.io</a><br><a href="https://istio.io/" target="_blank" rel="noopener">istio.io</a><br><a href="https://www.jianshu.com/p/c77a9303b0bb" target="_blank" rel="noopener">蚂蚁金服大规模微服务架构下的Service Mesh探索之路</a><br><a href="https://microservices.io/patterns/cn/microservices.html" target="_blank" rel="noopener">模式: 微服务架构</a><br><a href="https://microservices.io/patterns/cn/monolithic.html" target="_blank" rel="noopener">模式: 单体架构</a>  </p>
]]></content>
      <categories>
        <category>后端开发</category>
      </categories>
  </entry>
  <entry>
    <title>理解 The Google File System</title>
    <url>/2018/11/11/%E7%90%86%E8%A7%A3-The-Google-File-System/</url>
    <content><![CDATA[<p>分布式文件系统是构建整个分布式系统的基石，为分布式计算提供底层数据存储。谷歌早在 2013 年就发表了论文 <code>The Google File System</code>，它在谷歌内部是配合其分布式计算框架<code>MapReduce</code>使用，共同为谷歌搜索等业务提供技术栈支撑。虽然数据量激增以及技术革新使得<code>GFS</code>不断演进，但理解其最初的设计理念、运行原理以及关键实现技术同样让人受益匪浅，并指导着我们实际的学习和工程实践。这篇博文阐述个人对原论文的一些理解与心得，并不是对原论文的完整翻译，因此你需要提前阅读论文。</p>
<a id="more"></a>

<h2 id="设计动机与目标"><a href="#设计动机与目标" class="headerlink" title="设计动机与目标"></a>设计动机与目标</h2><p>设计一个通用的分布式文件系统是不现实的，它不仅在实现上异常困难（因为不得不考虑所有应用场景），而且实际使用也难以满足要求（往往存在显而易见的性能或容错瓶颈）。<a href="https://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf" target="_blank" rel="noopener">GFS</a> 设计初衷是利用数以千计的廉价机器为<code>MapReduce</code>提供底层<strong>可靠且高性能</strong>的分布式数据存储，以应对海量离线数据存储与处理的应用场景，比如存储应用程序持续产生的日志流以提供离线日志分析。由此，其设计目标为容错可靠(<code>fault tolerance</code>)、高性能读写(<code>high-performance read&amp;write</code>)以及节约网络带宽(<code>save bandwidth</code>)。</p>
<p>一致性(<code>consistency</code>)是分布式系统不可回避的问题。对于分布式文件系统而言，为了提供容错，必须维持数据副本(<code>replica</code>），那如何保证各副本间一致显得至关重要，特别是在应用并发访问场合。一致性是个极其宽泛的术语，你可以实现数据的强一致性(<code>strong consistency</code>)以保证用户始终读到的是最新的数据，这对于用户（客户端）而言是个极佳选择，但它提高了系统的实现难度，因为你必须设计复杂的一致性协议（如<code>Paxos</code>或<code>Raft</code>）来实现强一致性，它也会损害系统性能，典型的它需要机器之间通信以对副本状态达成一致。而弱一致性(<code>weak consistency</code>)则几乎相反。因此，必须根据特定的应用场景，在保证系统逻辑正确的提前下，放宽一致性要求，设计具备良好性能且能提供<strong>足够的一致性</strong>(<code>sufficient consistency</code>)的系统。对于<code>GFS</code>而言，它针对<code>MapReduce</code>应用程序进行了特定优化，比如，对<strong>大文件高性能读取</strong>、允许出现<strong>文件空洞</strong>(<code>hole</code>)、数据<strong>记录重复</strong>(<code>record duplicate</code>)以及偶尔<strong>读取不一致</strong>(<code>inconsistent reads</code>)。具体在数据读写方面，其侧重于大规模一次性写入和追加写入，而并非覆盖写和随机写；读取同样倾向于顺序读取，并不关心随机读取。</p>
<h2 id="Trade-off-理念哲学"><a href="#Trade-off-理念哲学" class="headerlink" title="Trade-off 理念哲学"></a>Trade-off 理念哲学</h2><p><code>GFS</code>在设计上存在大量的<code>trade-off</code>。正如前文所述，你不能企图设计出一个完美的系统，而只能针对具体应用场景作出各方面的权衡考量，以达到工程最佳实践目的。</p>
<p><code>chunk</code>大小设计。<code>GFS</code>针对大文件存储（数百上千兆）设计，因此若存储大量小文件则不能体现其性能。其默认块大小为 64MB。选择大文件作为存储目标原因如下：首先它减少了<code>client</code>与<code>master</code>的交互次数（即使<code>client</code>并不需要整个数据块，但实际上往往存在“就近原则”）；另外，这也直接减少了网络带宽；最后，它减少了存储在<code>master</code>内存中的元数据(<code>metadata</code>)的大小。但凡事总利弊相随。较大的块大小设定使得小文件也不得不占用整个块，浪费空间。</p>
<p>集群元数据‘存储。在<code>master</code>的内存中存放着三种类型的元数据：文件和<code>chunk</code>的名称空间(<code>namespace</code>)、文件到<code>chunk</code>的映射信息以及<code>chunk</code>副本的位置信息。且前两种元数据会定期通过<code>operation log</code>持久化到磁盘以及副本冗余。为什么将这些元信息存储到内存？一方面，缓存在内存无疑会提高性能，另外它也不会造成内存吃紧，因为每个64MB 的<code>chunk</code>只会占用到 64B 的内存空间（粗略估算普通 2G 内存的机器可以容纳 2PB 数据），而且为机器增加内存的代价也很小。那为什么<code>chunk</code>位置信息没有持久化？首先<code>master</code>在启动的时候可以通过<code>heartbeat</code>从各<code>chunk server</code>获取。另一方面，<code>chunk</code>的位置信息有时会变动频繁，比如进行<code>chunk garbage collection</code>、<code>chunk re-replication</code>以及<code>chunk migration</code>，因此，若<code>master</code>也定期持久化<code>chunk</code>位置信息，则<code>master</code>可能会成为集群性能<code>bottleneck</code>。从另一个角度来看，<code>chunck</code>是由<code>chunk server</code>保存，而且随时可能发生<code>disk failure</code>而导致<code>chunk</code>暂时不可被访问，因此其位置信息也应该由<code>chunk server</code>负责提供。</p>
<p><code>chunk</code>副本（默认3个）存放策略。<code>chunk</code>副本选择目标机器的原则包括两个方面：一是最大化数据可靠性(<code>reliability</code>)及可用性(<code>availability</code>)，这就要求不能把所有的副本存放在一台机器上，如果此机器的发生<code>disk failure</code>，则数据的所有副本全部不可用。放在同一个机架也类似，因为机架之间的交换机或其它网络设计也可能出现故障。另外一个原则是，最大化网络带宽，如果两个副本的位置相隔太远，跨机架甚至跨数据中心，那么副本的写复制代价是巨大的。因此一般的存放位置包括本机器、同一机架不同机器以及不同机架机器。</p>
<p>垃圾回收。当一个文件被删除，<code>GFS</code>不会真正回收对应的<code>chunk</code>，而只是在<code>log operation</code>记录删除日志后，将对应的文件名设置为隐藏。在一定期限内（默认3天），用户可以执行撤销删除操作。否则，<code>master</code>会通过其后台进程定期扫描其文件系统，回收那些隐藏的文件，并且对应的元数据信息也会从内存中擦除。另外，<code>master</code>的后台进程同时还会扫描孤儿块(<code>orphaned chunk</code>)，即那些不能链接到任何文件的<code>chunk</code>，并将这些<code>chunk</code>的元信息删除，这样在后续的<code>heartbeat</code>中让<code>chunk server</code>将对应的<code>chunk</code>删除。这种垃圾回收机制的优点如下：其一，很明显允许用户作出撤销删除操作。其二，统一管理的垃圾回收机制对于故障频繁的分布式系统而言是便捷且可靠的（系统中很容易出现孤儿块）；最后，也有利于提升系统性能。垃圾回收发生在后台进程定期扫描活动中，此时<code>masetr</code>相对空闲，它不会一次性将大量文件从系统移除，从而导致 IO 瓶颈，换言之，其<code>chunk</code>回收成本被<strong>均摊</strong>(<code>amortized</code>）。但其同样有缺点：如果系统中一段时间内频繁出现文件删除与创建操作时，可能使得系统的存储空间紧张（原论文中也提供了解决方案）。</p>
<h2 id="一致性模型-和-原子-Record-Append"><a href="#一致性模型-和-原子-Record-Append" class="headerlink" title="一致性模型 和 原子 Record Append"></a>一致性模型 和 原子 Record Append</h2><p>前文提到<code>GFS</code>并没有采用复杂的一致性协议来保证副本数据的一致性，而是通过定义了三种不同的文件状态，并保证在这三种文件状态下，能够使得客户端看到一致的副本。三种状态描述如下：<code>GFS</code>将文件处于<code>consistent</code>状态定义为：当<code>chunk</code>被并发执行了操作后，不同的客户端看到的并发执行后的副本内容是一致的。而<code>defined</code>状态被定义为：在文件处于<code>consistent</code>状态的基础上，还要保证所有客户端能够看到在此期间对文件执行的所有并发操作，换言之，当文件操作并发执行时，如果它们是全局有序执行的（执行过程中没有被打断），则由此产生的文件状态为<code>defined</code>（当然也是<code>consistent</code>）。换言之，如果某一操作在执行过程中被打断，但所有的并发操作仍然成功执行，只是对文件并发操作的结果不能反映出任一并发操作，因为此时文件的内容包含的是各个并发操作的结果的混合交叉，但无论如何，所有客户端看到的副本的内容还是一致的，在这种情况下就被称为<code>consistent</code>。自然而然，如果并发操作文件失败，此时各客户端看到的文件内容不一致，则称文件处于<code>undefined</code>状态，当然也处于<code>inconsistent</code>状态。</p>
<p>我们先区分几种不同的文件写类型：<code>write</code>指的是由应用程序在写入文件时指定写入的<code>offset</code>；而<code>append</code>同样也是由应用程序来指定写入文件时的<code>offeset</code>，只是此时的<code>offset</code>默认为文件末尾；而<code>record append</code>则指的是应用程序在写入文件时，只提供文件内容，而写入的<code>offset</code>则由<code>GFS</code>来指定，并在写成功后，返回给应用程序，而<code>record append</code>操作正是<code>GFS</code>提供一致性模型的关键，因为它能够保证所有的<code>record append</code>都是原子的(<code>atomic</code>)，并且是<code>at least once atomically</code>。这一点并非我们想像的简单，其所谓的<code>at least once atomic</code>，并不表示采用了<code>atomic record append</code>后，即使在客户端并发操作的情况，也能保证所有的副本完全相同(<code>bytewise idetical</code>)，它只保证数据是以原子的形式写入的，即一次完整的从<code>start chunk offset</code>到<code>end chunk offset</code>的写入，中间不会被其它操作打断。且所有副本被数据写入的<code>chunk offset</code>是相同的。但存在这种情况，<code>GFS</code>对某一副本的执行结果可能会出现<code>record duplicate</code>或者<code>inset padding</code>，这两种情况的写入所占居的文件区域被称为是<code>inconsistent</code>。而最后为了保证应用程序能够从所有副本看到一致的状态，需要由应用程序协同处理。</p>
<p>如果文件的并发操作成功，那么根据其定义的一致性模型，文件结果状态为<code>defined</code>。这通过两点来保证：其一，对文件的副本应用相同的客户端操作顺序。其二，使用<code>chunk version number</code>来检测过期(<code>stale</code>)副本。</p>
<p><code>record append</code>操作流程如下：客户端首先去请求<code>master</code>以获取<code>chunk</code>位置信息，之后当客户端完成将数据 push 到所有<code>replica</code>的最后一个<code>chunk</code>后，它会发送请求给<code>primiary chuck server</code>准备执行<code>record append</code>。<code>primary</code>首先为每一个客户端操作分配<code>sequence number</code>，然后立即检查此次的<code>record append</code>操作是否会使得<code>chunk</code>大小超过<code>chunk</code>预设定的值（64MB），若超过了则必须先执行<code>insert padding</code>，并将此操作命令同步给所有副本<code>chunk server</code>，然后回复客户端重新请求一个<code>chunk</code>并重试<code>record append</code>。如果未超过<code>chunk</code>阈值，<code>primary</code>会选择一个<code>offset</code>，然后先在本地执行<code>record append</code>操作，然后同样将命令发送给所有副本<code>chunk server</code>，最后回复写入成功给客户端。如果副本<code>chunk server</code>在执行<code>record append</code>的过程中宕机了，则<code>primary</code>会回复客户端此次操作失败，要求进行重试。客户端会请求<code>master</code>，然后重复上述流程。此时，毫无疑问会造成副本节点在相同的<code>chunk offset</code>存储不同的数据，因为有些副本<code>chunk server</code>可能上一次已经执行成功写入了所有数据(<code>duplicate record</code>)，或者写了部分数据(<code>record segment</code>)，因此，必须先进行<code>inset padding</code>，使得各副本能够有一个相同且可用的<code>offset</code>，然后才执行<code>record append</code>。<code>GFS</code>将这种包含<code>paddings &amp; record segments</code>的操作结果交由应用程序来处理。</p>
<p>应用程序的<code>writer</code>会为每个合法的<code>record</code>在其起始位置附加此<code>record</code>的<code>checksum</code>或者一个<code>predictable magic number</code>以检验其合法性，因此能检测出<code>paddings &amp; record segments</code>。如果应用程序不支持<code>record duplicate</code>（比如非幂等<code>idempotent</code>操作），则它会为每一个<code>record</code>赋予一个<code>unique ID</code>，一旦发现两个<code>record</code>具有相同的<code>ID</code>它便认为出现了<code>duplicate record</code>。由<code>GFS</code>为应用程序提供处理这些异常情况的库。</p>
<p>除此之外，<code>GFS</code>对<code>namespace</code>的操作也是原子的（具体通过文件与目录锁实现）。</p>
<p>我们再来理解为什么<code>GFS</code>的<code>record append</code>提供的是<code>at least once atomically</code>语义。这种一致性语义模型较为简单（简单意味着正确性易保证，且有利于工程实践落地，还能在一定程度上提升系统性能），因为如果客户端写入<code>record</code>失败，它只需要重试此过程直至收到操作成功的回复，而<code>server</code>也只需要正常对等待每一个请求，不用额外记录请求执行状态（但不表示不用执行额外的检查）。除此之外，若采用<code>Exactly-once</code>语义模型，那将使整个实现变得复杂：<code>primary</code>需要对请求执行的状态进行保存以实现<code>duplicate detection</code>，关键是这些状态信息必须进行冗余备份，以防<code>primary</code>宕机。事实上，<code>Exactly-once</code>的语义模型几乎不可能得到保证。另外，如果采用<code>at most once</code>语义模型，则因为<code>primary</code>可能收到相同的请求，因此它必须执行请求<code>duplicate detection</code>，而且还需缓存请求执行结果（而且需要处理缓存失效问题），一旦检测到重复的请求，对客户端直接回复上一次的请求执行结果。最后，数据库会采用<code>Zero or once</code>的事务语义(<code>transactional semantics</code>)模型，但严格的事务语义模型在分布式场景会严重影响系统性能。</p>
<h2 id="延迟-Copy-On-Write"><a href="#延迟-Copy-On-Write" class="headerlink" title="延迟 Copy On Write"></a>延迟 Copy On Write</h2><p>快照(<code>snapshot</code>)是存储系统常见的功能。对于分布式系统而言，一个关键挑战是如何尽可能地降低<code>snapshot</code>对成百上千的客户端并发访的性能影响。<code>GFS</code>同样采用的是<code>copy on write</code>技术。事实上，它延迟了<code>snapshot</code>的真正执行时间点，因为在分布式系统中，副本是必须的，大多数情况下，快照涉及的副本可能不会被修改，这样可以不用对那些副本进行 copy，以最大程度提升系统性能。换言之，只有收到客户端对快照的副本执行<code>mutations</code>才对副本进行 copy，然后，将客户端的<code>mutations</code>应用到新的副本。具体的操作流程如下：当<code>master</code>收到客户端的<code>snapshot</code>指令时，首先会从<code>primary</code>节点<code>revoke</code>相应<code>chunk</code>的<code>lease</code>（或者等待<code>lease expire</code>），以确保客户端后续对涉及<code>snapshot</code>的<code>chunk</code>的<code>mutations</code>必须先与<code>master</code>进行交互，并对这些操作执行<code>log operation</code>，然后会对涉及到的<code>chunk</code>的<code>metadata</code>执行<code>duplicate</code>操作，并且会对<code>chunk</code>的<code>reference count</code>进行累加（换言之，那些<code>chunk reference count</code>大于1的<code>chunk</code>即表示执行了<code>snapshot</code>）。如此一来，当客户端发现对已经快照的<code>chunk</code>的操作请求时，<code>master</code>发现请求的<code>chunk</code>的<code>reference count</code>大于1。因此，它会先<code>defer</code>客户端的操作请求，然后选择对应<code>chunk</code>的<code>handler</code>并将其发送给对应的<code>chunk server</code>，让<code>chunk server</code>真正执行<code>copy</code>操作，最后将<code>chunk handler</code>等信息返回给客户端。这种<code>delay snapshot</code>措施能够改善系统的性能。</p>
<p>最后，值得注意的是，虽然客户端并不缓存实际的数据文件（为什么？），但它缓存了<code>chunk</code>位置信息，因此若对应的<code>chunk server</code>因宕机而<code>miss</code>了部分<code>chunk mutations</code>，那客户端是有可能从这些<code>stale</code>的<code>replica</code>中读取到<code>premature</code>数据，这种读取数据不一致的时间取决于<code>chunk locations</code>的过期时间以及对应的文件下一次被<code>open</code>的时间（因为一旦触发这两个操作之一，客户端的<code>cache</code>信息会被<code>purge</code>）。</p>
<p>参考文献：</p>
<p>[1] Ghemawat S, Gobioff H, Leung S T. The Google file system[M]. ACM, 2003.<br>[2].<a href="https://pdos.csail.mit.edu/6.824/" target="_blank" rel="noopener">MIT 6.824 Lecture</a></p>
]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>分布式文件系统</tag>
        <tag>GFS</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式互斥算法解析与实现</title>
    <url>/2018/11/09/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%92%E6%96%A5%E7%AE%97%E6%B3%95%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<p>资源共享非常普遍，在单机系统中，进程间对共享资源的互斥访问可以通过互斥锁、信号量以及进程间通信等机制来实现。而在分布式系统中，也不可避免多个节点共享某一资源或同时执行某一函数，比如全局配置文件，因此分布式互斥算法必须保证任何时刻只允许一个进程访问资源或执行临界区(<code>critical section</code>)代码，即互斥算法的安全性，有些场景也有公平性要求。另外，好的互斥算法应该能尽可能降低消息带宽(<code>message overhead</code>)，减少进程（节点）等待时间，即时延(<code>latency</code>)，无系统瓶颈(<code>bottleneck</code>)，也能容忍消息乱序。</p>
<a id="more"></a>

<p>分布式互斥算法分为集中式算法(<code>centralized algorithm</code>)和分布式算法(<code>distributed algorithm</code>)，而分布式算法又包括了基于令牌的算法(<code>token based algorithm</code>)以及基于请求的算法(<code>permission based algorithm</code>)。无论基于何种原理实现，一般而言，理想的分布式互斥算法需要保证以下目标：</p>
<ul>
<li><strong>安全性</strong>，即任何时刻只能有一个进程访问共享资源，即持有互斥锁。</li>
<li><strong>公平性</strong>，有些场景需要尽量保证访问共享资源的公平性，这表明：系统不能出现死锁，任何进程持有锁的时间是有限的，任何等待的进程最终都能获取锁，以及等待获取锁的进程的等待时间是有限的。</li>
<li><strong>低带宽</strong>，即尽量减少消息传输的数目。</li>
<li><strong>低延迟</strong>，即进程进入临界区之前的等待的时间。</li>
<li>动态性，即允许进程在任何时刻加入到访问共享资源的进程集合中，或者从其中退出。</li>
<li>容忍进程失败，即允许访问共享资源的进程集合中的进程因失败而退出，而保证整个系统不受影响。</li>
<li>容忍消息丢失，即在消息不能按时到达、乱序甚至丢失的情况下，整个系统依然正常工作。</li>
</ul>
<p>在本文我们讨论前四个要求，假设<strong>进程数目是确定的，没有进程会失败，消息也不会丢失</strong>。下面我们通过简要阐述算法原理以及实现关键点来依次介绍<code>Centralized Mutual Server</code>算法、<code>Ricart Agrawala</code>算法、<code>Lamport Distributed Mutual Exclusion</code>算法以及<code>Token Ring</code>算法。</p>
<h2 id="Centralized-Mutual-Server"><a href="#Centralized-Mutual-Server" class="headerlink" title="Centralized Mutual Server"></a>Centralized Mutual Server</h2><p>顾名思义，<code>Centralized Muutal Server</code>为集中式的互斥算法。整个系统内部包括两种消息：请求(<code>reqeust</code>)消息、授权(<code>grant</code>)消息以及释放(<code>release</code>)消息。核心数据结构为一个请求消息队列。算法核心为：它选取一个进程(<code>centralized server</code>)作为协调者，负责对名进程的请求进行即时或推迟(<code>defer</code>)授权。它内部维护一个互斥锁锁请求队列，当收到请求消息时，如果队列为空，则直接授权，否则将其加入到队列中。当收到释放消息时，如果列队不为空，则从队列中取出一个请求并授权响应。算法公平性依赖于队列实现，如使用<code>FIFO</code>则能够保证各个进程的锁请求消息能够被公平地授权。消息带宽为3(<code>1 request, 1 grant, 1 release</code>)，即在某一进程从准备进入临界区到退出临界区所传输消息的数量。很明显，集中式互斥算法的缺点是协调者的瓶颈。</p>
<p>集中式互斥算法最容易实现。在网络通信层，可以采用基于<code>TCP</code>的<code>client-server</code>通信模型。关于协调者的实现，你可能需要关注当前是否已经授权了锁请求。同时，如果有必要，注意单进程内部锁的使用。</p>
<h2 id="Ricart-Agrawala"><a href="#Ricart-Agrawala" class="headerlink" title="Ricart Agrawala"></a>Ricart Agrawala</h2><p><code>Ricart &amp; Agrawala</code>算法是在1981年被提出的一个基于请求的分布式互斥算法。它基于<code>lamport clock</code>，即依赖于全局有序的逻辑时钟。整个系统内部包括两种消息：请求(<code>reqeust,i,ts</code>)消息与回复(<code>reply,j</code>)消息。核心数据结构包括缓存其它进程回复消息的队列(<code>replyQueue</code>)以及缓存推迟回复进程请求消息队列(<code>deferQueue</code>)。算法核心为：当进程<code>i</code>准备进入临界区时，必须发送一个带（逻辑）时间戳的请求消息给其它所有进程，当其收到了其它所有进程的对此请求的回复（响应）时，则进入临界区。但如果某一进程<code>j</code>在收到进程<code>i</code>的请求之前，发出了一个更早的请求消息，则它会将此进程(<code>i</code>)的请求消息放入到延迟队列(<code>deferQueue</code>)，并且先执行完临界区的代码，当准备退出临界区时，才发送请求响应给进程(<code>i</code>)。算法的公平性容易保证。而消息带宽为<code>{request: n-1, reply: n-1} =&gt; 2(n-1)</code>，其中<code>n</code>为进程数。</p>
<p><code>Ricart Agrawala</code>算法的相比集中式算法在实现上更为复杂。同样在通信层，则不能构建<code>one server, muliti-client</code>模型，而采用<code>peer to peer</code>模型，因为所有进程都是对等的，即同时充当<code>server</code>与<code>client</code>，而且作为一种简化实现，所有进程在启动后，应该互相建立连接。除此之外，你需要实现（模拟）<a href="https://qqzeng.top/2018/11/05/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E6%97%B6%E9%97%B4%E3%80%81%E6%97%B6%E9%92%9F%E4%B8%8E%E4%BA%8B%E4%BB%B6%E9%A1%BA%E5%BA%8F/" target="_blank" rel="noopener">lamport clock 算法</a>，否则互斥算法的正确性不能得到保证，注意对于某些消息（如<code>reply</code>）的发送事件，虽然可以更新消息时间戳，但其实不影响算法正确性。</p>
<h2 id="Lamport-Distributed-Mutual-Exclusion"><a href="#Lamport-Distributed-Mutual-Exclusion" class="headerlink" title="Lamport Distributed Mutual Exclusion"></a>Lamport Distributed Mutual Exclusion</h2><p><code>Lmpoart Distributed Mutual Exclusion</code>算法于1978年由 Lamport 在关于<code>lamport clock</code>理论论文中提出，其作为<code>lamport clock</code>的实际应用，因此，显然其依赖于<code>lamport clock</code>。事实上，此算法不仅可以作为分布式互斥算法，其内部的请求优先级队列也能作为分布式节点副本一致性的实现参考模型。但原论文提出的互斥算法基于消息按顺序到达的假设，解释如下：</p>
<blockquote>
<p>比如，进程i在时间片1发送锁请求a，但因为网络原因被极端延时了。而且在其它进程收到进程i发送的请求消息a之前，进程j在时间片5发送了请求b，而请求b恰好被顺利传输，很快被其他进程接收，并且其他进程（包括进程i）立刻发送了对请求消息b的回复消息，同时回复消息也立刻被进程j接收，但此时进程j仍未收到进程i的请求消息a，所以进程j以为自己成功获取到锁（收到了其它所有进程对请求消息b的回复）。而事实上，进程i的请求消息a要比进程j的请求消息b更早发送，因此应该是进程i先获取锁。其根本原因在于，进程i在收到其他节点请求消息（进程j的请求消息b）时，没有进行额外检查，理论上它需要判定自己是否在更早前发出过请求消息，而不只是直接对请求消息回复，即使最后其在请求消息队列里移除的消息是它自己的请求消息（因为自己是请求消息是最早的）。但这造成了整个系统的不正确性。</p>
</blockquote>
<p>因此，改变<code>Lmpoart Distributed Mutual Exclusion</code>算法在接收请求消息后发送回复消息的条件，消除了消息按序到达的假设，但同时也使得变更后的算法更为复杂。</p>
<p>系统内部包括三种消息：请求(<code>reqeust,i,ts</code>)消息、回复(<code>reply,j</code>)消息以及释放(<code>release</code>)消息。核心数据结构包括缓存其它进程回复消息的队列(<code>replyQueue</code>)、缓存推迟回复进程请求消息队列(<code>deferQueue</code>)以及一个以时间戳为依据的请求消息优先级队列(<code>requestPriorityQueue</code>)。算法变更的核心为：进程<code>i</code>在收到进程<code>j</code>的请求消息<code>(request, j, t)</code>时，（条件1）先判断自己是否发送过更早的请求消息，（条件2）并且未收到进程<code>j</code>针对此请求消息的回复消息。如果二者之中任一个未被满足，则对进程<code>i</code>的请求消息发送回复，否则将其加入到<code>deferQueue</code>。原因如下：条件1是明显的；关于条件2，如果进程<code>j</code>已经收到了进程<code>i</code>的消息回复，说明进程<code>i</code>先前发出的请求消息肯定已经被进程<code>j</code>接收（换言之，进程<code>i</code>若发送过请求消息，则此请求消息必定已经缓存到了进程<code>j</code>的<code>requestPriorityQueue</code>），因此消除了消息延迟（乱序）的影响。另一方面，当进程<code>i</code>收到请求回复消息时，它会先将其加入到<code>replyQueue</code>，并判断发送此回复消息的进程是否被加入到了其<code>deferQueue</code>中，如果已经加入到了，则将其移除，然后对此进程发送回复消息（因为进程<code>i</code>确认它已经收到被移除进程的回复消息）。其它的算法逻辑同论文中描述一致。事实上，消除消息按序到达的关键为<code>deferQueue</code>。算法的公平性容易保证。而消息带宽为<code>{request: n-1, reply: n-1, release: n-1} =&gt; 3(n-1)</code>，其中<code>n</code>为进程数。</p>
<p><code>Lmpoart Distributed Mutual Exclusion</code>算法的相比<code>Ricart Agrawala</code>算法在实现上更为复杂。通信层采用<code>peer to peer</code>模型。</p>
<h2 id="Token-Ring"><a href="#Token-Ring" class="headerlink" title="Token Ring"></a>Token Ring</h2><p><code>Token Ring</code>是基于令牌的互斥算法。是一种简单的互斥算法模型，局限性也较大。系统内部只有一种消息：传递 token 的(<code>OK</code>)消息。算法核心为：将所有进程在逻辑上组成一个环，并将 token 在环上依次传递，获取到 token 的进程则具备进行临界区的条件，未收到 token 的进程则必须等待。在进程启动时，必须先将 token 传递给某一进程，若此接收进程需要锁，则进入临界区，执行完临界区代码后，再将 token 传递给相邻的下一个进程。否则直接将 token 传递给相邻下一个进程。算法的公平性同样易保证。消息带宽为<code>n-1</code>，其中<code>n</code>为进程数。</p>
<p><code>Token Ring</code>算法较易实现，同样采用<code>peer to peer</code>通信模型。注意进程启动时，初始的 token 持有者。</p>
<h2 id="关于测试"><a href="#关于测试" class="headerlink" title="关于测试"></a>关于测试</h2><p>在实现上述四种算法时(<code>go</code>语言)，采用<code>TCP</code>协议（可靠的）。测试的流程包含两个独立的阶段：<br><strong>Phase a</strong>. 每个进程独立的重复以下操作若干次。</p>
<ol>
<li>执行本地操作。采用 sleep [100, 300]ms 来模拟。</li>
<li>开始进入临界区(<code>critical section</code>)。执行获取互斥锁逻辑。</li>
<li>执行临界区代码。对一个共享变量进行累加，在 [100, 200]ms超时时间内，每隔100ms，对共享变量随机增加 [1,10]。将累加过程写入文件，同时将累加的中间值记录到全局数组。</li>
<li>退出临界区。执行释放互斥锁逻辑。</li>
</ol>
<p><strong>Phase b</strong>. 每个进程独立的重复以下操作若干次。</p>
<ol>
<li>进程号为偶数的进程 sleep [100, 300]ms，然后重复 Phase a 操作流程。进程号奇数的进程直接重复 Phase b 流程。</li>
</ol>
<p>对上述四个分布式互斥算法的测试结果的验证侧重于两个方面：</p>
<ul>
<li><strong>算法正确性</strong>。通过检查 Phase a&amp;b 中全局数组的记录情况来确保共享资源的互斥访问。另外，核查 Phase a&amp;b 中进程访问共享资源的访问日志文件。</li>
<li><strong>带宽与延时</strong>。统计每个进程的消息读写数目，及获取互斥锁的延时，并计算平均延时。</li>
</ul>
<p><a href="https://github.com/qqzeng/distributed-mutual-exclusion" target="_blank" rel="noopener">参考代码在这里</a>。</p>
<p>参考文献：</p>
<p>[1] Ricart G, Agrawala A K. An Algorithm for Mutual Exclusion in Computer Networks[R]. MARYLAND UNIV COLLEGE PARK DEPT OF COMPUTER SCIENCE, 1980.<br>[2] Lamport L. Time, clocks, and the ordering of events in a distributed system[J]. Communications of the ACM, 1978, 21(7): 558-565.<br>[3].<a href="https://www.cs.cmu.edu/~dga/15-440/S14/" target="_blank" rel="noopener">CMU Distributed System Lecture.</a></p>
]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>互斥算法</tag>
        <tag>资源共享</tag>
        <tag>lamport clock</tag>
        <tag>逻辑时钟</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式系统时间、时钟与事件顺序</title>
    <url>/2018/11/05/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E6%97%B6%E9%97%B4%E3%80%81%E6%97%B6%E9%92%9F%E4%B8%8E%E4%BA%8B%E4%BB%B6%E9%A1%BA%E5%BA%8F/</url>
    <content><![CDATA[<p>如何确定分布式系统各节点（进程）中事件发生的先后顺序至关重要。时钟不一致会导致系统发生不可预料的逻辑错误。然而绝大部分情况下，不能依赖于物理时钟，因为不同的系统的物理时钟总会存在不同程度的时钟漂移（多处理器机器中也类似），即便各节点定期通过网络从时钟源进行时钟同步，也无法确保各节点时钟完全一致。因此，早在1978年，Leslie Lamport 便提出了逻辑时钟的概念，并描述了如何利用逻辑时钟来定义分布式系统中事件的发生顺序。它大致基于事件发生的因果关系，并保证能够正确排列系统中具有因果关系的事件，这使得分布式系统在逻辑上不会将具有因果关系事件的发生顺序倒置。</p>
<a id="more"></a>

<h2 id="时钟同步"><a href="#时钟同步" class="headerlink" title="时钟同步"></a>时钟同步</h2><p>事实上，计算机的时钟会以不同速率来计时，普通的石英钟漂移(<code>skew drift</code>)1秒所需的时间大概为11-12天。因此如果使用物理时钟<code>physical clock</code>所定义的时间戳来确定系统中事件发生顺序，需要对物理时钟进行定期同步(<code>clock synchronization</code>)。在理想网络环境下，通过网络将带有时间戳的消息在时钟源（<code>UTC</code>,<code>Coordinated Universal Time</code>）与本地机器之间传输，能够保证本地时间与时钟源基本一致。但事实上，网络是异步的且有延时，因此无法保证不同节点之间的时钟完全同步。尽管如此，我们可以通过算法来尽可能提高时钟同步精度。著名的时钟同步算法如<a href="https://en.wikipedia.org/wiki/Cristian%27s_algorithm" target="_blank" rel="noopener"><code>Cristian&#39;s Time Sync</code></a>和<a href="https://en.wikipedia.org/wiki/Berkeley_algorithm" target="_blank" rel="noopener"><code>Berkeley algorithm</code></a>。</p>
<h2 id="Lamport-Clock"><a href="#Lamport-Clock" class="headerlink" title="Lamport Clock"></a>Lamport Clock</h2><p>相比于通过同步物理时钟的方式来协调各节点的时间，在分布式系统中，更为普遍且合理的方式是使用逻辑时钟(<code>logical clock</code>)。Lamport 提出的逻辑时钟舍弃了物理时钟固有的无限粒度的性质，它基于事件发生的因果关系(<code>causality</code>)。换言之，所有的事件通过<code>happened before</code>来关联，以<code>-&gt;</code>表示。对于事件<code>a</code>与<code>b</code>，<code>a-&gt;b</code>表示<code>a happened before b</code>，它是一种偏序关系(<code>partial order</code>)，分布式系统中所阐述的事件发生的先后顺序一般为偏序。Lamport 在分布式系统内定义了三种类型的事件，包括进程（节点）内事件、进程发送消息事件以及进程接收消息事件。<code>a happened before b</code>由以下三个条件中任一一个触发：</p>
<ol>
<li>若<code>a</code>与<code>b</code>表示同一进程内的事件，并且<code>a</code>发生在<code>b</code>之前，则有<code>a-&gt;b</code>。</li>
<li>若<code>a</code>代表某一进程发送消息的事件，<code>b</code>代表另一进程接收此消息的事件，则有<code>a-&gt;b</code>。</li>
<li><code>happened before</code>关系满足传递性。</li>
</ol>
<p>如下图（水平方向表示物理时钟增加方向，垂直方向表示不同进程），由规则(1): <code>a-&gt;b</code>及<code>c-&gt;d</code>; 由规则(2): <code>b-&gt;c</code>和<code>d-&gt;f</code>; 由规则(3): <code>b-&gt;f</code>。但并非所有的事件都能通过<code>-&gt;</code>关联，比如<code>a</code>与<code>e</code>为不同进程不同消息链上的事件，则只能被定义为并发的两个事件，记作<code>a||e</code>。事实上，事件<code>a</code>与<code>e</code>没有因果关系，因此，从系统正确性的角度而言，它们之间真正的发生顺序不会影响到系统的正确性，所以我们不需要关注它们发生的先后顺序。</p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/blob/hexo/static/eb415390449c57ea8f6c9e33c82a7e9.png?raw=true" alt="lamport clock"></p>
<p>如果将系统中所有发生的事件<code>e</code>标记一个单调递增的时间戳(<code>L(e)</code>)（与物理时钟没有关系），也称为<code>lamport timestamp/clock</code>，每一个进程都会维护自己的逻辑时钟，时间戳标记原理如下：</p>
<ol>
<li>每个事件对应一个初始的时间戳，初始值为0。</li>
<li>如果发生的事件为进程内事件，则时间戳加1。</li>
<li>如果事件为发送事件，则将时间戳加1，并在消息中带上该时间戳。</li>
<li>如果事件为接收事件，则其时间戳为max(进程时间戳，消息中附带的时间戳)+1。</li>
</ol>
<p>如下图，<code>p1</code>、<code>p2</code>以及<code>p3</code>都有自己的初始的逻辑时钟0；进程的全局（当前）逻辑时钟即为当某一事件发生之后的逻辑时钟值，如事件<code>a</code>与<code>b</code>的逻辑时钟值分别为<code>0+1=1</code>和<code>1+1=2</code>。而发<code>p1</code>发送消息<code>m1</code>给<code>p2</code>后，<code>c</code>的逻辑时钟值为<code>max(0, 2)+1=3</code>。</p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/blob/hexo/static/lamport%20clock-2.png?raw=true" alt="lamport clock-2"></p>
<p>在<code>lamport clock</code>表示法中，对于事件<code>e1</code>与<code>e2</code>，<code>e1-&gt;e2</code>能推断出<code>L(e1)&lt;L(e2)</code>，但反之不成立，即<code>L(e1)&lt;L(e2)</code>不能推断出<code>e1-&gt;e2</code>，如在图(2)中，<code>L(b)&gt;L(e)</code>，但实际上有<code>b||e</code>。另外，并发事件也是类似的，即若<code>L(e1)=L(e2)</code>可以推断出<code>e1||e2</code>，但反之不成立。对于<code>lamport clock</code>，并发事件没有可比性，正如上文所述，并发事件发生的先后顺序并不影响系统逻辑正确性。</p>
<p>在<code>lamport clock</code>表示法中，无法确定没有因果关系的事件的先后顺序，而大多数分布式系统确实需要对所有的事件进行全局排序(<code>total order</code>)，而不仅仅得到影响系统正确性的事件之间的偏序关系(<code>partial order</code>)。换言之，为了得到一个全局的事件发生顺序，必须对并发事件进行先后发生顺序的判定。因为并发事件真正发生的先后顺序不影响系统的准确性，因此可以为它们统一制定一个任意顺序规则（事实上，<code>lamport clock</code>就是这么考虑的）。比如同其它因果关系事件类似，以逻辑时钟(<code>L(e)</code>)的大小来判定，逻辑时钟小的发生在前，反之则发生在后。而对于逻辑时钟相同的并发事件，在<code>lamport clock</code>算法当中，给出的解释是根据进程号(<code>PID</code>)的大小来确定，进程编号更小的发生在前。其实，Lamport 在论文中提到过，也可以采用其它方式来确定并发事件的先后顺序，这似乎没有理论依据，但是正如前面所述，通过引入<code>lamport clock</code>，可以在逻辑上保证系统的正确性，我们不关心那些不影响系统正确运行的事件之间的顺序。但以进程编号作为依据，似乎影响到了系统的公平性，比如当两个进程竞争同一物理资源，物理时间上先发出请求的进程不一定能先锁定资源，但这并不会造成系统逻辑错误。在<code>lamport clock</code>原论文中，给出的实例便是分布式系统资源竞争或者互斥占用，大家可以参考原论文。</p>
<h2 id="Vector-Clock"><a href="#Vector-Clock" class="headerlink" title="Vector Clock"></a>Vector Clock</h2><p>前文提到<code>lamport clock</code>存在一个缺点，即对于事件<code>e1</code>与<code>e2</code>，<code>L(e1)&lt;L(e2)</code>并不能推导出<code>e1 happened before e2</code>，换言之，其只能确定单方的因果关系关联。<code>vector clock</code>是在<code>lamport clock</code>上演进的一种逻辑时钟表示法，它完善了<code>lamport clock</code>这一缺陷，能提供完整的因果关系关联。在<code>vector clock</code>表示法中，每个进程维护的不仅仅是本进程的时间戳，而是通过一个向量(<code>vector</code>)来记录所有进程的<code>lamport clock</code>以此作为进程的逻辑时钟，即进程事件的逻辑时钟被表示为：<code>v(e)[c1, c2..., cn]</code>，其中<code>ci</code>为进程<code>i</code>中先于事件<code>e</code>发生的事件。<code>vector clock</code>的逻辑时钟标记原理同<code>lamport clock</code>原理类似。</p>
<p>如下图，在进程<code>p1</code>中，事件<code>a</code>的逻辑时钟为<code>(1,0,0)</code>，发送消息<code>m</code>的事件<code>b</code>的逻辑时钟为<code>(2,0,0)</code>。在进程<code>p2</code>中，其接收消息<code>m1</code>的事件<code>c</code>的逻辑时钟为<code>max((0,0,0),(2,0,0))+1=(2,1,0)</code>。此时，对于事件<code>e1</code>与<code>e2</code>，由<code>e1 happened before e2</code>推断出<code>v(e1)&lt;v(e2)</code>，反之亦然。在<code>vector clock</code>表示法中，事件<code>c</code>与<code>e</code>是并行事件，记作<code>c&lt;-&gt;e</code>，因为我们不能推导出<code>v(c)&lt;=v(e)</code>，也不能推导出<code>V(e)&lt;=v(c)</code>。注意，此时逻辑时钟值的比较(<code>&lt;|&gt;|&lt;=|&gt;=</code>)是对向量的分量逐一比较。</p>
<p><img src="https://github.com/qqzeng/qqzeng.github.io/blob/hexo/static/vector%20clock-1.png?raw=true" alt="vector clock"></p>
<p>参考资料：（插图出自 CMU Lecture）<br>[1] <a href="https://en.wikipedia.org/wiki/Cristian%27s_algorithm" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Cristian%27s_algorithm</a><br>[2] <a href="https://en.wikipedia.org/wiki/Berkeley_algorithm" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Berkeley_algorithm</a><br>[3] Lamport L. Time, clocks, and the ordering of events in a distributed system[J]. Communications of the ACM, 1978, 21(7): 558-565.<br>[4].<a href="https://www.cs.cmu.edu/~dga/15-440/S14/index.html" target="_blank" rel="noopener">CMU 15-440 Distributed System Lecutre 9</a></p>
]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>逻辑时钟</tag>
        <tag>时钟同步</tag>
        <tag>物理时钟</tag>
      </tags>
  </entry>
  <entry>
    <title>Java后端工程师技能树</title>
    <url>/2018/10/29/2018-10-29-Java%E5%90%8E%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%88%E6%8A%80%E8%83%BD%E6%A0%91/</url>
    <content><![CDATA[<h1 id="编程语言"><a href="#编程语言" class="headerlink" title="编程语言"></a>编程语言</h1><ol>
<li>JAVA SE</li>
<li>JAVA EE</li>
</ol>
<h1 id="必备框架"><a href="#必备框架" class="headerlink" title="必备框架"></a>必备框架</h1><ol>
<li>Spring</li>
<li>SpringMVC</li>
<li>SpringBoot</li>
<li>SpringCloud</li>
<li>Mybatis</li>
<li>Hibernate</li>
<li>Dubbo</li>
<li>Netty</li>
<li>Shiro</li>
<li>Ehcache</li>
<li>Quartz</li>
<li>Velocity</li>
<li>JUnit</li>
<li>Log4j</li>
</ol>
<a id="more"></a>

<h1 id="IDE"><a href="#IDE" class="headerlink" title="IDE"></a>IDE</h1><ol>
<li>Eclipse</li>
<li>IDEA</li>
</ol>
<h1 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h1><ol>
<li>Ubuntu</li>
<li>CentOS</li>
</ol>
<h1 id="性能分析"><a href="#性能分析" class="headerlink" title="性能分析"></a>性能分析</h1><ol>
<li>top</li>
<li>vmstat</li>
<li>iostat</li>
<li>sar</li>
<li>dstat</li>
</ol>
<h1 id="虚拟化管理"><a href="#虚拟化管理" class="headerlink" title="虚拟化管理"></a>虚拟化管理</h1><ol>
<li>Docker</li>
<li>OpenStack</li>
<li>CloudFoundry</li>
</ol>
<h1 id="Web服务器"><a href="#Web服务器" class="headerlink" title="Web服务器"></a>Web服务器</h1><ol>
<li>NGINX</li>
<li>Apache</li>
<li>IIS</li>
<li>Lighttpd</li>
<li>Zeus</li>
</ol>
<h1 id="Servlet容器"><a href="#Servlet容器" class="headerlink" title="Servlet容器"></a>Servlet容器</h1><ol>
<li>Tomcat</li>
<li>Jetty</li>
<li>JBoss</li>
<li>Resin</li>
<li>WebLogic</li>
<li>WebSphere</li>
<li>Glassfish</li>
</ol>
<h1 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h1><ol>
<li>LVS</li>
<li>Haproxy</li>
<li>Nginx/Tengine</li>
</ol>
<h1 id="网络编程"><a href="#网络编程" class="headerlink" title="网络编程"></a>网络编程</h1><ol>
<li>Socket</li>
<li>NIO</li>
<li>BIO</li>
<li>AIO</li>
<li>Netty</li>
</ol>
<h1 id="RPC框架"><a href="#RPC框架" class="headerlink" title="RPC框架"></a>RPC框架</h1><ol>
<li>Dubbo</li>
<li>RMI</li>
<li>Hessian</li>
<li>Thrift</li>
</ol>
<h1 id="Java垃圾回收器"><a href="#Java垃圾回收器" class="headerlink" title="Java垃圾回收器"></a>Java垃圾回收器</h1><ol>
<li>ParNew</li>
<li>CMS</li>
<li>G1</li>
<li>Parallell GC</li>
</ol>
<h1 id="性能调优"><a href="#性能调优" class="headerlink" title="性能调优"></a>性能调优</h1><ol>
<li>jmap</li>
<li>jstack</li>
<li>jcmd</li>
<li>jconsole</li>
<li>jinfo</li>
<li>btrace</li>
</ol>
<h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><ol>
<li>字节</li>
<li>字符</li>
<li>字符串</li>
<li>整型</li>
<li>长整型</li>
<li>数组</li>
<li>链表</li>
<li>哈希表</li>
<li>树</li>
<li>堆</li>
<li>图</li>
</ol>
<h1 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h1><ol>
<li>经典算法</li>
<li>递归</li>
<li>迭代</li>
<li>时间复杂度</li>
<li>空间复杂度</li>
</ol>
<h1 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h1><ol>
<li>分词</li>
<li>关键字提取</li>
<li>文本相似度</li>
<li>分类</li>
<li>推荐算法</li>
</ol>
<h1 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h1><ol>
<li>工厂模式</li>
<li>单例模式</li>
<li>观察者模式</li>
<li>代理模式</li>
<li>建筑者模式</li>
<li>装饰器模式</li>
<li>适配器模式</li>
<li>门面模式</li>
</ol>
<h1 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h1><ol>
<li>MySQL</li>
<li>PgSQL</li>
</ol>
<h1 id="NoSQL"><a href="#NoSQL" class="headerlink" title="NoSQL"></a>NoSQL</h1><ol>
<li>HBase</li>
<li>MongoDB</li>
</ol>
<h1 id="高速缓存"><a href="#高速缓存" class="headerlink" title="高速缓存"></a>高速缓存</h1><ol>
<li>Redis</li>
<li>Memcached</li>
</ol>
<h1 id="搜索引擎"><a href="#搜索引擎" class="headerlink" title="搜索引擎"></a>搜索引擎</h1><ol>
<li>Elasticsearch</li>
<li>Solr</li>
</ol>
<h1 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h1><ol>
<li>Kafka</li>
<li>RabbitMQ</li>
<li>RocketMQ</li>
<li>ActiveMQ</li>
<li>ZeroMQ</li>
</ol>
<h1 id="存储分析"><a href="#存储分析" class="headerlink" title="存储分析"></a>存储分析</h1><ol>
<li>Hadoop</li>
<li>Spark</li>
<li>Storm</li>
<li>Spark mlib</li>
</ol>
<h1 id="数据同步"><a href="#数据同步" class="headerlink" title="数据同步"></a>数据同步</h1><ol>
<li>Sqoop</li>
<li>Canal</li>
<li>MySQL-Binlog</li>
</ol>
<h1 id="构建工具"><a href="#构建工具" class="headerlink" title="构建工具"></a>构建工具</h1><ol>
<li>Maven</li>
<li>Gradle</li>
</ol>
<h1 id="版本管理"><a href="#版本管理" class="headerlink" title="版本管理"></a>版本管理</h1><ol>
<li>Git</li>
<li>SVN</li>
</ol>
<h1 id="微服务"><a href="#微服务" class="headerlink" title="微服务"></a>微服务</h1><ol>
<li>Dubbo</li>
<li>SpringCluod</li>
</ol>
<h1 id="工具库"><a href="#工具库" class="headerlink" title="工具库"></a>工具库</h1><ol>
<li>Google Guava</li>
<li>Apache Commons lang</li>
<li>Apache beanutils</li>
<li>Apache Codec</li>
<li>Apache collections</li>
<li>APache io</li>
<li>CDLIB代码生成</li>
</ol>
<h1 id="后端系统结构"><a href="#后端系统结构" class="headerlink" title="后端系统结构"></a>后端系统结构</h1><ol>
<li>单体应用ORM</li>
<li>垂直应用MVC</li>
<li>分布式服务</li>
</ol>
<h1 id="项目工具"><a href="#项目工具" class="headerlink" title="项目工具"></a>项目工具</h1><ol>
<li>GitHub</li>
<li>GitLab</li>
<li>Gitbucket</li>
<li>禅道</li>
<li>Scrum</li>
<li>Tower</li>
<li>Teambition</li>
<li>Phabricator</li>
</ol>
<h1 id="持续集成"><a href="#持续集成" class="headerlink" title="持续集成"></a>持续集成</h1><ol>
<li>Jenkins</li>
<li>Travis</li>
<li>Codeship</li>
<li>Strider</li>
</ol>
<h1 id="网络协议"><a href="#网络协议" class="headerlink" title="网络协议"></a>网络协议</h1><ol>
<li>TCP/IP</li>
<li>UDP</li>
<li>Http</li>
<li>Https</li>
<li>Restful API</li>
<li>REST</li>
<li>SOAP</li>
<li>XML-RPC</li>
</ol>
<h1 id="数据库连接池"><a href="#数据库连接池" class="headerlink" title="数据库连接池"></a>数据库连接池</h1><ol>
<li>JDBC</li>
<li>C3P0</li>
<li>Durid</li>
</ol>
<h1 id="鉴权技术"><a href="#鉴权技术" class="headerlink" title="鉴权技术"></a>鉴权技术</h1><ol>
<li>HTTP Basic Authentication</li>
<li>Session Cookie</li>
<li>JSON Web Token</li>
<li>OAuth</li>
</ol>
<h1 id="服务"><a href="#服务" class="headerlink" title="服务"></a>服务</h1><ol>
<li>RESTful</li>
<li>SOA</li>
<li>RPC</li>
<li>MicroServices</li>
</ol>
<h1 id="消息"><a href="#消息" class="headerlink" title="消息"></a>消息</h1><ol>
<li>JMS</li>
<li>IPC</li>
<li>MQ</li>
</ol>
<!--![Java后端工程师技能树](https://www.google.cn/assets/private/images/java/java_skill_tree.png "Java后端工程师技能树")-->

<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://github.com/phodal/growth-roadmap" target="_blank" rel="noopener">技能图谱</a><br><a href="http://www.rowkey.me/" target="_blank" rel="noopener">后端技术杂谈</a><br><a href="http://www.broadview.com.cn/book/13" target="_blank" rel="noopener">Java后端工程师修炼之道</a><br><a href="http://www.rowkey.me/blog/2016/06/27/java-backend-study/?spm=a2c4e.11153940.blogcont465224.18.72ee1c28py6kkE" target="_blank" rel="noopener">Java后端工程师学习大纲</a><br><a href="https://zhangzj.github.io/2016/11/06/JavaSkillTree.html" target="_blank" rel="noopener">Java后端技能树</a>  </p>
]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>groupcache 设计原理剖析</title>
    <url>/2018/10/29/groupcache-%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86%E5%89%96%E6%9E%90/</url>
    <content><![CDATA[<p><a href="https://github.com/golang/groupcache" target="_blank" rel="noopener"><code>groupcache</code></a>是一个用<code>go</code>实现的分布式k/v缓存及缓存填充库，它的作者也是<a href="https://github.com/memcached/memcached" target="_blank" rel="noopener"><code>memcached</code></a>的作者，它已在Google多个生产环境中使用。它非常小巧精致，比较适用于分布式缓存的学习。它本身只是一个代码包（大约2000行代码，不需要配置服务器，在不同的请求处理场合，它可以充当客户端或者服务器的角色。它支持一致性哈希，即通过一致性哈希来对查询请求进行路由。对于缓存的具体策略，<code>groupcache</code>采用的是<code>LRU</code>，使用了一个<code>List</code>和一个<code>Map</code>来实现，非常简单。下面先简述本地缓存的基本模型和常见问题，然后剖析<code>groupcache</code>的设计原理。</p>
<a id="more"></a>

<p>单机缓存或者本地缓存是简单的，通过在内存中维护一个cache，当收到查询时，先查询cache是否已缓存查询结果，如果命中则直接返回，否则必须到存储系统执行查询，然后将结果先缓存到cache，然后返回结果。当然，这是本地缓存的基本模型，一般而言，缓存系统都面临着诸如<strong>缓存穿透</strong>、<strong>缓存雪崩</strong>及<strong>缓存击穿</strong>等问题。</p>
<ul>
<li>缓存穿透指的是查询一定不存在的数据，此时从数据源查询不到结果，因此也无法对结果进行缓存，这直接导致此类型的查询请求每次都会落到数据源层，不仅使得缓存失效，当请求数量过多时也会浪费资源。</li>
<li>缓存雪崩指的是大量的缓存的过期时间被设置为相同或近似，使得缓存失效时，所有的查询请求全部落地到数据源层，同样，此时数据源层存在服务不可用的可能性。</li>
<li>缓存击穿则指的是对于那些热点数据，在缓存失效时，高并发的查询请求也会导致后端数据源层崩溃。</li>
</ul>
<p>对于<code>groupcache</code>的设计，文章从一致性哈希、缓存命名空间、热数据扩散以及缓存过滤几个方面进行阐述。</p>
<h2 id="一致性哈希"><a href="#一致性哈希" class="headerlink" title="一致性哈希"></a>一致性哈希</h2><p>一致性哈希最初是在论文<a href="https://www.akamai.com/us/en/multimedia/documents/technical-publication/consistent-hashing-and-random-trees-distributed-caching-protocols-for-relieving-hot-spots-on-the-world-wide-web-technical-publication.pdf" target="_blank" rel="noopener">《Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web》</a>中提出，目标是致力于解决因特网中的热点(<code>Hot spot</code>)问题，并真正应用于<code>p2p</code>环境，它弥补简单的哈希算法的不足。一般可以从四个方面来衡量哈希算法的适用性。</p>
<ul>
<li><strong>平衡性</strong>。平衡性即哈希的结果能够尽可能的分散到所有节点或缓冲，以保证缓冲空间被最大程度使用。</li>
<li><strong>单调性</strong>。单调性即如果当前缓存系统已经存在被映射的缓冲内容，当有新的节点加入到系统时，哈希算法应该能够尽可能保证原有已分配的的缓冲内容只能被映射到原有的对应节点或者新的节点，而不能被映射到旧的节点集合的其它节点。</li>
<li><strong>分散性</strong>。分布式环境中，不同终端所见的节点范围有可能不同（因为可能只能看见部分节点），这会导致不同终端的哈希结果不一致，最终，相同的内容被映射到了不同的节点。而分散性则专门用于描述此种情况发生的严重程度。好的哈希算法应该尽量避免发生这种情况，即降低分散性。</li>
<li><strong>负载</strong>。本质上与分散性阐述的是同一问题。但它从节点出发，即某一特定的节点应该尽可能被相同的缓冲内容所映射到，换言之，避免（不同终端）将相同的内容映射到不同的节点。</li>
</ul>
<p>所谓一致性哈希，简而言之，即将节点与缓冲内容分别映射到一个巨大的环形空间中，最终内容的缓存节点为在顺时针方向上最靠近它的节点。可以发现，系统中节点的添加与删除，一致性哈希算法仍能基本满足以上四个特性。另外一个关键问题是，当集群中节点数量较少时，节点分布不均匀（即节点所负责的内容范围相差较大）会直接导致内容（数据）倾斜，因此一般会引入虚拟节点，即将节点映射为虚拟节点。如此，整个缓存映射过程便拆分为两个阶段：对于特定缓冲内容，先找到其映射的虚拟节点，然后再由虚拟节点映射到物理节点。</p>
<p>一致性哈希在分布式缓存中充当查询路由角色，因为不同节点负责特定的<code>key</code>集合。因此，如果此时当查询没能在本节点缓存中命中时，则需通过一致性哈希路由特定节点(<code>peer</code>)，然后借助<code>http</code>发送数据查询请求，请求的协议格式为: <code>GET http://peer/key</code>。因此，所有节点必须监听其它节点的数据查询请求，同时具备相应的请求处理模块。</p>
<h2 id="缓存命名空间"><a href="#缓存命名空间" class="headerlink" title="缓存命名空间"></a>缓存命名空间</h2><p>即便是在单个节点上，也可以创建若干个不同名称的缓存命名空间，以使得不同命名空间的缓存相互独立。如此，可以在原本针对<code>key</code>进行分片的基础上，丰富缓存功能。因此，节点间的数据查询请求协议格式变更为：<code>GET http://peer/groupname/key</code>。</p>
<h2 id="热点数据扩散"><a href="#热点数据扩散" class="headerlink" title="热点数据扩散"></a>热点数据扩散</h2><p>分布式缓存系统，不同的节点会负责特定的<code>key</code>集合的查询请求。但因为并非所有的<code>key</code>的访问量是均匀的，因此，存在这种情况：某些<code>key</code>属于热点数据而被大量访问，这可能导致包含该<code>key</code>的节点无法及时处理甚至瘫痪。考虑到这一点，<code>groupcache</code>增加了热点数据自动扩展的功能。即针对每一个节点，除了会缓存本节点存在且大量被访问的<code>key</code>之外（缓存这些<code>key</code>的对象被称之为<code>maincache</code>），也会缓存那些不属于本节点，但同样被大量访问（发生大量地<code>miss cache</code>）的<code>key</code>，而缓存这些<code>key</code>的对象被称这为<code>hotcache</code>，如此便能缓解热点数据的查询请求集中某一个节点的问题。</p>
<h2 id="缓存过滤机制"><a href="#缓存过滤机制" class="headerlink" title="缓存过滤机制"></a>缓存过滤机制</h2><p><code>groupcache</code>的<code>singleflight</code>模块实现了缓存过滤机制。即在大量相同的请求并发访问时，若缓存未能命中，则会触发大量的<code>Load</code>过程。即所有的查询请求全部会落到数据源（如<code>DB</code>）或从其它节点加载数据，因此考虑到节点可靠性，此时<code>DB</code>存在因压力过大而导致服务不可用的情况，同时也浪费资源。<code>groupcache</code>设计所提供的解决方案是：尽管存在并发的查询，但能保证只有一个请求能够真正的转发到<code>DB</code>执行查询，而其余的请求都会阻塞等待，直至第一个请求的查询结果返回，同时，其它请求会使用第一个请求的查询结果，最后再返回给客户端。<code>singleflight</code>通过<code>go</code>的<code>sync.WaitGroup</code>实现同一时间相同查询请求的合并。</p>
<p>最后，虽然官方声称<code>groupcache</code>在很多场景下已经成为<code>memcached</code>的替代版，但其本身存在固有的”局限性”。</p>
<ul>
<li><code>groupcache</code>采用的是<code>LRU</code>缓存机制，使用<code>List</code>和<code>Map</code>实现，不支持过期机制（不支持设置过期时间），也没有明确的回收机制（只是简单地将队尾的数据移除），但能够控制缓存总大小在用户设置的阈值之下。</li>
<li><code>groupcache</code>不支持<code>set</code>、<code>update</code>以及<code>delete</code>，即对于客户端而言，只能执行<code>get</code>操作。</li>
<li><code>groupcache</code>针对<code>key</code>不支持多个版本的值。</li>
</ul>
<p>总而言之，<code>groupcache</code>是一个值得学习的开源分布式缓存系统，通过阅读源码，一方面可以了解分布式缓存相关的设计原则，也能学习编程相关的设计经验。</p>
]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>分布式缓存</tag>
        <tag>LRU缓存</tag>
        <tag>一致性哈希</tag>
        <tag>缓存过滤机制</tag>
        <tag>缓存击穿</tag>
        <tag>热点数据扩散</tag>
      </tags>
  </entry>
  <entry>
    <title>Live Sequence Protocol 实现</title>
    <url>/2018/10/25/Live-Sequence-Protocol-%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<p>分布式环境中，网络不稳定导致消息（数据包）的传输存在乱序、重复和丢失的情况，同时，节点宕机也不可避免。如何优雅地处理这些问题，是构建一个健壮的分布式系统的关键。网络的复杂性使得数据包传输协议至关重要。低级别的IP协议提供不可靠的数据报服务，即消息可能延时、重复或丢失，另外，它也限制了在网络节点中传输的消息的最大字节数，因此很少直接利用IP协议来构建分布式应用。在传输层，UDP也不提供可靠的数据报服务，但它可以通过端口定向传输报文。而TCP则会保证消息传输的可靠性、有序性，并允许任意字节大小的消息传递，还提供额外的功能，如流量控制、拥塞控制。</p>
<a id="more"></a>

<p>我们的目的是实现一个基于UDP、具备TCP几个关键特性的消息传输协议 (<code>Live Sequence Protocol</code>），同时它还具备如下功能：</p>
<ul>
<li>不同于UDP或TCP，它支持 <code>client-server</code>通信模型 。</li>
<li><code>server</code>会维护若干个<code>client</code>的连接。</li>
<li><code>server</code>与<code>client</code>的通信是通过向对方发送消息来实现，消息大小限制与UDP相同。</li>
<li>消息传输是可靠的：消息一旦发送，就会被顺序接收，且每个消息只会被接收一次。</li>
<li><code>server</code>与<code>client</code>可以检测连接的状态。</li>
</ul>
<p>协议具体的工作原理、关键特性、运行流程及开放使用的接口可以参考<a href="https://github.com/qqzeng/15-440/blob/master/p1/p1.pdf" target="_blank" rel="noopener"><code>p1.pdf</code></a>。下面我会讨论协议实现过程中的几个关键点，以及个人在实现过程中遇到的棘手的问题。</p>
<h2 id="系统逻辑框架构建"><a href="#系统逻辑框架构建" class="headerlink" title="系统逻辑框架构建"></a>系统逻辑框架构建</h2><p>清晰且优雅地构建整个系统的逻辑框架至关重要，代码框架设计关系到后期功能模块调试与扩展，不合理的系统逻辑框架设计会使得后期的扩展寸步难行，也会导致代码的可调试性、可读性变差。因此，在编写出你的第一个可用的版本之前，尽可能合理地安排系统框架，这需要理解并梳理系统的主干及各分支（异常）运行流程，为了更简单、高效且合理地实现模块功能，必须尽可能熟悉(<code>go</code>)语言的特性(<code>channel</code>、<code>gorountine</code>及<code>interface</code>)。 </p>
<p>协议实现文档清晰地描述了协议的完整工作流程，按照此流程，其核心是<code>epoch event</code>触发后，协议的应对逻辑，可以实现出一个可运行的版本。合理安排程序框架关键在于处理好以下三个方面的问题：</p>
<ul>
<li>哪些功能逻辑应该被顺序执行，如何保证同步顺序执行。<br>比如，当创建<code>client</code>后，只有当其与<code>server</code>建立连接<code>connection</code>（抽象连接，并非消息传输所使用的连接）后才能返回，同时启动后台服务。注意<code>client</code>创建UDP连接到<code>server</code>可能会尝试多次，因为<code>server</code>可能存在慢启动问题，而且<code>Connect</code>消息也可能丢失。</li>
<li>系统需要哪些后台服务(<code>background goroutine</code>)， 后台服务如何可靠地同主线程协调交互。<br>比如，对于<code>client</code>而言，至少需要三个<code>goroutine</code>来处理消息。<ul>
<li><code>read goroutine</code>持续从连接中读取消息，直到连接关闭。</li>
<li><code>write goroutine</code>，因为写操作的调用是非阻塞的，但由于滑动窗口大小限制，并非所有消息都能立刻cache到滑动窗口并立即发送出去，因此，可以将用户<code>wirte</code>的消息放入到消息的<code>write channel</code>中，然后由专门的后台服务从<code>channel</code>中取消息，并在恰当的时候发送消息。</li>
<li><code>epoch event trigger goroutine</code>，即处理与<code>epoch</code>相关的逻辑，超时如何处理？接收到<code>Ack</code>消息或<code>Data</code>消息如何处理？达到<code>max epoch</code>时如何处理？</li>
</ul>
</li>
<li>确保开放接口的实现符合协议规范中预定义的准则要求。<br>比如，<code>server</code>的<code>Read</code>接口的调用会阻塞直到其从任一<code>client</code>收到消息，然后返回消息的<code>payload</code>及对应的<code>connection ID</code>。如果连接丢失，关闭或者<code>Server</code>主动关闭终止，都应该返回错误提示。这个方法不应该被简单地设计成从连接中持续读取数据，因为<code>Server</code>可能连接多个<code>client</code>，针对每一个<code>client</code> 连接的读取，必须启用单独的<code>goroutine</code>。所以，一种简单的设计是<code>server</code>并发地从各连接读取数据，若通过了校验（如保证用户调用<code>Read</code>所返回的数据正是用户所期望的），则将数据放入到<code>channel</code>，让<code>Read</code>持续从<code>channel</code>中取数据，注意数据一旦添加到<code>channel</code>中，则会以放入的顺序被<code>Read</code>取出，并返回给用户。</li>
</ul>
<h2 id="理解UDP通信本质"><a href="#理解UDP通信本质" class="headerlink" title="理解UDP通信本质"></a>理解UDP通信本质</h2><p>大家可能对<code>TCP</code>原理及编程更为熟悉，<code>UDP</code>相对简单，但因为<code>lsp(Live Sequence Protocol)</code>基于<code>UDP</code>，并在更高的协议抽象层面具备TCP的特性，所以，不要混淆了二者的通信原理。<code>UDP</code>是无连接的！它会完全按照程序员的意愿发送消息，它不考虑对方主机是否存在或正常工作，也不会主动重发消息，因此，也就无法保证消息的可靠接收与发送。</p>
<p>所以，<code>server</code>不需要也不能维护其与<code>client</code>的连接！但应当在<code>sever</code>端创建并维护与其通信的<code>client</code>关联的信息实体（需包含哪些数据？），那何时创建？答案是当<code>server</code>读取到数据时，因为此时可以获取读取所返回的<code>client</code>地址，<code>server</code>可以通过cache已经连接的信息来判断此次读取对应的连接是否是新的连接。若不是，则直接进入消息读取处理逻辑，否则需要先初始化<code>server</code>维护的<code>client</code>相关联的信息实体。</p>
<p>最后，注意<code>server</code>与<code>client</code>使用的是不同的<code>UDP</code>读写通信接口。（<code>client</code>直接持有与<code>server</code>通信的连接，而<code>server</code>是通过指定地址（<code>IP+port</code>）发送与接收消息）。</p>
<h2 id="如何实现滑动窗口"><a href="#如何实现滑动窗口" class="headerlink" title="如何实现滑动窗口"></a>如何实现滑动窗口</h2><p>滑动窗口<code>sliding window</code>是协议实现流量控制的关键，是整个协议的功能核心，并且其与TCP的滑动窗口机制类似。关于滑动窗口，在理解它的工作原理后，重点考虑以下三个方面：</p>
<ul>
<li>设计滑动窗口的数据结构。<ul>
<li>消息应该被有序添加到滑动窗口。</li>
<li>发送消息窗口需要标识每一条消息是否已经被ack。</li>
</ul>
</li>
<li>发送消息所关联的滑动窗口<code>latestSentDataMsg</code>。<br>以<code>client</code>作为示例，维持其发送消息的窗口，以便对未按时返回<code>Ack</code>的消息进行重发（已发送的<code>data</code>消息可能会丢失，或者接收主机响应的<code>Ack</code>消息丢失）。<ul>
<li>因为窗口内的消息所返回的<code>Ack</code>是无序的（消息异步发送，网络传输也不能保证消息按序到达），所以，需要维护一个指针，表示当前返回的<code>Ack</code>消息的最小的序号<code>receivedAckSeqNum</code>，以作为窗口向前推进的依据。</li>
<li>当<code>client</code>发送<code>data</code>消息时，需同时将其cache到<code>latestSentDataMsg</code>。而当其接收到<code>Ack</code>消息时，需要执行更新此指针<code>receivedAckSeqNum</code>的逻辑。<br>而<code>server</code>则需要对其所维护的每一个连接构建对应的发送消息窗口，但处理逻辑类似。</li>
</ul>
</li>
<li>接收消息所关联的滑动窗口<code>latestReceivedDataMsg</code>。<br>同样以<code>client</code>作为示例，维持其接收消息的窗口，以便在计时器超时后，对最近收到的若干个<code>data</code>消息，重发<code>Ack</code>消息。<ul>
<li>同样，接收消息窗口也是无序的，因此，为了保证返回给用户的消息有序，需要维护一个指针，表示下一个期望接收到的<code>data</code>消息序号<code>nextReceiveDataSeqNum</code>（或者是当前已经接收到的最大的<code>data</code>消息的消息序号），它是依次递增的。对于接收到的任何<code>data</code>消息，若其<code>SeqNum</code>在此指针之后，都应该直接添加（暂时缓存）到<code>latestReceivedDataMsg</code>中，而不应该作为<code>Read</code>调用的返回结果。</li>
<li>当<code>client</code>收到<code>server</code>的<code>data</code>消息时，也需要将其cache到<code>latestReceivedDataMsg</code>，并判断是否需要更新<code>nextReceiveDataSeqNum</code>，若需要更新，则应当将更新过程中所涉及到的cache在接收消息窗口中的<code>data</code>消息按序添加到供<code>Read</code>接口所读取的<code>channel</code>。<br><code>server</code>同样是一个连接对应一个接收消息窗口。</li>
</ul>
</li>
</ul>
<h2 id="如何实现流量控制"><a href="#如何实现流量控制" class="headerlink" title="如何实现流量控制"></a>如何实现流量控制</h2><p>流量控制表示若当前主机有过多的消息未被ack（网络拥塞），因此发送主机需要对用户调用<code>Write</code>接口的<code>data</code>消息进行阻塞以延缓发送。其实现关键是滑动窗口机制。具体实现原理为：</p>
<ol>
<li>当用户调用<code>Write</code>接口以发送消息时，将消息添加到消息发送队列<code>channel</code>，然后返回，不能阻塞。</li>
<li>后台服务<code>write goroutine</code>从消息发送队列中不断的取消息，但在消息正式发送前，需要检测消息发送滑动窗口是否空闲<code>idle</code>，并且包含多少空闲的<code>slot</code>。</li>
<li>空闲的<code>slot</code>数目可以根据以下表达式计算：<br><code>idleSlotNum := cli.params.WindowSize-(lastMsg.SeqNum-cli.receivedAckSeqNum)</code>，其中，<code>lastMsg</code>为消息发送窗口中最后一个消息，即<code>SeqNum</code>最大的消息。</li>
<li>如果<code>idleSlotNum</code>大于0，则可以发送对应数目的消息，并将已经发送的消息记录到消息发送窗口，同时递增<code>nextSendDataSeqNum</code>指针。否则，<code>write goroutine</code>应该被阻塞住。那如何解除阻塞？每当<code>client</code>在接收到<code>Ack</code>消息时都要去尝试解除阻塞。</li>
</ol>
<p>如图所示，当滑动窗口处于(a)的情况下，当用户调用<code>Write</code>以发送消息时，消息会被阻塞在<code>write channel</code>中，因为此时<code>receivedAckSeqNum</code>为9，消息发送窗口的<code>idle</code>的<code>slot</code>数目为：5-(14-9)=0。而当<code>client</code>接收若干<code>Ack</code>消息后，滑动窗口转移到(b)状态时，注意到<code>receivedAckSeqNum</code>从9逐一递增到11，消息发送窗口<code>idleSlotNum</code>为：5-(14-11)=2，因此窗口前移，并可以从<code>write channel</code>中顺序取出两个消息，进行发送。</p>
<p><img src="https://raw.githubusercontent.com/qqzeng/15-440/master/p1/traffic%20control.png" alt="traffic control"></p>
<h2 id="如何检测消息重复"><a href="#如何检测消息重复" class="headerlink" title="如何检测消息重复"></a>如何检测消息重复</h2><p>消息重复主要包括<code>data</code>和<code>Ack</code>消息的重复接收。以<code>client</code>作为示例。</p>
<ul>
<li><code>data</code>消息的重复接收。<ul>
<li>当<code>client</code>读取到<code>data</code>消息后，需要判断消息是否已经接收过。若消息重复，则直接返回<code>Ack</code>消息，否则应该先将消息cache到<code>latestReceivedDataMsg</code>。</li>
<li>可以通过消息的<code>SeqNum</code>来去重。这涉及两种情况：其一，消息已经被<code>Ack</code>，并且已经从<code>latestReceivedDataMsg</code>中移除，我们称之为消息被丢弃(<code>discarded</code>)。其二，消息被<code>Ack</code>，但仍然cache在<code>latestReceivedDataMsg</code>中。</li>
</ul>
</li>
<li><code>Ack</code>消息的重复接收。<code>Ack</code>消息的去重逻辑同<code>data</code>消息类似。</li>
</ul>
<h2 id="如何保证消息顺序"><a href="#如何保证消息顺序" class="headerlink" title="如何保证消息顺序"></a>如何保证消息顺序</h2><p>发送主机异步发送消息，且消息在网络中传输也有不同程度的延迟，因此接收主机接收的消息序列的顺序很可能与发送主机发送的消息顺序不同。如何保证消息顺序？准确而言，如何以发送主机发送消息的顺序来返回给用户。</p>
<p>针对具备滑动窗口机制的消息传输，可以保证滑动窗口前所接收的消息，即已经被<code>discarded</code>的消息肯定是有序返回给用户的。而滑动窗口内的消息，因为无法规避从网络中读取乱序消息的问题，但在读取到消息后可以控制以何种顺序将消息返回给用户。简单而言，将收到的<code>data</code>消息先cache在<code>latestReceivedDataMsg</code>中，然后通过指针<code>nextReceiveDataSeqNum</code>来判断是否应该将窗口中cache的消息返回给用户。</p>
<h2 id="如何优雅地关闭连接"><a href="#如何优雅地关闭连接" class="headerlink" title="如何优雅地关闭连接"></a>如何优雅地关闭连接</h2><p>保证连接优雅地关闭是一个非常棘手的问题。其中，相比于<code>client</code>端的连接关闭，<code>server</code>的关闭又更为复杂。协议规范清晰地描述了<code>client</code>及<code>server</code>在关闭连接时需要注意的问题。其核心是：</p>
<ul>
<li>当存在<code>pending</code>消息时，需要将其处理完成（即需保证接收到<code>Ack</code>消息）。</li>
<li>同时，一旦<code>data</code>消息被加入到<code>write channel</code>，它必须保证最后能够被发送出去。<br><code>client</code>的关闭相对简单，具体处理逻辑为：当用户调用<code>Close</code>接口时，需要判断是否存在<code>pending</code>消息，如何检测？两个条件：</li>
<li>保证消息发送窗口的最后一个消息的<code>SeqNum</code>恰好为其持有的<code>receivedAckSeqNum</code>的值。</li>
<li>保证<code>write channel</code>中没有任何未被处理的消息。<br>因此如果此时存在<code>pending</code>消息，<code>Close</code>会被阻塞。那如何解除阻塞？每当<code>client</code>在接收到<code>Ack</code>消息时都要去尝试解除阻塞。此外，值得注意的是，在阻塞的过程中，如果触发了<code>max epoch event</code>，则<code>client</code>应该立刻返回，因为这表明连接已经<code>discarded</code>，此时要么所有<code>pending</code>消息已被处理，要么<code>server</code>主动关闭了连接。<br><code>server</code>的<code>CloseConn</code>接口可以看作是<code>client</code>的<code>Close</code>接口的非阻塞版本。而<code>Close</code>接口需要协调所有的<code>connection</code>的关闭。同样，<code>server</code>的某个连接也可能到达<code>max epoch</code>，此时其对应的连接应该被关闭。当所有连接都关闭时，<code>Close</code>才能返回。<br>在连接关闭时，需要及时退出对应的<code>background goroutine</code>。</li>
</ul>
<h2 id="需注意的细节问题"><a href="#需注意的细节问题" class="headerlink" title="需注意的细节问题"></a>需注意的细节问题</h2><p>往往一些编程方面的细节，包括逻辑漏洞或者被忽视的语法问题会造成很长时间的调试。而且，当通信过程中，数据交换复杂变得越发复杂时，很难从庞大的日志文件中找出错误的根源。个人在实现的过程中，遇到两个问题：</p>
<ul>
<li><code>dead lock</code>。死锁很容易产生，一般有两个原因，其一，资源的相互持有，造成两个线程都无法向前推进。其二，没有正确嵌套使用锁，你需要清楚锁是否可重入。</li>
<li><code>buffered channel</code>。其导致的问题比较隐蔽，你首先要明确是使用带缓冲的<code>channel</code>或者不带缓冲的<code>channel</code>，如果是<code>buffered channel</code>，你需要确定它的大小，如果你不确定缓冲区数量是否足够，建议设置的稍大一些，但这个前提是，必须在合适的时机清空<code>buffered channel</code>，避免在复用<code>buffered channel</code>之后导致逻辑受到影响。</li>
</ul>
<p>最后，需要提醒的是，分布式程序异步、并发，且网络复杂的特性导致其很难debug。所以，尽可能设计完善的日志流程，以帮助跟踪未符合期望的执行逻辑，并定位问题。</p>
<p>另外，cmu提供较为完善的测试程序，如果程序出现问题，可以对某一个或几个子测试用例进行单独测试，熟悉测试用例代码，了解测试用例流程是有必要的。</p>
<p><a href="https://github.com/qqzeng/15-440/tree/master/p1/src/github.com/cmu440/lsp" target="_blank" rel="noopener">参考代码在这里</a></p>
]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>网络编程</tag>
        <tag>传输协议</tag>
        <tag>可靠服务</tag>
        <tag>流量控制</tag>
      </tags>
  </entry>
  <entry>
    <title>TCP之3次握手和4次挥手</title>
    <url>/2018/10/15/2018-10-15-TCP%E4%B9%8B3%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%92%8C4%E6%AC%A1%E6%8C%A5%E6%89%8B/</url>
    <content><![CDATA[<h2 id="什么是TCP协议"><a href="#什么是TCP协议" class="headerlink" title="什么是TCP协议"></a>什么是TCP协议</h2><p>TCP协议是一种面向连接的、可靠的、全双工模式、基于字节流的运输层通信协议。  </p>
<a id="more"></a>

<h2 id="TCP首部6个标志位"><a href="#TCP首部6个标志位" class="headerlink" title="TCP首部6个标志位"></a>TCP首部6个标志位</h2><ul>
<li>URG：此标志表示TCP包的紧急指针域（后面马上就要说到）有效，用来保证TCP连接不被中断，并且督促中间层设备要尽快处理这些数据；</li>
<li>ACK：此标志表示应答域有效，就是说前面所说的TCP应答号将会包含在TCP数据包中；有两个取值：0和1，为1的时候表示应答域有效，反之为0；</li>
<li>PSH：这个标志位表示Push操作。所谓Push操作就是指在数据包到达接收端以后，立即传送给应用程序，而不是在缓冲区中排队；</li>
<li>RST：这个标志表示连接复位请求。用来复位那些产生错误的连接，也被用来拒绝错误和非法的数据包；</li>
<li>SYN：表示同步序号，用来建立连接。SYN标志位和ACK标志位搭配使用，当连接请求的时候，SYN=1，ACK=0；连接被响应的时候，SYN=1，ACK=1；这个标志的数据包经常被用来进行端口扫描。扫描者发送一个只有SYN的数据包，如果对方主机响应了一个数据包回来 ，就表明这台主机存在这个端口；但是由于这种扫描方式只是进行TCP三次握手的第一次握手，因此这种扫描的成功表示被扫描的机器不很安全，一台安全的主机将会强制要求一个连接严格的进行TCP的三次握手；</li>
<li>FIN： 表示发送端已经达到数据末尾，也就是说双方的数据传送完成，没有数据可以传送了，发送FIN标志位的TCP数据包后，连接将被断开。这个标志的数据包也经常被用于进行端口扫描。</li>
</ul>
<h2 id="状态说明"><a href="#状态说明" class="headerlink" title="状态说明"></a>状态说明</h2><ul>
<li>LISTEN: 表示监听状态。</li>
<li>FIN_WAIT_1: 这个状态要好好解释一下，其实FIN_WAIT_1和FIN_WAIT_2状态的真正含义都是表示等待对方的FIN报文。而这两种状态的区别是：FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，它想主动关闭连接，向对方发送了FIN报文，此时该SOCKET即进入到FIN_WAIT_1状态。而当对方回应ACK报文后，则进入到FIN_WAIT_2状态，当然在实际的正常情况下，无论对方何种情况下，都应该马上回应ACK报文，所以FIN_WAIT_1状态一般是比较难见到的，而FIN_WAIT_2状态还有时常常可以用netstat看到。（主动方）</li>
<li>FIN_WAIT_2：上面已经详细解释了这种状态，实际上FIN_WAIT_2状态下的SOCKET，表示半连接，也即有一方要求close连接，但另外还告诉对方，我暂时还有点数据需要传送给你(ACK信息)，稍后再关闭连接。（主动方）</li>
<li>CLOSE_WAIT：这种状态的含义其实是表示在等待关闭。怎么理解呢？当对方close一个SOCKET后发送FIN报文给自己，你系统毫无疑问地会回应一个ACK报文给对方，此时则进入到CLOSE_WAIT状态。接下来呢，实际上你真正需要考虑的事情是察看你是否还有数据发送给对方，如果没有的话，那么你也就可以 close这个SOCKET，发送FIN报文给对方，也即关闭连接。所以你在CLOSE_WAIT状态下，需要完成的事情是等待你去关闭连接。（被动方）</li>
<li>LAST_ACK: 这个状态还是比较容易好理解的，它是被动关闭一方在发送FIN报文后，最后等待对方的ACK报文。当收到ACK报文后，也即可以进入到CLOSED可用状态了。（被动方）</li>
<li>TIME_WAIT: 表示收到了对方的FIN报文，并发送出了ACK报文，就等2MSL后即可回到CLOSED可用状态了。如果FINWAIT1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无须经过FIN_WAIT_2状态。（主动方）</li>
<li>CLOSED: 表示连接中断。</li>
</ul>
<h2 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h2><ol>
<li>第一次握手：建立连接。客户端发送连接请求报文段，将SYN位置为1，Sequence Number为x；然后，客户端进入SYN_SEND状态，等待服务器的确认；</li>
<li>第二次握手：服务器收到SYN报文段。服务器收到客户端的SYN报文段，需要对这个SYN报文段进行确认，设置Acknowledgment Number为x+1(Sequence Number+1)；同时，自己自己还要发送SYN请求信息，将SYN位置为1，Sequence Number为y；服务器端将上述所有信息放到一个报文段（即SYN+ACK报文段）中，一并发送给客户端，此时服务器进入SYN_RECV状态；</li>
<li>第三次握手：客户端收到服务器的SYN+ACK报文段。然后将Acknowledgment Number设置为y+1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。</li>
<li>完成了三次握手，客户端和服务器端就可以开始传送数据。以上就是TCP三次握手的总体介绍。</li>
</ol>
<h2 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h2><ol>
<li>第一次分手：主机1（可以使客户端，也可以是服务器端），设置Sequence Number和Acknowledgment Number，向主机2发送一个FIN报文段；此时，主机1进入FIN_WAIT_1状态；这表示主机1没有数据要发送给主机2了；</li>
<li>第二次分手：主机2收到了主机1发送的FIN报文段，向主机1回一个ACK报文段，Acknowledgment Number为Sequence Number加1；主机1进入FIN_WAIT_2状态；主机2告诉主机1，我“同意”你的关闭请求；</li>
<li>第三次分手：主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入LAST_ACK状态；</li>
<li>第四次分手：主机1收到主机2发送的FIN报文段，向主机2发送ACK报文段，然后主机1进入TIME_WAIT状态；主机2收到主机1的ACK报文段以后，就关闭连接；此时，主机1等待2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，主机1也可以关闭连接了。</li>
</ol>
<h2 id="为什么三次握手"><a href="#为什么三次握手" class="headerlink" title="为什么三次握手"></a>为什么三次握手</h2><p>因为网络中存在延迟，阻塞，滞留消息的问题，会导致已经失效的报文依然发送到服务端，从而导致服务端出现错误并且浪费了计算资源的问题。因此运用三次握手的办法来解决这个问题。  </p>
<h2 id="为什么四次挥手"><a href="#为什么四次挥手" class="headerlink" title="为什么四次挥手"></a>为什么四次挥手</h2><p>客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。  </p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://github.com/jawil/blog/issues/14" target="_blank" rel="noopener">通俗大白话来理解TCP协议的三次握手和四次分手</a><br><a href="https://github.com/CyC2018/CS-Notes/blob/master/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.md#tcp-%E7%9A%84%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B" target="_blank" rel="noopener">计算机网络</a><br><a href="https://www.jianshu.com/p/9968b16b607e" target="_blank" rel="noopener">图解TCP协议中的三次握手和四次挥手</a>  </p>
]]></content>
      <categories>
        <category>后端开发</category>
      </categories>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title>Git学习笔记</title>
    <url>/2018/10/11/2018-10-11-Git%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="Git原理图"><a href="#Git原理图" class="headerlink" title="Git原理图"></a>Git原理图</h1><ul>
<li>Workspace：工作区</li>
<li>Index / Stage：暂存区</li>
<li>Repository：仓库区（或本地仓库）</li>
<li>Remote：远程仓库</li>
</ul>
<a id="more"></a>

<h1 id="什么是Git？"><a href="#什么是Git？" class="headerlink" title="什么是Git？"></a>什么是Git？</h1><p>Git是分布式版本控制系统  </p>
<h1 id="为什么需要Git？"><a href="#为什么需要Git？" class="headerlink" title="为什么需要Git？"></a>为什么需要Git？</h1><p>为了更好的管理项目源码，团队之间协同开发。  </p>
<h1 id="Git采用的校验机制？"><a href="#Git采用的校验机制？" class="headerlink" title="Git采用的校验机制？"></a>Git采用的校验机制？</h1><p>SHA-1散列由40个十六进制字符（0-9和a-f）所组成的字符串，这些字符串是根据文件内容和Git的目录结构计算所得  </p>
<h1 id="Git的使用"><a href="#Git的使用" class="headerlink" title="Git的使用"></a>Git的使用</h1><h2 id="配置个人信息"><a href="#配置个人信息" class="headerlink" title="配置个人信息"></a>配置个人信息</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git config --global user.name "your user name"</span><br><span class="line">git config --global user.email "your email"</span><br></pre></td></tr></table></figure>

<h2 id="查看个人信息"><a href="#查看个人信息" class="headerlink" title="查看个人信息"></a>查看个人信息</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git config --list</span><br></pre></td></tr></table></figure>

<h2 id="本地仓库初始化"><a href="#本地仓库初始化" class="headerlink" title="本地仓库初始化"></a>本地仓库初始化</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git init</span><br></pre></td></tr></table></figure>

<h2 id="克隆远程仓库"><a href="#克隆远程仓库" class="headerlink" title="克隆远程仓库"></a>克隆远程仓库</h2><h3 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/HuangDayu/Almanac.git</span><br></pre></td></tr></table></figure>

<h3 id="SSH"><a href="#SSH" class="headerlink" title="SSH"></a>SSH</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone git@github.com:HuangDayu/Almanac.git</span><br></pre></td></tr></table></figure>

<h2 id="查看文件状态"><a href="#查看文件状态" class="headerlink" title="查看文件状态"></a>查看文件状态</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git status</span><br></pre></td></tr></table></figure>

<ul>
<li>Changes to be committed：已暂存、可提交文件</li>
<li>Untracked files：未暂存文件</li>
</ul>
<h2 id="查看未缓存的文件的变更细节"><a href="#查看未缓存的文件的变更细节" class="headerlink" title="查看未缓存的文件的变更细节"></a>查看未缓存的文件的变更细节</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git diff</span><br></pre></td></tr></table></figure>

<h2 id="查看已缓存的文件的变更细节"><a href="#查看已缓存的文件的变更细节" class="headerlink" title="查看已缓存的文件的变更细节"></a>查看已缓存的文件的变更细节</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git diff --staged</span><br></pre></td></tr></table></figure>

<h2 id="添加文件的缓存区"><a href="#添加文件的缓存区" class="headerlink" title="添加文件的缓存区"></a>添加文件的缓存区</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 指定文件</span></span><br><span class="line">git add readme.md</span><br><span class="line"><span class="meta">#</span><span class="bash"> 所有文件</span></span><br><span class="line">git add .</span><br></pre></td></tr></table></figure>

<h2 id="提交缓存区的文件到本地仓库"><a href="#提交缓存区的文件到本地仓库" class="headerlink" title="提交缓存区的文件到本地仓库"></a>提交缓存区的文件到本地仓库</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git commit -m "update"</span><br></pre></td></tr></table></figure>

<h2 id="提交非缓存区的文件提交到本地"><a href="#提交非缓存区的文件提交到本地" class="headerlink" title="提交非缓存区的文件提交到本地"></a>提交非缓存区的文件提交到本地</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git commit -a -m "update"</span><br></pre></td></tr></table></figure>

<h2 id="查看本地仓库提交历史"><a href="#查看本地仓库提交历史" class="headerlink" title="查看本地仓库提交历史"></a>查看本地仓库提交历史</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git log</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git log --pretty=oneline</span><br></pre></td></tr></table></figure>

<h2 id="查看每次版本提交记录"><a href="#查看每次版本提交记录" class="headerlink" title="查看每次版本提交记录"></a>查看每次版本提交记录</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git reflog</span><br></pre></td></tr></table></figure>

<h2 id="回退到指定版本"><a href="#回退到指定版本" class="headerlink" title="回退到指定版本"></a>回退到指定版本</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git reset --hard 1dabc4e</span><br></pre></td></tr></table></figure>

<ul>
<li>1dabc4e 是commit id</li>
</ul>
<h2 id="查看文件修改历史"><a href="#查看文件修改历史" class="headerlink" title="查看文件修改历史"></a>查看文件修改历史</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git diff HEAD -- readme.md</span><br></pre></td></tr></table></figure>

<h2 id="撤销文件修改"><a href="#撤销文件修改" class="headerlink" title="撤销文件修改"></a>撤销文件修改</h2><ul>
<li>修改操作：增删改查</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git checkout -- readme.md</span><br></pre></td></tr></table></figure>

<h2 id="关联远程仓库"><a href="#关联远程仓库" class="headerlink" title="关联远程仓库"></a>关联远程仓库</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git remote add origin git@github.com:HuangDayu/Almanac.git</span><br></pre></td></tr></table></figure>

<h2 id="推送到远程仓库"><a href="#推送到远程仓库" class="headerlink" title="推送到远程仓库"></a>推送到远程仓库</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git push -u origin master</span><br></pre></td></tr></table></figure>

<h2 id="从远程仓库拉取数据到本地仓库"><a href="#从远程仓库拉取数据到本地仓库" class="headerlink" title="从远程仓库拉取数据到本地仓库"></a>从远程仓库拉取数据到本地仓库</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git fetch origin</span><br></pre></td></tr></table></figure>
<h2 id="合并远程仓库和本地仓库"><a href="#合并远程仓库和本地仓库" class="headerlink" title="合并远程仓库和本地仓库"></a>合并远程仓库和本地仓库</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git merge origin</span><br></pre></td></tr></table></figure>

<h2 id="从远程仓库拉取数据并直接合并到本地"><a href="#从远程仓库拉取数据并直接合并到本地" class="headerlink" title="从远程仓库拉取数据并直接合并到本地"></a>从远程仓库拉取数据并直接合并到本地</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git pull origin master</span><br></pre></td></tr></table></figure>

<h2 id="缓存本地更改"><a href="#缓存本地更改" class="headerlink" title="缓存本地更改"></a>缓存本地更改</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git stash</span><br></pre></td></tr></table></figure>

<h2 id="拉取远程仓库最近代码"><a href="#拉取远程仓库最近代码" class="headerlink" title="拉取远程仓库最近代码"></a>拉取远程仓库最近代码</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git pull --rebase</span><br></pre></td></tr></table></figure>

<h2 id="本地缓存更改和拉取的最近代码合并"><a href="#本地缓存更改和拉取的最近代码合并" class="headerlink" title="本地缓存更改和拉取的最近代码合并"></a>本地缓存更改和拉取的最近代码合并</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git stash pop</span><br></pre></td></tr></table></figure>

<h2 id="查看当前分支"><a href="#查看当前分支" class="headerlink" title="查看当前分支"></a>查看当前分支</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git branch</span><br></pre></td></tr></table></figure>

<h2 id="创建分支"><a href="#创建分支" class="headerlink" title="创建分支"></a>创建分支</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git branch master1</span><br></pre></td></tr></table></figure>

<h2 id="切换分支"><a href="#切换分支" class="headerlink" title="切换分支"></a>切换分支</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git checkout master1</span><br></pre></td></tr></table></figure>

<h2 id="创建并切换分支"><a href="#创建并切换分支" class="headerlink" title="创建并切换分支"></a>创建并切换分支</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git checkout -b master1</span><br></pre></td></tr></table></figure>

<h2 id="查看分支合并图"><a href="#查看分支合并图" class="headerlink" title="查看分支合并图"></a>查看分支合并图</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git log --graph --pretty=oneline --abbrev-commit</span><br></pre></td></tr></table></figure>


<h2 id="合并分支"><a href="#合并分支" class="headerlink" title="合并分支"></a>合并分支</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git merge master1</span><br></pre></td></tr></table></figure>

<h2 id="删除分支"><a href="#删除分支" class="headerlink" title="删除分支"></a>删除分支</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git branch -d master1</span><br></pre></td></tr></table></figure>

<h2 id="生成公钥"><a href="#生成公钥" class="headerlink" title="生成公钥"></a>生成公钥</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -C "your email" -f ~/.ssh/github</span><br></pre></td></tr></table></figure>

<h2 id="修改用户配置文件"><a href="#修改用户配置文件" class="headerlink" title="修改用户配置文件"></a>修改用户配置文件</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim ~/.ssh/config</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Host github.com</span><br><span class="line">HostName github.com</span><br><span class="line">User git</span><br><span class="line">IdentityFile ~/.ssh/github</span><br></pre></td></tr></table></figure>

<h2 id="测试配置文件"><a href="#测试配置文件" class="headerlink" title="测试配置文件"></a>测试配置文件</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure>

<h2 id="添加ssh-key代理"><a href="#添加ssh-key代理" class="headerlink" title="添加ssh-key代理"></a>添加ssh-key代理</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh-add ~/.ssh/github</span><br></pre></td></tr></table></figure>

<h2 id="查看ssh-key代理"><a href="#查看ssh-key代理" class="headerlink" title="查看ssh-key代理"></a>查看ssh-key代理</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh-add -l</span><br></pre></td></tr></table></figure>

<h2 id="删除ssh-key代理"><a href="#删除ssh-key代理" class="headerlink" title="删除ssh-key代理"></a>删除ssh-key代理</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh-add -D</span><br></pre></td></tr></table></figure>


<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://git-scm.com/book/zh/v2" target="_blank" rel="noopener">Git 官方文档</a><br><a href="http://www.ruanyifeng.com/blog/2015/12/git-cheat-sheet.html" target="_blank" rel="noopener">阮一峰：常用 Git 命令清单</a><br><a href="http://www.ruanyifeng.com/blog/2018/10/git-internals.html" target="_blank" rel="noopener">阮一峰：Git 原理入门</a><br><a href="https://www.jianshu.com/p/6c32ee2688b0" target="_blank" rel="noopener">看完不会Git命令行我跪搓板</a><br><a href="https://www.cnblogs.com/ayseeing/p/4445194.html" target="_blank" rel="noopener">生成多个git ssh密钥</a><br><a href="https://gitee.com/all-about-git" target="_blank" rel="noopener">Git大全</a>  </p>
]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>Http之状态码</title>
    <url>/2018/05/19/2018-05-19-Http%E4%B9%8B%E7%8A%B6%E6%80%81%E7%A0%81/</url>
    <content><![CDATA[<p>服务器返回的  <strong>响应报文</strong>  中第一行为状态行，包含了状态码以及原因短语，用来告知客户端请求的结果。  </p>
<table>
<thead>
<tr>
<th align="center">状态码</th>
<th align="center">类别</th>
<th align="center">原因短语</th>
</tr>
</thead>
<tbody><tr>
<td align="center">1XX</td>
<td align="center">Informational（信息性状态码）</td>
<td align="center">接收的请求正在处理</td>
</tr>
<tr>
<td align="center">2XX</td>
<td align="center">Success（成功状态码）</td>
<td align="center">请求正常处理完毕</td>
</tr>
<tr>
<td align="center">3XX</td>
<td align="center">Redirection（重定向状态码）</td>
<td align="center">需要进行附加操作以完成请求</td>
</tr>
<tr>
<td align="center">4XX</td>
<td align="center">Client Error（客户端错误状态码）</td>
<td align="center">服务器无法处理请求</td>
</tr>
<tr>
<td align="center">5XX</td>
<td align="center">Server Error（服务器错误状态码）</td>
<td align="center">服务器处理请求出错</td>
</tr>
</tbody></table>
<a id="more"></a>

<table>
<thead>
<tr>
<th>名称</th>
<th>状态码</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>Accepted</td>
<td>202</td>
<td>Accepted 指示请求已被接受进行进一步处理。</td>
</tr>
<tr>
<td>Ambiguous</td>
<td>300</td>
<td>Ambiguous 指示所需的信息有多种表示形式。 默认操作是将此状态视为一个重定向，并按照与此响应关联的位置标头的内容。</td>
</tr>
<tr>
<td>BadGateway</td>
<td>502</td>
<td>BadGateway 指示中间代理服务器从另一个代理或原始服务器接收到错误响应。</td>
</tr>
<tr>
<td>BadRequest</td>
<td>400</td>
<td>BadRequest 指示无法由服务器理解此请求。 BadRequest 如果没有其他错误适用，或者如果具体的错误是未知的或不具有其自己的错误代码发送。</td>
</tr>
<tr>
<td>Conflict</td>
<td>409</td>
<td>Conflict 指示该请求可能不会执行由于在服务器上发生冲突。</td>
</tr>
<tr>
<td>Continue</td>
<td>100</td>
<td>Continue 指示客户端可以继续其请求。</td>
</tr>
<tr>
<td>Created</td>
<td>201</td>
<td>Created 指示请求导致已发送响应之前创建一个新的资源。</td>
</tr>
<tr>
<td>ExpectationFailed</td>
<td>417</td>
<td>ExpectationFailed 指示无法由服务器满足 Expect 标头中给定。</td>
</tr>
<tr>
<td>Forbidden</td>
<td>403</td>
<td>Forbidden 指示服务器拒绝无法完成请求。</td>
</tr>
<tr>
<td>Found</td>
<td>302</td>
<td>Found 指示所需的信息位于的位置标头中指定的 URI。 当收到此状态时的默认操作是遵循与响应关联的位置标头。 当原始请求方法是 POST 时，重定向的请求将使用 GET 方法。</td>
</tr>
<tr>
<td>GatewayTimeout</td>
<td>504</td>
<td>GatewayTimeout 指示中间代理服务器在等待来自另一个代理或原始服务器的响应时已超时。</td>
</tr>
<tr>
<td>Gone</td>
<td>410</td>
<td>Gone 指示所请求的资源不再可用。</td>
</tr>
<tr>
<td>HttpVersionNotSupported</td>
<td>505</td>
<td>HttpVersionNotSupported 指示服务器不支持请求的 HTTP 版本。</td>
</tr>
<tr>
<td>InternalServerError</td>
<td>500</td>
<td>InternalServerError 表示在服务器上发生一般性错误。</td>
</tr>
<tr>
<td>LengthRequired</td>
<td>411</td>
<td>LengthRequired 指示缺少必需的内容长度标头。</td>
</tr>
<tr>
<td>MethodNotAllowed</td>
<td>405</td>
<td>MethodNotAllowed 指示请求方法 （POST 或 GET） 不允许对所请求的资源。</td>
</tr>
<tr>
<td>Moved</td>
<td>301</td>
<td>Moved 指示已将所需的信息移动到的位置标头中指定的 URI。 当收到此状态时的默认操作是遵循与响应关联的位置标头。 当原始请求方法是 POST 时，重定向的请求将使用 GET 方法。</td>
</tr>
<tr>
<td>MovedPermanently</td>
<td>301</td>
<td>MovedPermanently 指示已将所需的信息移动到的位置标头中指定的 URI。 当收到此状态时的默认操作是遵循与响应关联的位置标头。</td>
</tr>
<tr>
<td>MultipleChoices</td>
<td>300</td>
<td>MultipleChoices 指示所需的信息有多种表示形式。 默认操作是将此状态视为一个重定向，并按照与此响应关联的位置标头的内容。</td>
</tr>
<tr>
<td>NoContent</td>
<td>204</td>
<td>NoContent 指示已成功处理请求和响应是有意留为空白。</td>
</tr>
<tr>
<td>NonAuthoritativeInformation</td>
<td>203</td>
<td>NonAuthoritativeInformation 指示返回的元信息来自而不是原始服务器的缓存副本，因此可能不正确。</td>
</tr>
<tr>
<td>NotAcceptable</td>
<td>406</td>
<td>NotAcceptable 表示客户端已指定使用 Accept 标头，它将不接受任何可用的资源表示。</td>
</tr>
<tr>
<td>NotFound</td>
<td>404</td>
<td>NotFound 指示所请求的资源不存在的服务器上。</td>
</tr>
<tr>
<td>NotImplemented</td>
<td>501</td>
<td>NotImplemented 指示服务器不支持所请求的功能。</td>
</tr>
<tr>
<td>NotModified</td>
<td>304</td>
<td>NotModified 指示客户端的缓存的副本是最新。 不会传输资源的内容。</td>
</tr>
<tr>
<td>OK</td>
<td>200</td>
<td>OK 指示请求成功，且请求的信息包含在响应中。 这是要接收的最常见状态代码。</td>
</tr>
<tr>
<td>PartialContent</td>
<td>206</td>
<td>PartialContent 指示根据包括字节范围的 GET 请求的请求的响应是部分响应。</td>
</tr>
<tr>
<td>PaymentRequired</td>
<td>402</td>
<td>PaymentRequired 已保留供将来使用。</td>
</tr>
<tr>
<td>PreconditionFailed</td>
<td>412</td>
<td>PreconditionFailed 表示失败，此请求的设置的条件，无法执行请求。 使用条件请求标头，如果匹配项，如设置条件无-If-match，或如果-修改-自从。</td>
</tr>
<tr>
<td>ProxyAuthenticationRequired</td>
<td>407</td>
<td>ProxyAuthenticationRequired 指示请求的代理要求身份验证。 代理服务器进行身份验证标头包含如何执行身份验证的详细信息。</td>
</tr>
<tr>
<td>Redirect</td>
<td>302</td>
<td>Redirect 指示所需的信息位于的位置标头中指定的 URI。 当收到此状态时的默认操作是遵循与响应关联的位置标头。 当原始请求方法是 POST 时，重定向的请求将使用 GET 方法。</td>
</tr>
<tr>
<td>RedirectKeepVerb</td>
<td>307</td>
<td>RedirectKeepVerb 指示请求信息位于的位置标头中指定的 URI。 当收到此状态时的默认操作是遵循与响应关联的位置标头。 当原始请求方法是 POST 时，重定向的请求还将使用 POST 方法。</td>
</tr>
<tr>
<td>RedirectMethod</td>
<td>303</td>
<td>RedirectMethod 自动将客户端重定向到的位置标头中指定作为公告的结果的 URI。 对指定的位置标头的资源的请求将会执行与 GET。</td>
</tr>
<tr>
<td>RequestedRangeNotSatisfiable</td>
<td>416</td>
<td>RequestedRangeNotSatisfiable 指示从资源请求的数据范围不能返回，或者因为范围的开始处，然后该资源的开头或范围的末尾后在资源的结尾。</td>
</tr>
<tr>
<td>RequestEntityTooLarge</td>
<td>413</td>
<td>RequestEntityTooLarge 指示请求来说太大的服务器能够处理。</td>
</tr>
<tr>
<td>RequestTimeout</td>
<td>408</td>
<td>RequestTimeout 指示客户端的服务器预期请求的时间内没有未发送请求。</td>
</tr>
<tr>
<td>RequestUriTooLong</td>
<td>414</td>
<td>RequestUriTooLong 指示 URI 太长。</td>
</tr>
<tr>
<td>ResetContent</td>
<td>205</td>
<td>ResetContent 指示客户端应重置 （而不是重新加载） 的当前资源。</td>
</tr>
<tr>
<td>SeeOther</td>
<td>303</td>
<td>SeeOther 自动将客户端重定向到的位置标头中指定作为公告的结果的 URI。 对指定的位置标头的资源的请求将会执行与 GET。</td>
</tr>
<tr>
<td>ServiceUnavailable</td>
<td>503</td>
<td>ServiceUnavailable 指示将服务器暂时不可用，通常是由于高负载或维护。</td>
</tr>
<tr>
<td>SwitchingProtocols</td>
<td>101</td>
<td>SwitchingProtocols 指示正在更改的协议版本或协议。</td>
</tr>
<tr>
<td>TemporaryRedirect</td>
<td>307</td>
<td>TemporaryRedirect 指示请求信息位于的位置标头中指定的 URI。 当收到此状态时的默认操作是遵循与响应关联的位置标头。 当原始请求方法是 POST 时，重定向的请求还将使用 POST 方法。</td>
</tr>
<tr>
<td>Unauthorized</td>
<td>401</td>
<td>Unauthorized 指示所请求的资源需要身份验证。 Www-authenticate 标头包含如何执行身份验证的详细信息。</td>
</tr>
<tr>
<td>UnsupportedMediaType</td>
<td>415</td>
<td>UnsupportedMediaType 指示该请求是不受支持的类型。</td>
</tr>
<tr>
<td>Unused</td>
<td>306</td>
<td>Unused 是对未完全指定的 HTTP/1.1 规范建议的扩展。</td>
</tr>
<tr>
<td>UpgradeRequired</td>
<td>426</td>
<td>UpgradeRequired 指示客户端应切换到不同的协议，例如 TLS/1.0。</td>
</tr>
<tr>
<td>UseProxy</td>
<td>305</td>
<td>UseProxy 指示该请求应使用的位置标头中指定的 uri 的代理服务器。</td>
</tr>
</tbody></table>
<p>参考文献  </p>
<p><a href="http://www.runoob.com/http/http-status-codes.html" target="_blank" rel="noopener">菜鸟教程（<strong>推荐</strong>）</a><br><a href="http://www.ruanyifeng.com/blog/2018/10/restful-api-best-practices.html" target="_blank" rel="noopener">RESTful API 最佳实践</a><br><a href="https://zh.wikipedia.org/wiki/HTTP%E7%8A%B6%E6%80%81%E7%A0%81" target="_blank" rel="noopener">HTTP状态码</a><br><a href="https://msdn.microsoft.com/zh-cn/library/system.net.httpstatuscode(v=vs.110).aspx" target="_blank" rel="noopener">文档来源</a>  </p>
]]></content>
      <categories>
        <category>后端开发</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title>OAuth Server</title>
    <url>/2018/02/03/2018-02-03-OAuth-Server/</url>
    <content><![CDATA[<h2 id="OAuth2-0-协议原理"><a href="#OAuth2-0-协议原理" class="headerlink" title="OAuth2.0 协议原理"></a>OAuth2.0 协议原理</h2><hr>
<blockquote>
<p>OAuth 2.0 协议是一种三方授权协议，目前大部分的第三方登录与授权都是基于该协议的标准或改进实现。OAuth 1.0 的标准在 2007  年发布，2.0 的标准则在 2011 年发布，其中 2.0 的标准取消所有 Token 的加密过程，并简化了授权流程，但因强制使用 HTTPS  协议，被认为安全性高于 1.0 的标准。</p>
</blockquote>
<a id="more"></a>

<h2 id="一-基础应用：第三方登录"><a href="#一-基础应用：第三方登录" class="headerlink" title="一. 基础应用：第三方登录"></a>一. 基础应用：第三方登录</h2><p>​        对于  OAuth2.0 协议（以下简称 OAuth  协议）的第一次接触，我相信大部分开发者都是通过对接第三方登录才开始知道和了解该协议。的确，OAuth  协议被广泛应用于第三方授权登录中，借助第三方登录可以让用户免于再次注册之苦，支持第三方登录也对这些网站、APP起到了积极的作用，免去了复杂的注册过程，用户体验更佳，更愿意去登录。这样在提高留存率的同时，也更加易于收集用户的一些非敏感信息等，另外还可以借助一些社交类的第三方账号进行站点推广等。</p>
<p>​         帐号服务对于公司来说是一个基础类服务，既简单也复杂。说它简单，是因为帐号的主要业务就是注册和登录，相信很多人在初次接触 WEB  开发的时候，第一个作业就是实现一个用户注册和登录的流程；说它复杂，是因为帐号服务往往是一个公司开展其它业务的基础，必须是公司业务中 QPS  最高的业务之一，需具备高可用、低延迟等特点，因为涉及到用户的敏感信息，还需要在安全方面下足功夫，近几年听到的盗号、拖库事件越来越没有新鲜感了。所以对于一个规模不大的公司来说，将主要人力投入在建立自己的帐号业务上是一件性价比很低的事情，这个时候接入大公司的第三方帐号登录，应该是更加可取的一种选择。</p>
<h2 id="二-OAuth2-0协议的基本定义与授权流程"><a href="#二-OAuth2-0协议的基本定义与授权流程" class="headerlink" title="二. OAuth2.0协议的基本定义与授权流程"></a>二. OAuth2.0协议的基本定义与授权流程</h2><hr>
<p>​        作为第三方登录服务提供方，我们的核心矛盾点就是既要让用户在对接我们服务的APP上登录，同时还不能让该APP拿到用户的登录凭证。解决这一矛盾的利器就是  token（中文译为令牌），而 OAuth 协议的最终目的就是给第三方应用下发 token，它记录了用户的登录或授权状态，通过将 token  传递给第三方应用，既能让第三方应用登录并拿到用户许可数据，也可以将用户的凭证牢牢拽在自己的手里（token是加密存储的，所以不担心因token下发而泄露用户凭证数据）。</p>
<p>​        说到用户登录状态的记录，我们可能最先想到的是  session 机制，想想你在做的第一个用户登录应用的时候，是不是拿服务器的 session  去记录用户是否登录。这一做法简单，但是也存在问题，session  说到底也还是缓存，当用户量较大的时候，需要相当大容量的缓存才能够容纳所有用户的登录状态，并且我们的 WEB  服务器往往有多台，通过负载均衡机制来提升服务的可用性，这样的场景下，我们不能简单的通过本地 session 来记录用户的登录状态，必须有专门的  session 服务器，或者其它的一些 session 复制措施，还需要考虑宕机造成的 session  丢失等问题，总之用户量大了，许多最初不是问题的问题逐渐暴露出来，有的甚至可能是极其棘手的。实际上对于用户登录状态的保存，我们可以走 token  机制，让客户端自己去保存用户的登录状态，将服务器从繁重的压力中解脱出来，利用 SSO（单点登录：Single Sign  On）来实现公司内各业务之间“一次登录，到处可用”。</p>
<p>​        回到 OAuth  协议，上面的论述可能侧重了第三方登录，实际上登录只是一个授权的过程，对于一个应用，其最终目的还是希望能够拿到用户存储在资源服务器上的用户数据，所以登录授权还只是第一步，后续  APP 还需要携带 token 去资源服务器请求用户数据，这个时候是一个鉴权的过程，OAuth  协议的主要目的在于授权，至于鉴权，实现上主要是还是对 APP 传递过来的 token 进行解析和验证，这一块相对要简单一些，所以下面主要讲解  OAuth 授权的流程。</p>
<h3 id="2-1-OAuth2-0定义的5种角色"><a href="#2-1-OAuth2-0定义的5种角色" class="headerlink" title="2.1 OAuth2.0定义的5种角色"></a>2.1 OAuth2.0定义的5种角色</h3><ul>
<li><strong>客户端（Client）</strong></li>
</ul>
<p>客户端是 OAuth 服务的接入方，其目的是请求用户存储在资源服务器上的受保护资源，客户端可以移动应用、网页应用，以及电视应用等等。</p>
<ul>
<li><strong>用户代理（User Agent）</strong></li>
</ul>
<p>用户代理是用户参与互联网的工具，一般可以理解为浏览器。</p>
<ul>
<li><strong>资源所有者（Resource Owner）</strong></li>
</ul>
<p>受保护资源所属的实体，比如资源的持有人等，下文的用户即资源所有者。</p>
<ul>
<li><strong>授权服务器（Authorization Server）</strong></li>
</ul>
<p>授权服务器的主要职责是验证资源所有者的身份，并依据资源所有者的许可对第三方应用下发令牌。</p>
<ul>
<li><strong>资源服务器（Resource Server）</strong></li>
</ul>
<p>托管资源的服务器，能够接收和响应持有令牌的资源访问请求，可以与授权服务器是同一台服务器，也可以分开。</p>
<h3 id="2-2-基本概念"><a href="#2-2-基本概念" class="headerlink" title="2.2 基本概念"></a>2.2 基本概念</h3><h4 id="2-2-1-访问令牌（access-token）"><a href="#2-2-1-访问令牌（access-token）" class="headerlink" title="2.2.1 访问令牌（access token）"></a>2.2.1 访问令牌（access token）</h4><p>​        访问令牌是在用户授权许可下，授权服务器下发给客户端的一个授权凭证，该令牌所要表达的意思是“用户授予该APP在多少时间范围内允许访问哪些与自己相关的服务”，所以访问令牌主要在 时间范围 和 权限范围 两个维度进行控制，此外访问令牌对于客户端来说是非透明的，外在表现就是一个字符串，客户端无法知晓字符串背后所隐藏的用户信息，因此不用担心用户的登录凭证会因此而泄露。</p>
<h4 id="2-2-2-刷新令牌（refresh-token）"><a href="#2-2-2-刷新令牌（refresh-token）" class="headerlink" title="2.2.2 刷新令牌（refresh token）"></a>2.2.2 刷新令牌（refresh token）</h4><p>​        刷新令牌的作用在于更新访问令牌，访问令牌的有效期一般较短，这样可以保证在发生访问令牌泄露时，不至于造成太坏的影响，但是访问令牌有效期设置太短存在的副作用就是用户需要频繁授权，虽然可以通过一定的机制进行静默授权，但是频繁的调用授权接口，之于授权服务器也是一种压力，这种情况下就可以在下发访问令牌的同时下发一个刷新令牌，刷新令牌的有效期明显长于访问令牌，这样在访问令牌失效时，可以利用刷新令牌去授权服务器换取新的访问令牌，不过协议对于刷新令牌没有强制规定，是否需要该令牌是客户端可以自行选择。</p>
<h4 id="2-2-3-回调地址（redirect-uri）"><a href="#2-2-3-回调地址（redirect-uri）" class="headerlink" title="2.2.3 回调地址（redirect uri）"></a>2.2.3 回调地址（redirect uri）</h4><p>​        OAuth2.0   是一类基于回调的授权协议，在授权码模式中，整个授权需要分为两步进行，第一步下发授权码，第二步根据第一步拿到的授权码请求授权服务器下发访问令牌。OAuth  在第一步下发授权码时，是将授权码以参数的形式添加到回调地址后面，并以 302  跳转的形式进行下发，这样简化了客户端的操作，不需要再主动去触发一次请求，即可进入下一步流程。</p>
<p>​        回调请求的设计却存在一个很大的安全隐患，坏人如果在客户端请求过程中修改了对应的回调地址，并指向自己的服务器，那么坏人可以利用这种机制去拿到客户端的授权码，继而走后面的流程，最终拿到访问令牌，另外坏人可以利用该机制引导用户到一个恶意站点，继而对用户发起攻击。以上两点都是该机制对于用户所造成的安全威胁，对于授权服务器而言，也存在一定的危害，坏人可以利用该机制让授权服务器变成“请求发送器”，以授权服务器为代理请求目标地址，这样在消耗授权服务器性能的同时，也对目标地址服务器产生  DDOS 攻击。</p>
<p>​        为了避免上述安全隐患，OAuth  协议强制要求客户端在注册时填写自己的回调地址，这个回调地址的目的是为了让回调请求能够到达客户端自己的服务器，从而可以走获取访问令牌的流程。客户端可以同时配置多个回调地址，并在请求授权时携带一个地址，服务器会验证客户端传递上来的回调地址是否与之前注册的回调地址相同，或者前者是后者集合的一个元素，只有在满足这一条件下才允许下发授权码，同时协议还要求两步请求客户端携带的回调地址必须一致，通过这些措施来保证回调过程能够正常达到客户端自己的服务器，并继续后面拿授权码换取访问令牌的流程。</p>
<h4 id="2-2-4-权限范围（scope）"><a href="#2-2-4-权限范围（scope）" class="headerlink" title="2.2.4 权限范围（scope）"></a>2.2.4 权限范围（scope）</h4><p>​        访问令牌自带过期时间，可以在时间维度上对授权进行控制，而在范围维度上，OAuth  引入了一个 scope 的概念。scope 可以看做是一个对象，包含一个权限的  ID，名称，以及描述信息等，比如“获取您的基本资料（头像、昵称）”。应该在接入账号服务时必须向第三方登录服务提供方申请响应的  scope，并在请求授权时指明该参数（否则表明获取该应用所允许的所有权限），这些权限在用户确认授权时，必须毫无保留的展示给用户，以让用户知道该APP需要获取用户的哪些数据或服务。</p>
<h3 id="2-3-基本授权流程"><a href="#2-3-基本授权流程" class="headerlink" title="2.3 基本授权流程"></a>2.3 基本授权流程</h3><p>​        OAuth协议已定义了 4 种授权模式，其中最具代表性的就是授权码模式，这个在 3.1 小节中详细介绍，这里先以该模式来简单感受一下 OAuth2.0 的授权流程，授权流程图如下：</p>
<p><img src="https://www.google.cn/assets/private/images/OAuth2.0/oauth1.png" alt="img"></p>
<p>假设整个流程开始之前，用户已经登录，那么整个授权流程如下：</p>
<ol>
<li>客户端请求授权服务器</li>
<li>授权授权服务的授权端点重定向用户至授权交互页面，并询问用户是否授权</li>
<li>如果用户许可，则授权端点验证客户端的身份，并发放授权码给客户端</li>
<li>客户端拿到授权码之后，携带授权码请求授权服务器的令牌端点下发访问令牌</li>
<li>令牌端点验证客户端的身份和授权码，通过则下发访问令牌和刷新令牌（可选）</li>
<li>客户端拿到访问令牌后，携带访问令牌请求资源服务器上的受保护资源</li>
<li>资源服务器验证客户端身份和访问令牌，通过则响应受保护资源访问请求</li>
</ol>
<p>整个流程中，客户端都无法接触到用户的登录凭证信息，客户端通过访问令牌请求受保护资源，用户可以通过对授权操作的控制来间接控制客户端对于受保护资源的访问权限范围和时效。</p>
<h2 id="三-四种授权模式"><a href="#三-四种授权模式" class="headerlink" title="三. 四种授权模式"></a>三. 四种授权模式</h2><hr>
<p>​        OAuth2.0  相对于 1.0 版本在授权模式上做了更多的细化，已定义的授权模式分为四种：1）授权码模式（Authorization Code  Grant）；2)隐式授权模式（Implicit Grant）；3）资源所有者密码凭证模式（Resource Owner Password  Credentials Grant）；4）以及客户端凭证模式（Client Credentials Grant）。</p>
<h3 id="3-1-授权码授权模式（Authorization-Code-Grant）"><a href="#3-1-授权码授权模式（Authorization-Code-Grant）" class="headerlink" title="3.1 授权码授权模式（Authorization Code Grant）"></a>3.1 授权码授权模式（Authorization Code Grant）</h3><p>​        授权码模式在整个授权流程上与  1.0 版本最贴近，但是整个流程还是要简化了许多，也是 OAuth2.0  中最标准，应用最广泛的授权模式。这类授权模式非常适合于具备服务端的应用，当然现在大多数 APP 都有自己的服务端，所以大部分 APP 的  OAuth 授权都可以采取授权码模式，下图为授权码各个角色之间的交互时序（这里让用户直接参与其中，省略了用户代理）：</p>
<p><img src="https://www.google.cn/assets/private/images/OAuth2.0/oauth2.png" alt="img"></p>
<p>整个授权流程说明如下（具体参数释义见下文）：</p>
<ol>
<li>客户端携带 client_id, scope, redirect_uri, state 等信息引导用户请求授权服务器的授权端点下发 code</li>
<li>授权服务器验证客户端身份，验证通过则询问用户是否同意授权（此时会跳转到用户能够直观看到的授权页面，等待用户点击确认授权）</li>
<li>假设用户同意授权，此时授权服务器会将 code 和 state（如果客户端传递了该参数）拼接在 redirect_uri 后面，以302形式下发 code</li>
<li>客户端携带 code, redirect_uri, 以及 client_secret 请求授权服务器的令牌端点下发 access_token （这一步实际上中间经过了客户端的服务器，除了 code，其它参数都是在应用服务器端添加，下文会细讲）</li>
<li>授权服务器验证客户端身份，同时验证 code，以及 redirect_uri 是否与请求 code 时相同，验证通过后下发 access_token，并选择性下发 refresh_token</li>
</ol>
<h4 id="3-1-1-获取授权码"><a href="#3-1-1-获取授权码" class="headerlink" title="3.1.1 获取授权码"></a>3.1.1 获取授权码</h4><p>​        授权码是授权流程的一个中间临时凭证，是对用户确认授权这一操作的一个暂时性的证书，其生命周期一般较短，协议建议最大不要超过10分钟，在这一有效时间周期内，客户端可以凭借该暂时性证书去授权服务器换取访问令牌。</p>
<p>请求参数说明：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>是否必须</th>
<th>描述信息</th>
</tr>
</thead>
<tbody><tr>
<td>response_type</td>
<td>必须</td>
<td>对于授权码模式 <code>response_type=code</code></td>
</tr>
<tr>
<td>client_id</td>
<td>必须</td>
<td>客户端ID，用于标识一个客户端，等同于appId，在注册应用时生成</td>
</tr>
<tr>
<td>redirect_uri</td>
<td>可选</td>
<td>授权回调地址，具体参见 2.2.3 小节</td>
</tr>
<tr>
<td>scope</td>
<td>可选</td>
<td>权限范围，用于对客户端的权限进行控制，如果客户端没有传递该参数，那么服务器则以该应用的所有权限代替</td>
</tr>
<tr>
<td>state</td>
<td>推荐</td>
<td>用于维持请求和回调过程中的状态，防止<a href="https://zh.wikipedia.org/wiki/%E8%B7%A8%E7%AB%99%E8%AF%B7%E6%B1%82%E4%BC%AA%E9%80%A0" target="_blank" rel="noopener">CSRF攻击</a>，服务器不对该参数做任何处理，如果客户端携带了该参数，则服务器在响应时原封不动的返回</td>
</tr>
</tbody></table>
<p>请求参数示例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET /authorize?response_type=code&amp;client_id=s6BhdRkqt3&amp;state=xyz&amp;redirect_uri=https://client.example.com/cb HTTP/1.1  </span><br><span class="line">Host: server.example.com</span><br></pre></td></tr></table></figure>

<p>​         客户端携带上述参数请求授权服务器的令牌端点，授权服务器会验证客户端的身份以及相关参数，并在确认用户登录的前提下弹出确认授权页询问用户是否授权，如果用户同意授权，则会将授权码（code）和state信息（如果客户端传递了该参数）添加到回调地址后面，以  302 的形式下发。</p>
<p>成功响应参数说明：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>是否必须</th>
<th>描述信息</th>
</tr>
</thead>
<tbody><tr>
<td>code</td>
<td>必须</td>
<td>授权码，授权码代表用户确认授权的暂时性凭证，只能使用一次，推荐最大生命周期不超过10分钟</td>
</tr>
<tr>
<td>state</td>
<td>可选</td>
<td>如果客户端传递了该参数，则必须原封不动返回</td>
</tr>
</tbody></table>
<p>成功响应示例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">HTTP/1.1 302 Found</span><br><span class="line">Location: https://client.example.com/cb?code=SplxlOBeZQQYbYS6WxSbIA&amp;state=xyz</span><br></pre></td></tr></table></figure>

<p>如果请求参数错误，或者服务器端响应错误，那么需要将错误信息添加在回调地址后面，以 302 形式下发（回调地址错误，或客户端标识无效除外）。</p>
<p>错误响应参数说明：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>是否必须</th>
<th>描述信息</th>
</tr>
</thead>
<tbody><tr>
<td>error</td>
<td>必须</td>
<td>错误代码</td>
</tr>
<tr>
<td>error_description</td>
<td>可选</td>
<td>具备可读性的错误描述信息</td>
</tr>
<tr>
<td>error_uri</td>
<td>可选</td>
<td>错误描述信息页面地址</td>
</tr>
<tr>
<td>state</td>
<td>可选</td>
<td>如果客户端传递了该参数，则必须原封不动返回</td>
</tr>
</tbody></table>
<p>错误响应示例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">HTTP/1.1 302 Found</span><br><span class="line">Location: https://client.example.com/cb?error=access_denied&amp;state=xyz</span><br></pre></td></tr></table></figure>

<h4 id="3-1-2-下发访问令牌"><a href="#3-1-2-下发访问令牌" class="headerlink" title="3.1.2 下发访问令牌"></a>3.1.2 下发访问令牌</h4><p>​        授权服务器的授权端点在以  302 形式下发 code 之后，用户 User-Agent，比如浏览器，将携带对应的 code 回调请求用户指定的  redirect_url，这个地址应该能够保证请求打到应用服务器的对应接口，该接口可以由此拿到  code，并附加相应参数请求授权服务器的令牌端点，授权端点验证 code 和相关参数，验证通过则下发 access_token。</p>
<p>请求参数说明：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>是否必须</th>
<th>描述信息</th>
</tr>
</thead>
<tbody><tr>
<td>grant_type</td>
<td>必须</td>
<td>对于授权码模式 <code>grant_type=authorization_code</code></td>
</tr>
<tr>
<td>code</td>
<td>必须</td>
<td>上一步骤获取的授权码</td>
</tr>
<tr>
<td>redirect_uri</td>
<td>必须</td>
<td>授权回调地址，具体参见 2.2.3 小节，如果上一步有设置，则必须相同</td>
</tr>
<tr>
<td>client_id</td>
<td>必须</td>
<td>客户端ID，用于标识一个客户端，等同于appId，在注册应用时生成</td>
</tr>
</tbody></table>
<p>​        <strong>如果在注册应用时有下发客户端凭证信息（<code>client_secret</code>），那么客户端必须携带该参数以让授权服务器验证客户端的有效性。</strong>针对客户端凭证需要多说的一点就是，不能将其传递到客户端，客户端无法保证凭证的安全，凭证应该始终留在应用的服务器端，当下发code回调请求到应用服务器时，在服务器端携带上凭证再次请求下发令牌。</p>
<p>请求参数示例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST /token HTTP/1.1</span><br><span class="line">Host: server.example.com</span><br><span class="line">Authorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW</span><br><span class="line">Content-Type: application/x-www-form-urlencoded</span><br><span class="line">grant_type=authorization_code&amp;code=SplxlOBeZQQYbYS6WxSbIA&amp;redirect_uri=https://client.example.com/cb</span><br></pre></td></tr></table></figure>

<p>​        授权服务器需要验证客户端的有效性，以及是否与之前请求授权码的客户端是同一个（请求授权时的信息可以记录在  code，或以 code 为 key 建立缓存），授权服务器还要保证code  处于生命周期内（推荐10分钟内有效），且只能被使用一次。授权服务器验证通过之后，生成 access_token，并选择性下发  refresh_token，OAuth2.0 协议明确了 token 的下发策略，对于生成策略没有做太多说明。</p>
<p>成功响应参数说明：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>是否必须</th>
<th>描述信息</th>
</tr>
</thead>
<tbody><tr>
<td>access_token</td>
<td>必须</td>
<td>访问令牌</td>
</tr>
<tr>
<td>token_type</td>
<td>必须</td>
<td>访问令牌类型，比如 bearer，mac 等等</td>
</tr>
<tr>
<td>expires_in</td>
<td>推荐</td>
<td>访问令牌的生命周期，以秒为单位，表示令牌下发后多久时间过期，如果没有指定该项，则使用默认值</td>
</tr>
<tr>
<td>refresh_token</td>
<td>可选</td>
<td>刷新令牌，选择性下发，参见 2.2.2</td>
</tr>
<tr>
<td>scope</td>
<td>可选</td>
<td>权限范围，如果最终下发的访问令牌对应的权限范围与实际应用指定的不一致，则必须在下发访问令牌时用该参数指定说明</td>
</tr>
</tbody></table>
<p>最后访问令牌以 JSON 格式响应，并要求指定响应首部 Cache-Control: no-store 和 Pragma: no-cache。</p>
<p>成功响应示例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Content-Type: application/json;charset=UTF-8</span><br><span class="line">Cache-Control: no-store</span><br><span class="line">Pragma: no-cache</span><br><span class="line">&#123;</span><br><span class="line">&quot;access_token&quot;:&quot;2YotnFZFEjr1zCsicMWpAA&quot;,</span><br><span class="line">&quot;token_type&quot;:&quot;example&quot;,</span><br><span class="line">&quot;expires_in&quot;:3600,</span><br><span class="line">&quot;refresh_token&quot;:&quot;tGzv3JOkF0XG5Qx2TlKWIA&quot;,</span><br><span class="line">&quot;example_parameter&quot;:&quot;example_value&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>错误响应参数说明：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>是否必须</th>
<th>描述信息</th>
</tr>
</thead>
<tbody><tr>
<td>error</td>
<td>必须</td>
<td>错误代码</td>
</tr>
<tr>
<td>error_description</td>
<td>可选</td>
<td>具备可读性的错误描述信息</td>
</tr>
<tr>
<td>error_uri</td>
<td>可选</td>
<td>错误描述信息页面地址</td>
</tr>
</tbody></table>
<p>错误响应示例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">HTTP/1.1 400 Bad Request</span><br><span class="line">Content-Type: application/json;charset=UTF-8</span><br><span class="line">Cache-Control: no-store</span><br><span class="line">Pragma: no-cache</span><br><span class="line">&#123;</span><br><span class="line">&quot;error&quot;:&quot;invalid_request&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="3-1-3-对于授权码模式的一点感悟"><a href="#3-1-3-对于授权码模式的一点感悟" class="headerlink" title="3.1.3 对于授权码模式的一点感悟"></a>3.1.3 对于授权码模式的一点感悟</h4><p>​        授权码授权模式是  OAuth2.0 协议已定义 4 种模式中最严谨的模式，剩余 3  中模式都是建立在一些特殊场景下，并对这些场景做了一些妥协和优化。授权码授权流程分为两步走，将用户授权与下发 token  分开，这给授权带来了更多的灵活性，正常授权过程中必须经过用户登录这一步骤，在用户已登录的前提下，可以直接询问用户是否同意授权，但是在一些场景下，比如内部走  SSO 登录的应用集成了基于 OAuth 登录的第三方应用，这个时候在 OAuth  授权登录第三方应用时用户体验较好的流程是不需要用户再一次输入用户名和密码登录的，这就需要将外围 APP  的登录态传递给该应用，但是这样是存在安全问题的，用户的登录态必须把握在走 SSO  登录流程的应用中，这样的场景下授权码授权模式的两步走流程就可以满足在不交出用户登录态的情况下，无需再次登录即可授权。</p>
<p>​        内部应用可以拿着第三方应用的  client_id 等信息代替第三方应用去请求获取 code，因为自己持有用户的登录态，所以过程中无需用户再次输入用户名和密码，拿到 code  之后将其交给第三方应用，第三方应用利用 code 和自己的 client_secret 信息去请求授权服务器下发  token，整个流程内部应用不需要交出自己持有的用户登录态，第三方应用也无需交出自己的 client_secret  信息，最终却能够实现在保护用户登录凭证的前提下无需再次登录即可完成整个授权流程。</p>
<h3 id="3-2-隐式授权模式（Implicit-Grant）"><a href="#3-2-隐式授权模式（Implicit-Grant）" class="headerlink" title="3.2 隐式授权模式（Implicit Grant）"></a>3.2 隐式授权模式（Implicit Grant）</h3><p>略。(三方云接入不支持此类授权模式)</p>
<h3 id="3-3-资源所有者密码凭证授权模式（Resource-Owner-Password-Credentials-Grant）"><a href="#3-3-资源所有者密码凭证授权模式（Resource-Owner-Password-Credentials-Grant）" class="headerlink" title="3.3 资源所有者密码凭证授权模式（Resource Owner Password Credentials Grant）"></a>3.3 资源所有者密码凭证授权模式（Resource Owner Password Credentials Grant）</h3><p>略。(三方云接入不支持此类授权模式)</p>
<h3 id="3-4-客户端凭证授权模式（Client-Credentials-Grant）"><a href="#3-4-客户端凭证授权模式（Client-Credentials-Grant）" class="headerlink" title="3.4 客户端凭证授权模式（Client Credentials Grant）"></a>3.4 客户端凭证授权模式（Client Credentials Grant）</h3><p>略。(三方云接入不支持此类授权模式)</p>
<h2 id="四-OAuth2-0-错误码"><a href="#四-OAuth2-0-错误码" class="headerlink" title="四. OAuth2.0 错误码"></a>四. OAuth2.0 错误码</h2><hr>
<table>
<thead>
<tr>
<th>错误码(error)</th>
<th>错误编号(error_code)</th>
<th>错误描述(error_description)</th>
</tr>
</thead>
<tbody><tr>
<td>invalid_code</td>
<td>21321</td>
<td>code无效</td>
</tr>
<tr>
<td>redirect_uri_mismatch</td>
<td>21322</td>
<td>重定向地址不匹配</td>
</tr>
<tr>
<td>invalid_request</td>
<td>21323</td>
<td>请求不合法</td>
</tr>
<tr>
<td>invalid_client</td>
<td>21324</td>
<td>client_id或client_secret参数无效</td>
</tr>
<tr>
<td>invalid_grant</td>
<td>21325</td>
<td>提供的Access Grant是无效的、过期的或已撤销的</td>
</tr>
<tr>
<td>unauthorized_client</td>
<td>21326</td>
<td>客户端没有权限</td>
</tr>
<tr>
<td>expired_token</td>
<td>21327</td>
<td>token过期</td>
</tr>
<tr>
<td>unsupported_grant_type</td>
<td>21328</td>
<td>不支持的 GrantType</td>
</tr>
<tr>
<td>unsupported_response_type</td>
<td>21329</td>
<td>不支持的 ResponseType</td>
</tr>
<tr>
<td>access_denied</td>
<td>21330</td>
<td>用户或授权服务器拒绝授予数据访问权限</td>
</tr>
<tr>
<td>temporarily_unavailable</td>
<td>21331</td>
<td>服务暂时无法访问</td>
</tr>
</tbody></table>
<h2 id="五-本篇小结"><a href="#五-本篇小结" class="headerlink" title="五. 本篇小结"></a>五. 本篇小结</h2><hr>
<h3 id="3-1-使用postman请求accessToken（测试）"><a href="#3-1-使用postman请求accessToken（测试）" class="headerlink" title="3.1 使用postman请求accessToken（测试）"></a>3.1 使用postman请求accessToken（测试）</h3><p><img src="https://www.google.cn/assets/private/images/OAuth2.0/oauth_getAccessToken.png" alt="getAccessToken"></p>
<h3 id="3-2-使用postman刷新accessToken（测试）"><a href="#3-2-使用postman刷新accessToken（测试）" class="headerlink" title="3.2 使用postman刷新accessToken（测试）"></a>3.2 使用postman刷新accessToken（测试）</h3><p><img src="https://www.google.cn/assets/private/images/OAuth2.0/oauth_refreshToken.png" alt="refreshToken"></p>
<h2 id="六-本篇小结"><a href="#六-本篇小结" class="headerlink" title="六. 本篇小结"></a>六. 本篇小结</h2><hr>
<p>​        本篇介绍了 OAuth2.0 授权协议的理论知识，OAuth2.0 被广泛应用于第三方授权登录，很多其它的协议都是可以基于该协议进行改造的，比如前面多次提到的 SSO，作为开发人员，还是建议对该协议或多或少有些了解。</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ol>
<li><a href="https://tools.ietf.org/html/rfc5849" target="_blank" rel="noopener">RFC5849 - The OAuth 1.0 Protocol</a></li>
<li><a href="https://tools.ietf.org/html/rfc6749" target="_blank" rel="noopener">RFC6749 - The OAuth 2.0 Authorization Framework</a></li>
<li><a href="https://tools.ietf.org/html/rfc6750" target="_blank" rel="noopener">RFC6750 - The OAuth 2.0 Authorization Framework: Bearer Token Usage</a></li>
<li><a href="https://tools.ietf.org/html/draft-hammer-oauth-v2-mac-token-02" target="_blank" rel="noopener">HTTP Authentication: MAC Authentication (draft-hammer-oauth-v2-mac-token-02)</a></li>
<li><a href="https://github.com/MiEcosystem/miot-spec-doc/blob/master/%E7%AC%AC%E4%B8%89%E6%96%B9%E8%AE%BE%E5%A4%87%E4%BA%91OAUTH.md" target="_blank" rel="noopener">小米开放平台文档</a></li>
<li><a href="http://doc-bot.tmall.com/docs/doc.htm?spm=0.0.0.0.AHD7k9&treeId=393&articleId=106999&docType=1" target="_blank" rel="noopener">天猫AliGenie开放平台文档</a></li>
<li><a href="http://developer.baidu.com/wiki/index.php?title=docs/oauth" target="_blank" rel="noopener">百度DuerOS开放平台文档</a></li>
<li><a href="https://open.ainirobot.com/tutor/zn_sqlc" target="_blank" rel="noopener">猎豹OrionOS开放平台文档</a></li>
<li><a href="http://www.zhenchao.org/2018/03/04/oauth-v2-protocol/" target="_blank" rel="noopener">OAuth 2.0 开放授权那些事儿</a></li>
<li><a href="https://devdocs.magento.com/guides/v2.2/get-started/authentication/oauth-errors.html" target="_blank" rel="noopener">错误码参考</a></li>
</ol>
]]></content>
      <categories>
        <category>后端开发</category>
      </categories>
      <tags>
        <tag>OAuth</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringMVC常用注解</title>
    <url>/2017/05/16/2017-05-16-SpringMVC%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3/</url>
    <content><![CDATA[<h2 id="SpringMVC常用注解"><a href="#SpringMVC常用注解" class="headerlink" title="SpringMVC常用注解"></a>SpringMVC常用注解</h2><h3 id="Controller"><a href="#Controller" class="headerlink" title="@Controller"></a>@Controller</h3><blockquote>
<ul>
<li>定义了一个控制器类或者方法</li>
<li>控制器Controller 负责处理由DispatcherServlet 分发的请求</li>
<li>分发处理器将会扫描使用了该注解的类的方法，并检测该方法是否使用了@RequestMapping 注解</li>
<li>使用Model对象在View和Controller层传输数据</li>
<li>单独使用不是真正能处理请求的处理器，需要配合@RequestMapping 使用</li>
</ul>
</blockquote>
<h4 id="配置控制器bean"><a href="#配置控制器bean" class="headerlink" title="配置控制器bean"></a>配置控制器bean</h4><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!--方式一--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">class</span>=<span class="string">"com.packageName.MyController"</span>/&gt;</span></span><br><span class="line"><span class="comment">&lt;!--方式二 路径写到controller的上一层(扫描包详解见下面浅析)--&gt;</span></span><br><span class="line"><span class="tag">&lt; <span class="attr">context:component-scan</span> <span class="attr">base-package</span> = <span class="string">"com.packageName"</span> /&gt;</span></span><br></pre></td></tr></table></figure>

<a id="more"></a>

<h3 id="RequestMapping"><a href="#RequestMapping" class="headerlink" title="@RequestMapping"></a>@RequestMapping</h3><blockquote>
<ul>
<li>RequestMapping是一个用来处理请求地址映射的注解，可用于类或方法上。</li>
<li>用于类上，表示类中的所有响应请求的方法都是以该地址作为父路径。</li>
<li>RequestMapping注解有六个属性</li>
</ul>
</blockquote>
<h4 id="value"><a href="#value" class="headerlink" title="value"></a>value</h4><blockquote>
<ul>
<li>指定请求的实际地址，指定的地址可以是URI Template 模式</li>
</ul>
</blockquote>
<h4 id="method"><a href="#method" class="headerlink" title="method"></a>method</h4><blockquote>
<ul>
<li>指定请求的method类型， GET、POST、PUT、DELETE等</li>
</ul>
</blockquote>
<h4 id="consumes"><a href="#consumes" class="headerlink" title="consumes"></a>consumes</h4><blockquote>
<ul>
<li>指定处理请求的提交内容类型（Content-Type），例如application/json, text/html;</li>
</ul>
</blockquote>
<h4 id="produces"><a href="#produces" class="headerlink" title="produces"></a>produces</h4><blockquote>
<ul>
<li>指定返回的内容类型，仅当request请求头中的(Accept)类型中包含该指定类型才返回；</li>
</ul>
</blockquote>
<h4 id="params"><a href="#params" class="headerlink" title="params"></a>params</h4><blockquote>
<ul>
<li>指定request中必须包含某些参数值是，才让该方法处理。</li>
</ul>
</blockquote>
<h4 id="headers"><a href="#headers" class="headerlink" title="headers"></a>headers</h4><blockquote>
<ul>
<li>指定request中必须包含某些指定的header值，才能让该方法处理请求。</li>
</ul>
</blockquote>
<h3 id="Autowired"><a href="#Autowired" class="headerlink" title="@Autowired"></a>@Autowired</h3><blockquote>
<ul>
<li>标记bean注入时使用</li>
<li>使用在字段或者setter方法上</li>
<li>如果使用在字段上，就不需要再写setter方法了</li>
<li>默认是ByType注入</li>
<li>默认情况下它要求依赖对象必须存在，如果允许null值，可以设置它的required属性为false</li>
</ul>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestServiceImpl</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 下面两种@Autowired只要使用一种即可</span></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> UserDao userDao; <span class="comment">// 用于字段上</span></span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUserDao</span><span class="params">(UserDao userDao)</span> </span>&#123; <span class="comment">// 用于属性的方法上</span></span><br><span class="line">        <span class="keyword">this</span>.userDao = userDao;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<ul>
<li>如果我们想使用按照名称（byName）来装配，可以结合@Qualifier注解一起使用,如下</li>
</ul>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestServiceImpl</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="meta">@Qualifier</span>(<span class="string">"userDao"</span>)</span><br><span class="line">    <span class="keyword">private</span> UserDao userDao; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Resource"><a href="#Resource" class="headerlink" title="@Resource"></a>@Resource</h3><blockquote>
<ul>
<li>@Resource的作用相当于@Autowired，只不过@Autowired按照byType自动注入。</li>
<li>@Resource并不是Spring的注解，它的包是javax.annotation.Resource，但是Spring支持该注解的注入</li>
<li>标记bean注入时使用</li>
<li>使用在字段或者setter方法上</li>
<li>如果使用在字段上，就不需要再写setter方法了</li>
<li>默认按照ByName自动注入</li>
<li>@Resource有两个重要的属性：name和type，而Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。</li>
<li>所以，如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。</li>
<li>如果既不制定name也不制定type属性，这时将通过反射机制使用byName自动注入策略。</li>
<li>最好是将@Resource放在setter方法上，因为这样更符合面向对象的思想，通过set、get去操作属性，而不是直接去操作属性。</li>
</ul>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> javax.annotation.Resource;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestServiceImpl</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 下面两种@Resource只要使用一种即可</span></span><br><span class="line">    <span class="meta">@Resource</span>(name=<span class="string">"userDao"</span>)</span><br><span class="line">    <span class="keyword">private</span> UserDao userDao; <span class="comment">// 用于字段上</span></span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Resource</span>(name=<span class="string">"userDao"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUserDao</span><span class="params">(UserDao userDao)</span> </span>&#123; <span class="comment">// 用于属性的setter方法上</span></span><br><span class="line">        <span class="keyword">this</span>.userDao = userDao;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="Resource装配Bean的顺序"><a href="#Resource装配Bean的顺序" class="headerlink" title="@Resource装配Bean的顺序"></a>@Resource装配Bean的顺序</h4><blockquote>
<ul>
<li>①如果同时指定了name和type，则从Spring上下文中找到唯一匹配的bean进行装配，找不到则抛出异常。  </li>
<li>②如果指定了name，则从上下文中查找名称（id）匹配的bean进行装配，找不到则抛出异常。  </li>
<li>③如果指定了type，则从上下文中找到类似匹配的唯一bean进行装配，找不到或是找到多个，都会抛出异常。  </li>
<li>④如果既没有指定name，又没有指定type，则自动按照byName方式进行装配；如果没有匹配，则回退为一个原始类型进行匹配，如果匹配则自动装配。  </li>
</ul>
</blockquote>
<h3 id="ModelAttribute"><a href="#ModelAttribute" class="headerlink" title="@ModelAttribute"></a>@ModelAttribute</h3><blockquote>
<ul>
<li>该Controller的所有方法在调用前，先执行此@ModelAttribute方法，可用于注解和方法参数中</li>
<li>应用在BaseController当中，所有的Controller继承BaseController，即可实现在调用Controller时，先执行@ModelAttribute方法。</li>
<li>标记在处理器方法参数上的时候，表示该参数的值将从模型或者 Session 中取对应名称的属性值，该名称可以通过 @ModelAttribute(“attributeName”) 来指定，若未指定，则使用参数类型的类名称（首字母小写）作为属性名称。</li>
<li>该注解有两个用法，一个是用于方法上，一个是用于参数上；</li>
<li>用于方法上时：  通常用来在处理@RequestMapping之前，为请求绑定需要从后台查询的model；</li>
<li>用于参数上时： 用来通过名称对应，把相应名称的值绑定到注解的参数bean上；要绑定的值来源于：</li>
<li><ul>
<li>A） @SessionAttributes 启用的attribute 对象上；</li>
</ul>
</li>
<li><ul>
<li>B） @ModelAttribute 用于方法上时指定的model对象；</li>
</ul>
</li>
<li><ul>
<li>C） 上述两种情况都没有时，new一个需要绑定的bean对象，然后把request中按名称对应的方式把值绑定到bean中。</li>
</ul>
</li>
</ul>
</blockquote>
<blockquote>
<p>用到方法上@ModelAttribute的示例代码<br>这种方式实际的效果就是在调用@RequestMapping的方法之前，为request对象的model里put（“account”， Account）。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ModelAttribute</span>  </span><br><span class="line"><span class="function"><span class="keyword">public</span> Account <span class="title">addAccount</span><span class="params">(@RequestParam String number)</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">return</span> accountManager.findAccount(number);  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>用在参数上的@ModelAttribute示例代码<br>首先查询 @SessionAttributes有无绑定的Pet对象，若没有则查询@ModelAttribute方法层面上是否绑定了Pet对象，若没有则将URI template中的值按对应的名称绑定到Pet对象的各属性上</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RequestMapping</span>(value=<span class="string">"/owners/&#123;ownerId&#125;/pets/&#123;petId&#125;/edit"</span>, method = RequestMethod.POST)  </span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">processSubmit</span><span class="params">(@ModelAttribute Pet pet)</span> </span>&#123;  </span><br><span class="line">     </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="SessionAttributes"><a href="#SessionAttributes" class="headerlink" title="@SessionAttributes"></a>@SessionAttributes</h3><blockquote>
<ul>
<li>支持使用 @ModelAttribute 和 @SessionAttributes 在不同的模型（model）和控制器之间共享数据。 @ModelAttribute 主要有两种使用方式，一种是标注在方法上，一种是标注在 Controller 方法参数上。</li>
<li>@SessionAttributes即将值放到session作用域中，写在class上面。</li>
<li>@SessionAttributes 属性标记哪些是需要存放到 session 中的</li>
<li>等处理器方法执行完成后 Spring 才会把模型中对应的属性添加到 session 中</li>
<li>该注解用来绑定HttpSession中的attribute对象的值，便于在方法中的参数里使用。</li>
<li>该注解有value、types两个属性，可以通过名字和类型指定要使用的attribute 对象；</li>
</ul>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Controller</span>  </span><br><span class="line"><span class="meta">@RequestMapping</span>(<span class="string">"/editPet.do"</span>)  </span><br><span class="line"><span class="meta">@SessionAttributes</span>(<span class="string">"pet"</span>)  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EditPetForm</span> </span>&#123;  </span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="PathVariable"><a href="#PathVariable" class="headerlink" title="@PathVariable"></a>@PathVariable</h3><blockquote>
<ul>
<li>用于将请求URL中的模板变量映射到功能处理方法的参数上，即取出uri模板中的变量作为参数</li>
</ul>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Controller</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestController</span> </span>&#123;  </span><br><span class="line">     <span class="meta">@RequestMapping</span>(value=<span class="string">"/user/&#123;userId&#125;/roles/&#123;roleId&#125;"</span>,method = RequestMethod.GET)  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> String <span class="title">getLogin</span><span class="params">(@PathVariable(<span class="string">"userId"</span>)</span> String userId,  </span></span><br><span class="line"><span class="function">         @<span class="title">PathVariable</span><span class="params">(<span class="string">"roleId"</span>)</span> String roleId)</span>&#123;  </span><br><span class="line">         System.out.println(<span class="string">"User Id : "</span> + userId);  </span><br><span class="line">         System.out.println(<span class="string">"Role Id : "</span> + roleId);  </span><br><span class="line">         <span class="keyword">return</span> <span class="string">"hello"</span>;  </span><br><span class="line">     &#125;  </span><br><span class="line">     <span class="meta">@RequestMapping</span>(value=<span class="string">"/product/&#123;productId&#125;"</span>,method = RequestMethod.GET)  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> String <span class="title">getProduct</span><span class="params">(@PathVariable(<span class="string">"productId"</span>)</span> String productId)</span>&#123;  </span><br><span class="line">           System.out.println(<span class="string">"Product Id : "</span> + productId);  </span><br><span class="line">           <span class="keyword">return</span> <span class="string">"hello"</span>;  </span><br><span class="line">     &#125;  </span><br><span class="line">     <span class="meta">@RequestMapping</span>(value=<span class="string">"/javabeat/&#123;regexp1:[a-z-]+&#125;"</span>,  </span><br><span class="line">           method = RequestMethod.GET)  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> String <span class="title">getRegExp</span><span class="params">(@PathVariable(<span class="string">"regexp1"</span>)</span> String regexp1)</span>&#123;  </span><br><span class="line">           System.out.println(<span class="string">"URI Part 1 : "</span> + regexp1);  </span><br><span class="line">           <span class="keyword">return</span> <span class="string">"hello"</span>;  </span><br><span class="line">     &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="RequestParam"><a href="#RequestParam" class="headerlink" title="@RequestParam"></a>@RequestParam</h3><blockquote>
<ul>
<li>获取请求url中的参数值</li>
<li>类似request.getParameter(“name”)</li>
<li>defaultValue 表示设置默认值，</li>
<li>required 通过boolean设置是否是必须要传入的参数，</li>
<li>value 值表示接受的传入的参数类型。</li>
<li>用来处理Content-Type: 为 application/x-www-form-urlencoded编码的内容，提交方式GET、POST；</li>
</ul>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Controller</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestController</span> </span>&#123;  </span><br><span class="line">     <span class="meta">@RequestMapping</span>(value=<span class="string">"/update"</span>,method=RequestMethod.POST)</span><br><span class="line">	<span class="function"><span class="keyword">public</span> Object <span class="title">update</span><span class="params">(@RequestParam(value=<span class="string">"id"</span>,required = <span class="keyword">true</span>, defaultValue = <span class="number">0</span>)</span><span class="keyword">int</span> id)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"OK"</span>;  </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="RequestBody"><a href="#RequestBody" class="headerlink" title="@RequestBody"></a>@RequestBody</h3><blockquote>
<ul>
<li>获取请求中的数据</li>
<li>常用来处理Content-Type: 不是application/x-www-form-urlencoded编码的内容，例如application/json, application/xml等；</li>
<li>因为配置有FormHttpMessageConverter，所以也可以用来处理 application/x-www-form-urlencoded的内容</li>
</ul>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RequestMapping</span>(value = <span class="string">"/something"</span>, method = RequestMethod.PUT)  </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(@RequestBody String body, Writer writer)</span> <span class="keyword">throws</span> IOException </span>&#123;  </span><br><span class="line">    writer.write(body);  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="ResponseBody"><a href="#ResponseBody" class="headerlink" title="@ResponseBody"></a>@ResponseBody</h3><blockquote>
<ul>
<li>该注解用于将Controller的方法返回的对象，通过适当的HttpMessageConverter转换为指定格式后，写入到Response对象的body数据区</li>
<li>返回的数据不是html标签的页面，而是其他某种格式的数据时（如json、xml等）使用</li>
</ul>
</blockquote>
<h3 id="Component"><a href="#Component" class="headerlink" title="@Component"></a>@Component</h3><blockquote>
<ul>
<li>相当于通用的注解，当不知道一些类归到哪个层时使用，但是不建议。</li>
</ul>
</blockquote>
<h3 id="Repository"><a href="#Repository" class="headerlink" title="@Repository"></a>@Repository</h3><blockquote>
<ul>
<li>用于注解dao层，在daoImpl类上面注解。</li>
<li>@Repository, @Service 和 @Controller有着类似的作用</li>
</ul>
</blockquote>
<h2 id="注："><a href="#注：" class="headerlink" title="注："></a>注：</h2><hr>
<h3 id="RequestMapping-详细说明"><a href="#RequestMapping-详细说明" class="headerlink" title="RequestMapping 详细说明"></a>RequestMapping 详细说明</h3><h4 id="支持通配符“-”"><a href="#支持通配符“-”" class="headerlink" title="支持通配符“*”"></a>支持通配符“*”</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="meta">@RequestMapping</span> ( <span class="string">"/myTest"</span> )</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyController</span> </span>&#123;</span><br><span class="line">    <span class="meta">@RequestMapping</span> ( <span class="string">"*/wildcard"</span> )</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">testWildcard</span><span class="params">()</span> </span>&#123;</span><br><span class="line">       System. out .println( <span class="string">"wildcard------------"</span> );</span><br><span class="line">       <span class="keyword">return</span> <span class="string">"wildcard"</span> ;</span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>/myTest/whatever/wildcard.do          :heavy_check_mark:</p>
<h4 id="params属性"><a href="#params属性" class="headerlink" title="params属性"></a>params属性</h4><ul>
<li>表示参数param1 的值必须等于value1 ，参数param2 必须存在，值无所谓，参数param3 必须不存在<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RequestMapping</span> (value= <span class="string">"testParams"</span> , params=&#123; <span class="string">"param1=value1"</span> , <span class="string">"param2"</span> , <span class="string">"!param3"</span> &#125;)</span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">testParams</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">"testParams"</span> ;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>/testParams.do?param1=value1&amp;param2=value2                             :x:</li>
<li>/testParams.do?param1=value1&amp;param2=value2&amp;param3=value3               :heavy_check_mark:</li>
</ul>
<h4 id="method属性"><a href="#method属性" class="headerlink" title="method属性"></a>method属性</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RequestMapping</span> (value= <span class="string">"testMethod"</span> , method=&#123;RequestMethod. GET , RequestMethod. DELETE &#125;)</span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">testMethod</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">"method"</span> ;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>method 参数限制了以GET 或DELETE 方法请求/testMethod 的时候才能访问到该Controller 的testMethod 方法</li>
</ul>
<h4 id="headers属性"><a href="#headers属性" class="headerlink" title="headers属性"></a>headers属性</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RequestMapping</span> (value= <span class="string">"testHeaders"</span> , headers=&#123; <span class="string">"host=localhost"</span> , <span class="string">"Accept"</span> &#125;)</span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">testHeaders</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">"headers"</span> ;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>只有当请求头包含Accept 信息，且请求的host 为localhost 的时候才能正确的访问到testHeaders 方法</li>
</ul>
<h4 id="支持的方法参数类型"><a href="#支持的方法参数类型" class="headerlink" title="支持的方法参数类型"></a>支持的方法参数类型</h4><ul>
<li>使用方法：在方法的参数中加入</li>
<li>（ 1 ）HttpServlet 对象，主要包括HttpServletRequest 、HttpServletResponse 和HttpSession 对象。</li>
<li>（ 2 ）Spring 自己的WebRequest 对象。</li>
<li>（ 3 ）InputStream 、OutputStream 、Reader 和Writer 。</li>
<li><ul>
<li>InputStream 和Reader 是针对HttpServletRequest 而言的，可以从里面取数据；</li>
</ul>
</li>
<li><ul>
<li>OutputStream 和Writer 是针对HttpServletResponse 而言的，可以往里面写数据。</li>
</ul>
</li>
<li>（ 4 ）使用@PathVariable 、@RequestParam 、@CookieValue 和@RequestHeader 标记的参数。</li>
<li>（ 5 ）使用@ModelAttribute 标记的参数。</li>
<li>（ 6 ）java.util.Map 、Spring 封装的Model 和ModelMap 。</li>
<li><ul>
<li>用来封装模型数据，用来给视图做展示</li>
</ul>
</li>
<li>（ 7 ）实体类</li>
<li><ul>
<li>可以用来接收上传的参数。</li>
</ul>
</li>
<li>（ 8 ）Spring 封装的MultipartFile</li>
<li><ul>
<li>用来接收上传文件的。</li>
</ul>
</li>
<li>（ 9 ）Spring 封装的Errors 和BindingResult 对象。</li>
<li><ul>
<li>这两个对象参数必须紧接在需要验证的实体对象参数之后，它里面包含了实体对象的验证结果。</li>
</ul>
</li>
</ul>
<h4 id="支持的返回类型"><a href="#支持的返回类型" class="headerlink" title="支持的返回类型"></a>支持的返回类型</h4><ul>
<li>（ 1 ）一个包含模型和视图的ModelAndView 对象。</li>
<li>（ 2 ）一个模型对象，这主要包括Spring 封装好的Model 和ModelMap ，以及java.util.Map ，当没有视图返回的时候视图名称将由RequestToViewNameTranslator 来决定。</li>
<li>（ 3 ）一个View 对象。这个时候如果在渲染视图的过程中模型的话就可以给处理器方法定义一个模型参数，然后在方法体里面往模型中添加值。</li>
<li>（ 4 ）一个String 字符串。这往往代表的是一个视图名称。这个时候如果需要在渲染视图的过程中需要模型的话就可以给处理器方法一个模型参数，然后在方法体里面往模型中添加值就可以了。</li>
<li>（ 5 ）返回值是void 。这种情况一般是我们直接把返回结果写到HttpServletResponse 中了，如果没有写的话，那么Spring 将会利用RequestToViewNameTranslator 来返回一个对应的视图名称。如果视图中需要模型的话，处理方法与返回字符串的情况相同。</li>
<li>（ 6 ）如果处理器方法被注解@ResponseBody 标记的话，那么处理器方法的任何返回类型都会通过HttpMessageConverters 转换之后写到HttpServletResponse 中，而不会像上面的那些情况一样当做视图或者模型来处理。</li>
<li>（ 7 ）除以上几种情况之外的其他任何返回类型都会被当做模型中的一个属性来处理，而返回的视图还是由RequestToViewNameTranslator 来决定，添加到模型中的属性名称可以在该方法上用@ModelAttribute(“attributeName”) 来定义，否则将使用返回类型的类名称的首字母小写形式来表示。使用@ModelAttribute 标记的方法会在@RequestMapping 标记的方法执行之前执行。</li>
</ul>
<h3 id="PathVariable和-RequestParam的区别"><a href="#PathVariable和-RequestParam的区别" class="headerlink" title="@PathVariable和@RequestParam的区别"></a>@PathVariable和@RequestParam的区别</h3><blockquote>
<p>handler method 参数绑定常用的注解,我们根据他们处理的Request的不同内容部分分为四类：（主要讲解常用类型）</p>
</blockquote>
<ul>
<li>A、处理requet uri 部分（这里指uri template中variable，不含queryString部分）的注解：   @PathVariable;</li>
<li>B、处理request header部分的注解：   @RequestHeader, @CookieValue;</li>
<li>C、处理request body部分的注解：@RequestParam,  @RequestBody;</li>
<li>D、处理attribute类型是注解： @SessionAttributes, @ModelAttribute;</li>
</ul>
<h4 id="PathVariable-1"><a href="#PathVariable-1" class="headerlink" title="@PathVariable"></a>@PathVariable</h4><ul>
<li>通过 @Pathvariable注解绑定它传过来的值到方法的参数<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Controller</span>  </span><br><span class="line"><span class="meta">@RequestMapping</span>(<span class="string">"/owners/&#123;ownerId&#125;"</span>)  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RelativePathUriTemplateController</span> </span>&#123;  </span><br><span class="line">    <span class="meta">@RequestMapping</span>(<span class="string">"/pets/&#123;petId&#125;"</span>)  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">findPet</span><span class="params">(@PathVariable String ownerId, @PathVariable String petId, Model model)</span></span>&#123;      </span><br><span class="line">    <span class="comment">// implementation omitted   </span></span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="RequestHeader"><a href="#RequestHeader" class="headerlink" title="@RequestHeader"></a>@RequestHeader</h4><ul>
<li>@RequestHeader 注解可以把Request请求header部分的值绑定到方法的参数上。<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">Host                    localhost:8080  </span><br><span class="line">Accept                  text/html,application/xhtml+xml,application/xml;q=0.9  </span><br><span class="line">Accept-Language         fr,en-gb;q=0.7,en;q=0.3  </span><br><span class="line">Accept-Encoding         gzip,deflate  </span><br><span class="line">Accept-Charset          ISO-8859-1,utf-8;q=0.7,*;q=0.7  </span><br><span class="line">Keep-Alive              300</span><br></pre></td></tr></table></figure>

</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">displayHeaderInfo</span><span class="params">(@RequestHeader(<span class="string">"Accept-Encoding"</span>)</span> String encoding,@<span class="title">RequestHeader</span><span class="params">(<span class="string">"Keep-Alive"</span>)</span> <span class="keyword">long</span> keepAlive)  </span>&#123;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="CookieValue"><a href="#CookieValue" class="headerlink" title="@CookieValue"></a>@CookieValue</h4><ul>
<li>@CookieValue 可以把Request header中关于cookie的值绑定到方法的参数上。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RequestMapping</span>(<span class="string">"/displayHeaderInfo.do"</span>)  </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">displayHeaderInfo</span><span class="params">(@CookieValue(<span class="string">"JSESSIONID"</span>)</span> String cookie)  </span>&#123;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="component-scan浅析"><a href="#component-scan浅析" class="headerlink" title="component-scan浅析"></a>component-scan浅析</h4><blockquote>
<p>  @Repository, @Service 和 @Controller 是 @Component 的子注解</p>
</blockquote>
<ul>
<li><code>&lt;context:component-scan&gt;</code>有一个use-default-filters属性，属性默认为true,表示会扫描指定包下的全部的标有@Component的类，并注册成bean.也就是@Component的子注解@Service,@Reposity等</li>
</ul>
<blockquote>
<p><code>&lt;context:annotation-config/&gt;</code> 提供了两个子标签</p>
</blockquote>
<ul>
<li><p><code>&lt;context:include-filter&gt;</code> 指定扫描的路径</p>
</li>
<li><p><code>&lt;context:exclude-filter&gt;</code> 排除扫描的路径</p>
</li>
<li><p>use-default-filters属性为false示例</p>
</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">context:component-scan</span> <span class="attr">base-package</span>=<span class="string">"com.tan"</span> <span class="attr">use-default-filters</span>=<span class="string">"false"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">context:include-filter</span> <span class="attr">type</span>=<span class="string">"regex"</span> <span class="attr">expression</span>=<span class="string">"com.tan.*"</span>/&gt;</span>//注意后面要写.*</span><br><span class="line"><span class="tag">&lt;/<span class="name">context:component-scan</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>use-default-filters属性为true示例</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">context:component-scan</span> <span class="attr">base-package</span>=<span class="string">"com.tan"</span> &gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">context:include-filter</span> <span class="attr">type</span>=<span class="string">"regex"</span> <span class="attr">expression</span>=<span class="string">".controller.*"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">context:include-filter</span> <span class="attr">type</span>=<span class="string">"regex"</span> <span class="attr">expression</span>=<span class="string">".service.*"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">context:include-filter</span> <span class="attr">type</span>=<span class="string">"regex"</span> <span class="attr">expression</span>=<span class="string">".dao.*"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">context:component-scan</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>相当于：</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">context:component-scan</span> <span class="attr">base-package</span>=<span class="string">"com.tan"</span> &gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">context:exclude-filter</span> <span class="attr">type</span>=<span class="string">"regex"</span> <span class="attr">expression</span>=<span class="string">".model.*"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">context:component-scan</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>无论哪种情况<code>&lt;context:include-filter&gt;</code>和<code>&lt;context:exclude-filter&gt;</code>都不能同时存在</li>
</ul>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p><a href="https://www.cnblogs.com/leskang/p/5445698.html" target="_blank" rel="noopener">博客园leskang</a>  </p>
<h3 id="SpringMVC中文文档"><a href="#SpringMVC中文文档" class="headerlink" title="SpringMVC中文文档"></a>SpringMVC中文文档</h3><p><a href="https://www.w3cschool.cn/spring_mvc_documentation_linesh_translation/" target="_blank" rel="noopener">国内W3CSchool</a><br><a href="https://linesh.gitbooks.io/spring-mvc-documentation-linesh-translation/content/" target="_blank" rel="noopener">国外GitBook</a></p>
]]></content>
      <categories>
        <category>后端开发</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux学习笔记</title>
    <url>/2017/04/16/2017-04-16-Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h3 id="linux系统目录"><a href="#linux系统目录" class="headerlink" title="linux系统目录"></a>linux系统目录</h3><ul>
<li>/boot 放置Linux内核以及其他用来启动树莓派的软件包</li>
<li>/bin 放置与Raspbian有关(包括运行图形界面所需的)的二进制可执行文件</li>
<li>/dev 这是虚拟文件夹之一，用来访问所有连接设备，包括存储卡</li>
<li>/etc 系统管理和配置文件</li>
<li>/home Linux上的我的文档，包含用户名命名的文件夹</li>
<li>/lib 各种应用需要的代码库</li>
<li>/lost+found 一般情况下是空的，当系统非法关机后，这里就存放了一些文件</li>
<li>/media 放置可移动存储驱动器，比如USB和CD</li>
<li>/mnt 用来手动挂在外部硬件驱动器或存储设备</li>
<li>/opt 可选软件文件夹，非系统部分的软件将会放置在这里</li>
<li>/sbin 放置超级用户使用的系统管理命令</li>
<li>/sys 放置操作系统文件</li>
<li>/tmp 放置临时文件</li>
<li>/usr 放置用户使用的程序</li>
<li>/var 虚拟文件，用于程序保存数据</li>
</ul>
<a id="more"></a>

<h3 id="更新源信息数据库"><a href="#更新源信息数据库" class="headerlink" title="更新源信息数据库"></a>更新源信息数据库</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure>
<h3 id="更新已安装的包"><a href="#更新已安装的包" class="headerlink" title="更新已安装的包"></a>更新已安装的包</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get upgrade</span><br></pre></td></tr></table></figure>
<h3 id="升级系统"><a href="#升级系统" class="headerlink" title="升级系统"></a>升级系统</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get dist-upgrade</span><br></pre></td></tr></table></figure>

<h3 id="开启root权限，su进入root"><a href="#开启root权限，su进入root" class="headerlink" title="开启root权限，su进入root"></a>开启root权限，su进入root</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo passwd root</span><br><span class="line">sudo passwd --unlock root</span><br><span class="line">su</span><br></pre></td></tr></table></figure>

<h3 id="显示系统日期时间"><a href="#显示系统日期时间" class="headerlink" title="显示系统日期时间"></a>显示系统日期时间</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">date</span><br></pre></td></tr></table></figure>

<h3 id="从最后一行开始显示"><a href="#从最后一行开始显示" class="headerlink" title="从最后一行开始显示"></a>从最后一行开始显示</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tac /proc/cgroups</span><br></pre></td></tr></table></figure>

<h3 id="显示的时候，顺道输出行号"><a href="#显示的时候，顺道输出行号" class="headerlink" title="显示的时候，顺道输出行号"></a>显示的时候，顺道输出行号</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nl /proc/cgroups</span><br></pre></td></tr></table></figure>

<h3 id="一页一页的显示文件内容"><a href="#一页一页的显示文件内容" class="headerlink" title="一页一页的显示文件内容"></a>一页一页的显示文件内容</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">more /proc/cgroups</span><br></pre></td></tr></table></figure>

<h3 id="一页一页的显示文件内容-可以往前翻页"><a href="#一页一页的显示文件内容-可以往前翻页" class="headerlink" title="一页一页的显示文件内容(可以往前翻页)"></a>一页一页的显示文件内容(可以往前翻页)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">less /proc/cgroups</span><br></pre></td></tr></table></figure>

<h3 id="只看头几行"><a href="#只看头几行" class="headerlink" title="只看头几行"></a>只看头几行</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">head -5 /proc/cgroups</span><br></pre></td></tr></table></figure>

<h3 id="只看尾巴几行"><a href="#只看尾巴几行" class="headerlink" title="只看尾巴几行"></a>只看尾巴几行</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tail -5 /proc/cgroups</span><br></pre></td></tr></table></figure>

<h3 id="删除一个空的目录"><a href="#删除一个空的目录" class="headerlink" title="删除一个空的目录"></a>删除一个空的目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rmdir name</span><br></pre></td></tr></table></figure>

<h3 id="编译c语言"><a href="#编译c语言" class="headerlink" title="编译c语言"></a>编译c语言</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">gcc test.c -o test</span><br><span class="line"><span class="meta">#</span><span class="bash"> arm 平台</span></span><br><span class="line">arm-linux-gcc test.c -o test</span><br><span class="line"><span class="meta">#</span><span class="bash"> 运行</span></span><br><span class="line">./test</span><br></pre></td></tr></table></figure>

<h3 id="赋予超级可执行权限"><a href="#赋予超级可执行权限" class="headerlink" title="赋予超级可执行权限"></a>赋予超级可执行权限</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chmod u+x test</span><br><span class="line">chmod 777 test</span><br></pre></td></tr></table></figure>

<h3 id="关机"><a href="#关机" class="headerlink" title="关机"></a>关机</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 可以定时</span></span><br><span class="line">sudo shutdown -h now</span><br><span class="line">sudo halt</span><br><span class="line">sudo poweroff</span><br><span class="line">sudo init 0</span><br></pre></td></tr></table></figure>

<h3 id="重启"><a href="#重启" class="headerlink" title="重启"></a>重启</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo reboot</span><br><span class="line">sudo init 6</span><br></pre></td></tr></table></figure>

<h3 id="软件包管理软件"><a href="#软件包管理软件" class="headerlink" title="软件包管理软件"></a>软件包管理软件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">apt --help</span><br><span class="line">dpkg --help</span><br><span class="line">yum --help</span><br></pre></td></tr></table></figure>

<h3 id="Wget"><a href="#Wget" class="headerlink" title="Wget"></a>Wget</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://www.python.org/ftp/python/3.4.3/Python-3.4.3.tgz</span><br></pre></td></tr></table></figure>

<h3 id="查看系统信息"><a href="#查看系统信息" class="headerlink" title="查看系统信息"></a>查看系统信息</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看操作系统版本</span></span><br><span class="line">cat /proc/version</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看主板版</span></span><br><span class="line">cat /proc/cpuinfo</span><br><span class="line">cat /proc/...</span><br></pre></td></tr></table></figure>

<h3 id="查看硬盘剩余空间"><a href="#查看硬盘剩余空间" class="headerlink" title="查看硬盘剩余空间"></a>查看硬盘剩余空间</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">df -h</span><br></pre></td></tr></table></figure>

<h3 id="搜索局域网中IP地址"><a href="#搜索局域网中IP地址" class="headerlink" title="搜索局域网中IP地址"></a>搜索局域网中IP地址</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">arp -a</span><br></pre></td></tr></table></figure>

<h3 id="查看挂载信息"><a href="#查看挂载信息" class="headerlink" title="查看挂载信息"></a>查看挂载信息</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo fdisk –l</span><br></pre></td></tr></table></figure>

<h3 id="执行shell脚本"><a href="#执行shell脚本" class="headerlink" title="执行shell脚本"></a>执行shell脚本</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./test.sh</span><br><span class="line">sh test.sh</span><br></pre></td></tr></table></figure>

<h3 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 解压一个zip格式压缩包</span></span><br><span class="line">unzip file1.zip </span><br><span class="line"><span class="meta">#</span><span class="bash"> 解压一个gzip格式的压缩包</span></span><br><span class="line">tar -xvfz archive.tar.gz</span><br></pre></td></tr></table></figure>

<h3 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建一个zip格式的压缩包</span></span><br><span class="line">zip file1.zip file1 </span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建一个gzip格式的压缩包</span></span><br><span class="line">tar -cvfz archive.tar.gz dir1</span><br></pre></td></tr></table></figure>

<h3 id="查看USB设备"><a href="#查看USB设备" class="headerlink" title="查看USB设备"></a>查看USB设备</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">lsusb</span><br></pre></td></tr></table></figure>

<h3 id="显示已载入系统的模块"><a href="#显示已载入系统的模块" class="headerlink" title="显示已载入系统的模块"></a>显示已载入系统的模块</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> lsmod 其实就是list modules的缩写</span></span><br><span class="line">lsmod</span><br></pre></td></tr></table></figure>

<h3 id="设置启动服务"><a href="#设置启动服务" class="headerlink" title="设置启动服务"></a>设置启动服务</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo insserv /etc/init.d/mysript</span><br></pre></td></tr></table></figure>

<h3 id="删除启动服务"><a href="#删除启动服务" class="headerlink" title="删除启动服务"></a>删除启动服务</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo insserv -r /etc/init.d/mysript</span><br></pre></td></tr></table></figure>

<h3 id="修改主机名"><a href="#修改主机名" class="headerlink" title="修改主机名"></a>修改主机名</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo hostname newname</span><br></pre></td></tr></table></figure>

<h3 id="增加用户"><a href="#增加用户" class="headerlink" title="增加用户"></a>增加用户</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo adduser username</span><br></pre></td></tr></table></figure>

<h3 id="删除用户"><a href="#删除用户" class="headerlink" title="删除用户"></a>删除用户</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo deluser username</span><br></pre></td></tr></table></figure>

<h3 id="查看系统运行情况"><a href="#查看系统运行情况" class="headerlink" title="查看系统运行情况"></a>查看系统运行情况</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">top</span><br></pre></td></tr></table></figure>

<h3 id="进程管理"><a href="#进程管理" class="headerlink" title="进程管理"></a>进程管理</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ps -aux</span><br><span class="line"><span class="meta">#</span><span class="bash"> 或者</span></span><br><span class="line">ps -ef | less</span><br></pre></td></tr></table></figure>
<blockquote>
<p>静态显示系统正在运行的进程</p>
<ul>
<li>ps -aux</li>
<li><ul>
<li>参数</li>
</ul>
</li>
<li><ul>
<li>-a：显示终端上的所有进程，包括造作系统动态执行的基本单元</li>
</ul>
</li>
<li><ul>
<li>-u：显示进程的详细状态</li>
</ul>
</li>
<li><ul>
<li>-x：显示没有控制的终端的进程</li>
</ul>
</li>
<li><ul>
<li>-w：显示加宽，以便显示等多信息</li>
</ul>
</li>
<li><ul>
<li>-r：只显示正在进行的进程<br>动态显示系统进程：top</li>
</ul>
</li>
<li>top</li>
<li><ul>
<li>参数</li>
</ul>
</li>
<li><ul>
<li>M：根据内存使用量来排序</li>
</ul>
</li>
<li><ul>
<li>P：根据CPU占有率来排序</li>
</ul>
</li>
<li><ul>
<li>T：根据进程运行时间长短来排序</li>
</ul>
</li>
<li><ul>
<li>U：可以根据后面输入的用户名来筛选进程</li>
</ul>
</li>
<li><ul>
<li>K：可以根据后面输入的PID来杀死进程</li>
</ul>
</li>
<li><ul>
<li>q：退出</li>
</ul>
</li>
<li><ul>
<li>h：获取帮助</li>
</ul>
</li>
<li><ul>
<li><ul>
<li>查看进程树：pstree [选项]  [PID或用户名]</li>
</ul>
</li>
</ul>
</li>
<li><ul>
<li><ul>
<li>查看后台任务列表： jobs -l</li>
</ul>
</li>
</ul>
</li>
<li><ul>
<li><ul>
<li>将后台任务恢复到前台运行： fg</li>
</ul>
</li>
</ul>
</li>
<li><ul>
<li><ul>
<li>激活后台被挂起的任务： bg</li>
</ul>
</li>
</ul>
</li>
<li><ul>
<li><ul>
<li>挂起当前进程：Ctrl+z 组合键</li>
</ul>
</li>
</ul>
</li>
<li><ul>
<li><ul>
<li>中断正在执行的命令程序：Ctrl+c组合键</li>
</ul>
</li>
</ul>
</li>
<li><ul>
<li><ul>
<li>杀死置顶PID的进程： kill 13613</li>
</ul>
</li>
</ul>
</li>
<li><ul>
<li><ul>
<li>显示同名的进程：pgrep -l vim</li>
</ul>
</li>
</ul>
</li>
<li><ul>
<li><ul>
<li>杀死多个同名进程： killall -9 vim</li>
</ul>
</li>
</ul>
</li>
<li><ul>
<li><ul>
<li>杀死符合条件的进程： pgrep -l -U google</li>
</ul>
</li>
</ul>
</li>
<li><ul>
<li><ul>
<li>强制提出用户： pkill -9 -U google</li>
</ul>
</li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="查看内存分配情况"><a href="#查看内存分配情况" class="headerlink" title="查看内存分配情况"></a>查看内存分配情况</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">free -m (-k, -g)</span><br></pre></td></tr></table></figure>

<h3 id="当前目录下的磁盘使用信息"><a href="#当前目录下的磁盘使用信息" class="headerlink" title="当前目录下的磁盘使用信息"></a>当前目录下的磁盘使用信息</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo du -sh</span><br></pre></td></tr></table></figure>

<h3 id="对进程做出一定的操作"><a href="#对进程做出一定的操作" class="headerlink" title="对进程做出一定的操作"></a>对进程做出一定的操作</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kill -&lt;signal&gt; &lt;PID&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li>signal 1 (SIGHUP): hang-up的缩写，该信号通知应用程序重新启动</li>
<li>signal 3 （SIGQUIT）：该信号通知应用程序清理自身资源并退出</li>
<li>signal 6 （SIGABRT）：该信号通知应用程序终止并立即退出</li>
<li>signal 9  （SIGKILL）：该信号立即终止应用程序</li>
<li>PID ：应用程序的进程号，可以通过ps 查看</li>
</ul>
<h3 id="文件管理"><a href="#文件管理" class="headerlink" title="文件管理"></a>文件管理</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 显示当前的绝对路径</span></span><br><span class="line">pwd</span><br><span class="line"><span class="meta">#</span><span class="bash"> 切换路径</span></span><br><span class="line">cd </span><br><span class="line"><span class="meta">#</span><span class="bash"> 新建文件夹</span></span><br><span class="line">mkdir</span><br><span class="line"><span class="meta">#</span><span class="bash"> 新建文件</span></span><br><span class="line">touch</span><br></pre></td></tr></table></figure>

<blockquote>
<p>cd</p>
<ul>
<li>cd .. :切换到上级目录</li>
<li>cd ~ :切换到/home/pi</li>
<li>cd / :切换到更目录</li>
<li><ul>
<li>-L ：表示启动符号连接跟踪，默认情况下是不会启动的。</li>
</ul>
</li>
<li><ul>
<li>-maxdepth<number>: 该选项指定find命令最大的目录查看深度，如果为1的话表示当前目录文件和一级子目录文件。</number></li>
</ul>
</li>
<li><ul>
<li>-newer<file>:表示只查找指定文件的修改时间更新的文件</file></li>
</ul>
</li>
<li><ul>
<li>-empty：表示只查找空文件</li>
</ul>
</li>
<li><ul>
<li>-atime<number> ：表示只查找距离上次访问指定天数之后的文件</number></li>
</ul>
</li>
<li><ul>
<li>-name<filename>:表示搜索完全匹配指定文件名的文件</filename></li>
</ul>
</li>
<li><ul>
<li>-exec<command>:指示find命令为每个匹配的文件路径执行指定的命令。</li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="查找文件"><a href="#查找文件" class="headerlink" title="查找文件"></a>查找文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find</span><br><span class="line"><span class="meta">#</span><span class="bash"> 该命令会搜索/mnt/volumer 中的所有名称匹配foobar的空文件，并执行rm命令将其删去</span></span><br><span class="line">find /mnt/volumer -empty -name foobar -exec rm</span><br><span class="line"><span class="meta">#</span><span class="bash"> 按文件名查找文件</span></span><br><span class="line">ind ./ -name test.py</span><br><span class="line"><span class="meta">#</span><span class="bash"> 按文件大小查找文件</span></span><br><span class="line">find ./ -size +2M</span><br></pre></td></tr></table></figure>

<h3 id="通过读取filename文件"><a href="#通过读取filename文件" class="headerlink" title="通过读取filename文件"></a>通过读取filename文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">file &lt;filename&gt;</span><br></pre></td></tr></table></figure>

<h3 id="grep"><a href="#grep" class="headerlink" title="grep"></a>grep</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">grep &lt;pattern&gt; &lt;file&gt;</span><br><span class="line"><span class="meta">#</span><span class="bash"> &gt; 定向符号(以把一个命令的输出结果重定向到一个文件)</span></span><br><span class="line">top &gt; Desktop/file_top.txt</span><br><span class="line"><span class="meta">#</span><span class="bash"> &gt;&gt; 重定向符号(在一个文件里追加内容)</span></span><br><span class="line">ls -alh &gt;&gt; Desktop/file_top.txt</span><br><span class="line"><span class="meta">#</span><span class="bash"> 筛选内容</span></span><br><span class="line">tail -f /linux.log | grep 'error'</span><br><span class="line"><span class="meta">#</span><span class="bash"> 搜索文件中的内容(头部：^ 结尾：$)</span></span><br><span class="line">grep -n 'abcd' test.py</span><br></pre></td></tr></table></figure>
<h3 id="查看历史命令"><a href="#查看历史命令" class="headerlink" title="查看历史命令"></a>查看历史命令</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">history</span><br></pre></td></tr></table></figure>

<h3 id="管道命令"><a href="#管道命令" class="headerlink" title="管道命令"></a>管道命令</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 管道命令允许你把一个命令的输出结果转移给另一个命令</span></span><br><span class="line">ls /home/pi | grep duer_linux.log</span><br></pre></td></tr></table></figure>

<h3 id="声卡"><a href="#声卡" class="headerlink" title="声卡"></a>声卡</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看声卡</span></span><br><span class="line">arecord -l</span><br><span class="line"><span class="meta">#</span><span class="bash"> 录音</span></span><br><span class="line">arecord -Dhw:1,0 -c 2 -r 16000 -f S16_LE test.wav</span><br><span class="line">arecord -D "plughw:0,0" -f S16_LE -r 16000 -d 5 -t wav file.wav</span><br></pre></td></tr></table></figure>

<h3 id="软链接"><a href="#软链接" class="headerlink" title="软链接"></a>软链接</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建文件的软链接（win中的快捷方式）</span></span><br><span class="line">ln -s test.py test_link.py</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建文件的硬链接(创建文件的不同文件名：内存中记录指向该数据的文件名的个数，为0时是彻底删除)</span></span><br><span class="line">ln test.py test_link.py</span><br></pre></td></tr></table></figure>

<h3 id="合并两个文件"><a href="#合并两个文件" class="headerlink" title="合并两个文件"></a>合并两个文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat test_1.py test_2.py &gt; test_3.py</span><br></pre></td></tr></table></figure>

<h3 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tree .</span><br></pre></td></tr></table></figure>

<blockquote>
<p>文件打包管理：tar</p>
<ul>
<li>-c ：生成压缩包文件，创建打包文件</li>
<li>-v ：列出压缩解压的详细过程，显示进度</li>
<li>-f ：指出压缩文件名称，f后面一定是.tar文件，所以必须放选项最后（必须在参数的最后）</li>
<li>-t ：列出压缩中包含的文件</li>
<li>-x ：解开压缩文件</li>
<li>-C ：指定解压路径（大写字母C）</li>
<li>-z ：表示是tar.gz格式</li>
</ul>
</blockquote>
<h3 id="解压缩"><a href="#解压缩" class="headerlink" title="解压缩"></a>解压缩</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 打包成tar文件（未压缩）</span></span><br><span class="line">tar -cvf testTar.tar ./*</span><br><span class="line"><span class="meta">#</span><span class="bash"> 解压tar文件</span></span><br><span class="line">tar -xvf testTar.tar</span><br><span class="line"><span class="meta">#</span><span class="bash"> 将已经打包的文件压缩成tar.gz文件：gzip</span></span><br><span class="line">gzip -r testTar.tar</span><br><span class="line"><span class="meta">#</span><span class="bash"> 将tar.gz压缩包文件解压成tar打包文件</span></span><br><span class="line">gzip -d testTar.tar.gz</span><br><span class="line"><span class="meta">#</span><span class="bash"> 直接压缩成tar.gz压缩包：</span></span><br><span class="line">tar -zcvf teatTar.tar.gz ./*</span><br><span class="line"><span class="meta">#</span><span class="bash"> 直接解压tar.gz压缩包</span></span><br><span class="line">tar -zxvf tearTar.tar.gz</span><br><span class="line"><span class="meta">#</span><span class="bash"> 解压到指定路径</span></span><br><span class="line">tar -zxvf testTar.tar.gz -C /home/pi/test</span><br><span class="line"><span class="meta">#</span><span class="bash"> 直接压缩成tar.bz2压缩包：</span></span><br><span class="line">tar -jcvf testTar.tar.bz2 ./*</span><br><span class="line"><span class="meta">#</span><span class="bash"> 直接解压tar.bz2压缩包</span></span><br><span class="line">tar -jxvf tesrTar.tar.bz2</span><br><span class="line"><span class="meta">#</span><span class="bash"> 压缩成zip</span></span><br><span class="line">zip -r testZip.zip ./*</span><br><span class="line"><span class="meta">#</span><span class="bash"> 解压zip</span></span><br><span class="line">unzip -d /home/pi/test testZip.zip</span><br></pre></td></tr></table></figure>

<h3 id="查看位置"><a href="#查看位置" class="headerlink" title="查看位置"></a>查看位置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">which java</span><br><span class="line"><span class="meta">#</span><span class="bash"> 或者</span></span><br><span class="line">whereis java</span><br></pre></td></tr></table></figure>

<h3 id="退出超级管理员"><a href="#退出超级管理员" class="headerlink" title="退出超级管理员"></a>退出超级管理员</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">exit</span><br></pre></td></tr></table></figure>

<h3 id="查看Linux系统操作位"><a href="#查看Linux系统操作位" class="headerlink" title="查看Linux系统操作位"></a>查看Linux系统操作位</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">getconf LONG_BIT</span><br><span class="line"><span class="meta">#</span><span class="bash"> 包括系统内核</span></span><br><span class="line">uname -a</span><br></pre></td></tr></table></figure>

<h3 id="查看端口占用"><a href="#查看端口占用" class="headerlink" title="查看端口占用"></a>查看端口占用</h3><p><code>id</code>是指端口号或进程ID  </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">netstat -anp | grep id</span><br></pre></td></tr></table></figure>

<h3 id="查看进程信息"><a href="#查看进程信息" class="headerlink" title="查看进程信息"></a>查看进程信息</h3><p><code>id/name</code>:值进程ID或进程名称  </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ps aux | grep id/name</span><br></pre></td></tr></table></figure>

<p>或者  </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ll /proc/id</span><br></pre></td></tr></table></figure>

<h3 id="远程复制本地-20190112"><a href="#远程复制本地-20190112" class="headerlink" title="远程复制本地^20190112"></a>远程复制本地<a href="20190112更新">^20190112</a></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp -rp www.yibuwulianwang.com:/usr/local/java/jdk1.8.0_151/ ./</span><br></pre></td></tr></table></figure>

<h3 id="本地复制到远程"><a href="#本地复制到远程" class="headerlink" title="本地复制到远程"></a>本地复制到远程</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">apt install sshpass</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sshpass -p "password" scp -rp ./target/ybwlw.war root@47.106.91.50:/usr/local/src/tomcat/tomcat-1/webapps/</span><br></pre></td></tr></table></figure>

<h3 id="检查和控制内核的环形缓冲区-20190409"><a href="#检查和控制内核的环形缓冲区-20190409" class="headerlink" title="检查和控制内核的环形缓冲区^20190409"></a>检查和控制内核的环形缓冲区<a href="20190409更新">^20190409</a></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">dmesg | grep pid/name</span><br></pre></td></tr></table></figure>

<h3 id="Linux命令大全"><a href="#Linux命令大全" class="headerlink" title="Linux命令大全"></a>Linux命令大全</h3><p><a href="http://man.linuxde.net/" target="_blank" rel="noopener">Linux命令大全</a>  </p>
]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
</search>
